ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 15.3 Logs CentralisÃ©s (ELK/EFK Stack)

## Introduction aux Logs CentralisÃ©s

### Le ProblÃ¨me des Logs DistribuÃ©s

Dans un cluster Kubernetes comme MicroK8s, vous avez potentiellement :
- Plusieurs pods rÃ©partis sur diffÃ©rents nÅ“uds
- Des pods qui redÃ©marrent et perdent leurs logs
- Des applications qui Ã©crivent dans diffÃ©rents formats
- Des logs Ã©parpillÃ©s difficiles Ã  corrÃ©ler

**Exemple du problÃ¨me** :
```
Utilisateur : "Mon achat a Ã©chouÃ© Ã  14h32"
Vous : "Voyons voir..."
  â†’ Logs du pod frontend : âŒ Pod redÃ©marrÃ©, logs perdus
  â†’ Logs du pod backend : âœ… "Error: payment timeout"
  â†’ Logs du pod database : âœ… "Slow query: 3.2s"
  â†’ Logs du pod payment : âŒ Pod sur un autre nÅ“ud

Comment tout relier ? ğŸ¤”
```

### La Solution : Centralisation des Logs

L'idÃ©e est simple : **collecter tous les logs au mÃªme endroit**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pod 1   â”‚  â”‚  Pod 2   â”‚  â”‚  Pod 3   â”‚
â”‚  logs    â”‚  â”‚  logs    â”‚  â”‚  logs    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚             â”‚             â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Collecteur  â”‚
           â”‚  (Fluentd)   â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Elasticsearchâ”‚ â† Stockage centralisÃ©
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Kibana     â”‚ â† Interface de recherche
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avantages** :
- âœ… Tous les logs accessibles depuis un seul endroit
- âœ… Logs prÃ©servÃ©s mÃªme si les pods redÃ©marrent
- âœ… Recherche puissante sur tous les logs
- âœ… CorrÃ©lation facile entre services
- âœ… RÃ©tention configurable (garder les logs X jours)
- âœ… Visualisation et dashboards

## ELK vs EFK : Deux Stacks Similaires

Il existe deux stacks principales pour la centralisation des logs. Elles sont trÃ¨s similaires et utilisent les mÃªmes principes.

### Stack ELK

**ELK** = **E**lasticsearch + **L**ogstash + **K**ibana

```
Logs â†’ Logstash â†’ Elasticsearch â†’ Kibana
```

**Composants** :
- **Elasticsearch** : Base de donnÃ©es pour stocker et indexer les logs
- **Logstash** : Collecteur et transformateur de logs (Ã©crit en Ruby/JRuby)
- **Kibana** : Interface web pour visualiser et rechercher dans les logs

### Stack EFK

**EFK** = **E**lasticsearch + **F**luentd + **K**ibana

```
Logs â†’ Fluentd â†’ Elasticsearch â†’ Kibana
```

**Composants** :
- **Elasticsearch** : Base de donnÃ©es (identique Ã  ELK)
- **Fluentd** : Collecteur et transformateur de logs (Ã©crit en Ruby/C)
- **Kibana** : Interface web (identique Ã  ELK)

### Comparaison ELK vs EFK

| Aspect | Logstash (ELK) | Fluentd (EFK) |
|--------|---------------|---------------|
| **Langage** | Ruby/JRuby | Ruby + C |
| **MÃ©moire** | ~200-500 MB | ~40-80 MB |
| **Performance** | Bon | Excellent |
| **Plugins** | ~200+ | ~500+ |
| **Configuration** | DSL complexe | YAML simple |
| **Docker/K8s** | Bon support | Natif, mieux intÃ©grÃ© |
| **PopularitÃ©** | TrÃ¨s populaire | Standard dans K8s |

### Quelle Stack Choisir ?

**Pour MicroK8s, nous recommandons EFK** pour ces raisons :
- âœ… Plus lÃ©ger en mÃ©moire (important pour un lab)
- âœ… Configuration plus simple
- âœ… Mieux intÃ©grÃ© dans l'Ã©cosystÃ¨me Kubernetes
- âœ… Standard de facto dans Kubernetes
- âœ… DaemonSet natif pour collecter sur tous les nÅ“uds

**Mais** : Les concepts sont identiques, si vous connaissez l'un, vous connaissez l'autre.

## Architecture de la Stack EFK

### Vue d'Ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Cluster MicroK8s                       â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Pod 1  â”‚  â”‚ Pod 2  â”‚  â”‚ Pod 3  â”‚  â”‚ Pod N  â”‚         â”‚
â”‚  â”‚ stdout â”‚  â”‚ stdout â”‚  â”‚ stdout â”‚  â”‚ stdout â”‚         â”‚
â”‚  â”‚ stderr â”‚  â”‚ stderr â”‚  â”‚ stderr â”‚  â”‚ stderr â”‚         â”‚
â”‚  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â”‚
â”‚      â”‚           â”‚           â”‚           â”‚              â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                  â†“                                      â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚        â”‚   Docker/containerd  â”‚                         â”‚
â”‚        â”‚   (stocke logs)      â”‚                         â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                  â†“                                      â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚        â”‚  Fluentd DaemonSet   â”‚ â† Un pod par nÅ“ud       â”‚
â”‚        â”‚  (lit les logs)      â”‚                         â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Elasticsearch     â”‚ â† Stockage et indexation
         â”‚   StatefulSet       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      Kibana         â”‚ â† Interface utilisateur
         â”‚      Deployment     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de DonnÃ©es

1. **Application** Ã©crit des logs sur `stdout/stderr`
2. **Container runtime** (Docker/containerd) capture et stocke dans des fichiers
3. **Fluentd** (DaemonSet) lit ces fichiers de logs
4. **Fluentd** transforme et enrichit les logs (ajout namespace, pod, labels)
5. **Fluentd** envoie vers **Elasticsearch**
6. **Elasticsearch** indexe et stocke les logs
7. **Kibana** permet de rechercher et visualiser

### Pourquoi un DaemonSet pour Fluentd ?

Un **DaemonSet** garantit qu'un pod Fluentd tourne sur **chaque nÅ“ud** du cluster :
```
NÅ“ud 1                      NÅ“ud 2                    NÅ“ud 3
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  App Pods   â”‚            â”‚  App Pods   â”‚          â”‚  App Pods   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Fluentd Pod â”‚ â† Lit      â”‚ Fluentd Pod â”‚â† Lit     â”‚ Fluentd Pod â”‚â† Lit
â”‚  (DaemonSet)â”‚   logs     â”‚  (DaemonSet)â”‚  logs    â”‚  (DaemonSet)â”‚  logs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                          â”‚                        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
                          Elasticsearch
```

Chaque Fluentd collecte les logs des pods sur son nÅ“ud.

## Les Composants en DÃ©tail

### 1. Elasticsearch - Le Stockage

#### Qu'est-ce que c'est ?

Elasticsearch est une **base de donnÃ©es de recherche** distribuÃ©e et scalable, optimisÃ©e pour :
- Stocker de grandes quantitÃ©s de donnÃ©es textuelles
- Indexer rapidement pour des recherches ultra-rapides
- Recherches full-text avec scoring de pertinence

#### Concepts ClÃ©s

**Index** : Un conteneur logique pour vos donnÃ©es (comme une table SQL)
```
Index "logs-2025.10.25" contient tous les logs du 25 octobre 2025
Index "logs-2025.10.24" contient tous les logs du 24 octobre 2025
```

**Document** : Une entrÃ©e de log individuelle (comme une ligne SQL)
```json
{
  "timestamp": "2025-10-25T14:32:15Z",
  "level": "ERROR",
  "message": "Payment failed: timeout",
  "kubernetes": {
    "namespace": "production",
    "pod": "payment-service-abc123",
    "container": "payment"
  }
}
```

**Mapping** : Le schÃ©ma des champs (types de donnÃ©es)
```json
{
  "timestamp": "date",
  "level": "keyword",
  "message": "text",
  "kubernetes.namespace": "keyword"
}
```

#### CaractÃ©ristiques

- **Quasi temps-rÃ©el** : Les logs sont recherchables en ~1 seconde
- **DistribuÃ©** : Peut s'Ã©tendre sur plusieurs nÅ“uds
- **RESTful** : API HTTP pour tout
- **Gourmand en ressources** : NÃ©cessite mÃ©moire et CPU
- **Gestion des index** : Rotation automatique par jour/semaine

### 2. Fluentd - Le Collecteur

#### Qu'est-ce que c'est ?

Fluentd est un **collecteur de logs unifiÃ©** qui :
- Lit les logs depuis diverses sources
- Les transforme et les enrichit
- Les envoie vers diverses destinations

#### Architecture de Fluentd

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Fluentd                 â”‚
â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚       INPUT plugins        â”‚    â”‚
â”‚  â”‚  - tail (fichiers)         â”‚    â”‚
â”‚  â”‚  - forward (rÃ©seau)        â”‚    â”‚
â”‚  â”‚  - http (API)              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â†“                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      FILTER plugins        â”‚    â”‚
â”‚  â”‚  - parser (JSON, regex)    â”‚    â”‚
â”‚  â”‚  - record_transformer      â”‚    â”‚
â”‚  â”‚  - kubernetes_metadata     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â†“                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      OUTPUT plugins        â”‚    â”‚
â”‚  â”‚  - elasticsearch           â”‚    â”‚
â”‚  â”‚  - file                    â”‚    â”‚
â”‚  â”‚  - s3, kafka, etc.         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Plugin Kubernetes Metadata

C'est le plugin **star** pour Kubernetes. Il enrichit chaque log avec des mÃ©tadonnÃ©es :

**Log brut du container** :
```
2025-10-25 14:32:15 ERROR Payment failed
```

**AprÃ¨s enrichissement Fluentd** :
```json
{
  "log": "2025-10-25 14:32:15 ERROR Payment failed",
  "stream": "stderr",
  "time": "2025-10-25T14:32:15Z",
  "kubernetes": {
    "namespace_name": "production",
    "pod_name": "payment-service-7d8c9-x4b2k",
    "container_name": "payment",
    "labels": {
      "app": "payment-service",
      "version": "v1.2.3"
    }
  }
}
```

Maintenant vous pouvez filtrer par namespace, pod, labels, etc. !

#### Configuration Fluentd

Exemple de configuration (format YAML simplifiÃ©) :

```xml
<source>
  @type tail
  path /var/log/containers/*.log
  pos_file /var/log/fluentd-containers.log.pos
  tag kubernetes.*
  read_from_head true
  <parse>
    @type json
    time_format %Y-%m-%dT%H:%M:%S.%NZ
  </parse>
</source>

<filter kubernetes.**>
  @type kubernetes_metadata
  @id filter_kube_metadata
</filter>

<match **>
  @type elasticsearch
  host elasticsearch.logging.svc.cluster.local
  port 9200
  logstash_format true
  logstash_prefix logs
  <buffer>
    @type file
    path /var/log/fluentd-buffers/kubernetes.system.buffer
    flush_mode interval
    flush_interval 5s
  </buffer>
</match>
```

**Explication** :
- `<source>` : Lit les logs des containers dans `/var/log/containers/`
- `<filter>` : Enrichit avec les mÃ©tadonnÃ©es Kubernetes
- `<match>` : Envoie vers Elasticsearch avec format Logstash

### 3. Kibana - L'Interface de Visualisation

#### Qu'est-ce que c'est ?

Kibana est l'**interface web** pour Elasticsearch. C'est votre outil principal pour :
- Rechercher dans les logs
- CrÃ©er des dashboards
- Analyser les patterns
- Configurer des alertes

#### FonctionnalitÃ©s Principales

**Discover** : Recherche et exploration des logs
- Interface de recherche principale
- Filtres et requÃªtes
- Analyse des champs

**Dashboard** : Tableaux de bord personnalisÃ©s
- Graphiques de volumes de logs
- Top erreurs
- Timeline des Ã©vÃ©nements

**Visualize** : CrÃ©ation de visualisations
- Graphiques, tableaux, cartes
- AgrÃ©gations de donnÃ©es

**Dev Tools** : Console pour requÃªtes directes
- RequÃªtes Elasticsearch brutes
- DÃ©bogage

## DÃ©ploiement dans MicroK8s

### PrÃ©requis

Avant de dÃ©ployer la stack EFK :

```bash
# VÃ©rifier les ressources disponibles
microk8s kubectl top nodes

# Recommandations minimales :
# - CPU : 2 cores disponibles
# - RAM : 4 GB disponibles
# - Stockage : 20 GB disponibles
```

### CrÃ©er le Namespace

```bash
microk8s kubectl create namespace logging
```

### Architecture de DÃ©ploiement

Nous allons dÃ©ployer :
1. **Elasticsearch** : StatefulSet avec PersistentVolume (pour garder les logs)
2. **Fluentd** : DaemonSet (un pod par nÅ“ud)
3. **Kibana** : Deployment (interface web)

### 1. DÃ©ployer Elasticsearch

#### ConfigMap pour la Configuration

Fichier `elasticsearch-config.yaml` :

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: elasticsearch-config
  namespace: logging
data:
  elasticsearch.yml: |
    cluster.name: "k8s-logs"
    network.host: 0.0.0.0
    discovery.type: single-node
    xpack.security.enabled: false
    # Pour un lab, dÃ©sactivation de la sÃ©curitÃ©
    # En production, TOUJOURS activer xpack.security !
```

#### Service Elasticsearch

Fichier `elasticsearch-service.yaml` :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  namespace: logging
  labels:
    app: elasticsearch
spec:
  selector:
    app: elasticsearch
  ports:
  - name: http
    port: 9200
    targetPort: 9200
  - name: transport
    port: 9300
    targetPort: 9300
  type: ClusterIP
```

#### StatefulSet Elasticsearch

Fichier `elasticsearch-statefulset.yaml` :

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: logging
spec:
  serviceName: elasticsearch
  replicas: 1
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        ports:
        - containerPort: 9200
          name: http
        - containerPort: 9300
          name: transport
        env:
        - name: discovery.type
          value: "single-node"
        - name: ES_JAVA_OPTS
          value: "-Xms1g -Xmx1g"
        - name: xpack.security.enabled
          value: "false"
        volumeMounts:
        - name: elasticsearch-data
          mountPath: /usr/share/elasticsearch/data
  volumeClaimTemplates:
  - metadata:
      name: elasticsearch-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 10Gi
```

**Points importants** :
- **StatefulSet** : Pour persistance et identitÃ© stable
- **PVC** : Volume persistant de 10GB pour les logs
- **Memory** : 2GB allouÃ©s (1GB heap Java)
- **Single-node** : SimplifiÃ© pour un lab

#### DÃ©ployer Elasticsearch

```bash
microk8s kubectl apply -f elasticsearch-config.yaml
microk8s kubectl apply -f elasticsearch-service.yaml
microk8s kubectl apply -f elasticsearch-statefulset.yaml

# Attendre que le pod soit prÃªt (peut prendre 2-3 minutes)
microk8s kubectl wait --for=condition=ready pod -l app=elasticsearch -n logging --timeout=300s

# VÃ©rifier
microk8s kubectl get pods -n logging
microk8s kubectl logs elasticsearch-0 -n logging
```

#### Tester Elasticsearch

```bash
# Port-forward pour tester localement
microk8s kubectl port-forward svc/elasticsearch 9200:9200 -n logging

# Dans un autre terminal
curl http://localhost:9200
# Devrait retourner des infos sur le cluster

curl http://localhost:9200/_cluster/health?pretty
# Devrait montrer "status": "green" ou "yellow"
```

### 2. DÃ©ployer Fluentd

#### ConfigMap Fluentd

Fichier `fluentd-config.yaml` :

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: logging
data:
  fluent.conf: |
    # Lecture des logs des containers
    <source>
      @type tail
      @id in_tail_container_logs
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      read_from_head true
      <parse>
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

    # Enrichissement avec mÃ©tadonnÃ©es Kubernetes
    <filter kubernetes.**>
      @type kubernetes_metadata
      @id filter_kube_metadata
      kubernetes_url "#{ENV['FLUENT_FILTER_KUBERNETES_URL'] || 'https://' + ENV.fetch('KUBERNETES_SERVICE_HOST') + ':' + ENV.fetch('KUBERNETES_SERVICE_PORT') + '/api'}"
      verify_ssl "#{ENV['KUBERNETES_VERIFY_SSL'] || true}"
      ca_file "#{ENV['KUBERNETES_CA_FILE']}"
    </filter>

    # Parser pour extraire les niveaux de log
    <filter kubernetes.**>
      @type parser
      key_name log
      reserve_data true
      remove_key_name_field true
      <parse>
        @type regexp
        expression /^(?<time>[^ ]+) (?<level>[^ ]+) (?<message>.*)$/
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </filter>

    # Exclusion des logs de la stack logging elle-mÃªme (Ã©viter boucle)
    <filter kubernetes.**>
      @type grep
      <exclude>
        key $.kubernetes.namespace_name
        pattern /^(logging|kube-system)$/
      </exclude>
    </filter>

    # Envoi vers Elasticsearch
    <match **>
      @type elasticsearch
      @id out_es
      @log_level info
      include_tag_key true
      host elasticsearch.logging.svc.cluster.local
      port 9200
      scheme http
      logstash_format true
      logstash_prefix logs
      logstash_dateformat %Y.%m.%d
      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes.system.buffer
        flush_mode interval
        retry_type exponential_backoff
        flush_interval 5s
        retry_forever false
        retry_max_interval 30
        chunk_limit_size 2M
        queue_limit_length 8
        overflow_action block
      </buffer>
    </match>
```

#### ServiceAccount et RBAC pour Fluentd

Fichier `fluentd-rbac.yaml` :

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  namespace: logging
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluentd
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - namespaces
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: fluentd
roleRef:
  kind: ClusterRole
  name: fluentd
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: fluentd
  namespace: logging
```

**Pourquoi ces permissions ?**
Fluentd a besoin de lire les mÃ©tadonnÃ©es des pods et namespaces pour enrichir les logs.

#### DaemonSet Fluentd

Fichier `fluentd-daemonset.yaml` :

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: logging
  labels:
    app: fluentd
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      serviceAccountName: fluentd
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.logging.svc.cluster.local"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        - name: FLUENT_ELASTICSEARCH_SCHEME
          value: "http"
        - name: FLUENTD_SYSTEMD_CONF
          value: disable
        resources:
          requests:
            memory: "200Mi"
            cpu: "100m"
          limits:
            memory: "500Mi"
            cpu: "500m"
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: fluentd-config
          mountPath: /fluentd/etc/fluent.conf
          subPath: fluent.conf
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: fluentd-config
        configMap:
          name: fluentd-config
```

**Points importants** :
- **DaemonSet** : Un pod sur chaque nÅ“ud
- **Volumes hostPath** : AccÃ¨s aux logs sur le nÅ“ud hÃ´te
- **ServiceAccount** : Permissions pour lire mÃ©tadonnÃ©es K8s

#### DÃ©ployer Fluentd

```bash
microk8s kubectl apply -f fluentd-config.yaml
microk8s kubectl apply -f fluentd-rbac.yaml
microk8s kubectl apply -f fluentd-daemonset.yaml

# VÃ©rifier (un pod par nÅ“ud)
microk8s kubectl get daemonset -n logging
microk8s kubectl get pods -n logging -l app=fluentd

# Voir les logs Fluentd
microk8s kubectl logs -n logging -l app=fluentd --tail=50
```

### 3. DÃ©ployer Kibana

#### Service Kibana

Fichier `kibana-service.yaml` :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: kibana
  namespace: logging
  labels:
    app: kibana
spec:
  selector:
    app: kibana
  ports:
  - port: 5601
    targetPort: 5601
    name: http
  type: ClusterIP
```

#### Deployment Kibana

Fichier `kibana-deployment.yaml` :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: logging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:8.11.0
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        env:
        - name: ELASTICSEARCH_HOSTS
          value: "http://elasticsearch.logging.svc.cluster.local:9200"
        - name: SERVER_NAME
          value: "kibana"
        - name: SERVER_HOST
          value: "0.0.0.0"
        ports:
        - containerPort: 5601
          name: http
        readinessProbe:
          httpGet:
            path: /api/status
            port: 5601
          initialDelaySeconds: 60
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /api/status
            port: 5601
          initialDelaySeconds: 120
          periodSeconds: 30
```

#### DÃ©ployer Kibana

```bash
microk8s kubectl apply -f kibana-service.yaml
microk8s kubectl apply -f kibana-deployment.yaml

# Attendre que Kibana soit prÃªt (peut prendre 2-3 minutes)
microk8s kubectl wait --for=condition=ready pod -l app=kibana -n logging --timeout=300s

# VÃ©rifier
microk8s kubectl get pods -n logging -l app=kibana
microk8s kubectl logs -n logging -l app=kibana
```

#### AccÃ©der Ã  Kibana

**Option 1 : Port-forward (temporaire)**
```bash
microk8s kubectl port-forward -n logging svc/kibana 5601:5601

# AccÃ©dez Ã  http://localhost:5601
```

**Option 2 : Ingress (permanent)**

Fichier `kibana-ingress.yaml` :

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: kibana
  namespace: logging
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: kibana.votre-domaine.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: kibana
            port:
              number: 5601
```

```bash
microk8s kubectl apply -f kibana-ingress.yaml

# Ajoutez dans /etc/hosts :
# 192.168.1.100  kibana.votre-domaine.local

# AccÃ©dez Ã  http://kibana.votre-domaine.local
```

### VÃ©rification de la Stack ComplÃ¨te

```bash
# VÃ©rifier tous les composants
microk8s kubectl get all -n logging

# Devrait afficher :
# - elasticsearch-0 (StatefulSet)
# - fluentd-xxxxx (DaemonSet, un par nÅ“ud)
# - kibana-xxxxx (Deployment)
```

## Utiliser Kibana pour Explorer les Logs

### PremiÃ¨re Connexion

1. Ouvrez Kibana dans votre navigateur
2. PremiÃ¨re page : Configuration de l'index pattern

### CrÃ©er un Index Pattern

Un **index pattern** dÃ©finit quels index Elasticsearch vous voulez explorer.

**Ã‰tapes** :
1. Dans le menu, allez Ã  **Stack Management** â†’ **Index Patterns**
2. Cliquez sur **Create index pattern**
3. Entrez le pattern : `logs-*`
   - Cela correspondra Ã  `logs-2025.10.25`, `logs-2025.10.26`, etc.
4. Cliquez **Next step**
5. SÃ©lectionnez le champ de temps : `@timestamp`
6. Cliquez **Create index pattern**

### Discover : Explorer les Logs

1. Dans le menu, allez Ã  **Discover**
2. SÃ©lectionnez votre index pattern `logs-*`
3. Vous voyez maintenant vos logs ! ğŸ‰

**Interface Discover** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [Recherche]                           [15 min â–¼]   â”‚ â† Barre de recherche et time range
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â–â–‚â–„â–ˆâ–‡â–…â–ƒâ–‚â–                                          â”‚ â† Histogramme temporel
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Champs      â”‚  Logs                                â”‚
â”‚              â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  kubernetes  â”‚  Oct 25 14:32:15  ERROR Payment...   â”‚
â”‚  level       â”‚  Oct 25 14:32:14  INFO  User lo...   â”‚
â”‚  message     â”‚  Oct 25 14:32:13  WARN  Slow qu...   â”‚
â”‚  pod_name    â”‚  Oct 25 14:32:12  DEBUG Request...   â”‚
â”‚              â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Recherches Basiques

#### Recherche Full-Text

Dans la barre de recherche :
```
payment failed
```
Trouve tous les logs contenant "payment" ET "failed"

#### Recherche par Champ

```
level: ERROR
```
Trouve tous les logs avec level = ERROR

```
kubernetes.namespace_name: production
```
Trouve tous les logs du namespace production

#### Combiner des CritÃ¨res

```
level: ERROR AND kubernetes.namespace_name: production
```
Logs d'erreur dans production

```
level: (ERROR OR WARN) AND message: database
```
Erreurs ou warnings contenant "database"

### Filtres Visuels

Au lieu de taper les requÃªtes, vous pouvez cliquer sur les valeurs dans les logs :

1. Cliquez sur un champ dans la liste (ex: `level`)
2. Survolez une valeur (ex: `ERROR`)
3. Cliquez sur la **loupe +** pour filtrer
4. Cliquez sur la **loupe -** pour exclure

### Time Range (Plage Temporelle)

En haut Ã  droite, sÃ©lectionnez la pÃ©riode :
- Last 15 minutes
- Last 1 hour
- Last 24 hours
- Last 7 days
- Custom (pÃ©riode personnalisÃ©e)

### Champs Utiles

Affichez les champs pertinents en cliquant dessus dans la liste :

**Champs recommandÃ©s** :
- `@timestamp` : Date/heure
- `level` : Niveau de log (INFO, WARN, ERROR)
- `message` ou `log` : Message du log
- `kubernetes.namespace_name` : Namespace
- `kubernetes.pod_name` : Nom du pod
- `kubernetes.container_name` : Nom du container
- `kubernetes.labels.*` : Labels du pod

### Sauvegarder des Recherches

Une fois que vous avez une recherche utile :

1. Cliquez sur **Save** en haut
2. Donnez un nom : "Erreurs Production"
3. Cliquez **Save**

Pour la retrouver :
- Menu **Discover** â†’ **Open** â†’ SÃ©lectionnez votre recherche

## Exemples de RequÃªtes Utiles

### 1. Toutes les Erreurs

```
level: ERROR
```

### 2. Erreurs dans un Namespace SpÃ©cifique

```
level: ERROR AND kubernetes.namespace_name: production
```

### 3. Logs d'un Pod SpÃ©cifique

```
kubernetes.pod_name: payment-service-7d8c9-x4b2k
```

### 4. Logs d'une Application (par label)

```
kubernetes.labels.app: payment-service
```

### 5. Recherche dans le Message

```
message: "connection timeout" OR message: "database error"
```

### 6. Exclure les Logs INFO (seulement WARN et ERROR)

```
NOT level: INFO
```

### 7. Logs avec une DurÃ©e > 1 Seconde

Si vous parsez la durÃ©e dans un champ `duration` :
```
duration: >1000
```

### 8. RequÃªte Complexe

```
(level: ERROR OR level: WARN)
AND kubernetes.namespace_name: production
AND (message: timeout OR message: failed OR message: error)
NOT kubernetes.labels.app: monitoring
```

Traduit en langage naturel :
- Erreurs ou warnings
- Dans le namespace production
- Contenant "timeout", "failed", ou "error"
- Mais pas de l'application monitoring

## Patterns de Logs Courants

### Pattern 1 : Debugging d'une Erreur Utilisateur

**ScÃ©nario** : Un utilisateur signale une erreur Ã  14h32.

**DÃ©marche** :
1. Time range : Autour de 14h32 (ex: 14h25 - 14h35)
2. Recherche : `level: ERROR`
3. Affinez : Ajoutez des mots-clÃ©s du rapport utilisateur
4. Trouvez le pod concernÃ©
5. Explorez les logs de ce pod avant et aprÃ¨s l'erreur

### Pattern 2 : Analyse d'un Incident

**ScÃ©nario** : Le site Ã©tait lent entre 10h et 11h.

**DÃ©marche** :
1. Time range : 10h - 11h
2. Recherche : `message: slow OR message: timeout`
3. Groupez par pod : Identifiez quel service avait des problÃ¨mes
4. CorrÃ©lation : Regardez si d'autres services Ã©taient impactÃ©s

### Pattern 3 : Suivi d'une RequÃªte

Si vous avez un **request ID** dans vos logs :

```
request_id: "abc-123-xyz"
```

Cela affiche tous les logs de cette requÃªte Ã  travers tous les services.

**Exemple de logs** :
```
14:32:15 frontend  INFO  Request abc-123-xyz received
14:32:16 auth      INFO  Request abc-123-xyz authenticated user 456
14:32:17 api       INFO  Request abc-123-xyz processing order
14:32:18 payment   ERROR Request abc-123-xyz payment timeout
```

Histoire complÃ¨te de la requÃªte ! ğŸ¯

### Pattern 4 : Top Erreurs

Pour voir les erreurs les plus frÃ©quentes :

1. Recherche : `level: ERROR`
2. Dans la liste des champs, cliquez sur `message`
3. Cliquez sur **Visualize** â†’ **Top values**
4. Vous voyez les messages d'erreur les plus frÃ©quents

## CrÃ©er des Dashboards

### Dashboard d'Overview

CrÃ©ez un dashboard pour avoir une vue d'ensemble :

1. Menu **Dashboard** â†’ **Create dashboard**
2. Ajoutez des panneaux :

**Panneau 1 : Volume de Logs**
- Type : Line chart
- MÃ©trique : Count
- Buckets : Date histogram sur @timestamp

**Panneau 2 : RÃ©partition par Niveau**
- Type : Pie chart
- Buckets : Terms sur `level`

**Panneau 3 : Top 10 Pods avec le Plus d'Erreurs**
- Type : Table
- Filter : `level: ERROR`
- Buckets : Terms sur `kubernetes.pod_name`
- MÃ©trique : Count

**Panneau 4 : Erreurs par Namespace**
- Type : Bar chart
- Filter : `level: ERROR`
- Buckets : Terms sur `kubernetes.namespace_name`

3. Sauvegardez le dashboard : "Logs Overview"

### Dashboard par Application

CrÃ©ez un dashboard spÃ©cifique pour chaque application importante :

1. Filtre global : `kubernetes.labels.app: payment-service`
2. Ajoutez des panneaux pertinents :
   - Volume de logs
   - Taux d'erreur
   - Top erreurs
   - Latence (si parsÃ©e)

## Gestion des Index et RÃ©tention

### Rotation des Index

Par dÃ©faut, Fluentd crÃ©e un index par jour :
```
logs-2025.10.25
logs-2025.10.26
logs-2025.10.27
```

### Politique de RÃ©tention

Les logs prennent de l'espace. Il faut dÃ©finir combien de temps les garder.

#### Index Lifecycle Management (ILM)

Dans Kibana :
1. **Stack Management** â†’ **Index Lifecycle Policies**
2. **Create policy**
3. DÃ©finissez les phases :
   - **Hot** : Index actif (0-1 jour)
   - **Warm** : Lectures occasionnelles (1-7 jours)
   - **Cold** : Archives (7-30 jours)
   - **Delete** : Suppression aprÃ¨s X jours

**Exemple de politique simple** :
```json
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_age": "1d",
            "max_size": "50gb"
          }
        }
      },
      "delete": {
        "min_age": "7d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
```

Cette politique :
- CrÃ©e un nouvel index chaque jour ou quand l'index atteint 50GB
- Supprime les index de plus de 7 jours

### Suppression Manuelle

Pour supprimer un index :

**Via Kibana** :
1. **Stack Management** â†’ **Index Management**
2. SÃ©lectionnez l'index
3. **Manage** â†’ **Delete index**

**Via API** :
```bash
curl -X DELETE "localhost:9200/logs-2025.10.01"
```

### Monitoring de l'Espace Disque

```bash
# Voir l'utilisation du stockage Elasticsearch
microk8s kubectl exec -n logging elasticsearch-0 -- df -h /usr/share/elasticsearch/data

# Voir la taille des index
curl -X GET "localhost:9200/_cat/indices?v&h=index,store.size&s=store.size:desc"
```

## Bonnes Pratiques

### 1. Structure de Logs

**Utilisez JSON** dans vos applications :

```json
{
  "timestamp": "2025-10-25T14:32:15Z",
  "level": "ERROR",
  "message": "Payment failed",
  "context": {
    "user_id": "12345",
    "order_id": "98765",
    "error_code": "TIMEOUT"
  }
}
```

Avantages :
- âœ… Facile Ã  parser
- âœ… Champs structurÃ©s automatiquement
- âœ… Recherches prÃ©cises possibles

### 2. Niveaux de Log CohÃ©rents

Utilisez des niveaux standards :
- **TRACE** : DÃ©tails trÃ¨s verbeux (rarement utilisÃ© en prod)
- **DEBUG** : Informations de dÃ©bogage
- **INFO** : Informations gÃ©nÃ©rales
- **WARN** : Avertissements, situations anormales mais gÃ©rables
- **ERROR** : Erreurs nÃ©cessitant attention
- **FATAL** : Erreurs critiques causant l'arrÃªt

### 3. Contexte Riche

Incluez toujours du contexte :

```
âŒ "Error"
âœ… "Payment processing error: timeout after 30s for order #12345, user 456"

âŒ "Request failed"
âœ… "API request failed: POST /api/orders, status 500, duration 3.2s, request_id abc-123"
```

### 4. Request ID / Trace ID

GÃ©nÃ©rez un ID unique par requÃªte et propagez-le :

```python
import uuid

@app.before_request
def before_request():
    request.request_id = request.headers.get('X-Request-ID', str(uuid.uuid4()))

@app.route('/api/order')
def create_order():
    logger.info(f"Processing order", extra={'request_id': request.request_id})
```

Permet de suivre une requÃªte Ã  travers tous les services !

### 5. Ã‰viter les Logs Sensibles

**Ne loguez JAMAIS** :
- âŒ Mots de passe
- âŒ Tokens d'authentification
- âŒ NumÃ©ros de carte bancaire
- âŒ DonnÃ©es personnelles sensibles (RGPD)

**Masquez les donnÃ©es sensibles** :
```
âœ… "User john.doe@example.com logged in"
âœ… "Payment with card ending in 1234"
```

### 6. Log Sampling pour Haute VolumÃ©trie

Si vous avez Ã©normÃ©ment de logs (ex: 1000 req/s) :

```python
import random

if random.random() < 0.1:  # Log 10% des requÃªtes
    logger.debug(f"Request details: {request}")
```

Ou loguez seulement les requÃªtes lentes :
```python
if duration > 1.0:  # Plus de 1 seconde
    logger.warn(f"Slow request: {duration}s")
```

### 7. CorrÃ©lation avec les MÃ©triques

Ajoutez les mÃªmes labels dans logs et mÃ©triques :

```python
# Dans le log
logger.error("Payment failed", extra={
    'order_id': '12345',
    'payment_method': 'credit_card'
})

# Dans la mÃ©trique
payment_failures.labels(payment_method='credit_card').inc()
```

Permet de corrÃ©ler facilement !

## DÃ©pannage

### ProblÃ¨me : Aucun Log dans Kibana

**VÃ©rifications** :

1. **Elasticsearch est-il accessible ?**
   ```bash
   kubectl exec -n logging -it fluentd-xxxxx -- curl http://elasticsearch.logging.svc.cluster.local:9200/_cluster/health
   ```

2. **Fluentd envoie-t-il des logs ?**
   ```bash
   kubectl logs -n logging fluentd-xxxxx | grep -i error
   ```

3. **Y a-t-il des index dans Elasticsearch ?**
   ```bash
   curl http://localhost:9200/_cat/indices?v
   ```
   Devrait montrer `logs-2025.10.25`

4. **L'index pattern est-il correct dans Kibana ?**
   - VÃ©rifiez que le pattern `logs-*` existe
   - VÃ©rifiez que des documents sont prÃ©sents

### ProblÃ¨me : Fluentd en CrashLoop

**Causes possibles** :
- Configuration invalide
- Permissions insuffisantes
- Elasticsearch inaccessible

**DÃ©bogage** :
```bash
kubectl logs -n logging fluentd-xxxxx
# Cherchez les erreurs de config ou de connexion
```

### ProblÃ¨me : Elasticsearch Out of Memory

**SymptÃ´me** : Pod Elasticsearch redÃ©marre frÃ©quemment

**Solutions** :
1. Augmentez la mÃ©moire allouÃ©e dans le StatefulSet
2. RÃ©duisez la heap size Java si nÃ©cessaire
3. Activez la politique de rÃ©tention pour supprimer les vieux index

### ProblÃ¨me : Kibana Lent

**Causes** :
- Trop de donnÃ©es (index trop gros)
- RequÃªtes non optimisÃ©es
- Ressources insuffisantes

**Solutions** :
1. Utilisez des time ranges plus courts
2. Ajoutez des filtres pour rÃ©duire les donnÃ©es
3. Augmentez les ressources Kibana

## Ce Qu'il Faut Retenir

ğŸ“š **La stack EFK centralise tous vos logs** :
- **E**lasticsearch : Stocke et indexe
- **F**luentd : Collecte et enrichit
- **K**ibana : Visualise et recherche

ğŸ”„ **Architecture distribuÃ©e** :
- Fluentd en DaemonSet sur chaque nÅ“ud
- Elasticsearch en StatefulSet avec persistance
- Kibana en Deployment pour l'interface

ğŸ” **Kibana Discover** :
- Recherche full-text et par champs
- Filtres visuels et temporels
- Sauvegarde de recherches

ğŸ“Š **Dashboards** :
- CrÃ©ez des vues d'ensemble
- Surveillez les patterns
- Partagez avec l'Ã©quipe

âš™ï¸ **Gestion des index** :
- Rotation automatique par jour
- Politique de rÃ©tention (ILM)
- Nettoyage rÃ©gulier nÃ©cessaire

âœ… **Bonnes pratiques** :
- Logs structurÃ©s en JSON
- Niveaux cohÃ©rents
- Contexte riche avec request ID
- Protection des donnÃ©es sensibles

ğŸ¯ **Prochaine Ã©tape** :
- Section 15.4 : CorrÃ©lation logs-mÃ©triques avec Loki (alternative plus lÃ©gÃ¨re)
- Section 15.5 : Tracing distribuÃ© avec Jaeger

Avec vos logs centralisÃ©s, vous avez maintenant une visibilitÃ© complÃ¨te sur ce qui se passe dans votre cluster MicroK8s ! ğŸš€

â­ï¸ [Correlation logs-mÃ©triques avec Loki](/15-observabilite-avancee/04-correlation-logs-metriques-avec-loki.md)
