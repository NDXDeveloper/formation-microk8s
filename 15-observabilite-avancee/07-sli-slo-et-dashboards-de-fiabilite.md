ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 15.7 SLI/SLO et Dashboards de FiabilitÃ©

## Introduction

Vous avez maintenant une observabilitÃ© complÃ¨te de votre cluster MicroK8s :
- âœ… MÃ©triques avec Prometheus
- âœ… Logs avec Loki
- âœ… Traces avec Jaeger
- âœ… Synthetic monitoring avec Blackbox

Mais une question reste : **Comment mesurer si votre service est "bon" ?**

Les **SLI** et **SLO** rÃ©pondent Ã  cette question en dÃ©finissant des **objectifs mesurables** pour la fiabilitÃ© de vos services.

### Le ProblÃ¨me Sans SLI/SLO

**Conversation typique** :

```
Manager : "Le site est-il fiable ?"
DevOps : "Euh... on a 99% d'uptime ?"
Manager : "C'est bien ou pas ?"
DevOps : "Ã‡a dÃ©pend... de quoi ?"
Manager : "Est-ce qu'on peut dÃ©ployer cette nouvelle fonctionnalitÃ© ?"
DevOps : "Je ne sais pas si on peut se permettre plus de risques..."
```

**Sans objectifs clairs** :
- âŒ Pas de rÃ©fÃ©rentiel commun
- âŒ Discussions subjectives ("c'est lent" vs "non, c'est rapide")
- âŒ Impossible de prendre des dÃ©cisions basÃ©es sur les donnÃ©es
- âŒ Burn-out des Ã©quipes (tout est "urgent")

**Avec SLI/SLO** :
- âœ… Objectifs mesurables et partagÃ©s
- âœ… Discussions basÃ©es sur les faits
- âœ… DÃ©cisions Ã©clairÃ©es (dÃ©ployer ou pas ?)
- âœ… Ã‰quilibre entre innovation et stabilitÃ©

## Les Trois Concepts : SLI, SLO, SLA

### SLI (Service Level Indicator)

**DÃ©finition** : Un **SLI** est une **mÃ©trique** qui mesure un aspect spÃ©cifique de votre service.

**En franÃ§ais simple** : "Comment je mesure si mon service fonctionne bien ?"

**Exemples** :
- Pourcentage de requÃªtes rÃ©ussies
- Temps de rÃ©ponse (latence)
- DisponibilitÃ© du service
- DÃ©bit (throughput)
- DurabilitÃ© des donnÃ©es

**CaractÃ©ristiques d'un bon SLI** :
- âœ… Mesurable objectivement (mÃ©trique)
- âœ… Important pour l'utilisateur
- âœ… Directement contrÃ´lable par vous

**Exemple concret** :

```
SLI: "Pourcentage de requÃªtes HTTP qui retournent un status code 2xx en moins de 1 seconde"

Mesure sur la derniÃ¨re heure:
- Total requÃªtes: 10 000
- RequÃªtes rÃ©ussies (<1s): 9 950
- SLI = 9950/10000 = 99.5%
```

### SLO (Service Level Objective)

**DÃ©finition** : Un **SLO** est un **objectif** pour votre SLI.

**En franÃ§ais simple** : "Quel niveau je veux atteindre pour cette mÃ©trique ?"

**Format typique** : `[SLI] [comparateur] [seuil]` sur `[pÃ©riode]`

**Exemples** :
- 99% des requÃªtes doivent rÃ©ussir (sur 30 jours)
- 95% des requÃªtes doivent Ãªtre servies en moins de 500ms (sur 7 jours)
- Le service doit Ãªtre disponible 99.9% du temps (sur 1 mois)

**Exemple concret** :

```
SLO: "99.5% des requÃªtes HTTP doivent rÃ©ussir en moins de 1 seconde sur une fenÃªtre glissante de 30 jours"

Ã‰tat actuel:
- SLI actuel: 99.7%
- SLO cible: 99.5%
- Marge: +0.2%
âœ… SLO respectÃ© !
```

### SLA (Service Level Agreement)

**DÃ©finition** : Un **SLA** est un **contrat** (souvent lÃ©gal) qui dÃ©finit les consÃ©quences si un SLO n'est pas atteint.

**En franÃ§ais simple** : "Qu'est-ce qui se passe si je rate mon objectif ?"

**Exemples** :
- Remboursement de 10% si uptime < 99.9%
- CrÃ©dit de 25% si latence > 500ms pour 5% des requÃªtes
- PÃ©nalitÃ©s contractuelles

**DiffÃ©rence clÃ©** :

```
SLI: "Comment je mesure"        â†’ MÃ©trique technique
SLO: "Quel niveau je vise"      â†’ Objectif interne
SLA: "Engagement contractuel"   â†’ Promesse client avec consÃ©quences
```

**Relation** :

```
        SLA (99.0%)  â† Promesse client (contrat)
           â†‘
    SLO interne (99.5%)  â† Objectif interne (plus strict)
           â†‘
        SLI (99.7%)  â† Performance rÃ©elle (mesure)
```

**Pour un lab MicroK8s** : Vous utilisez principalement **SLI** et **SLO**. Les SLA sont pour les environnements production avec clients externes.

## Pourquoi les SLI/SLO Sont Importants

### 1. Langage Commun

**Sans SLO** :
```
Dev: "Le service est rapide"
Ops: "Non, il est lent"
Product: "Les utilisateurs se plaignent"
```

**Avec SLO** :
```
Tous: "Notre SLO est 95% des requÃªtes < 500ms"
Monitoring: "On est Ã  92%"
Tous: "On a un problÃ¨me, qu'est-ce qu'on fait ?"
```

### 2. Priorisation

**Sans SLO** :
- Toutes les alertes semblent critiques
- Impossible de prioriser
- Burn-out de l'Ã©quipe

**Avec SLO** :
```
Alerte 1: SLO violation (95% â†’ 92%)  â†’ PRIORITÃ‰ 1
Alerte 2: CPU Ã  60% (seuil: 80%)     â†’ Pas urgent
Alerte 3: 1 pod down (sur 10)        â†’ Impact sur SLO ? Non â†’ Pas urgent
```

### 3. Error Budget (Budget d'Erreur)

**Concept rÃ©volutionnaire** introduit par Google SRE.

**Calcul** :

```
SLO: 99.5% de disponibilitÃ©
Donc acceptable: 100% - 99.5% = 0.5% d'indisponibilitÃ©

Sur 30 jours:
30 jours Ã— 24h Ã— 60min Ã— 60s = 2,592,000 secondes
Budget d'erreur = 2,592,000 Ã— 0.5% = 12,960 secondes
                = 216 minutes
                = 3.6 heures

Vous pouvez Ãªtre down 3.6 heures par mois sans violer le SLO !
```

**Utilisation du budget** :

```
DÃ©but du mois: Budget = 3.6h
Incident 1 (30 min): Budget restant = 3.1h
DÃ©ploiement risquÃ© (10 min downtime): Budget = 3.0h
Incident 2 (1h): Budget = 2.0h

Question: "Peut-on dÃ©ployer cette feature risquÃ©e ?"
RÃ©ponse: "Oui, on a encore 2h de budget. Mais attention !"
```

**Si le budget est Ã©puisÃ©** :
- âŒ STOP les dÃ©ploiements (sauf critiques)
- âœ… FOCUS sur la stabilitÃ©
- âœ… Post-mortem des incidents
- âœ… Correction des problÃ¨mes

**Avantage** : Ã‰quilibre entre **innovation** (dÃ©ployer) et **stabilitÃ©** (ne pas casser).

### 4. DÃ©cisions BasÃ©es sur les DonnÃ©es

**Question** : "Doit-on ajouter plus de rÃ©plicas ?"

**Sans SLO** :
```
"Je pense que oui... le service semble lent parfois"
```

**Avec SLO** :
```
SLO latence: 95% < 500ms
SLI actuel: 93% < 500ms
âŒ SLO violÃ© â†’ OUI, il faut scaler
```

**Question** : "Doit-on optimiser ce code qui prend 100ms ?"

**Sans SLO** :
```
"100ms c'est lent, optimisons !"
Temps perdu: 2 semaines
Impact utilisateur: NÃ©gligeable
```

**Avec SLO** :
```
SLO latence: 95% < 500ms
Ce code reprÃ©sente 0.1% des requÃªtes
Impact sur SLO: 0.1% Ã— 100ms = nÃ©gligeable
DÃ©cision: PAS PRIORITAIRE, focus ailleurs
```

## Choisir les Bons SLI

### Les Quatre Golden Signals

Google SRE recommande de surveiller 4 mÃ©triques clÃ©s :

#### 1. Latence (Latency)

**DÃ©finition** : Temps pour traiter une requÃªte.

**MÃ©triques** :
- Latence moyenne
- P50 (mÃ©diane)
- P95 (95Ã¨me percentile)
- P99 (99Ã¨me percentile)

**Pourquoi les percentiles ?**

```
100 requÃªtes:
- 95 requÃªtes: 100ms
- 4 requÃªtes: 200ms
- 1 requÃªte: 5000ms (timeout)

Moyenne: 147ms (masque le problÃ¨me)
P95: 200ms (capte les vraies expÃ©riences)
P99: 5000ms (rÃ©vÃ¨le les pires cas)
```

**SLI exemple** :
```
"P95 de la latence des requÃªtes HTTP"
```

**SLO exemple** :
```
"P95 < 500ms sur 30 jours"
```

#### 2. Trafic (Traffic)

**DÃ©finition** : Demande sur votre systÃ¨me.

**MÃ©triques** :
- RequÃªtes par seconde
- Utilisateurs actifs
- Bande passante

**SLI exemple** :
```
"Nombre de requÃªtes par seconde"
```

**SLO exemple** :
```
"Le systÃ¨me doit supporter au moins 1000 req/s"
```

**Note** : Le trafic est souvent un input, pas un SLO direct.

#### 3. Erreurs (Errors)

**DÃ©finition** : Taux de requÃªtes qui Ã©chouent.

**Types d'erreurs** :
- Explicites : Status 5xx, exceptions
- Implicites : Status 2xx mais donnÃ©es incorrectes
- Partielle : Timeouts, dÃ©gradation

**SLI exemple** :
```
"Pourcentage de requÃªtes qui retournent 5xx ou timeout"
```

**SLO exemple** :
```
"Taux d'erreur < 0.1% sur 30 jours"
ou
"99.9% des requÃªtes doivent rÃ©ussir sur 30 jours"
```

#### 4. Saturation (Saturation)

**DÃ©finition** : "PlÃ©nitude" du systÃ¨me.

**MÃ©triques** :
- CPU
- MÃ©moire
- Espace disque
- Connexions DB
- Queue depth

**SLI exemple** :
```
"Pourcentage d'utilisation CPU moyenne"
```

**SLO exemple** :
```
"CPU < 80% sur 95% du temps (30 jours)"
```

### Choisir VOS SLI

**Ã‰tapes** :

1. **Identifiez ce qui compte pour l'utilisateur**
   - Qu'est-ce qui rend votre service "bon" ?
   - Qu'est-ce qui frustre vos utilisateurs ?

2. **Rendez-le mesurable**
   - Quelle mÃ©trique capture Ã§a ?
   - Pouvez-vous la mesurer avec vos outils ?

3. **Gardez Ã§a simple**
   - 3-5 SLI maximum par service
   - Trop de SLI = dilution de l'attention

**Exemples par type de service** :

**API REST** :
- DisponibilitÃ© : % de requÃªtes rÃ©ussies
- Latence : P95 du temps de rÃ©ponse
- Erreurs : % de status 5xx

**Application Web** :
- DisponibilitÃ© : % de pages chargÃ©es avec succÃ¨s
- Latence : P95 du temps de chargement
- Completeness : % de pages avec toutes les ressources chargÃ©es

**Service de Base de DonnÃ©es** :
- DisponibilitÃ© : % de connexions rÃ©ussies
- Latence : P95 du temps de requÃªte
- DurabilitÃ© : % de donnÃ©es sans corruption

**Service de Traitement Batch** :
- DÃ©bit : Jobs traitÃ©s par heure
- DurÃ©e : P95 du temps de traitement
- Success rate : % de jobs rÃ©ussis

## ImplÃ©menter les SLI dans Prometheus

### Exemple 1 : SLI de DisponibilitÃ©

**Objectif** : Mesurer le pourcentage de requÃªtes HTTP rÃ©ussies.

**MÃ©triques Prometheus nÃ©cessaires** :

```promql
# Total des requÃªtes
http_requests_total{job="myapp"}

# RequÃªtes rÃ©ussies (status 2xx-3xx)
http_requests_total{job="myapp", status=~"[23].."}
```

**Calcul du SLI** :

```promql
# SLI = requÃªtes rÃ©ussies / total requÃªtes
sum(rate(http_requests_total{job="myapp", status=~"[23].."}[5m]))
/
sum(rate(http_requests_total{job="myapp"}[5m]))
```

**RÃ©sultat** : Valeur entre 0 et 1 (ex: 0.995 = 99.5%)

**Pour l'afficher en pourcentage** :

```promql
(
  sum(rate(http_requests_total{job="myapp", status=~"[23].."}[5m]))
  /
  sum(rate(http_requests_total{job="myapp"}[5m]))
) * 100
```

### Exemple 2 : SLI de Latence

**Objectif** : P95 du temps de rÃ©ponse.

**MÃ©trique Prometheus** (histogram) :

```promql
http_request_duration_seconds_bucket{job="myapp"}
```

**Calcul du SLI** :

```promql
# P95 de la latence
histogram_quantile(
  0.95,
  sum(rate(http_request_duration_seconds_bucket{job="myapp"}[5m])) by (le)
)
```

**RÃ©sultat** : Latence en secondes (ex: 0.234)

### Exemple 3 : SLI d'Erreurs

**Objectif** : Pourcentage de requÃªtes en erreur.

**Calcul du SLI** :

```promql
# SLI = requÃªtes en erreur / total requÃªtes
sum(rate(http_requests_total{job="myapp", status=~"5.."}[5m]))
/
sum(rate(http_requests_total{job="myapp"}[5m]))
* 100
```

**RÃ©sultat** : Pourcentage d'erreurs (ex: 0.5%)

### Exemple 4 : Synthetic Monitoring (Blackbox)

**Objectif** : DisponibilitÃ© du service vue de l'extÃ©rieur.

**MÃ©trique Prometheus** :

```promql
probe_success{job="blackbox-http"}
```

**Calcul du SLI** :

```promql
# DisponibilitÃ© moyenne
avg_over_time(probe_success{instance="https://myapp.com"}[30d]) * 100
```

**RÃ©sultat** : Pourcentage de disponibilitÃ© (ex: 99.7%)

## Recording Rules pour les SLI

Pour Ã©viter de recalculer les SLI Ã  chaque fois, utilisez des **recording rules**.

**Fichier `prometheus-sli-rules.yaml`** :

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-sli-rules
  namespace: monitoring
data:
  sli-rules.yml: |
    groups:
    - name: sli_availability
      interval: 30s
      rules:
      # SLI: Availability
      - record: sli:http_requests:availability:rate5m
        expr: |
          sum(rate(http_requests_total{status=~"[23].."}[5m])) by (job)
          /
          sum(rate(http_requests_total[5m])) by (job)

      # SLI sur 30 jours
      - record: sli:http_requests:availability:rate30d
        expr: |
          sum(rate(http_requests_total{status=~"[23].."}[30d])) by (job)
          /
          sum(rate(http_requests_total[30d])) by (job)

    - name: sli_latency
      interval: 30s
      rules:
      # SLI: P95 Latency
      - record: sli:http_request_duration:p95:rate5m
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, job)
          )

      # SLI: P99 Latency
      - record: sli:http_request_duration:p99:rate5m
        expr: |
          histogram_quantile(
            0.99,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, job)
          )

    - name: sli_errors
      interval: 30s
      rules:
      # SLI: Error rate
      - record: sli:http_requests:error_rate:rate5m
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (job)
          /
          sum(rate(http_requests_total[5m])) by (job)

    - name: sli_synthetic
      interval: 1m
      rules:
      # SLI: Synthetic availability
      - record: sli:probe:availability:rate30d
        expr: |
          avg_over_time(probe_success[30d])
```

**Appliquer** :

```bash
kubectl apply -f prometheus-sli-rules.yaml

# Ajouter Ã  la config Prometheus
# rule_files:
#   - /etc/prometheus/rules/sli-rules.yml

# Recharger Prometheus
kubectl rollout restart statefulset prometheus -n monitoring
```

**Avantage** : RequÃªtes plus rapides, nommage cohÃ©rent.

## DÃ©finir les SLO

### MÃ©thodologie

**1. Commencer Simple**

Ne dÃ©finissez pas 20 SLO le premier jour. Commencez par 1-3 SLO critiques.

**2. BasÃ© sur les DonnÃ©es Historiques**

```
Regardez vos 30 derniers jours:
- P95 latence: 234ms
- Availability: 99.7%
- Error rate: 0.2%

Ne mettez PAS un SLO de "P95 < 100ms" si vous Ãªtes Ã  234ms !
Soyez rÃ©aliste.
```

**3. Pensez au CoÃ»t**

Plus le SLO est strict, plus c'est coÃ»teux :

```
SLO 99%   = 7.2h downtime/mois   â†’ Facile et peu coÃ»teux
SLO 99.9% = 43 min downtime/mois â†’ CoÃ»t moyen
SLO 99.99% = 4.3 min downtime/mois â†’ TrÃ¨s coÃ»teux !
```

**Pour un lab** : 95-99% est raisonnable.
**Pour production critique** : 99.5-99.9%.

**4. ItÃ©rez**

```
Mois 1: SLO 95% â†’ Atteint facilement â†’ Trop facile
Mois 2: SLO 98% â†’ Atteint avec efforts â†’ Bon Ã©quilibre
Mois 3: SLO 99% â†’ RatÃ© plusieurs fois â†’ Trop dur

Retour Ã  98% â†’ C'est votre SLO idÃ©al
```

### Exemples de SLO RÃ©alistes

**Service Web (Lab Personnel)** :

```yaml
SLO:
  - name: "DisponibilitÃ©"
    sli: "sli:http_requests:availability:rate30d"
    target: 0.95  # 95%
    window: 30d

  - name: "Latence P95"
    sli: "sli:http_request_duration:p95:rate5m"
    target: 1.0  # 1 seconde
    window: 30d

  - name: "Taux d'erreur"
    sli: "sli:http_requests:error_rate:rate5m"
    target: 0.01  # < 1%
    window: 30d
```

**API de Production** :

```yaml
SLO:
  - name: "DisponibilitÃ©"
    target: 0.999  # 99.9%
    window: 30d

  - name: "Latence P95"
    target: 0.5  # 500ms
    window: 30d

  - name: "Latence P99"
    target: 1.0  # 1 seconde
    window: 30d
```

## Alertes basÃ©es sur les SLO

### Approche Traditionnelle (SymptÃ´me)

```yaml
# âŒ Alerte sur un symptÃ´me
- alert: HighCPU
  expr: cpu_usage > 80
  for: 5m
```

**ProblÃ¨me** : Est-ce que 80% CPU impacte rÃ©ellement l'utilisateur ?

### Approche SLO (Impact)

```yaml
# âœ… Alerte sur l'impact SLO
- alert: SLO_AvailabilityBreach
  expr: sli:http_requests:availability:rate5m < 0.95
  for: 5m
  labels:
    severity: warning
  annotations:
    summary: "SLO Availability breached"
    description: "Availability is {{ $value | humanizePercentage }}, below target of 95%"
```

**Avantage** : Vous Ãªtes alertÃ© seulement quand Ã§a impacte vraiment les utilisateurs.

### Multi-Window Multi-Burn-Rate

**Concept avancÃ©** de Google SRE.

**ProblÃ¨me** :
- Alerte immÃ©diate sur violation â†’ Trop de faux positifs
- Alerte aprÃ¨s 1 heure â†’ Trop tard

**Solution** : Alertes Ã  plusieurs niveaux de sÃ©vÃ©ritÃ©.

```yaml
groups:
- name: slo_alerts
  rules:

  # CRITICAL: Burn rapide, fenÃªtre courte
  # Consomme le budget en 2 jours au rythme actuel
  - alert: SLO_ErrorBudget_CriticalBurn
    expr: |
      (
        sli:http_requests:availability:rate1h < (1 - 0.95)  # Target SLO
        and
        sli:http_requests:availability:rate5m < (1 - 0.95)
      )
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "Critical: SLO error budget burning fast"

  # WARNING: Burn moyen, fenÃªtre moyenne
  # Consomme le budget en 7 jours au rythme actuel
  - alert: SLO_ErrorBudget_HighBurn
    expr: |
      (
        sli:http_requests:availability:rate6h < (1 - 0.95)
        and
        sli:http_requests:availability:rate30m < (1 - 0.95)
      )
    for: 15m
    labels:
      severity: warning
    annotations:
      summary: "Warning: SLO error budget burning"

  # INFO: Burn lent mais constant
  - alert: SLO_ErrorBudget_SlowBurn
    expr: |
      sli:http_requests:availability:rate30d < (1 - 0.95)
    for: 1h
    labels:
      severity: info
    annotations:
      summary: "Info: SLO error budget exhausted"
```

**Logique** :
- **Critical** : ProblÃ¨me immÃ©diat et sÃ©vÃ¨re â†’ Action maintenant
- **Warning** : ProblÃ¨me qui s'installe â†’ Action bientÃ´t
- **Info** : Budget Ã©puisÃ© â†’ Post-mortem, pas d'urgence

## Dashboards de FiabilitÃ©

### Dashboard SLO Complet

CrÃ©ez un dashboard Grafana dÃ©diÃ© aux SLO.

**Structure recommandÃ©e** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Service: MyApp                  [30d â–¼]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚  ğŸ“Š SLO Summary                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ DisponibilitÃ©  99.7% âœ… Target: 95%      â”‚  â”‚
â”‚  â”‚ Latence P95    234ms âœ… Target: 500ms    â”‚  â”‚
â”‚  â”‚ Error Rate     0.2%  âœ… Target: 1%       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                â”‚
â”‚  ğŸ’° Error Budget                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Budget restant: 2.1h / 3.6h (58%) âœ…     â”‚  â”‚
â”‚  â”‚ [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘]                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                â”‚
â”‚  ğŸ“ˆ SLI Trends (30 days)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  [Graphe de disponibilitÃ©]               â”‚  â”‚
â”‚  â”‚  [Graphe de latence]                     â”‚  â”‚
â”‚  â”‚  [Graphe d'erreurs]                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                â”‚
â”‚  ğŸš¨ Recent Incidents                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Oct 20: 30min downtime (database)       â”‚  â”‚
â”‚  â”‚  Oct 15: 10min high latency (deploy)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Panneaux Grafana

#### 1. SLO Gauge (Jauge)

**Type** : Gauge

**RequÃªte** :

```promql
sli:http_requests:availability:rate30d * 100
```

**Configuration** :
- Min : 0
- Max : 100
- Thresholds :
  - Red : 0-95
  - Yellow : 95-98
  - Green : 98-100
- UnitÃ© : percent (0-100)

**Display** :
- Show : Current value
- Title : "DisponibilitÃ© (30d)"

#### 2. SLO vs Target (Stat avec spark line)

**Type** : Stat

**RequÃªte** :

```promql
sli:http_requests:availability:rate30d
```

**Second query** (Target) :

```promql
0.95
```

**Configuration** :
- Show : Both (value + graph)
- Thresholds :
  - Base (Red) : 0
  - Green : 0.95 (SLO target)
- Value :  Display : Percent (0.0-1.0)

#### 3. Error Budget Gauge

**Calcul du budget restant** :

```promql
# Budget total (en secondes sur 30 jours)
(1 - 0.95) * 30 * 24 * 60 * 60  # = 129,600 secondes

# Budget consommÃ© (downtime constatÃ©)
(1 - sli:http_requests:availability:rate30d) * 30 * 24 * 60 * 60

# Budget restant
(1 - 0.95) * 30 * 24 * 60 * 60
-
(1 - sli:http_requests:availability:rate30d) * 30 * 24 * 60 * 60
```

**SimplifiÃ©** :

```promql
# Budget restant en pourcentage
(sli:http_requests:availability:rate30d - 0.95) / (1 - 0.95) * 100
```

**Type** : Gauge

**Configuration** :
- Min : 0
- Max : 100
- Thresholds :
  - Red : 0-10 (Presque Ã©puisÃ©)
  - Yellow : 10-50
  - Green : 50-100
- UnitÃ© : percent

#### 4. SLI Timeline (30 jours)

**Type** : Time series

**RequÃªtes** :

```promql
# SLI actuel
sli:http_requests:availability:rate30d * 100

# Target SLO (ligne de rÃ©fÃ©rence)
95
```

**Configuration** :
- Legend : {{ job }} et "SLO Target"
- Y-axis : Percent (90-100)
- Thresholds :
  - Red : < 95
  - Green : >= 95

#### 5. Latence Multi-Percentile

**Type** : Time series

**RequÃªtes** :

```promql
# P50
sli:http_request_duration:p50:rate5m * 1000

# P95
sli:http_request_duration:p95:rate5m * 1000

# P99
sli:http_request_duration:p99:rate5m * 1000

# Target (ligne)
500
```

**Configuration** :
- UnitÃ© : ms
- Legend : P50, P95, P99, Target

#### 6. Error Budget Burn Rate

**Type** : Time series

**RequÃªte** :

```promql
# Taux de consommation du budget
# 1.0 = consommation normale
# > 1.0 = consommation rapide (problÃ¨me)
# < 1.0 = meilleur que prÃ©vu

(1 - sli:http_requests:availability:rate1h) / (1 - 0.95)
```

**Configuration** :
- Thresholds :
  - Red : > 10 (burn 10x plus rapide)
  - Yellow : > 5
  - Green : <= 1

#### 7. Table de SynthÃ¨se

**Type** : Table

**RequÃªtes** :

```promql
# Query A: Availability
sli:http_requests:availability:rate30d

# Query B: Latency P95
sli:http_request_duration:p95:rate5m

# Query C: Error Rate
sli:http_requests:error_rate:rate5m
```

**Transformations** :
- Join by job
- Organize fields

**Colonnes** :
- Service (job)
- Availability %
- Latency P95 (ms)
- Error Rate %
- Status (âœ…/âš ï¸/âŒ)

### Variables de Dashboard

```
$service : label_values(sli:http_requests:availability:rate30d, job)
$window : 1h, 6h, 24h, 7d, 30d
$slo_target : 0.90, 0.95, 0.99, 0.999
```

Utilisez dans les requÃªtes :

```promql
sli:http_requests:availability:rate30d{job="$service"}
```

## Calcul de l'Error Budget

### Formule de Base

```
Error Budget (temps) = Total Time Ã— (1 - SLO)
```

**Exemple : SLO 99% sur 30 jours**

```
Total Time = 30 jours Ã— 24h Ã— 60min = 43,200 minutes
Error Budget = 43,200 Ã— (1 - 0.99) = 432 minutes = 7.2 heures
```

Vous pouvez avoir **7.2 heures d'indisponibilitÃ©** par mois.

### Tracking du Budget

**Recording rule** :

```yaml
- name: error_budget
  interval: 1m
  rules:
  # Budget total (en secondes)
  - record: slo:error_budget:total_seconds
    expr: |
      (1 - 0.95) * 30 * 24 * 60 * 60  # 129,600 secondes pour SLO 95%

  # Budget consommÃ© (downtime en secondes)
  - record: slo:error_budget:consumed_seconds
    expr: |
      (1 - sli:http_requests:availability:rate30d) * 30 * 24 * 60 * 60

  # Budget restant (en secondes)
  - record: slo:error_budget:remaining_seconds
    expr: |
      slo:error_budget:total_seconds - slo:error_budget:consumed_seconds

  # Budget restant (en pourcentage)
  - record: slo:error_budget:remaining_ratio
    expr: |
      slo:error_budget:remaining_seconds / slo:error_budget:total_seconds
```

**Affichage dans Grafana** :

```promql
# Heures restantes
slo:error_budget:remaining_seconds / 3600

# Pourcentage restant
slo:error_budget:remaining_ratio * 100
```

### Politique d'Error Budget

**Document Ã  crÃ©er** : "Error Budget Policy"

**Exemple** :

```markdown
# Error Budget Policy - MyApp Service

## SLO
- DisponibilitÃ©: 95% sur 30 jours
- Error Budget: 3.6 heures/mois

## Politiques

### Budget > 50% âœ…
- âœ… DÃ©ploiements autorisÃ©s sans restrictions
- âœ… Features risquÃ©es acceptÃ©es
- âœ… ExpÃ©rimentations encouragÃ©es

### Budget 25-50% âš ï¸
- âš ï¸ DÃ©ploiements autorisÃ©s avec review
- âš ï¸ Features risquÃ©es Ã  Ã©valuer
- âš ï¸ Tests approfondis requis

### Budget < 25% ğŸš¨
- âŒ FREEZE des dÃ©ploiements non-critiques
- âœ… Seulement hotfixes de sÃ©curitÃ©/stabilitÃ©
- ğŸ“‹ Post-mortem obligatoire
- ğŸ”§ Focus stabilitÃ© jusqu'Ã  rÃ©cupÃ©ration

### Budget Ã©puisÃ© ğŸ”¥
- ğŸš« ARRÃŠT TOTAL des dÃ©ploiements
- ğŸ¥ Mode "incident" activÃ©
- ğŸ‘¥ War room quotidien
- ğŸ“Š Analyse root cause
- ğŸ› ï¸ Correction des problÃ¨mes systÃ©miques
```

## Rapport SLO Mensuel

### Template de Rapport

```markdown
# SLO Report - October 2025

## Executive Summary

- âœ… SLO Availability: **99.7%** (Target: 95%)
- âœ… SLO Latency P95: **234ms** (Target: 500ms)
- âš ï¸ SLO Error Rate: **1.2%** (Target: 1%)

## Error Budget

- Budget total: 3.6 heures
- Budget consommÃ©: 1.5 heures (42%)
- Budget restant: 2.1 heures (58%)

**Status: HEALTHY** âœ…

## Incidents

### Oct 20 - Database Outage (30 min)
- **Impact**: 30 minutes downtime
- **Root Cause**: Primary DB node crash
- **Resolution**: Automatic failover to replica
- **Action Items**:
  - [ ] Implement health checks
  - [ ] Tune failover timeout

### Oct 15 - Deployment Rollout Issues (10 min)
- **Impact**: 10 minutes high latency
- **Root Cause**: Insufficient resources during rolling update
- **Resolution**: Increased replica count
- **Action Items**:
  - [ ] Update deployment strategy
  - [ ] Pre-scale before deploys

## Trends

- Availability improving (+0.2% vs last month)
- Latency stable
- Error rate slightly increased (investigation needed)

## Next Month

- Target: Maintain current SLO levels
- Focus: Reduce error rate below 1%
- Project: Implement caching to improve latency
```

### Automatisation du Rapport

**Script Python avec Prometheus API** :

```python
import requests
from datetime import datetime, timedelta

PROMETHEUS_URL = "http://prometheus:9090"

def query_prometheus(query):
    response = requests.get(f"{PROMETHEUS_URL}/api/v1/query", params={'query': query})
    return response.json()['data']['result'][0]['value'][1]

def generate_slo_report():
    # Query SLI metrics
    availability = float(query_prometheus('sli:http_requests:availability:rate30d'))
    latency_p95 = float(query_prometheus('sli:http_request_duration:p95:rate5m'))
    error_rate = float(query_prometheus('sli:http_requests:error_rate:rate5m'))

    # Error budget
    budget_total = 3.6  # hours
    budget_consumed = (1 - availability) * 30 * 24  # hours
    budget_remaining = budget_total - budget_consumed

    # Generate report
    report = f"""
# SLO Report - {datetime.now().strftime('%B %Y')}

## Metrics

- Availability: {availability * 100:.2f}% (Target: 95%)
- Latency P95: {latency_p95 * 1000:.0f}ms (Target: 500ms)
- Error Rate: {error_rate * 100:.2f}% (Target: 1%)

## Error Budget

- Consumed: {budget_consumed:.2f}h / {budget_total}h ({budget_consumed/budget_total*100:.0f}%)
- Remaining: {budget_remaining:.2f}h

## Status

{"âœ… HEALTHY" if budget_remaining > budget_total * 0.5 else "âš ï¸ AT RISK" if budget_remaining > 0 else "ğŸš¨ EXHAUSTED"}
    """

    return report

if __name__ == "__main__":
    print(generate_slo_report())
```

## Bonnes Pratiques

### 1. Commencez Simple

```
âŒ Premier jour: 20 SLO sur 10 services
âœ… Premier mois: 3 SLO sur 1 service critique
```

### 2. BasÃ© sur l'ExpÃ©rience Utilisateur

```
âŒ SLO: "CPU < 80%"  (mÃ©trique interne)
âœ… SLO: "P95 latency < 500ms"  (expÃ©rience utilisateur)
```

### 3. Mesurez Ce Que Vous Pouvez ContrÃ´ler

```
âŒ SLO sur API externe dont vous dÃ©pendez
âœ… SLO sur votre propre service (avec fallbacks si API externe down)
```

### 4. Documentez les SLO

CrÃ©ez un fichier `SLO.md` dans votre repo :

```markdown
# Service Level Objectives - MyApp

## SLO 1: Availability
- **Indicator**: % of HTTP requests returning 2xx/3xx
- **Target**: 95% over 30 days
- **Measurement**: `sli:http_requests:availability:rate30d`
- **Rationale**: Users must be able to access the service
- **Owner**: Team Backend

## SLO 2: Latency
- **Indicator**: P95 of HTTP request duration
- **Target**: < 500ms over 30 days
- **Measurement**: `sli:http_request_duration:p95:rate5m`
- **Rationale**: Users expect fast responses
- **Owner**: Team Backend
```

### 5. Revue RÃ©guliÃ¨re

```
Mensuel:
- Revue des SLO atteints/ratÃ©s
- Ajustement des targets si nÃ©cessaire
- Post-mortem des incidents

Trimestriel:
- RÃ©Ã©valuation des SLI (sont-ils toujours pertinents ?)
- Ajustement de l'error budget policy
```

### 6. Culture, Pas Seulement des MÃ©triques

Les SLO ne sont pas juste des chiffres :

```
âœ… Utilisez les SLO pour prendre des dÃ©cisions
âœ… Partagez les dashboards SLO avec toute l'Ã©quipe
âœ… CÃ©lÃ©brez quand les SLO sont atteints
âœ… Apprenez des violations de SLO (blameless post-mortems)
```

### 7. Ã‰vitez le Perfectionnisme

```
âŒ SLO 99.999% "five nines"
   â†’ CoÃ»t exorbitant
   â†’ Ã‰quipe en burn-out
   â†’ Pas de place pour l'innovation

âœ… SLO 99% "two nines"
   â†’ CoÃ»t raisonnable
   â†’ Ã‰quipe Ã©quilibrÃ©e
   â†’ Budget pour expÃ©rimenter
```

Google dit : "L'objectif n'est pas 100%, c'est l'Ã©quilibre."

## Cas Pratique : Lab Personnel

Voici une configuration rÃ©aliste pour un lab MicroK8s :

### SLO DÃ©finis

```yaml
services:
  - name: grafana
    slos:
      - name: availability
        target: 0.95  # 95%
        window: 30d

      - name: latency_p95
        target: 2.0   # 2 secondes (lab, pas critique)
        window: 30d

  - name: prometheus
    slos:
      - name: availability
        target: 0.95
        window: 30d
```

### Recording Rules

```yaml
groups:
- name: lab_sli
  interval: 1m
  rules:
  - record: sli:blackbox:availability:rate30d
    expr: |
      avg_over_time(probe_success{job="blackbox-http"}[30d])

  - record: sli:blackbox:latency:rate5m
    expr: |
      probe_duration_seconds{job="blackbox-http"}
```

### Dashboard Simple

Trois panneaux :
1. **Uptime** (Gauge) : `sli:blackbox:availability:rate30d * 100`
2. **Latency** (Graph) : `sli:blackbox:latency:rate5m * 1000`
3. **Error Budget** : `(sli:blackbox:availability:rate30d - 0.95) / 0.05 * 100`

## Ce Qu'il Faut Retenir

ğŸ¯ **SLI/SLO = Langage commun** :
- SLI : Comment je mesure (mÃ©trique)
- SLO : Quel niveau je vise (objectif)
- SLA : Engagement contractuel (promesse)

ğŸ“Š **Les 4 Golden Signals** :
- Latency (temps de rÃ©ponse)
- Traffic (charge)
- Errors (taux d'Ã©chec)
- Saturation (utilisation ressources)

ğŸ’° **Error Budget** :
- Budget = Temps d'indisponibilitÃ© acceptable
- Ã‰quilibre innovation vs stabilitÃ©
- Budget Ã©puisÃ© = Focus stabilitÃ©

ğŸ¨ **Dashboard de FiabilitÃ©** :
- SLO summary (gauges)
- Trends (30 jours)
- Error budget (%)
- RÃ©cents incidents

ğŸš¨ **Alerting basÃ© sur SLO** :
- Multi-window multi-burn-rate
- Critical / Warning / Info
- Impact utilisateur, pas symptÃ´mes internes

âœ… **Bonnes pratiques** :
- Commencer simple (1-3 SLO)
- BasÃ© sur l'expÃ©rience utilisateur
- Documentez et partagez
- Revue mensuelle
- Culture, pas juste des chiffres

ğŸ“ˆ **Pour un lab MicroK8s** :
- SLO 95-98% est raisonnable
- Utilisez Blackbox pour synthetic monitoring
- Dashboard simple mais informatif
- Apprenez les concepts pour le futur

---

## Conclusion

Les **SLI/SLO** transforment votre monitoring de "rÃ©actif" (on rÃ©pond aux alertes) Ã  "proactif" (on mesure si on atteint nos objectifs).

**Avant SLI/SLO** :
```
"Le service marche ?"
"Euh... je crois ?"
*Check plein de dashboards*
"Je pense que oui ?"
```

**Avec SLI/SLO** :
```
"Le service marche ?"
"Oui, SLO Ã  99.7%, budget restant: 58%"
"Peut-on dÃ©ployer ?"
"Oui, on a de la marge"
```

**Votre stack d'observabilitÃ© est maintenant complÃ¨te** :

1. âœ… **MÃ©triques** (Prometheus) â†’ Quoi et combien
2. âœ… **Logs** (Loki) â†’ Pourquoi et dÃ©tails
3. âœ… **Traces** (Jaeger) â†’ OÃ¹ et comment (parcours)
4. âœ… **Synthetic** (Blackbox) â†’ Vue utilisateur
5. âœ… **SLI/SLO** â†’ Objectifs et fiabilitÃ©

Vous avez maintenant les outils et les pratiques pour gÃ©rer un cluster Kubernetes avec un **niveau d'observabilitÃ© professionnel**, mÃªme dans un lab personnel ! ğŸ‰ğŸš€

**Prochains chapitres** vous apprendront d'autres aspects avancÃ©s de Kubernetes, mais vous avez maintenant une base solide en observabilitÃ© qui vous servira tout au long de votre parcours Kubernetes.

FÃ©licitations pour avoir complÃ©tÃ© cette section ! ğŸŠ

â­ï¸ [SÃ©curitÃ© Kubernetes](/16-securite-kubernetes/README.md)
