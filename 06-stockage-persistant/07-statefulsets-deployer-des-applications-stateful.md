ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 6.7 StatefulSets : dÃ©ployer des applications stateful

## Introduction

Jusqu'Ã  prÃ©sent, nous avons principalement travaillÃ© avec des **Deployments** pour dÃ©ployer nos applications dans Kubernetes. Les Deployments sont parfaits pour des applications **stateless** (sans Ã©tat), c'est-Ã -dire des applications oÃ¹ chaque instance est interchangeable et oÃ¹ aucune donnÃ©e n'a besoin d'Ãªtre conservÃ©e entre les redÃ©marrages.

Mais que se passe-t-il quand vous avez besoin de dÃ©ployer des applications **stateful** (avec Ã©tat) comme :
- Des bases de donnÃ©es (PostgreSQL, MySQL, MongoDB)
- Des systÃ¨mes de cache distribuÃ©s (Redis, Memcached)
- Des systÃ¨mes de messaging (Kafka, RabbitMQ)
- Des systÃ¨mes de stockage distribuÃ©s (Elasticsearch, Cassandra)

Ces applications ont des besoins spÃ©cifiques :
- Chaque instance a une **identitÃ© unique et stable**
- Chaque instance a besoin de son **propre stockage persistant**
- L'**ordre** de dÃ©marrage et d'arrÃªt est important
- Les instances doivent pouvoir se **retrouver** entre elles de maniÃ¨re prÃ©visible

C'est exactement ce que les **StatefulSets** sont conÃ§us pour gÃ©rer.

## Qu'est-ce qu'un StatefulSet ?

### DÃ©finition

Un **StatefulSet** est un contrÃ´leur Kubernetes spÃ©cialement conÃ§u pour gÃ©rer des applications stateful. Il garantit :

1. **IdentitÃ© stable** : Chaque pod a un nom prÃ©visible et permanent
2. **RÃ©seau stable** : Chaque pod a un nom DNS stable
3. **Stockage stable** : Chaque pod a son propre volume persistant dÃ©diÃ©
4. **Ordre garanti** : DÃ©ploiement et scaling sÃ©quentiels et prÃ©visibles

**Analogie** : Imaginez un orchestre. Dans un Deployment, tous les musiciens sont interchangeables (si l'un part, un autre peut le remplacer sans problÃ¨me). Dans un StatefulSet, chaque musicien a un rÃ´le unique (premier violon, chef d'orchestre, etc.), et on ne peut pas simplement les Ã©changer - chacun a son identitÃ© et sa place spÃ©cifique.

### Pourquoi avons-nous besoin de StatefulSets ?

**ProblÃ¨mes avec les Deployments pour les applications stateful** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DEPLOYMENT (Stateless)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  webapp-7f8d9c-abc12   â”‚  webapp-7f8d9c-def34           â”‚
â”‚  webapp-7f8d9c-ghi56   â”‚  webapp-7f8d9c-jkl78           â”‚
â”‚                                                         â”‚
â”‚  â€¢ Noms alÃ©atoires                                      â”‚
â”‚  â€¢ Interchangeables                                     â”‚
â”‚  â€¢ Pas d'ordre de dÃ©marrage                             â”‚
â”‚  â€¢ Stockage partagÃ© ou aucun                            â”‚
â”‚  â€¢ Parfait pour applications web sans Ã©tat              â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STATEFULSET (Stateful)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  postgres-0  â†’  [Volume-0]                              â”‚
â”‚  postgres-1  â†’  [Volume-1]                              â”‚
â”‚  postgres-2  â†’  [Volume-2]                              â”‚
â”‚                                                         â”‚
â”‚  â€¢ Noms prÃ©visibles (0, 1, 2...)                        â”‚
â”‚  â€¢ IdentitÃ© unique et stable                            â”‚
â”‚  â€¢ Ordre de dÃ©marrage garanti (0â†’1â†’2)                   â”‚
â”‚  â€¢ Chaque pod a son volume dÃ©diÃ©                        â”‚
â”‚  â€¢ Parfait pour bases de donnÃ©es, clusters              â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Deployment vs StatefulSet : Comparaison dÃ©taillÃ©e

| CaractÃ©ristique | Deployment | StatefulSet |
|----------------|------------|-------------|
| **Nom des pods** | AlÃ©atoire (app-xxx-yyy) | OrdonnÃ© (app-0, app-1, app-2) |
| **IdentitÃ©** | Interchangeable | Unique et stable |
| **Nom DNS** | Variable | Stable et prÃ©visible |
| **Ordre de dÃ©ploiement** | ParallÃ¨le | SÃ©quentiel (0â†’1â†’2) |
| **Ordre de suppression** | AlÃ©atoire | Inverse (2â†’1â†’0) |
| **Stockage** | PartagÃ© ou Ã©phÃ©mÃ¨re | DÃ©diÃ© par pod |
| **Persistance aprÃ¨s redÃ©marrage** | Non garantie | Garantie |
| **Scaling** | ParallÃ¨le | SÃ©quentiel |
| **Cas d'usage** | Applications stateless | Applications stateful |

### Exemple concret des diffÃ©rences

**Deployment** :
```bash
# Scaling de 1 Ã  3 replicas
webapp-abc123-xyz    # DÃ©marrÃ© immÃ©diatement
webapp-def456-uvw    # DÃ©marrÃ© immÃ©diatement
webapp-ghi789-rst    # DÃ©marrÃ© immÃ©diatement

# Si un pod meurt et est recrÃ©Ã©
webapp-jkl012-mno    # Nouveau nom alÃ©atoire
```

**StatefulSet** :
```bash
# Scaling de 1 Ã  3 replicas
postgres-0    # DÃ©marrÃ© d'abord
postgres-1    # DÃ©marrÃ© aprÃ¨s que postgres-0 soit Ready
postgres-2    # DÃ©marrÃ© aprÃ¨s que postgres-1 soit Ready

# Si postgres-1 meurt et est recrÃ©Ã©
postgres-1    # MÃªme nom, mÃªme volume, mÃªme DNS
```

## Concepts clÃ©s des StatefulSets

### 1. IdentitÃ© de pod ordonnÃ©e

Chaque pod dans un StatefulSet reÃ§oit un nom dans le format :
```
<statefulset-name>-<ordinal>
```

**Exemple** :
- StatefulSet nommÃ© `mysql` avec 3 replicas
- Pods crÃ©Ã©s : `mysql-0`, `mysql-1`, `mysql-2`

**CaractÃ©ristiques** :
- L'ordinal commence Ã  0
- Les noms ne changent jamais, mÃªme aprÃ¨s redÃ©marrage
- Les pods sont crÃ©Ã©s dans l'ordre (0, puis 1, puis 2, etc.)
- Les pods sont supprimÃ©s dans l'ordre inverse (2, puis 1, puis 0)

### 2. RÃ©seau stable avec Headless Service

Un StatefulSet nÃ©cessite un **Headless Service** pour fournir une identitÃ© rÃ©seau stable Ã  chaque pod.

**Service normal** :
```yaml
apiVersion: v1
kind: Service
metadata:
  name: webapp
spec:
  selector:
    app: webapp
  ports:
  - port: 80
```
**DNS** : `webapp.default.svc.cluster.local` â†’ load balance entre tous les pods

**Headless Service** :
```yaml
apiVersion: v1
kind: Service
metadata:
  name: mysql
spec:
  clusterIP: None    # Headless !
  selector:
    app: mysql
  ports:
  - port: 3306
```

**DNS individuel** :
- `mysql-0.mysql.default.svc.cluster.local` â†’ mysql-0
- `mysql-1.mysql.default.svc.cluster.local` â†’ mysql-1
- `mysql-2.mysql.default.svc.cluster.local` â†’ mysql-2

**Pourquoi c'est important ?**

Les applications stateful ont souvent besoin de communiquer avec des instances spÃ©cifiques :
- Le pod 1 doit se connecter spÃ©cifiquement au pod 0 (master)
- Les pods doivent savoir qui est qui dans le cluster
- Les connexions peer-to-peer nÃ©cessitent des adresses stables

### 3. Stockage persistant avec volumeClaimTemplates

Contrairement aux Deployments oÃ¹ vous rÃ©fÃ©rencez un PVC existant, les StatefulSets utilisent des **volumeClaimTemplates** qui crÃ©ent automatiquement un PVC unique pour chaque pod.

**Deployment** (tous les pods partagent le mÃªme PVC) :
```yaml
volumes:
- name: data
  persistentVolumeClaim:
    claimName: shared-pvc    # PVC existant, partagÃ©
```

**StatefulSet** (chaque pod a son propre PVC) :
```yaml
volumeClaimTemplates:
- metadata:
    name: data
  spec:
    accessModes: [ "ReadWriteOnce" ]
    resources:
      requests:
        storage: 10Gi
# CrÃ©e automatiquement :
# - data-mysql-0 pour mysql-0
# - data-mysql-1 pour mysql-1
# - data-mysql-2 pour mysql-2
```

### 4. Garanties d'ordre

**Au dÃ©ploiement** :
```
1. mysql-0 crÃ©Ã©
2. Attendre que mysql-0 soit Ready
3. mysql-1 crÃ©Ã©
4. Attendre que mysql-1 soit Ready
5. mysql-2 crÃ©Ã©
```

**Au scaling down** (3 â†’ 1) :
```
1. mysql-2 supprimÃ©
2. Attendre que mysql-2 soit complÃ¨tement terminÃ©
3. mysql-1 supprimÃ©
4. Attendre que mysql-1 soit complÃ¨tement terminÃ©
5. mysql-0 reste en cours d'exÃ©cution
```

**Ã€ la mise Ã  jour** :
```
1. Mettre Ã  jour mysql-2
2. Attendre que mysql-2 soit Ready
3. Mettre Ã  jour mysql-1
4. Attendre que mysql-1 soit Ready
5. Mettre Ã  jour mysql-0
```

## Anatomie d'un StatefulSet

Examinons la structure complÃ¨te d'un StatefulSet :

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web
spec:
  serviceName: "web"           # Headless Service associÃ© (REQUIS)
  replicas: 3                  # Nombre de pods
  selector:
    matchLabels:
      app: web
  template:                    # Template de pod (comme dans un Deployment)
    metadata:
      labels:
        app: web
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www            # RÃ©fÃ©rence au volume template
          mountPath: /usr/share/nginx/html
  volumeClaimTemplates:        # Templates de PVC (spÃ©cifique aux StatefulSets)
  - metadata:
      name: www
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "microk8s-hostpath"
      resources:
        requests:
          storage: 1Gi
```

DÃ©cortiquons chaque section :

### serviceName : Le service headless

```yaml
spec:
  serviceName: "web"    # REQUIS - Nom du Headless Service
```

**Points importants** :
- C'est un champ **obligatoire**
- Doit correspondre au nom d'un Headless Service existant
- Fournit l'identitÃ© rÃ©seau stable

### selector : SÃ©lection des pods

```yaml
spec:
  selector:
    matchLabels:
      app: web
```

**Fonction** :
- Identifie les pods gÃ©rÃ©s par ce StatefulSet
- Doit correspondre aux labels dans `template.metadata.labels`
- Immuable aprÃ¨s crÃ©ation

### template : Template de pod

```yaml
spec:
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
        # ... configuration du conteneur
```

**Points clÃ©s** :
- Identique Ã  la section template d'un Deployment
- DÃ©finit la configuration de chaque pod
- Les volumeMounts rÃ©fÃ©rencent les volumeClaimTemplates

### volumeClaimTemplates : Stockage automatique

```yaml
volumeClaimTemplates:
- metadata:
    name: www           # Nom du volume
  spec:
    accessModes: [ "ReadWriteOnce" ]
    storageClassName: "microk8s-hostpath"
    resources:
      requests:
        storage: 1Gi
```

**Comportement** :
- CrÃ©e automatiquement un PVC pour chaque pod
- Format du PVC : `<nom-volume>-<nom-statefulset>-<ordinal>`
- Exemple : `www-web-0`, `www-web-1`, `www-web-2`
- Les PVC persistent mÃªme si le StatefulSet est supprimÃ© (protection des donnÃ©es)

### Champs optionnels importants

#### podManagementPolicy

```yaml
spec:
  podManagementPolicy: OrderedReady    # ou Parallel
```

**OrderedReady** (dÃ©faut) :
- DÃ©ploiement sÃ©quentiel strict
- Attendre que chaque pod soit Ready avant le suivant

**Parallel** :
- DÃ©ploiement parallÃ¨le
- Ne garantit pas l'ordre
- Plus rapide mais moins sÃ»r

#### updateStrategy

```yaml
spec:
  updateStrategy:
    type: RollingUpdate    # ou OnDelete
    rollingUpdate:
      partition: 0         # Pods >= partition sont mis Ã  jour
```

**RollingUpdate** (dÃ©faut) :
- Mise Ã  jour automatique des pods
- Dans l'ordre inverse (n-1 â†’ 0)

**OnDelete** :
- Les pods ne sont mis Ã  jour que quand ils sont supprimÃ©s manuellement
- ContrÃ´le total sur le moment de la mise Ã  jour

## Exemple complet : DÃ©ploiement d'un cluster Redis

Voyons un exemple concret de StatefulSet avec Redis :

```yaml
# Headless Service pour Redis
apiVersion: v1
kind: Service
metadata:
  name: redis
  labels:
    app: redis
spec:
  ports:
  - port: 6379
    name: redis
  clusterIP: None    # Headless !
  selector:
    app: redis
---
# StatefulSet Redis
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
spec:
  serviceName: redis
  replicas: 3
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
          name: redis
        command:
        - redis-server
        args:
        - --appendonly
        - "yes"
        - --dir
        - /data
        volumeMounts:
        - name: data
          mountPath: /data
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          tcpSocket:
            port: 6379
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 5
          periodSeconds: 5
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: microk8s-hostpath
      resources:
        requests:
          storage: 5Gi
```

**DÃ©ploiement** :
```bash
microk8s kubectl apply -f redis-statefulset.yaml
```

**Ce qui est crÃ©Ã©** :

1. **Headless Service** : `redis`
2. **Pods** :
   - `redis-0` avec DNS `redis-0.redis.default.svc.cluster.local`
   - `redis-1` avec DNS `redis-1.redis.default.svc.cluster.local`
   - `redis-2` avec DNS `redis-2.redis.default.svc.cluster.local`
3. **PVCs** :
   - `data-redis-0` (5Gi)
   - `data-redis-1` (5Gi)
   - `data-redis-2` (5Gi)

**Observation du dÃ©ploiement** :
```bash
# Regarder les pods se crÃ©er sÃ©quentiellement
watch microk8s kubectl get pods

# RÃ©sultat :
# redis-0   1/1   Running   (dÃ©marre d'abord)
# redis-1   0/1   Pending   (attend que redis-0 soit Ready)
# ...
# redis-1   1/1   Running   (maintenant dÃ©marre)
# redis-2   0/1   Pending   (attend que redis-1 soit Ready)
# ...
# redis-2   1/1   Running
```

## Exemple complet : Base de donnÃ©es PostgreSQL

Un exemple plus Ã©laborÃ© avec PostgreSQL :

```yaml
# Service Headless
apiVersion: v1
kind: Service
metadata:
  name: postgres
  labels:
    app: postgres
spec:
  ports:
  - port: 5432
    name: postgres
  clusterIP: None
  selector:
    app: postgres
---
# ConfigMap pour la configuration PostgreSQL
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
data:
  postgresql.conf: |
    max_connections = 100
    shared_buffers = 128MB
    effective_cache_size = 256MB
    maintenance_work_mem = 64MB
    checkpoint_completion_target = 0.9
    wal_buffers = 16MB
    default_statistics_target = 100
    random_page_cost = 1.1
    effective_io_concurrency = 200
---
# Secret pour le mot de passe
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
type: Opaque
stringData:
  password: "MySecurePassword123!"
---
# StatefulSet PostgreSQL
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:15-alpine
        ports:
        - containerPort: 5432
          name: postgres
        env:
        - name: POSTGRES_DB
          value: mydb
        - name: POSTGRES_USER
          value: admin
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
        - name: config
          mountPath: /etc/postgresql
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - pg_isready -U admin -d mydb
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - pg_isready -U admin -d mydb
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
      volumes:
      - name: config
        configMap:
          name: postgres-config
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: microk8s-hostpath
      resources:
        requests:
          storage: 20Gi
```

**DÃ©ploiement** :
```bash
microk8s kubectl apply -f postgres-statefulset.yaml
```

**Connexion Ã  PostgreSQL** :
```bash
# Depuis l'intÃ©rieur du cluster
microk8s kubectl run psql-client --rm -it --image=postgres:15-alpine -- \
  psql -h postgres-0.postgres.default.svc.cluster.local -U admin -d mydb

# Port-forward pour accÃ¨s local
microk8s kubectl port-forward postgres-0 5432:5432
psql -h localhost -U admin -d mydb
```

## Gestion des StatefulSets

### DÃ©ployer un StatefulSet

```bash
# CrÃ©er depuis un fichier
microk8s kubectl apply -f statefulset.yaml

# VÃ©rifier le statut
microk8s kubectl get statefulset

# Voir les pods crÃ©Ã©s
microk8s kubectl get pods -l app=<nom-app>

# Voir les PVCs crÃ©Ã©s
microk8s kubectl get pvc
```

### Scaling d'un StatefulSet

#### Scale up (augmenter le nombre de replicas)

```bash
# Via kubectl scale
microk8s kubectl scale statefulset redis --replicas=5

# Ou Ã©diter directement
microk8s kubectl edit statefulset redis
```

**Processus** :
```
redis-0 (existe dÃ©jÃ )
redis-1 (existe dÃ©jÃ )
redis-2 (existe dÃ©jÃ )
redis-3 (crÃ©Ã©, attend d'Ãªtre Ready)
redis-4 (sera crÃ©Ã© aprÃ¨s redis-3)
```

**Observation** :
```bash
# Observer le scaling
watch microk8s kubectl get pods -l app=redis

# Voir les nouveaux PVCs
microk8s kubectl get pvc
```

#### Scale down (rÃ©duire le nombre de replicas)

```bash
# RÃ©duire Ã  2 replicas
microk8s kubectl scale statefulset redis --replicas=2
```

**Processus** :
```
1. redis-4 supprimÃ©
2. Attendre terminaison complÃ¨te
3. redis-3 supprimÃ©
4. Attendre terminaison complÃ¨te
5. redis-2 supprimÃ©
6. redis-0 et redis-1 restent
```

**âš ï¸ Important** : Les PVCs ne sont **pas supprimÃ©s** automatiquement !

```bash
# Les PVCs persistent
microk8s kubectl get pvc
# data-redis-0  (utilisÃ© par redis-0)
# data-redis-1  (utilisÃ© par redis-1)
# data-redis-2  (orphelin, non utilisÃ©)
# data-redis-3  (orphelin, non utilisÃ©)
# data-redis-4  (orphelin, non utilisÃ©)
```

**Nettoyage des PVCs orphelins** :
```bash
# Supprimer manuellement
microk8s kubectl delete pvc data-redis-2 data-redis-3 data-redis-4
```

### Mettre Ã  jour un StatefulSet

#### Rolling Update

Par dÃ©faut, les mises Ã  jour se font pod par pod, dans l'ordre inverse :

```bash
# Mettre Ã  jour l'image
microk8s kubectl set image statefulset/redis redis=redis:7.2-alpine

# Ou Ã©diter
microk8s kubectl edit statefulset redis
```

**Processus (pour 3 replicas)** :
```
1. redis-2 mis Ã  jour (derniÃ¨re ordinal)
2. Attendre que redis-2 soit Ready
3. redis-1 mis Ã  jour
4. Attendre que redis-1 soit Ready
5. redis-0 mis Ã  jour
6. Attendre que redis-0 soit Ready
```

**Observer la mise Ã  jour** :
```bash
# Voir le statut de rollout
microk8s kubectl rollout status statefulset/redis

# Voir l'historique
microk8s kubectl rollout history statefulset/redis
```

#### Mise Ã  jour progressive avec partition

Permet de mettre Ã  jour seulement une partie des pods :

```yaml
spec:
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 2    # Seuls les pods >= 2 seront mis Ã  jour
```

```bash
# Appliquer
microk8s kubectl patch statefulset redis -p '{"spec":{"updateStrategy":{"type":"RollingUpdate","rollingUpdate":{"partition":2}}}}'
```

**RÃ©sultat** :
```
redis-0   (ancienne version, non mis Ã  jour)
redis-1   (ancienne version, non mis Ã  jour)
redis-2   (nouvelle version, mis Ã  jour)
redis-3   (nouvelle version, mis Ã  jour)
```

**Usage** :
- Tester la nouvelle version sur quelques pods
- Rollout progressif contrÃ´lÃ©
- Canary deployments

#### Annuler une mise Ã  jour

```bash
# Annuler le dernier rollout
microk8s kubectl rollout undo statefulset/redis

# Annuler vers une rÃ©vision spÃ©cifique
microk8s kubectl rollout undo statefulset/redis --to-revision=2
```

### Supprimer un StatefulSet

#### Option 1 : Suppression cascade (dÃ©faut)

Supprime le StatefulSet ET les pods :

```bash
microk8s kubectl delete statefulset redis
```

**RÃ©sultat** :
- StatefulSet supprimÃ©
- Pods supprimÃ©s (dans l'ordre inverse : 2â†’1â†’0)
- PVCs **conservÃ©s** (protection des donnÃ©es)

#### Option 2 : Suppression non-cascade

Supprime le StatefulSet mais garde les pods :

```bash
microk8s kubectl delete statefulset redis --cascade=orphan
```

**RÃ©sultat** :
- StatefulSet supprimÃ©
- Pods continuent de fonctionner
- PVCs conservÃ©s

**Usage** : RecrÃ©er le StatefulSet sans perturber les pods en cours.

#### Suppression complÃ¨te (StatefulSet + Pods + PVCs)

```bash
# 1. Supprimer le StatefulSet
microk8s kubectl delete statefulset redis

# 2. Attendre que les pods soient terminÃ©s
microk8s kubectl wait --for=delete pod -l app=redis --timeout=60s

# 3. Supprimer les PVCs
microk8s kubectl delete pvc -l app=redis

# Ou manuellement
microk8s kubectl delete pvc data-redis-0 data-redis-1 data-redis-2
```

## Patterns et cas d'usage

### Pattern 1 : Master-Slave avec PostgreSQL

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 3
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      initContainers:
      - name: init-postgres
        image: postgres:15-alpine
        command:
        - bash
        - "-c"
        - |
          set -ex
          # Si c'est le pod-0 (master)
          if [[ $HOSTNAME =~ -0$ ]]; then
            echo "I am the master"
            # Configuration master
          else
            echo "I am a replica"
            # Configuration rÃ©plica - se connecter au master
            # postgres-0.postgres pour rÃ©plication
          fi
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
      containers:
      - name: postgres
        image: postgres:15-alpine
        # ... (configuration du conteneur)
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
```

**Points clÃ©s** :
- `postgres-0` = Master (Ã©criture)
- `postgres-1`, `postgres-2` = Replicas (lecture)
- Les replicas se connectent au master via `postgres-0.postgres`

### Pattern 2 : Cluster Elasticsearch

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
spec:
  serviceName: elasticsearch
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      initContainers:
      - name: increase-vm-max-map
        image: busybox:1.35
        command:
        - sysctl
        - -w
        - vm.max_map_count=262144
        securityContext:
          privileged: true
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
        env:
        - name: cluster.name
          value: k8s-logs
        - name: cluster.initial_master_nodes
          value: "elasticsearch-0,elasticsearch-1,elasticsearch-2"
        - name: discovery.seed_hosts
          value: "elasticsearch-0.elasticsearch,elasticsearch-1.elasticsearch,elasticsearch-2.elasticsearch"
        - name: ES_JAVA_OPTS
          value: "-Xms512m -Xmx512m"
        - name: xpack.security.enabled
          value: "false"
        ports:
        - containerPort: 9200
          name: http
        - containerPort: 9300
          name: transport
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
        resources:
          limits:
            memory: "1Gi"
            cpu: "1000m"
          requests:
            memory: "512Mi"
            cpu: "500m"
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 10Gi
```

**Points clÃ©s** :
- Cluster de 3 nÅ“uds Elasticsearch
- Chaque nÅ“ud dÃ©couvre les autres via DNS stable
- Formation automatique du cluster

### Pattern 3 : Cache Redis avec rÃ©plication

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
data:
  master.conf: |
    bind 0.0.0.0
    protected-mode no
    port 6379
  slave.conf: |
    bind 0.0.0.0
    protected-mode no
    port 6379
    slaveof redis-0.redis.default.svc.cluster.local 6379
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
spec:
  serviceName: redis
  replicas: 3
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      initContainers:
      - name: config
        image: redis:7-alpine
        command:
        - sh
        - -c
        - |
          if [[ $HOSTNAME =~ -0$ ]]; then
            cp /mnt/master.conf /mnt/redis.conf
          else
            cp /mnt/slave.conf /mnt/redis.conf
          fi
        volumeMounts:
        - name: conf
          mountPath: /mnt
        - name: config
          mountPath: /etc/redis
      containers:
      - name: redis
        image: redis:7-alpine
        command:
        - redis-server
        - /etc/redis/redis.conf
        ports:
        - containerPort: 6379
          name: redis
        volumeMounts:
        - name: data
          mountPath: /data
        - name: config
          mountPath: /etc/redis
      volumes:
      - name: conf
        configMap:
          name: redis-config
      - name: config
        emptyDir: {}
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 5Gi
```

**Points clÃ©s** :
- `redis-0` = Master
- `redis-1`, `redis-2` = Slaves qui rÃ©pliquent depuis `redis-0`
- Configuration diffÃ©rente selon l'ordinal

## Bonnes pratiques

### 1. Toujours crÃ©er un Headless Service

```yaml
# Service requis AVANT le StatefulSet
apiVersion: v1
kind: Service
metadata:
  name: mon-app
spec:
  clusterIP: None    # Headless !
  selector:
    app: mon-app
  ports:
  - port: 8080
```

### 2. DÃ©finir des readiness et liveness probes

```yaml
containers:
- name: postgres
  # ...
  livenessProbe:
    exec:
      command:
      - pg_isready
    initialDelaySeconds: 30
    periodSeconds: 10
  readinessProbe:
    exec:
      command:
      - pg_isready
    initialDelaySeconds: 5
    periodSeconds: 5
```

**Importance** : Les pods suivants ne dÃ©marrent que quand le prÃ©cÃ©dent est **Ready**.

### 3. Utiliser des init containers pour la configuration

```yaml
initContainers:
- name: init-config
  image: busybox:1.35
  command:
  - sh
  - -c
  - |
    # Configuration basÃ©e sur le nom du pod
    if [[ $HOSTNAME =~ -0$ ]]; then
      echo "Configuration master"
    else
      echo "Configuration replica"
    fi
```

### 4. DÃ©finir des ressources appropriÃ©es

```yaml
resources:
  requests:
    memory: "512Mi"
    cpu: "500m"
  limits:
    memory: "1Gi"
    cpu: "1000m"
```

### 5. Utiliser PodDisruptionBudgets

ProtÃ©ger contre les interruptions involontaires :

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: postgres-pdb
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: postgres
```

**Effet** : Garantit qu'au moins 1 pod reste disponible lors de maintenances.

### 6. Nommer clairement les volumeClaimTemplates

```yaml
volumeClaimTemplates:
- metadata:
    name: data    # Sera data-postgres-0, data-postgres-1, etc.
```

### 7. Sauvegarder rÃ©guliÃ¨rement

Les StatefulSets ne protÃ¨gent pas contre :
- Suppression accidentelle des PVCs
- Corruption de donnÃ©es
- Erreurs d'application

**Solution** : Mettez en place des sauvegardes automatiques (voir section 6.6).

### 8. Documenter avec des annotations

```yaml
metadata:
  annotations:
    description: "Cluster PostgreSQL - Master sur pod-0"
    replication: "Streaming replication"
    backup-schedule: "daily at 2AM"
    contact: "dba-team@example.com"
```

## DÃ©pannage des StatefulSets

### ProblÃ¨me 1 : Les pods ne dÃ©marrent pas sÃ©quentiellement

**SymptÃ´mes** :
```bash
$ microk8s kubectl get pods
NAME        READY   STATUS    RESTARTS   AGE
postgres-0  0/1     Pending   0          5m
postgres-1  0/1     Pending   0          5m
```

**Cause** : Le Headless Service n'existe pas ou est mal configurÃ©.

**Solution** :
```bash
# VÃ©rifier le service
microk8s kubectl get service postgres

# VÃ©rifier qu'il est headless
microk8s kubectl get service postgres -o jsonpath='{.spec.clusterIP}'
# Doit retourner: None
```

### ProblÃ¨me 2 : Un pod est bloquÃ© en "Pending"

**Diagnostic** :
```bash
microk8s kubectl describe pod postgres-0
```

**Causes courantes** :
1. PVC ne peut pas Ãªtre crÃ©Ã© (pas de StorageClass, quota dÃ©passÃ©)
2. Ressources insuffisantes sur le nÅ“ud
3. Le pod prÃ©cÃ©dent n'est pas Ready

**Solutions** :
```bash
# VÃ©rifier les PVCs
microk8s kubectl get pvc

# VÃ©rifier les Ã©vÃ©nements
microk8s kubectl get events --sort-by='.lastTimestamp'

# VÃ©rifier le pod prÃ©cÃ©dent
microk8s kubectl get pod postgres-0 -o jsonpath='{.status.conditions}'
```

### ProblÃ¨me 3 : Un pod se redÃ©marre en boucle

**Diagnostic** :
```bash
microk8s kubectl logs postgres-1 --previous
microk8s kubectl describe pod postgres-1
```

**Causes courantes** :
1. ProblÃ¨me de configuration
2. Ne peut pas se connecter au master
3. ProblÃ¨me de permissions sur le volume

**Solution** :
```bash
# VÃ©rifier les logs
microk8s kubectl logs postgres-1

# Tester la connectivitÃ© rÃ©seau
microk8s kubectl exec postgres-1 -- ping postgres-0.postgres
microk8s kubectl exec postgres-1 -- nslookup postgres-0.postgres
```

### ProblÃ¨me 4 : Les PVCs ne sont pas crÃ©Ã©s

**SymptÃ´mes** :
```bash
$ microk8s kubectl get pvc
No resources found
```

**Causes** :
1. StorageClass inexistante ou incorrecte
2. Pas de provisioner configurÃ©

**Solution** :
```bash
# VÃ©rifier les StorageClasses
microk8s kubectl get storageclass

# Pour MicroK8s, activer l'addon
microk8s enable hostpath-storage

# VÃ©rifier le StatefulSet
microk8s kubectl describe statefulset postgres | grep -A5 "Volume Claims"
```

### ProblÃ¨me 5 : Mise Ã  jour bloquÃ©e

**SymptÃ´mes** : Le rollout ne progresse pas.

**Diagnostic** :
```bash
microk8s kubectl rollout status statefulset/postgres
```

**Causes** :
- Un pod ne devient jamais Ready
- Erreur dans la nouvelle version

**Solution** :
```bash
# Voir les pods
microk8s kubectl get pods -l app=postgres

# VÃ©rifier le pod problÃ©matique
microk8s kubectl describe pod postgres-2
microk8s kubectl logs postgres-2

# Annuler le rollout si nÃ©cessaire
microk8s kubectl rollout undo statefulset/postgres
```

## Commandes essentielles pour les StatefulSets

```bash
# CrÃ©er
microk8s kubectl apply -f statefulset.yaml

# Lister
microk8s kubectl get statefulset
microk8s kubectl get sts    # AbrÃ©viation

# DÃ©tails
microk8s kubectl describe statefulset <nom>

# Voir les pods
microk8s kubectl get pods -l app=<nom>

# Scaling
microk8s kubectl scale statefulset <nom> --replicas=5

# Mise Ã  jour
microk8s kubectl set image statefulset/<nom> <container>=<image>

# Rollout status
microk8s kubectl rollout status statefulset/<nom>

# Rollback
microk8s kubectl rollout undo statefulset/<nom>

# Supprimer (garde les PVCs)
microk8s kubectl delete statefulset <nom>

# Supprimer (et les PVCs)
microk8s kubectl delete statefulset <nom>
microk8s kubectl delete pvc -l app=<nom>

# Voir les PVCs
microk8s kubectl get pvc -l app=<nom>

# Exec dans un pod spÃ©cifique
microk8s kubectl exec -it <nom>-0 -- /bin/bash

# Logs
microk8s kubectl logs -f <nom>-0

# Port-forward
microk8s kubectl port-forward <nom>-0 8080:8080
```

## StatefulSets vs Deployments : Quand utiliser quoi ?

### Utilisez un Deployment quand :
- âœ… Application stateless
- âœ… Toutes les instances sont identiques
- âœ… Pas besoin de stockage persistant par instance
- âœ… L'ordre de dÃ©marrage n'importe pas
- âœ… Exemples : API REST, serveurs web, workers

### Utilisez un StatefulSet quand :
- âœ… Application stateful
- âœ… Chaque instance a une identitÃ© unique
- âœ… Besoin de stockage persistant dÃ©diÃ© par instance
- âœ… L'ordre de dÃ©marrage/arrÃªt est important
- âœ… Instances doivent se dÃ©couvrir mutuellement
- âœ… Exemples : bases de donnÃ©es, systÃ¨mes de cache distribuÃ©s, systÃ¨mes de messaging

## Limitations des StatefulSets

### Limitations Ã  connaÃ®tre

1. **Pas de scaling automatique par dÃ©faut**
   - HPA (Horizontal Pod Autoscaler) fonctionne mais avec prÃ©cautions
   - Le scaling automatique d'applications stateful est complexe

2. **Suppression des PVCs manuelle**
   - Les PVCs ne sont jamais supprimÃ©s automatiquement
   - Protection contre la perte de donnÃ©es, mais nÃ©cessite nettoyage manuel

3. **ComplexitÃ© de la migration**
   - DÃ©placer un StatefulSet est plus complexe qu'un Deployment
   - NÃ©cessite planification pour conserver l'identitÃ© et les donnÃ©es

4. **ResponsabilitÃ© de la configuration**
   - Le StatefulSet ne configure pas automatiquement les applications
   - Vous devez gÃ©rer la configuration master/replica vous-mÃªme

5. **Pas de Load Balancing automatique intelligent**
   - Le Headless Service ne fait pas de load balancing
   - Vous devez implÃ©menter la logique de routage (master vs replicas)

## RÃ©sumÃ© visuel : Architecture complÃ¨te

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STATEFULSET                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Headless Service: postgres                          â”‚  â”‚
â”‚  â”‚  clusterIP: None                                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                 â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚          â”‚               â”‚               â”‚                 â”‚
â”‚     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚     â”‚postgres-0â”‚    â”‚postgres-1â”‚    â”‚postgres-2â”‚           â”‚
â”‚     â”‚  Master  â”‚    â”‚ Replica  â”‚    â”‚ Replica  â”‚           â”‚
â”‚     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜           â”‚
â”‚          â”‚               â”‚               â”‚                 â”‚
â”‚     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”            â”‚
â”‚     â”‚PVC-0    â”‚     â”‚PVC-1    â”‚     â”‚PVC-2    â”‚            â”‚
â”‚     â”‚20Gi     â”‚     â”‚20Gi     â”‚     â”‚20Gi     â”‚            â”‚
â”‚     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜            â”‚
â”‚          â”‚               â”‚               â”‚                 â”‚
â”‚     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”            â”‚
â”‚     â”‚PV-0     â”‚     â”‚PV-1     â”‚     â”‚PV-2     â”‚            â”‚
â”‚     â”‚Stockage â”‚     â”‚Stockage â”‚     â”‚Stockage â”‚            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                            â”‚
â”‚  PropriÃ©tÃ©s:                                               â”‚
â”‚  â€¢ Noms stables: postgres-0, postgres-1, postgres-2        â”‚
â”‚  â€¢ DNS stables: postgres-X.postgres.default.svc...         â”‚
â”‚  â€¢ Stockage dÃ©diÃ©: chaque pod a son PVC                    â”‚
â”‚  â€¢ Ordre garanti: 0 â†’ 1 â†’ 2 au dÃ©ploiement                 â”‚
â”‚  â€¢ Ordre inverse: 2 â†’ 1 â†’ 0 Ã  la suppression               â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Conclusion

Les StatefulSets sont un outil puissant pour dÃ©ployer des applications stateful dans Kubernetes. Ils fournissent les garanties nÃ©cessaires pour exÃ©cuter des bases de donnÃ©es, des systÃ¨mes de cache distribuÃ©s et d'autres applications qui nÃ©cessitent :
- Une identitÃ© stable
- Un stockage dÃ©diÃ©
- Un ordre de dÃ©ploiement prÃ©visible

**Points clÃ©s Ã  retenir** :

- Les StatefulSets crÃ©ent des pods avec des identitÃ©s ordonnÃ©es et stables
- Chaque pod a son propre stockage persistant via volumeClaimTemplates
- Un Headless Service est requis pour fournir l'identitÃ© rÃ©seau
- Le dÃ©ploiement et le scaling sont sÃ©quentiels et ordonnÃ©s
- Les PVCs persistent mÃªme aprÃ¨s suppression du StatefulSet
- Parfait pour les bases de donnÃ©es et applications distribuÃ©es

Avec MicroK8s, dÃ©ployer des StatefulSets est simple grÃ¢ce au provisionnement dynamique intÃ©grÃ©. Vous pouvez maintenant exÃ©cuter des applications stateful sophistiquÃ©es dans votre environnement Kubernetes !

---

**Points clÃ©s Ã  retenir** :

âœ… **StatefulSet** = Pour applications stateful nÃ©cessitant identitÃ© stable
âœ… **IdentitÃ© stable** = Noms prÃ©visibles (app-0, app-1, app-2)
âœ… **Headless Service** = Requis pour DNS stable
âœ… **volumeClaimTemplates** = CrÃ©e automatiquement un PVC par pod
âœ… **Ordre garanti** = DÃ©ploiement sÃ©quentiel (0â†’1â†’2)
âœ… **Persistence** = PVCs conservÃ©s mÃªme aprÃ¨s suppression
âœ… **Cas d'usage** = Bases de donnÃ©es, caches distribuÃ©s, systÃ¨mes stateful
âœ… **vs Deployment** = Utilisez StatefulSet quand l'identitÃ© et l'ordre comptent

â­ï¸ [Exemples pratiques (bases de donnÃ©es, etc.)](/06-stockage-persistant/08-exemples-pratiques.md)
