ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 18.3 LimitRanges

## Introduction

Nous avons maintenant couvert deux concepts importants :
- **18.1 - Requests et Limits** : contrÃ´le des ressources au niveau des conteneurs
- **18.2 - Resource Quotas** : contrÃ´le du total des ressources dans un namespace

Mais il manque une piÃ¨ce au puzzle : comment **empÃªcher qu'un seul Pod monopolise tout le quota** d'un namespace ? C'est exactement le rÃ´le des **LimitRanges**.

Les LimitRanges dÃ©finissent des **contraintes par dÃ©faut** et des **valeurs min/max** pour les ressources au niveau individuel (Pod, conteneur, PVC).

## La trilogie complÃ¨te de gestion des ressources

Voici comment ces trois concepts travaillent ensemble :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     NAMESPACE                            â”‚
â”‚                                                          â”‚
â”‚  ResourceQuota: Max total = 10 CPU, 20Gi RAM             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ LimitRange: Par Pod max = 2 CPU, 4Gi RAM           â”‚  â”‚
â”‚  â”‚                                                    â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  â”‚
â”‚  â”‚  â”‚  Pod 1           â”‚  â”‚  Pod 2           â”‚        â”‚  â”‚
â”‚  â”‚  â”‚  â”€â”€â”€â”€â”€â”€          â”‚  â”‚  â”€â”€â”€â”€â”€â”€          â”‚        â”‚  â”‚
â”‚  â”‚  â”‚  Requests/Limits â”‚  â”‚  Requests/Limits â”‚        â”‚  â”‚
â”‚  â”‚  â”‚  500m / 1 CPU    â”‚  â”‚  800m / 1.5 CPU  â”‚        â”‚  â”‚
â”‚  â”‚  â”‚  1Gi / 2Gi       â”‚  â”‚  2Gi / 3Gi       â”‚        â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Niveau 1** - Requests/Limits : Ressources de chaque conteneur
**Niveau 2** - LimitRange : Contraintes par objet (Pod, conteneur, PVC)
**Niveau 3** - ResourceQuota : Budget total du namespace

## Pourquoi les LimitRanges sont-ils nÃ©cessaires ?

### Le problÃ¨me sans LimitRange

Imaginez un namespace avec un Resource Quota de **10 CPU** :

âŒ **Sans LimitRange** :
```yaml
# Quelqu'un crÃ©e ce Pod
apiVersion: v1
kind: Pod
metadata:
  name: pod-gourmand
spec:
  containers:
  - name: app
    image: my-app
    resources:
      requests:
        cpu: "9"        # Monopolise 90% du quota !
        memory: "18Gi"
```

**ConsÃ©quences** :
- Ce Pod unique consomme presque tout le quota
- Les autres Ã©quipes ne peuvent plus dÃ©ployer
- Une seule erreur de configuration bloque tout le namespace

### La solution avec LimitRange

âœ… **Avec LimitRange** :
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: limit-per-pod
spec:
  limits:
  - max:
      cpu: "2"          # Maximum par Pod
      memory: "4Gi"
    type: Pod
```

**RÃ©sultat** :
- Le Pod gourmand serait **refusÃ©** car il dÃ©passe le max
- Impossible de monopoliser le quota accidentellement
- Protection collective du namespace

## Analogie pour comprendre

Pensez Ã  une bibliothÃ¨que publique :

**Sans LimitRange** :
- Une personne pourrait emprunter 50 livres
- Les autres n'auraient plus rien Ã  lire
- MÃªme si la bibliothÃ¨que a 200 livres (quota total)

**Avec LimitRange** :
- Maximum 5 livres par personne (limit)
- Tout le monde peut emprunter Ã©quitablement
- La bibliothÃ¨que reste accessible Ã  tous

Dans Kubernetes :
- **BibliothÃ¨que** = Namespace
- **Total des livres** = ResourceQuota
- **Limite par personne** = LimitRange
- **Livres empruntÃ©s** = Requests/Limits des Pods

## Types de LimitRange

Un LimitRange peut contrÃ´ler trois types d'objets :

### 1. Container (Conteneur)

Contraintes appliquÃ©es Ã  **chaque conteneur individuellement**.

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: container-limits
  namespace: dev
spec:
  limits:
  - type: Container
    max:
      cpu: "2"
      memory: "2Gi"
    min:
      cpu: "100m"
      memory: "128Mi"
    default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "250m"
      memory: "256Mi"
```

**Champs disponibles** :
- `max` : Valeur maximum autorisÃ©e
- `min` : Valeur minimum requise
- `default` : Valeur par dÃ©faut pour les **limits** si non spÃ©cifiÃ©es
- `defaultRequest` : Valeur par dÃ©faut pour les **requests** si non spÃ©cifiÃ©es

### 2. Pod

Contraintes appliquÃ©es au **total de tous les conteneurs d'un Pod**.

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: pod-limits
  namespace: dev
spec:
  limits:
  - type: Pod
    max:
      cpu: "4"
      memory: "8Gi"
    min:
      cpu: "200m"
      memory: "256Mi"
```

**Important** : C'est la **somme** des ressources de tous les conteneurs du Pod qui est vÃ©rifiÃ©e.

### 3. PersistentVolumeClaim (PVC)

Contraintes pour les demandes de stockage persistant.

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: storage-limits
  namespace: dev
spec:
  limits:
  - type: PersistentVolumeClaim
    max:
      storage: "10Gi"
    min:
      storage: "1Gi"
```

## Configuration complÃ¨te

### Exemple 1 : LimitRange de base pour conteneurs

Configuration simple pour un environnement de dÃ©veloppement :

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: dev-limits
  namespace: development
spec:
  limits:
  - type: Container
    max:
      cpu: "1"
      memory: "1Gi"
    min:
      cpu: "50m"
      memory: "64Mi"
    default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "100m"
      memory: "128Mi"
```

**Ce que cela signifie** :
- Aucun conteneur ne peut demander plus de 1 CPU / 1Gi
- Aucun conteneur ne peut demander moins de 50m CPU / 64Mi
- Si pas spÃ©cifiÃ©, limits = 500m CPU / 512Mi
- Si pas spÃ©cifiÃ©, requests = 100m CPU / 128Mi

**Appliquer** :
```bash
kubectl apply -f dev-limits.yaml
```

### Exemple 2 : LimitRange complet (Container + Pod)

Protection Ã  deux niveaux :

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: multi-level-limits
  namespace: production
spec:
  limits:
  # Niveau conteneur
  - type: Container
    max:
      cpu: "2"
      memory: "4Gi"
    min:
      cpu: "100m"
      memory: "128Mi"
    default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "250m"
      memory: "256Mi"
  # Niveau Pod (somme de tous les conteneurs)
  - type: Pod
    max:
      cpu: "4"
      memory: "8Gi"
    min:
      cpu: "200m"
      memory: "256Mi"
```

**Validation** :
- Un conteneur seul : max 2 CPU / 4Gi
- Un Pod entier : max 4 CPU / 8Gi (permet 2 conteneurs de 2 CPU chacun)

### Exemple 3 : Environnement avec stockage contrÃ´lÃ©

Inclure des limites sur les PVC :

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: complete-limits
  namespace: data-team
spec:
  limits:
  # Conteneurs
  - type: Container
    max:
      cpu: "2"
      memory: "4Gi"
    defaultRequest:
      cpu: "500m"
      memory: "512Mi"

  # Pods
  - type: Pod
    max:
      cpu: "6"
      memory: "12Gi"

  # Stockage persistant
  - type: PersistentVolumeClaim
    max:
      storage: "50Gi"
    min:
      storage: "1Gi"
```

### Exemple 4 : Ratio limits/requests

ContrÃ´ler le ratio entre requests et limits :

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: ratio-control
  namespace: my-namespace
spec:
  limits:
  - type: Container
    maxLimitRequestRatio:
      cpu: "4"        # Limits CPU max = 4x requests
      memory: "2"     # Limits memory max = 2x requests
```

**Validation** :
- âœ… Requests: 500m, Limits: 2000m (ratio 4:1) â†’ OK
- âŒ Requests: 500m, Limits: 3000m (ratio 6:1) â†’ REFUSÃ‰
- âœ… Requests: 1Gi, Limits: 2Gi (ratio 2:1) â†’ OK
- âŒ Requests: 1Gi, Limits: 3Gi (ratio 3:1) â†’ REFUSÃ‰

## Comment Ã§a fonctionne en pratique

### ScÃ©nario 1 : Pod sans resources dÃ©finies

**Sans LimitRange** :
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - name: nginx
    image: nginx
    # Pas de resources - problÃ¨me si ResourceQuota existe !
```

Ce Pod serait **refusÃ©** s'il y a un ResourceQuota.

**Avec LimitRange** :
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: defaults
spec:
  limits:
  - type: Container
    default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "250m"
      memory: "256Mi"
```

Le mÃªme Pod serait **acceptÃ©** avec les valeurs par dÃ©faut appliquÃ©es automatiquement :
```yaml
# Pod rÃ©el crÃ©Ã© par Kubernetes
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - name: nginx
    image: nginx
    resources:
      requests:
        cpu: "250m"
        memory: "256Mi"
      limits:
        cpu: "500m"
        memory: "512Mi"
```

C'est **automatique** ! Vous n'avez rien Ã  faire.

### ScÃ©nario 2 : Pod avec des valeurs trop Ã©levÃ©es

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: big-pod
  namespace: dev
spec:
  containers:
  - name: app
    image: my-app
    resources:
      requests:
        cpu: "5"          # Trop !
        memory: "10Gi"    # Trop !
```

**Avec LimitRange** :
```yaml
spec:
  limits:
  - type: Container
    max:
      cpu: "2"
      memory: "4Gi"
```

**RÃ©sultat** :
```
Error from server (Forbidden): error when creating "big-pod.yaml":
pods "big-pod" is forbidden: maximum cpu usage per Container is 2, but request is 5
```

Le Pod est **rejetÃ©** immÃ©diatement.

### ScÃ©nario 3 : Pod avec des valeurs trop basses

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: tiny-pod
spec:
  containers:
  - name: app
    image: my-app
    resources:
      requests:
        cpu: "10m"       # Trop petit
        memory: "32Mi"   # Trop petit
```

**Avec LimitRange** :
```yaml
spec:
  limits:
  - type: Container
    min:
      cpu: "100m"
      memory: "128Mi"
```

**RÃ©sultat** :
```
Error from server (Forbidden): error when creating "tiny-pod.yaml":
pods "tiny-pod" is forbidden: minimum memory usage per Container is 128Mi, but request is 32Mi
```

Le Pod est **rejetÃ©** car trop petit.

### ScÃ©nario 4 : Pod multi-conteneurs

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-pod
spec:
  containers:
  - name: app
    image: my-app
    resources:
      requests:
        cpu: "1"
        memory: "2Gi"
  - name: sidecar
    image: nginx
    resources:
      requests:
        cpu: "500m"
        memory: "1Gi"
  # Total Pod = 1.5 CPU, 3Gi RAM
```

**Avec LimitRange** :
```yaml
spec:
  limits:
  - type: Container
    max:
      cpu: "2"
      memory: "4Gi"
  - type: Pod
    max:
      cpu: "4"
      memory: "8Gi"
```

**Validation** :
- âœ… Chaque conteneur < 2 CPU / 4Gi â†’ OK
- âœ… Total Pod (1.5 CPU / 3Gi) < 4 CPU / 8Gi â†’ OK
- Pod **acceptÃ©**

## Combinaison avec Resource Quotas

Les LimitRanges et Resource Quotas travaillent ensemble :

```yaml
# 1. Resource Quota : budget total du namespace
apiVersion: v1
kind: ResourceQuota
metadata:
  name: team-quota
  namespace: my-team
spec:
  hard:
    requests.cpu: "20"
    requests.memory: "40Gi"
    limits.cpu: "40"
    limits.memory: "80Gi"
---
# 2. LimitRange : contraintes individuelles
apiVersion: v1
kind: LimitRange
metadata:
  name: team-limits
  namespace: my-team
spec:
  limits:
  # Niveau conteneur
  - type: Container
    max:
      cpu: "2"
      memory: "4Gi"
    defaultRequest:
      cpu: "500m"
      memory: "512Mi"
  # Niveau Pod
  - type: Pod
    max:
      cpu: "4"
      memory: "8Gi"
```

**ScÃ©nario** :
- Quota total : 20 CPU requests
- Max par Pod : 4 CPU
- Minimum de Pods possibles : 5 Pods (5 Ã— 4 = 20)
- Maximum de Pods possibles : 40 Pods (40 Ã— 500m = 20)

**Protection Ã  deux niveaux** :
1. LimitRange empÃªche un Pod de monopoliser le quota
2. ResourceQuota empÃªche le namespace de dÃ©passer ses limites

## Valeurs par dÃ©faut intelligentes

Les LimitRanges permettent d'avoir des **valeurs par dÃ©faut sensÃ©es** sans forcer les dÃ©veloppeurs Ã  toujours spÃ©cifier les resources.

### Pattern : Defaults pour dÃ©veloppeurs paresseux

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: dev-defaults
  namespace: development
spec:
  limits:
  - type: Container
    # Valeurs par dÃ©faut raisonnables
    default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "250m"
      memory: "256Mi"
    # Mais possibilitÃ© d'aller plus haut si besoin
    max:
      cpu: "2"
      memory: "4Gi"
```

**Avantages** :
- Les dÃ©veloppeurs peuvent dÃ©ployer rapidement sans se soucier des resources
- Les valeurs par dÃ©faut sont raisonnables
- Protection contre les abus avec les max
- PossibilitÃ© d'optimiser manuellement si besoin

### Pattern : Strict en production

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: prod-limits
  namespace: production
spec:
  limits:
  - type: Container
    # Pas de defaults - force la spÃ©cification manuelle
    max:
      cpu: "4"
      memory: "8Gi"
    min:
      cpu: "100m"
      memory: "128Mi"
```

**Philosophie** :
- En production, les Ã©quipes **doivent** spÃ©cifier explicitement les resources
- Pas de valeurs par dÃ©faut = configuration consciente et rÃ©flÃ©chie
- Ã‰vite les dÃ©ploiements accidentels mal dimensionnÃ©s

## Exemples par type d'environnement

### Environnement Development

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: development-limits
  namespace: development
spec:
  limits:
  - type: Container
    max:
      cpu: "1"
      memory: "2Gi"
    min:
      cpu: "50m"
      memory: "64Mi"
    default:
      cpu: "200m"
      memory: "256Mi"
    defaultRequest:
      cpu: "100m"
      memory: "128Mi"
  - type: Pod
    max:
      cpu: "2"
      memory: "4Gi"
  - type: PersistentVolumeClaim
    max:
      storage: "5Gi"
    min:
      storage: "1Gi"
```

**CaractÃ©ristiques** :
- Limites basses (Ã©conomie de ressources)
- Defaults gÃ©nÃ©reux pour faciliter le travail
- Stockage limitÃ©

### Environnement Staging

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: staging-limits
  namespace: staging
spec:
  limits:
  - type: Container
    max:
      cpu: "2"
      memory: "4Gi"
    min:
      cpu: "100m"
      memory: "128Mi"
    default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "250m"
      memory: "256Mi"
  - type: Pod
    max:
      cpu: "4"
      memory: "8Gi"
  - type: PersistentVolumeClaim
    max:
      storage: "20Gi"
```

**CaractÃ©ristiques** :
- Limites moyennes (proche de la prod)
- Defaults raisonnables
- Plus de stockage que dev

### Environnement Production

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: production-limits
  namespace: production
spec:
  limits:
  - type: Container
    max:
      cpu: "4"
      memory: "8Gi"
    min:
      cpu: "100m"
      memory: "256Mi"
    # Pas de defaults en prod !
    maxLimitRequestRatio:
      cpu: "2"         # Limite le ratio
      memory: "2"
  - type: Pod
    max:
      cpu: "8"
      memory: "16Gi"
  - type: PersistentVolumeClaim
    max:
      storage: "100Gi"
    min:
      storage: "5Gi"
```

**CaractÃ©ristiques** :
- Limites Ã©levÃ©es (applications critiques)
- Pas de defaults (spÃ©cification explicite)
- Ratio contrÃ´lÃ© (Ã©vite les sur-allocations)
- Stockage gÃ©nÃ©reux

## Commandes utiles

### Lister les LimitRanges

```bash
# Tous les LimitRanges du cluster
kubectl get limitrange --all-namespaces

# LimitRanges d'un namespace
kubectl get limitrange -n dev

# Alias court
kubectl get limits -n dev
```

### Voir les dÃ©tails

```bash
kubectl describe limitrange dev-limits -n dev
```

RÃ©sultat :
```
Name:       dev-limits
Namespace:  dev
Type        Resource  Min   Max  Default Request  Default Limit
----        --------  ---   ---  ---------------  -------------
Container   cpu       50m   1    100m             200m
Container   memory    64Mi  2Gi  128Mi            256Mi
Pod         cpu       -     2    -                -
Pod         memory    -     4Gi  -                -
```

### VÃ©rifier l'impact sur un Pod

```bash
# CrÃ©er un Pod et voir les resources appliquÃ©es
kubectl apply -f my-pod.yaml -n dev

# VÃ©rifier les resources
kubectl get pod my-pod -n dev -o jsonpath='{.spec.containers[0].resources}'
```

### Modifier un LimitRange

```bash
# Ã‰diter directement
kubectl edit limitrange dev-limits -n dev

# Ou rÃ©appliquer le fichier modifiÃ©
kubectl apply -f dev-limits-updated.yaml
```

### Supprimer un LimitRange

```bash
kubectl delete limitrange dev-limits -n dev
```

âš ï¸ **Attention** : Supprimer un LimitRange n'affecte pas les Pods existants, mais les nouveaux Pods n'auront plus les contraintes.

## Bonnes pratiques

### 1. Toujours avoir un LimitRange par namespace

âœ… **Recommandation** : Chaque namespace devrait avoir un LimitRange, sauf `kube-system`.

```yaml
# Template minimal
apiVersion: v1
kind: LimitRange
metadata:
  name: namespace-defaults
  namespace: <YOUR-NAMESPACE>
spec:
  limits:
  - type: Container
    default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "250m"
      memory: "256Mi"
```

### 2. Defaults en dev, pas en prod

âœ… **Pattern recommandÃ©** :

**Development** : Avec defaults (facilite le travail)
```yaml
default:
  cpu: "500m"
  memory: "512Mi"
```

**Production** : Sans defaults (force la rÃ©flexion)
```yaml
# Pas de section default/defaultRequest
max:
  cpu: "4"
  memory: "8Gi"
```

### 3. Ratio raisonnable entre min et max

âœ… **Bon ratio** :
```yaml
min:
  cpu: "100m"
  memory: "128Mi"
max:
  cpu: "2"        # 20x le min
  memory: "4Gi"   # 32x le min
```

âŒ **Mauvais ratio** :
```yaml
min:
  cpu: "10m"
  memory: "16Mi"
max:
  cpu: "16"       # 1600x le min - trop large !
  memory: "64Gi"  # 4096x le min - trop large !
```

Un ratio trop large rend les contraintes inefficaces.

### 4. Limites Pod cohÃ©rentes avec limites Container

âœ… **Configuration cohÃ©rente** :
```yaml
- type: Container
  max:
    cpu: "2"
    memory: "4Gi"
- type: Pod
  max:
    cpu: "6"        # Permet 3 conteneurs de 2 CPU
    memory: "12Gi"  # Permet 3 conteneurs de 4Gi
```

âŒ **Configuration incohÃ©rente** :
```yaml
- type: Container
  max:
    cpu: "4"
    memory: "8Gi"
- type: Pod
  max:
    cpu: "2"        # Impossible ! Un conteneur seul dÃ©passe
    memory: "4Gi"   # Impossible !
```

### 5. ContrÃ´ler le ratio limits/requests

âœ… **EmpÃªcher les sur-allocations** :
```yaml
- type: Container
  maxLimitRequestRatio:
    cpu: "2"      # Limits max = 2x requests
    memory: "2"
```

Cela Ã©vite des configurations comme :
- Requests: 100m, Limits: 8000m (ratio 80:1) âŒ
- Encourage des configurations rÃ©alistes

### 6. Documenter les LimitRanges

âœ… **Ajouter des annotations** :
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: dev-limits
  namespace: development
  annotations:
    description: "Limites pour l'environnement de dÃ©veloppement"
    contact: "platform-team@company.com"
    last-review: "2025-10-01"
spec:
  limits: [...]
```

### 7. Tester avant d'appliquer

âœ… **Processus de test** :

1. CrÃ©er le LimitRange dans un namespace de test
2. DÃ©ployer des Pods typiques
3. VÃ©rifier qu'ils sont acceptÃ©s
4. VÃ©rifier que les Pods abusifs sont rejetÃ©s
5. Appliquer dans les namespaces rÃ©els

### 8. Adapter aux workloads

âœ… **DiffÃ©rencier selon le type d'application** :

**Namespace frontend** (apps lÃ©gÃ¨res) :
```yaml
max:
  cpu: "1"
  memory: "2Gi"
```

**Namespace backend** (apps moyennes) :
```yaml
max:
  cpu: "2"
  memory: "4Gi"
```

**Namespace data** (apps lourdes) :
```yaml
max:
  cpu: "8"
  memory: "16Gi"
```

## Diagnostic et dÃ©pannage

### ProblÃ¨me 1 : Pod refusÃ© Ã  cause du max

**SymptÃ´me** :
```bash
kubectl apply -f my-pod.yaml -n dev
# Error: maximum cpu usage per Container is 2, but request is 4
```

**Diagnostic** :
```bash
# Voir les LimitRanges
kubectl describe limitrange -n dev

# Voir les resources du Pod
kubectl describe -f my-pod.yaml | grep -A10 "Containers:"
```

**Solutions** :
1. RÃ©duire les resources du Pod
2. Augmenter le max du LimitRange (si justifiÃ©)
3. Utiliser un namespace diffÃ©rent avec des limites plus Ã©levÃ©es

### ProblÃ¨me 2 : Pod refusÃ© Ã  cause du min

**SymptÃ´me** :
```
Error: minimum memory usage per Container is 256Mi, but request is 128Mi
```

**Cause** : Les requests du Pod sont trop basses.

**Solutions** :
1. Augmenter les requests du Pod
2. RÃ©duire le min du LimitRange (si justifiÃ©)

### ProblÃ¨me 3 : Pod multi-conteneurs refusÃ©

**SymptÃ´me** :
```
Error: maximum cpu usage per Pod is 4, but request is 5
```

**Cause** : La somme des conteneurs dÃ©passe le max Pod.

**Exemple** :
```yaml
spec:
  containers:
  - name: app
    resources:
      requests:
        cpu: "3"     # 3 CPU
  - name: sidecar
    resources:
      requests:
        cpu: "2"     # 2 CPU
  # Total = 5 CPU > max Pod (4 CPU)
```

**Solutions** :
1. RÃ©duire les resources de certains conteneurs
2. SÃ©parer en plusieurs Pods
3. Augmenter le max Pod du LimitRange

### ProblÃ¨me 4 : Ratio refusÃ©

**SymptÃ´me** :
```
Error: cpu max limit to request ratio per Container is 2, but provided ratio is 4
```

**Cause** :
```yaml
resources:
  requests:
    cpu: "500m"
  limits:
    cpu: "2"      # Ratio 4:1 mais max autorisÃ© = 2:1
```

**Solutions** :
1. RÃ©duire les limits : `cpu: "1"` (ratio 2:1)
2. Augmenter les requests : `cpu: "1"` (ratio 2:1)
3. Modifier le maxLimitRequestRatio du LimitRange

### ProblÃ¨me 5 : PVC refusÃ©

**SymptÃ´me** :
```
Error: maximum storage usage per PersistentVolumeClaim is 10Gi, but request is 50Gi
```

**Diagnostic** :
```bash
kubectl describe limitrange -n dev | grep -A5 "PersistentVolumeClaim"
```

**Solutions** :
1. RÃ©duire le storage demandÃ©
2. Augmenter le max storage du LimitRange
3. CrÃ©er le PVC dans un autre namespace

## Cas d'usage avancÃ©s

### Cas 1 : Cluster multi-tenant

Chaque Ã©quipe a des besoins diffÃ©rents :

```yaml
# Ã‰quipe Frontend
apiVersion: v1
kind: LimitRange
metadata:
  name: frontend-limits
  namespace: team-frontend
spec:
  limits:
  - type: Container
    max:
      cpu: "1"
      memory: "2Gi"
---
# Ã‰quipe Backend
apiVersion: v1
kind: LimitRange
metadata:
  name: backend-limits
  namespace: team-backend
spec:
  limits:
  - type: Container
    max:
      cpu: "2"
      memory: "4Gi"
---
# Ã‰quipe Data
apiVersion: v1
kind: LimitRange
metadata:
  name: data-limits
  namespace: team-data
spec:
  limits:
  - type: Container
    max:
      cpu: "8"
      memory: "16Gi"
```

### Cas 2 : Review apps temporaires

Applications Ã©phÃ©mÃ¨res avec limites strictes :

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: review-limits
  namespace: review-apps
spec:
  limits:
  - type: Container
    max:
      cpu: "500m"
      memory: "1Gi"
    default:
      cpu: "250m"
      memory: "512Mi"
    defaultRequest:
      cpu: "100m"
      memory: "256Mi"
  - type: Pod
    max:
      cpu: "1"
      memory: "2Gi"
  - type: PersistentVolumeClaim
    max:
      storage: "2Gi"  # Stockage limitÃ©
```

### Cas 3 : Environnement de formation

Pour des labs Kubernetes :

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: training-limits
  namespace: training
spec:
  limits:
  - type: Container
    max:
      cpu: "500m"
      memory: "512Mi"
    default:
      cpu: "100m"
      memory: "128Mi"
    defaultRequest:
      cpu: "50m"
      memory: "64Mi"
  - type: Pod
    max:
      cpu: "1"
      memory: "1Gi"
```

**Objectif** : Permettre Ã  de nombreux Ã©tudiants de travailler simultanÃ©ment.

## Points clÃ©s Ã  retenir

ğŸ”‘ **Les essentiels** :

1. **LimitRange** = contraintes min/max par objet individuel
2. **Trois niveaux** : Container, Pod, PersistentVolumeClaim
3. **Valeurs par dÃ©faut** automatiques si non spÃ©cifiÃ©es
4. **ComplÃ¨te** les Resource Quotas (total namespace)
5. **EmpÃªche** qu'un objet monopolise le quota
6. **Un seul LimitRange** par namespace (peut avoir plusieurs sections)
7. **DÃ©faults en dev**, pas en prod (bonne pratique)
8. **CohÃ©rence** entre limites Container et Pod

## La hiÃ©rarchie complÃ¨te

Voici comment tous les concepts s'imbriquent :

```
CLUSTER
â”‚
â”œâ”€ NAMESPACE A
â”‚  â”œâ”€ ResourceQuota: 20 CPU total
â”‚  â”œâ”€ LimitRange: max 4 CPU/Pod, defaults 500m
â”‚  â”‚
â”‚  â”œâ”€ Pod 1 (uses defaults)
â”‚  â”‚  â””â”€ Container: 500m CPU (default applied)
â”‚  â”‚
â”‚  â”œâ”€ Pod 2 (explicit values)
â”‚  â”‚  â””â”€ Container: 2 CPU (explicit)
â”‚  â”‚
â”‚  â””â”€ Pod 3 (rejected)
â”‚     â””â”€ Container: 5 CPU (exceeds LimitRange max)
â”‚
â””â”€ NAMESPACE B
   â”œâ”€ ResourceQuota: 10 CPU total
   â”œâ”€ LimitRange: max 2 CPU/Pod
   â””â”€ ...
```

**Ordre de validation** :
1. LimitRange vÃ©rifie les valeurs individuelles
2. ResourceQuota vÃ©rifie le total du namespace
3. Les deux doivent Ãªtre satisfaits pour accepter le Pod

## Conclusion

Les LimitRanges sont la **clÃ© de voÃ»te** d'une bonne gouvernance des ressources dans Kubernetes. Ils complÃ¨tent parfaitement les Requests/Limits et les Resource Quotas pour offrir un systÃ¨me complet de contrÃ´le.

**En rÃ©sumÃ©** :
- **Requests/Limits** (18.1) : Que demande chaque conteneur ?
- **Resource Quotas** (18.2) : Combien peut consommer tout le namespace ?
- **LimitRanges** (18.3) : Quelles sont les bornes acceptables ?

Ensemble, ces trois mÃ©canismes assurent :
- âœ… StabilitÃ© du cluster
- âœ… Ã‰quitÃ© entre les Ã©quipes
- âœ… PrÃ©visibilitÃ© des coÃ»ts
- âœ… Protection contre les erreurs de configuration

**Prochaine Ã©tape** : Dans la section suivante (18.4), nous verrons les **QoS Classes** qui dÃ©terminent comment Kubernetes priorise les Pods en cas de pression sur les ressources.

---


â­ï¸ [QoS Classes](/18-gestion-des-ressources/04-qos-classes.md)
