ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 18.4 QoS Classes

## Introduction

Nous avons maintenant couvert tous les mÃ©canismes de configuration des ressources :
- **18.1 - Requests et Limits** : dÃ©finir les ressources des conteneurs
- **18.2 - Resource Quotas** : limiter le total d'un namespace
- **18.3 - LimitRanges** : contraindre les valeurs individuelles

Mais que se passe-t-il quand un nÅ“ud Kubernetes manque de ressources ? Quels Pods sont sacrifiÃ©s en premier ? C'est ici qu'interviennent les **QoS Classes** (Quality of Service Classes).

Les QoS Classes sont un systÃ¨me de **prioritÃ© automatique** que Kubernetes attribue Ã  chaque Pod en fonction de la faÃ§on dont vous dÃ©finissez ses requests et limits. Ce n'est pas quelque chose que vous configurez directement - c'est **calculÃ© automatiquement** par Kubernetes.

## Qu'est-ce qu'une QoS Class ?

Une QoS Class (Classe de QualitÃ© de Service) est une **Ã©tiquette de prioritÃ©** que Kubernetes assigne automatiquement Ã  chaque Pod. Cette Ã©tiquette dÃ©termine **l'ordre dans lequel les Pods seront Ã©vincÃ©s** (tuÃ©s) si le nÅ“ud manque de ressources.

**Analogie** : Pensez Ã  un bateau qui prend l'eau et coule lentement.

Le capitaine doit dÃ©cider qui Ã©vacuer en premier :
- **Passagers VIP** (billets premiÃ¨re classe) : Ã©vacuÃ©s en dernier - **Guaranteed**
- **Passagers standard** (billets Ã©conomiques) : Ã©vacuÃ©s en milieu - **Burstable**
- **Passagers clandestins** (sans billet) : Ã©vacuÃ©s en premier - **BestEffort**

Dans Kubernetes :
- **Bateau** = NÅ“ud Kubernetes
- **Eau qui monte** = Pression sur les ressources (RAM, CPU)
- **Passagers** = Pods
- **Ordre d'Ã©vacuation** = Ordre d'Ã©viction des Pods

## Pourquoi les QoS Classes sont-elles importantes ?

### Le problÃ¨me : Pression sur les ressources

Imaginons un nÅ“ud avec 16 Gi de RAM qui hÃ©berge plusieurs Pods. Si la consommation totale de RAM approche 16 Gi, le nÅ“ud entre en **pression mÃ©moire** (memory pressure).

**Que fait Kubernetes ?**

Il doit **tuer des Pods** pour libÃ©rer de la RAM et Ã©viter que le nÅ“ud entier ne plante. Mais lesquels ?

âŒ **Sans systÃ¨me de prioritÃ©** :
- Kubernetes tue des Pods au hasard
- Risque de tuer des Pods critiques
- InstabilitÃ© imprÃ©visible

âœ… **Avec QoS Classes** :
- Kubernetes tue d'abord les Pods moins critiques (BestEffort)
- Puis les Pods moyennement critiques (Burstable)
- En dernier les Pods critiques (Guaranteed)
- PrÃ©dictibilitÃ© et stabilitÃ©

## Les trois QoS Classes

Kubernetes dÃ©finit exactement **trois classes** de QoS, de la moins prioritaire Ã  la plus prioritaire :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Ordre d'Ã©viction (Memory Pressure)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  1ï¸âƒ£  BestEffort    â†  TuÃ©s en PREMIER                  â”‚
â”‚      (PrioritÃ© la plus basse)                           â”‚
â”‚                                                         â”‚
â”‚  2ï¸âƒ£  Burstable     â†  TuÃ©s en DEUXIÃˆME                 â”‚
â”‚      (PrioritÃ© moyenne)                                 â”‚
â”‚                                                         â”‚
â”‚  3ï¸âƒ£  Guaranteed    â†  TuÃ©s en DERNIER                  â”‚
â”‚      (PrioritÃ© la plus haute)                           â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Vue d'ensemble des classes

| QoS Class | PrioritÃ© | Conditions | Usage recommandÃ© |
|-----------|----------|------------|------------------|
| **BestEffort** | ğŸ”´ Basse | Aucune requests/limits | Tests, jamais en prod |
| **Burstable** | ğŸŸ¡ Moyenne | Requests â‰  Limits | Cas gÃ©nÃ©ral |
| **Guaranteed** | ğŸŸ¢ Haute | Requests = Limits | Applications critiques |

## 1. BestEffort - La classe la plus basse

### Conditions pour Ãªtre BestEffort

Un Pod est classÃ© **BestEffort** quand **aucun** de ses conteneurs ne dÃ©finit de requests ni de limits pour CPU et mÃ©moire.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: besteffort-pod
spec:
  containers:
  - name: nginx
    image: nginx
    # Aucune section resources - BestEffort !
```

### CaractÃ©ristiques

**Avantages** :
- ğŸŸ¢ Simple (pas besoin de dÃ©finir les resources)
- ğŸŸ¢ Peut utiliser toutes les ressources disponibles sur le nÅ“ud
- ğŸŸ¢ Flexible

**InconvÃ©nients** :
- ğŸ”´ **Premier Ã  Ãªtre tuÃ©** en cas de pression mÃ©moire
- ğŸ”´ Aucune garantie de ressources
- ğŸ”´ Performances imprÃ©visibles
- ğŸ”´ Peut Ãªtre Ã©jectÃ© Ã  tout moment

### Comportement en cas de pression mÃ©moire

Quand un nÅ“ud manque de RAM :
1. Kubernetes identifie tous les Pods BestEffort
2. Calcule quel Pod BestEffort consomme le plus
3. **Tue ce Pod en premier**
4. Continue jusqu'Ã  ce que la pression disparaisse

**SchÃ©ma** :
```
NÅ“ud en pression mÃ©moire (95% RAM utilisÃ©e)
â”‚
â”œâ”€ Pod A (Guaranteed) â†’ ProtÃ©gÃ© âœ…
â”œâ”€ Pod B (Burstable)  â†’ ProtÃ©gÃ© âœ…
â”œâ”€ Pod C (BestEffort) â†’ TUÃ‰ ğŸ’€
â””â”€ Pod D (BestEffort) â†’ TUÃ‰ ğŸ’€
```

### Quand utiliser BestEffort ?

âœ… **Acceptable** :
- Tests rapides en dÃ©veloppement
- ExpÃ©rimentations locales
- Scripts one-shot non critiques

âŒ **Ã€ Ã©viter** :
- **JAMAIS en production**
- Applications importantes
- Services avec SLA
- Tout ce qui doit Ãªtre stable

### Exemple rÃ©el

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: test-rapide
  labels:
    qos-class: besteffort
spec:
  containers:
  - name: busybox
    image: busybox
    command: ["sleep", "3600"]
    # Pas de resources = BestEffort
```

**VÃ©rification** :
```bash
kubectl get pod test-rapide -o jsonpath='{.status.qosClass}'
# RÃ©sultat : BestEffort
```

## 2. Burstable - La classe intermÃ©diaire

### Conditions pour Ãªtre Burstable

Un Pod est classÃ© **Burstable** dans les cas suivants :
1. Au moins un conteneur a des requests **ou** des limits
2. Requests â‰  Limits (au moins pour une ressource)
3. Pas tous les conteneurs n'ont requests = limits pour tout

C'est le **cas le plus courant** et le plus flexible.

### Exemples de configurations Burstable

**Cas 1 : Requests sans limits**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: burstable-pod-1
spec:
  containers:
  - name: app
    image: my-app
    resources:
      requests:
        memory: "256Mi"
        cpu: "250m"
      # Pas de limits - Burstable !
```

**Cas 2 : Limits sans requests**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: burstable-pod-2
spec:
  containers:
  - name: app
    image: my-app
    resources:
      limits:
        memory: "1Gi"
        cpu: "1"
      # Pas de requests - Burstable !
```

**Cas 3 : Requests â‰  Limits**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: burstable-pod-3
spec:
  containers:
  - name: app
    image: my-app
    resources:
      requests:
        memory: "256Mi"
        cpu: "250m"
      limits:
        memory: "512Mi"   # DiffÃ©rent de requests
        cpu: "500m"       # DiffÃ©rent de requests
      # Burstable !
```

**Cas 4 : Pod multi-conteneurs mixte**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: burstable-pod-4
spec:
  containers:
  - name: app
    image: my-app
    resources:
      requests:
        memory: "512Mi"
        cpu: "500m"
      limits:
        memory: "512Mi"   # Ã‰gal pour ce conteneur
        cpu: "500m"
  - name: sidecar
    image: nginx
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"   # DiffÃ©rent pour ce conteneur
        cpu: "200m"
      # Pod global = Burstable car au moins un conteneur a requests â‰  limits
```

### CaractÃ©ristiques

**Avantages** :
- ğŸŸ¢ Bon compromis flexibilitÃ©/stabilitÃ©
- ğŸŸ¢ Peut "burst" (utiliser plus que les requests) si ressources disponibles
- ğŸŸ¢ Garanties minimales avec requests
- ğŸŸ¢ Protection contre sur-consommation avec limits
- ğŸŸ¢ Meilleure prioritÃ© que BestEffort

**InconvÃ©nients** :
- ğŸŸ¡ Peut Ãªtre tuÃ© en cas de pression mÃ©moire (aprÃ¨s BestEffort)
- ğŸŸ¡ Moins de garanties que Guaranteed

### Comportement en cas de pression mÃ©moire

Quand un nÅ“ud manque de RAM **aprÃ¨s avoir tuÃ© tous les BestEffort** :
1. Kubernetes identifie tous les Pods Burstable
2. Calcule pour chaque Pod : `(usage actuel - requests) / requests`
3. **Tue d'abord les Pods qui dÃ©passent le plus leurs requests**
4. Continue jusqu'Ã  ce que la pression disparaisse

**Exemple** :
```
Pods Burstable sur le nÅ“ud :
â”œâ”€ Pod A : requests 512Mi, usage 800Mi â†’ dÃ©passement 56%
â”œâ”€ Pod B : requests 1Gi, usage 1.2Gi  â†’ dÃ©passement 20%
â””â”€ Pod C : requests 256Mi, usage 400Mi â†’ dÃ©passement 56%

Ordre d'Ã©viction : Pod A ou Pod C d'abord (dÃ©passement le plus Ã©levÃ©)
```

### Quand utiliser Burstable ?

âœ… **RecommandÃ© pour** :
- **La majoritÃ© des applications** en production
- Services web classiques
- APIs backend
- Workers de traitement
- Applications dont la charge varie

C'est le **choix par dÃ©faut** pour la plupart des workloads.

### Exemple rÃ©el

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-backend
  template:
    metadata:
      labels:
        app: api-backend
    spec:
      containers:
      - name: api
        image: my-api:v1.0
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"    # Peut burst jusqu'Ã  1Gi
            cpu: "1"         # Peut burst jusqu'Ã  1 CPU
        # QoS = Burstable
```

**VÃ©rification** :
```bash
kubectl get pods -l app=api-backend -o jsonpath='{.items[0].status.qosClass}'
# RÃ©sultat : Burstable
```

## 3. Guaranteed - La classe la plus haute

### Conditions pour Ãªtre Guaranteed

Un Pod est classÃ© **Guaranteed** quand **tous** ses conteneurs respectent ces conditions **strictes** :

1. âœ… Chaque conteneur doit avoir requests **ET** limits pour CPU et mÃ©moire
2. âœ… Requests CPU = Limits CPU (pour chaque conteneur)
3. âœ… Requests Memory = Limits Memory (pour chaque conteneur)

C'est la configuration la **plus stricte** mais aussi la **plus protÃ©gÃ©e**.

### Configuration correcte Guaranteed

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: guaranteed-pod
spec:
  containers:
  - name: app
    image: my-app
    resources:
      requests:
        memory: "1Gi"
        cpu: "1"
      limits:
        memory: "1Gi"    # Exactement Ã©gal Ã  requests
        cpu: "1"         # Exactement Ã©gal Ã  requests
      # Guaranteed âœ…
```

### Configurations incorrectes (non-Guaranteed)

**Erreur 1 : Manque CPU limits**
```yaml
resources:
  requests:
    memory: "1Gi"
    cpu: "1"
  limits:
    memory: "1Gi"
    # Manque cpu limits - Burstable âŒ
```

**Erreur 2 : Requests â‰  Limits**
```yaml
resources:
  requests:
    memory: "1Gi"
    cpu: "1"
  limits:
    memory: "2Gi"    # DiffÃ©rent - Burstable âŒ
    cpu: "1"
```

**Erreur 3 : Manque requests**
```yaml
resources:
  limits:
    memory: "1Gi"
    cpu: "1"
    # Manque requests - Burstable âŒ
```

### Forme courte (recommandÃ©e)

Kubernetes permet une forme plus courte. Si vous dÃ©finissez **seulement** les limits, les requests sont automatiquement Ã©gales :

```yaml
resources:
  limits:
    memory: "1Gi"
    cpu: "1"
  # requests seront automatiquement = limits
  # Guaranteed âœ…
```

C'est **Ã©quivalent** Ã  :
```yaml
resources:
  requests:
    memory: "1Gi"
    cpu: "1"
  limits:
    memory: "1Gi"
    cpu: "1"
```

### Pod multi-conteneurs Guaranteed

**Tous les conteneurs** doivent Ãªtre Guaranteed :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: guaranteed-multi
spec:
  containers:
  - name: app
    image: my-app
    resources:
      limits:
        memory: "2Gi"
        cpu: "1"
  - name: sidecar
    image: nginx
    resources:
      limits:
        memory: "512Mi"
        cpu: "500m"
  # Les deux conteneurs sont Guaranteed
  # Donc le Pod est Guaranteed âœ…
```

### CaractÃ©ristiques

**Avantages** :
- ğŸŸ¢ **PrioritÃ© maximale** - tuÃ© en dernier
- ğŸŸ¢ Performances prÃ©visibles et constantes
- ğŸŸ¢ Ressources garanties et fixes
- ğŸŸ¢ IdÃ©al pour applications critiques
- ğŸŸ¢ Pas de throttling CPU surprise
- ğŸŸ¢ Meilleure stabilitÃ©

**InconvÃ©nients** :
- ğŸ”´ Moins de flexibilitÃ© (pas de burst)
- ğŸ”´ Peut "gaspiller" des ressources si sous-utilisÃ©
- ğŸ”´ CoÃ»t d'infrastructure potentiellement plus Ã©levÃ©
- ğŸ”´ NÃ©cessite de bien dimensionner les ressources

### Comportement en cas de pression mÃ©moire

Quand un nÅ“ud manque de RAM **aprÃ¨s avoir tuÃ© tous les BestEffort et Burstable** :
1. Kubernetes identifie tous les Pods Guaranteed
2. Calcule pour chaque Pod : `usage actuel`
3. **Tue en dernier recours le Pod qui consomme le plus**
4. C'est la situation d'urgence absolue

**SchÃ©ma** :
```
Pression mÃ©moire extrÃªme (98% RAM)
â”‚
Phase 1 : Tue tous les BestEffort    ğŸ’€
Phase 2 : Tue tous les Burstable     ğŸ’€
Phase 3 : Tue Guaranteed si nÃ©cessaire ğŸ’€ (dernier recours)
```

### Quand utiliser Guaranteed ?

âœ… **RecommandÃ© pour** :
- Bases de donnÃ©es (PostgreSQL, MySQL, MongoDB)
- Caches critiques (Redis, Memcached)
- Files de messages (RabbitMQ, Kafka)
- Applications avec SLA strict
- Services core infrastructure
- SystÃ¨mes de monitoring critiques

âŒ **Ã‰viter pour** :
- Applications dont la charge fluctue beaucoup
- Workers batch occasionnels
- Services non critiques
- Environnements de dÃ©veloppement

### Exemple rÃ©el

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgresql
spec:
  serviceName: postgresql
  replicas: 1
  selector:
    matchLabels:
      app: postgresql
  template:
    metadata:
      labels:
        app: postgresql
    spec:
      containers:
      - name: postgresql
        image: postgres:15
        resources:
          limits:
            memory: "2Gi"
            cpu: "2"
          # requests = limits automatiquement
          # QoS = Guaranteed âœ…
        env:
        - name: POSTGRES_PASSWORD
          value: "secret"
```

**VÃ©rification** :
```bash
kubectl get pods -l app=postgresql -o jsonpath='{.items[0].status.qosClass}'
# RÃ©sultat : Guaranteed
```

## Comparaison des trois classes

### Tableau rÃ©capitulatif

| Aspect | BestEffort | Burstable | Guaranteed |
|--------|------------|-----------|------------|
| **PrioritÃ© d'Ã©viction** | 1ï¸âƒ£ Premier | 2ï¸âƒ£ DeuxiÃ¨me | 3ï¸âƒ£ Dernier |
| **Configuration** | Aucune resources | Requests â‰  Limits | Requests = Limits |
| **FlexibilitÃ©** | ğŸŸ¢ Maximale | ğŸŸ¡ Moyenne | ğŸ”´ Minimale |
| **PrÃ©visibilitÃ©** | ğŸ”´ Faible | ğŸŸ¡ Moyenne | ğŸŸ¢ Haute |
| **StabilitÃ©** | ğŸ”´ Faible | ğŸŸ¡ Moyenne | ğŸŸ¢ Haute |
| **CoÃ»t ressources** | ğŸŸ¢ Minimal | ğŸŸ¡ Moyen | ğŸ”´ Maximal |
| **Usage en prod** | âŒ Jamais | âœ… RecommandÃ© | âœ… Pour critiques |

### SchÃ©ma de dÃ©cision

```
                    Votre application
                          |
                          |
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              |                       |
         Critique ?              Non critique ?
              |                       |
              |                       |
         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
         |         |             |         |
    Stable    Variable     Stable    Variable
    charge    charge       charge    charge
         |         |             |         |
         |         |             |         |
    Guaranteed  Burstable   Burstable  Burstable
```

**RÃ¨gle simple** :
- Application critique + charge stable = **Guaranteed**
- Tout le reste en production = **Burstable**
- Tests uniquement = **BestEffort** (acceptable)

## VÃ©rifier la QoS Class d'un Pod

### MÃ©thode 1 : kubectl get

```bash
kubectl get pod mon-pod -o jsonpath='{.status.qosClass}'
```

RÃ©sultat : `Guaranteed`, `Burstable`, ou `BestEffort`

### MÃ©thode 2 : kubectl describe

```bash
kubectl describe pod mon-pod
```

Cherchez la ligne :
```
QoS Class:       Burstable
```

### MÃ©thode 3 : Lister tous les Pods par QoS

```bash
# Pods Guaranteed
kubectl get pods -o jsonpath='{range .items[?(@.status.qosClass=="Guaranteed")]}{.metadata.name}{"\n"}{end}'

# Pods Burstable
kubectl get pods -o jsonpath='{range .items[?(@.status.qosClass=="Burstable")]}{.metadata.name}{"\n"}{end}'

# Pods BestEffort
kubectl get pods -o jsonpath='{range .items[?(@.status.qosClass=="BestEffort")]}{.metadata.name}{"\n"}{end}'
```

### MÃ©thode 4 : Statistiques par namespace

Script pour voir la distribution des QoS dans un namespace :

```bash
echo "QoS Class distribution:"
echo "Guaranteed: $(kubectl get pods -n production -o json | jq '[.items[].status.qosClass] | map(select(. == "Guaranteed")) | length')"
echo "Burstable:  $(kubectl get pods -n production -o json | jq '[.items[].status.qosClass] | map(select(. == "Burstable")) | length')"
echo "BestEffort: $(kubectl get pods -n production -o json | jq '[.items[].status.qosClass] | map(select(. == "BestEffort")) | length')"
```

## Ordre d'Ã©viction dÃ©taillÃ©

### En cas de pression mÃ©moire

Voici le processus complet d'Ã©viction :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Processus d'Ã©viction (Memory Pressure)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Ã‰tape 1 : BestEffort Pods                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚  â€¢ Tous les Pods BestEffort                             â”‚
â”‚  â€¢ Ordre : celui qui consomme le plus en premier        â”‚
â”‚                                                         â”‚
â”‚  Ã‰tape 2 : Burstable Pods                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚  â€¢ Tous les Pods Burstable                              â”‚
â”‚  â€¢ Ordre : celui qui dÃ©passe le plus ses requests       â”‚
â”‚  â€¢ Formule : (usage - requests) / requests              â”‚
â”‚                                                         â”‚
â”‚  Ã‰tape 3 : Guaranteed Pods (dernier recours)            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚  â€¢ Tous les Pods Guaranteed                             â”‚
â”‚  â€¢ Ordre : celui qui consomme le plus                   â”‚
â”‚  â€¢ Situation critique !                                 â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Exemple concret

**NÅ“ud** : 16 Gi RAM total, 15.8 Gi utilisÃ© (98.75%) â†’ Pression mÃ©moire !

**Pods sur le nÅ“ud** :
```yaml
# Pod A - BestEffort
Usage : 2 Gi
PrioritÃ© d'Ã©viction : 1 (tuÃ© en premier)

# Pod B - BestEffort
Usage : 1 Gi
PrioritÃ© d'Ã©viction : 2

# Pod C - Burstable
Requests : 4 Gi, Usage : 6 Gi (dÃ©passement 50%)
PrioritÃ© d'Ã©viction : 3

# Pod D - Burstable
Requests : 2 Gi, Usage : 3 Gi (dÃ©passement 50%)
PrioritÃ© d'Ã©viction : 4

# Pod E - Burstable
Requests : 1 Gi, Usage : 1.2 Gi (dÃ©passement 20%)
PrioritÃ© d'Ã©viction : 5

# Pod F - Guaranteed
Requests = Limits = 2 Gi, Usage : 1.8 Gi
PrioritÃ© d'Ã©viction : 6 (tuÃ© en dernier)
```

**Ordre rÃ©el d'Ã©viction** :
1. **Pod A** (BestEffort, 2 Gi) â†’ LibÃ¨re 2 Gi â†’ Pression rÃ©solue âœ…

Si pas suffisant :
2. **Pod B** (BestEffort, 1 Gi)
3. **Pod C ou D** (Burstable, mÃªme dÃ©passement 50%)
4. **Pod E** (Burstable, dÃ©passement 20%)
5. **Pod F** (Guaranteed) - dernier recours

## Bonnes pratiques

### 1. Production = Pas de BestEffort

âœ… **RÃ¨gle absolue** : ZÃ©ro Pod BestEffort en production.

**Mise en place** : Utilisez un LimitRange pour forcer les resources :

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: no-besteffort
  namespace: production
spec:
  limits:
  - type: Container
    defaultRequest:
      memory: "256Mi"
      cpu: "250m"
    default:
      memory: "512Mi"
      cpu: "500m"
```

Cela garantit que tous les Pods auront au minimum Burstable.

### 2. Identifier les applications critiques

âœ… **Processus** :

1. Lister vos applications
2. Identifier celles qui sont critiques :
   - Bases de donnÃ©es
   - Caches
   - APIs core
   - Services de paiement
3. Passer ces applications en Guaranteed
4. Garder le reste en Burstable

### 3. Monitoring des QoS Classes

âœ… **MÃ©triques Ã  suivre** :

```yaml
# Exemple de dashboard Grafana
- Nombre de Pods par QoS Class
- Pourcentage de Pods Guaranteed vs Burstable
- Alertes si Pods BestEffort en production
- Historique des Ã©victions par QoS Class
```

### 4. Documented QoS choices

âœ… **Documenter dans les annotations** :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
  annotations:
    qos-strategy: "Burstable"
    qos-rationale: "Variable load, non-critical service"
spec:
  template:
    spec:
      containers:
      - name: app
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1"
```

### 5. Testing des configurations

âœ… **Tester la rÃ©silience** :

```bash
# Simuler la pression mÃ©moire avec stress-ng
kubectl run stress-test --image=polinux/stress-ng --restart=Never -- \
  --vm 1 --vm-bytes 90% --timeout 60s

# Observer les Ã©victions
kubectl get events --sort-by='.lastTimestamp' | grep -i evict
```

### 6. Ã‰quilibrer le cluster

âœ… **Distribution recommandÃ©e** dans un cluster de production :

```
Guaranteed:  20-30% des Pods (applications critiques)
Burstable:   70-80% des Pods (applications standard)
BestEffort:  0% des Pods (interdit)
```

### 7. RÃ©vision rÃ©guliÃ¨re

âœ… **Processus trimestriel** :

1. Analyser les mÃ©triques d'utilisation des ressources
2. Identifier les Pods qui mÃ©riteraient Guaranteed
3. Identifier les Pods Guaranteed sous-utilisÃ©s â†’ passer en Burstable
4. Ajuster les requests/limits en fonction de l'usage rÃ©el

## Cas d'usage par type d'application

### Applications web frontend

```yaml
# Configuration : Burstable
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        # QoS : Burstable
        # Raison : Charge variable, non critique
```

### API backend

```yaml
# Configuration : Burstable (ou Guaranteed si critique)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-backend
spec:
  replicas: 5
  template:
    spec:
      containers:
      - name: api
        image: my-api:v2
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1"
        # QoS : Burstable
        # Peut burst pendant les pics de charge
```

### Base de donnÃ©es

```yaml
# Configuration : Guaranteed
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: postgres
        image: postgres:15
        resources:
          limits:
            memory: "4Gi"
            cpu: "2"
          # requests = limits automatiquement
        # QoS : Guaranteed
        # Critique - ne doit JAMAIS Ãªtre Ã©vincÃ©
```

### Cache Redis

```yaml
# Configuration : Guaranteed
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: redis
        image: redis:7
        resources:
          limits:
            memory: "2Gi"
            cpu: "1"
        # QoS : Guaranteed
        # Critique - perte de cache = dÃ©gradation service
```

### Worker batch

```yaml
# Configuration : Burstable
apiVersion: apps/v1
kind: Deployment
metadata:
  name: worker
spec:
  replicas: 10
  template:
    spec:
      containers:
      - name: worker
        image: my-worker:latest
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "2"
        # QoS : Burstable
        # Peut burst pendant le traitement
        # Peut Ãªtre Ã©vincÃ© sans impact critique
```

### CronJob de backup

```yaml
# Configuration : Burstable
apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup
spec:
  schedule: "0 2 * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: backup-tool:latest
            resources:
              requests:
                memory: "512Mi"
                cpu: "500m"
              limits:
                memory: "2Gi"
                cpu: "2"
            # QoS : Burstable
            # S'exÃ©cute la nuit, peut utiliser plus si disponible
          restartPolicy: OnFailure
```

## Interaction avec d'autres mÃ©canismes

### QoS + PriorityClass

Les QoS Classes et PriorityClasses travaillent ensemble mais sont diffÃ©rentes :

```yaml
# Pod avec PriorityClass ET QoS
apiVersion: v1
kind: Pod
metadata:
  name: high-priority-guaranteed
spec:
  priorityClassName: system-cluster-critical  # PriorityClass
  containers:
  - name: app
    image: critical-app
    resources:
      limits:
        memory: "2Gi"
        cpu: "2"
      # QoS : Guaranteed
```

**Ordre d'Ã©viction combinÃ©** :
1. BestEffort + Low Priority (premier)
2. BestEffort + High Priority
3. Burstable + Low Priority
4. Burstable + High Priority
5. Guaranteed + Low Priority
6. Guaranteed + High Priority (dernier)

### QoS + Node Affinity

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: db-on-dedicated-node
spec:
  # QoS Guaranteed
  containers:
  - name: postgres
    resources:
      limits:
        memory: "8Gi"
        cpu: "4"
  # Sur un nÅ“ud dÃ©diÃ©
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: workload-type
            operator: In
            values:
            - database
```

Combinaison idÃ©ale pour applications critiques.

### QoS + Resource Quotas

Les Resource Quotas peuvent indirectement favoriser certaines QoS :

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: guaranteed-only
  namespace: critical-services
spec:
  hard:
    requests.cpu: "20"
    limits.cpu: "20"      # MÃªme valeur
    requests.memory: "40Gi"
    limits.memory: "40Gi"  # MÃªme valeur
  # Force requests = limits â†’ tous les Pods seront Guaranteed
```

## Debugging et observabilitÃ©

### Voir les Ã©victions rÃ©centes

```bash
# Ã‰vÃ©nements d'Ã©viction
kubectl get events --all-namespaces --field-selector reason=Evicted

# DÃ©tails d'une Ã©viction
kubectl describe pod <pod-name> | grep -A 10 "State:"
```

### Identifier les Pods Ã  risque

```bash
# Pods Burstable qui dÃ©passent beaucoup leurs requests
kubectl top pods --all-namespaces --sort-by=memory
```

### Monitoring avec Prometheus

```yaml
# Exemple de mÃ©triques utiles
- kube_pod_status_qos_class
- kube_pod_container_resource_requests
- kube_pod_container_resource_limits
- container_memory_working_set_bytes
```

**Alerte exemple** :
```yaml
alert: HighMemoryUsageVsRequests
expr: |
  (container_memory_working_set_bytes /
   kube_pod_container_resource_requests{resource="memory"}) > 1.5
annotations:
  summary: "Pod {{ $labels.pod }} uses 50% more than requests"
```

### Dashboard Grafana recommandÃ©

Panels Ã  crÃ©er :
1. **Distribution des QoS Classes** (pie chart)
2. **Pods par QoS et namespace** (bar chart)
3. **Utilisation vs Requests** par QoS (time series)
4. **Historique des Ã©victions** par QoS (counter)
5. **Pods BestEffort en production** (table - devrait Ãªtre vide)

## Points clÃ©s Ã  retenir

ğŸ”‘ **Les essentiels** :

1. **QoS Classes** = systÃ¨me de prioritÃ© automatique de Kubernetes
2. **Trois classes** : BestEffort < Burstable < Guaranteed
3. **CalculÃ© automatiquement** selon requests/limits
4. **Ordre d'Ã©viction** : BestEffort tuÃ©s en premier, Guaranteed en dernier
5. **Production** : JAMAIS de BestEffort, majoritÃ© Burstable, critiques en Guaranteed
6. **Guaranteed** : requests = limits pour tout (CPU et mÃ©moire)
7. **Burstable** : requests â‰  limits (cas gÃ©nÃ©ral)
8. **BestEffort** : aucune resources dÃ©finie (tests uniquement)

## RÃ©capitulatif des 4 sections

Nous avons maintenant couvert l'ensemble de la gestion des ressources :

| Section | Concept | Niveau | RÃ´le |
|---------|---------|--------|------|
| **18.1** | Requests/Limits | Conteneur | DÃ©finir les ressources |
| **18.2** | Resource Quotas | Namespace | Limiter le total |
| **18.3** | LimitRanges | Namespace | Contraindre les valeurs |
| **18.4** | QoS Classes | Pod | PrioritÃ© d'Ã©viction |

**Ensemble, ces mÃ©canismes assurent** :
- âœ… StabilitÃ© du cluster
- âœ… Protection des applications critiques
- âœ… Utilisation efficace des ressources
- âœ… PrÃ©visibilitÃ© et observabilitÃ©

## Conclusion

Les QoS Classes sont un mÃ©canisme Ã©lÃ©gant qui transforme votre configuration de resources (requests/limits) en un systÃ¨me de prioritÃ© intelligent. Vous n'avez rien Ã  configurer directement - Kubernetes calcule automatiquement la QoS Class de chaque Pod.

**En pratique** :
- Commencez par dÃ©finir des requests et limits raisonnables
- La majoritÃ© de vos Pods seront Burstable (c'est normal et bien)
- Identifiez vos applications critiques et passez-les en Guaranteed
- Bannissez BestEffort de la production
- Monitorer les Ã©victions pour ajuster votre stratÃ©gie

**Prochaine Ã©tape** : Dans la section suivante (18.5), nous verrons les **PriorityClasses** qui permettent un contrÃ´le encore plus fin des prioritÃ©s.

---


â­ï¸ [PriorityClasses](/18-gestion-des-ressources/05-priorityclasses.md)
