ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 18.1 Requests et Limits

## Introduction

Dans Kubernetes, chaque conteneur dans un Pod consomme des ressources systÃ¨me : principalement du **CPU** et de la **mÃ©moire (RAM)**. Sans contrÃ´le, un conteneur pourrait monopoliser toutes les ressources disponibles sur un nÅ“ud, impactant nÃ©gativement les autres applications.

Les **Requests** et **Limits** sont les mÃ©canismes que Kubernetes met Ã  votre disposition pour gÃ©rer intelligemment ces ressources et garantir la stabilitÃ© de votre cluster.

## Pourquoi est-ce important ?

Imaginez un immeuble d'appartements oÃ¹ chaque locataire (conteneur) partage les mÃªmes ressources communes (eau, Ã©lectricitÃ©). Sans rÃ¨gles :
- Un locataire pourrait utiliser toute l'eau disponible
- Les autres locataires seraient privÃ©s de ressources
- L'immeuble entier pourrait devenir invivable

Dans Kubernetes, c'est exactement le mÃªme principe. Les Requests et Limits permettent de :

âœ… **Garantir des ressources minimales** Ã  chaque application
âœ… **Ã‰viter qu'une application monopolise tout**
âœ… **AmÃ©liorer la stabilitÃ© globale** du cluster
âœ… **Optimiser l'utilisation des ressources** disponibles
âœ… **Permettre au scheduler de prendre de meilleures dÃ©cisions** de placement

## Les deux concepts clÃ©s

### 1. Requests (Demandes)

Les **Requests** reprÃ©sentent la **quantitÃ© minimale de ressources garantie** Ã  votre conteneur.

**Analogie** : C'est comme rÃ©server une place dans un restaurant. Vous Ãªtes certain d'avoir au moins cette place, mÃªme si le restaurant est plein.

**Ce qu'il faut savoir :**
- Le scheduler Kubernetes utilise les requests pour dÃ©cider sur quel nÅ“ud placer votre Pod
- Si un nÅ“ud n'a pas suffisamment de ressources disponibles pour satisfaire les requests, le Pod ne sera pas placÃ© sur ce nÅ“ud
- Les requests sont **garanties** : votre conteneur aura toujours au minimum ces ressources
- Votre conteneur peut utiliser **plus** que ses requests si des ressources sont disponibles

### 2. Limits (Limites)

Les **Limits** reprÃ©sentent la **quantitÃ© maximale de ressources** qu'un conteneur peut utiliser.

**Analogie** : C'est comme un compteur d'eau dans un appartement. Vous ne pouvez pas dÃ©passer un certain dÃ©bit, mÃªme si vous le souhaitez.

**Ce qu'il faut savoir :**
- Les limits empÃªchent un conteneur de consommer plus que prÃ©vu
- Si un conteneur tente de dÃ©passer sa limit, Kubernetes prendra des mesures correctives
- Les limits protÃ¨gent les autres conteneurs du cluster

## Ressources concernÃ©es

Kubernetes gÃ¨re deux types principaux de ressources :

### CPU (Processeur)

**UnitÃ©s :**
- ExprimÃ© en "cores" (cÅ“urs)
- `1` = 1 core CPU complet
- `0.5` ou `500m` = un demi-core (m = millicore, 1000m = 1 core)
- `100m` = 10% d'un core

**Comportement :**
- Le CPU est une ressource **compressible**
- Si un conteneur atteint sa limit CPU, il sera simplement **ralenti** (throttled)
- Il ne sera pas tuÃ©, juste moins performant

**Exemple de valeurs courantes :**
```yaml
cpu: "100m"   # Application lÃ©gÃ¨re (petit service web)
cpu: "500m"   # Application moyenne
cpu: "2"      # Application intensive (traitement de donnÃ©es)
```

### Memory (MÃ©moire)

**UnitÃ©s :**
- ExprimÃ© en bytes avec des suffixes
- `128Mi` = 128 Mebibytes (Mi = 1024Â² bytes)
- `1Gi` = 1 Gibibyte (Gi = 1024Â³ bytes)
- `256M` = 256 Megabytes (M = 1000Â² bytes)

**Note** : PrÃ©fÃ©rez toujours les unitÃ©s binaires (Mi, Gi) qui sont plus prÃ©cises dans le contexte Kubernetes.

**Comportement :**
- La mÃ©moire est une ressource **non-compressible**
- Si un conteneur dÃ©passe sa limit mÃ©moire, il sera **tuÃ©** (OOMKilled - Out Of Memory Killed)
- Le Pod sera ensuite redÃ©marrÃ© automatiquement

**Exemple de valeurs courantes :**
```yaml
memory: "128Mi"  # Application trÃ¨s lÃ©gÃ¨re
memory: "512Mi"  # Application moyenne
memory: "2Gi"    # Application gourmande (base de donnÃ©es)
```

## Comment Ã§a fonctionne ?

### SchÃ©ma conceptuel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Ressources du NÅ“ud                â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Request    â”‚  Usage rÃ©el â”‚  Limit   â”‚  â”‚
â”‚  â”‚   (garanti)  â”‚             â”‚  (max)   â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚      â”‚       â”‚      â”‚      â”‚    â”‚     â”‚  â”‚
â”‚  â”‚      â”‚       â”‚      â–¼      â”‚    â”‚     â”‚  â”‚
â”‚  â”‚      â–¼       â”‚   Flexible  â”‚    â–¼     â”‚  â”‚
â”‚  â”‚   Minimum    â”‚   peut      â”‚ Maximum  â”‚  â”‚
â”‚  â”‚   garanti    â”‚   augmenter â”‚ autorisÃ© â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cas de figure

**Cas 1 : Usage normal**
- Votre conteneur utilise entre ses requests et limits
- Tout va bien, le conteneur fonctionne normalement

**Cas 2 : Sous-utilisation**
- Votre conteneur utilise moins que ses requests
- Les ressources inutilisÃ©es peuvent Ãªtre utilisÃ©es par d'autres conteneurs
- Pas de problÃ¨me, mais vous avez peut-Ãªtre surestimÃ© les requests

**Cas 3 : Sur-utilisation (CPU)**
- Votre conteneur veut utiliser plus que sa limit CPU
- Kubernetes limite (throttle) l'utilisation du CPU
- Le conteneur ralentit mais continue de fonctionner

**Cas 4 : Sur-utilisation (Memory)**
- Votre conteneur veut utiliser plus que sa limit mÃ©moire
- Kubernetes tue le conteneur (OOMKilled)
- Le Pod redÃ©marre automatiquement

## Configuration dans les manifestes

### Syntaxe de base

Voici comment dÃ©finir les requests et limits dans un manifeste YAML :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mon-application
spec:
  containers:
  - name: mon-conteneur
    image: nginx:latest
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
```

### Exemple complet avec Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-backend
  labels:
    app: api-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-backend
  template:
    metadata:
      labels:
        app: api-backend
    spec:
      containers:
      - name: api
        image: mon-api:v1.0
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "500m"
```

### Exemple avec plusieurs conteneurs

Un Pod peut contenir plusieurs conteneurs. Chacun doit avoir ses propres resources :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: application-avec-sidecar
spec:
  containers:
  # Conteneur principal
  - name: app-principale
    image: mon-app:latest
    resources:
      requests:
        memory: "512Mi"
        cpu: "500m"
      limits:
        memory: "1Gi"
        cpu: "1000m"

  # Conteneur sidecar (proxy)
  - name: proxy-sidecar
    image: envoy:latest
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
```

**Note importante** : Les requests et limits du Pod sont la **somme** des requests et limits de tous ses conteneurs.

## Que se passe-t-il sans Requests et Limits ?

### Sans Requests

âŒ **ProblÃ¨mes potentiels :**
- Le scheduler ne peut pas prendre de dÃ©cisions Ã©clairÃ©es
- Risque de surcharge d'un nÅ“ud (trop de Pods sur un nÅ“ud sous-dimensionnÃ©)
- Pas de garantie de ressources pour vos applications
- Performances imprÃ©visibles

### Sans Limits

âŒ **ProblÃ¨mes potentiels :**
- Un conteneur peut monopoliser toutes les ressources d'un nÅ“ud
- Impact nÃ©gatif sur les autres applications
- Risque de dÃ©stabilisation du nÅ“ud entier
- Difficile de prÃ©voir les coÃ»ts d'infrastructure

### Sans aucune configuration

C'est le **pire des scÃ©narios** :
- Kubernetes place les Pods un peu au hasard
- Aucune protection contre la surconsommation
- InstabilitÃ© globale du cluster
- DifficultÃ© extrÃªme Ã  diagnostiquer les problÃ¨mes de performance

## Bonnes pratiques

### 1. Toujours dÃ©finir les Requests

âœ… **Recommandation** : DÃ©finissez **toujours** des requests, mÃªme approximatives.

```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "200m"
```

MÃªme si vous n'Ãªtes pas sÃ»r des valeurs exactes, c'est mieux que rien.

### 2. DÃ©finir des Limits pour la mÃ©moire

âœ… **Recommandation** : DÃ©finissez **toujours** une limit mÃ©moire pour Ã©viter les fuites mÃ©moire incontrÃ´lÃ©es.

```yaml
resources:
  requests:
    memory: "256Mi"
  limits:
    memory: "512Mi"  # Important !
```

### 3. Limits CPU : Ã  utiliser avec prÃ©caution

âš ï¸ **Attention** : Les limits CPU peuvent causer des problÃ¨mes de performance subtils.

**Option 1 - Conservative** : DÃ©finir des limits CPU
```yaml
resources:
  requests:
    cpu: "200m"
  limits:
    cpu: "500m"
```

**Option 2 - Permissive** : Ne pas dÃ©finir de limits CPU (seulement requests)
```yaml
resources:
  requests:
    cpu: "200m"
  # Pas de limit CPU - le conteneur peut burst si nÃ©cessaire
```

Cette deuxiÃ¨me approche permet Ã  votre application d'utiliser plus de CPU quand disponible.

### 4. Ratio Requests/Limits raisonnable

âœ… **Recommandation** : Gardez un ratio de 1:2 ou 1:3 maximum entre requests et limits.

**Bon exemple** :
```yaml
resources:
  requests:
    memory: "256Mi"
  limits:
    memory: "512Mi"  # Ratio 1:2
```

**Mauvais exemple** :
```yaml
resources:
  requests:
    memory: "64Mi"
  limits:
    memory: "2Gi"  # Ratio 1:32 - trop Ã©levÃ© !
```

### 5. Ajuster selon l'environnement

Les besoins en ressources varient selon l'environnement :

**DÃ©veloppement** :
```yaml
resources:
  requests:
    memory: "128Mi"
    cpu: "100m"
  limits:
    memory: "256Mi"
    cpu: "200m"
```

**Production** :
```yaml
resources:
  requests:
    memory: "512Mi"
    cpu: "500m"
  limits:
    memory: "1Gi"
    cpu: "1000m"
```

### 6. Monitorer et ajuster

âœ… **Cycle d'amÃ©lioration continue** :

1. **DÃ©marrez** avec des valeurs raisonnables estimÃ©es
2. **Monitorez** l'utilisation rÃ©elle avec Prometheus/Grafana
3. **Analysez** les mÃ©triques sur plusieurs jours/semaines
4. **Ajustez** les valeurs en fonction des observations
5. **RÃ©pÃ©tez** rÃ©guliÃ¨rement

## Comment dÃ©terminer les bonnes valeurs ?

### MÃ©thode 1 : DÃ©marrer avec des valeurs conservatrices

Pour une application que vous ne connaissez pas encore :

```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "200m"
  limits:
    memory: "512Mi"
    cpu: "500m"
```

### MÃ©thode 2 : Tester en local d'abord

1. Lancez votre application sans limits
2. Utilisez `kubectl top pod` pour observer la consommation
3. Ajoutez une marge de sÃ©curitÃ© (ex: +30%)
4. Configurez les requests et limits

```bash
# Observer la consommation
kubectl top pod mon-pod

# Exemple de sortie :
# NAME      CPU(cores)   MEMORY(bytes)
# mon-pod   150m         280Mi
```

Si votre pod utilise 150m CPU et 280Mi RAM :
- Requests : `200m` CPU, `300Mi` RAM (lÃ©gÃ¨rement au-dessus)
- Limits : `400m` CPU, `600Mi` RAM (double pour la marge)

### MÃ©thode 3 : Utiliser le monitoring

Une fois Prometheus installÃ© (voir chapitre 12), vous pouvez analyser :

**MÃ©triques CPU** :
- `container_cpu_usage_seconds_total` : utilisation rÃ©elle
- Observez le percentile 95 sur plusieurs jours

**MÃ©triques mÃ©moire** :
- `container_memory_working_set_bytes` : mÃ©moire rÃ©ellement utilisÃ©e
- Observez le maximum atteint

## Patterns courants

### Application web simple (frontend)

```yaml
resources:
  requests:
    memory: "128Mi"
    cpu: "100m"
  limits:
    memory: "256Mi"
    cpu: "200m"
```

### API backend

```yaml
resources:
  requests:
    memory: "512Mi"
    cpu: "250m"
  limits:
    memory: "1Gi"
    cpu: "500m"
```

### Base de donnÃ©es (PostgreSQL, MySQL)

```yaml
resources:
  requests:
    memory: "1Gi"
    cpu: "500m"
  limits:
    memory: "2Gi"
    cpu: "1000m"
```

### Worker de traitement batch

```yaml
resources:
  requests:
    memory: "512Mi"
    cpu: "500m"
  limits:
    memory: "2Gi"
    cpu: "2000m"  # Peut avoir besoin de bursts CPU
```

### Proxy/Sidecar (Envoy, nginx)

```yaml
resources:
  requests:
    memory: "64Mi"
    cpu: "50m"
  limits:
    memory: "128Mi"
    cpu: "100m"
```

## Comprendre les QoS Classes

Kubernetes classe automatiquement vos Pods en 3 catÃ©gories de **Quality of Service** (QoS) selon comment vous dÃ©finissez les requests et limits :

### 1. Guaranteed (Garantie maximale)

**Conditions** :
- Tous les conteneurs ont des requests ET limits
- Requests = Limits pour CPU et mÃ©moire

```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "500m"
  limits:
    memory: "256Mi"  # Ã‰gal Ã  requests
    cpu: "500m"      # Ã‰gal Ã  requests
```

**Avantages** :
- PrioritÃ© la plus Ã©levÃ©e
- Dernier Ã  Ãªtre Ã©vincÃ© en cas de pression sur les ressources
- Performances prÃ©visibles

**Quand l'utiliser** : Applications critiques en production

### 2. Burstable (Flexible)

**Conditions** :
- Au moins un conteneur a des requests ou limits
- Requests â‰  Limits

```yaml
resources:
  requests:
    memory: "128Mi"
    cpu: "250m"
  limits:
    memory: "512Mi"  # DiffÃ©rent de requests
    cpu: "1000m"     # DiffÃ©rent de requests
```

**Avantages** :
- Bon compromis flexibilitÃ©/stabilitÃ©
- Peut utiliser plus que les requests si disponible

**Quand l'utiliser** : Cas gÃ©nÃ©ral, la majoritÃ© des applications

### 3. BestEffort (Meilleur effort)

**Conditions** :
- Aucun requests ni limits dÃ©finis

```yaml
# Pas de section resources du tout
```

**CaractÃ©ristiques** :
- PrioritÃ© la plus basse
- Premier Ã  Ãªtre Ã©vincÃ© en cas de pression
- Aucune garantie de ressources

**Quand l'utiliser** : Jamais en production ! Uniquement pour des tests rapides.

## VÃ©rifier la configuration

### Voir les resources d'un Pod

```bash
kubectl describe pod mon-pod
```

Cherchez la section `Containers` qui affiche :
```
Containers:
  mon-conteneur:
    Limits:
      cpu:     500m
      memory:  512Mi
    Requests:
      cpu:        250m
      memory:     256Mi
```

### Voir la QoS Class

```bash
kubectl get pod mon-pod -o jsonpath='{.status.qosClass}'
```

RÃ©sultat possible : `Guaranteed`, `Burstable`, ou `BestEffort`

### Voir l'utilisation actuelle

```bash
kubectl top pod mon-pod
```

Affiche la consommation en temps rÃ©el :
```
NAME      CPU(cores)   MEMORY(bytes)
mon-pod   234m         384Mi
```

## Signes que vos valeurs sont incorrectes

### Requests trop basses

**SymptÃ´mes** :
- Pods frÃ©quemment Ã©vincÃ©s (evicted)
- Performances dÃ©gradÃ©es
- Messages `Insufficient memory` dans les Ã©vÃ©nements

**Solution** : Augmentez les requests

### Requests trop hautes

**SymptÃ´mes** :
- Pods en Ã©tat `Pending` (ne trouvent pas de nÅ“ud)
- Faible densitÃ© de Pods par nÅ“ud
- Sous-utilisation des ressources du cluster

**Solution** : RÃ©duisez les requests

### Limits trop basses (mÃ©moire)

**SymptÃ´mes** :
- Pods tuÃ©s frÃ©quemment (OOMKilled)
- RedÃ©marrages constants
- Messages `OOMKilled` dans `kubectl describe pod`

**Solution** : Augmentez les limits mÃ©moire

### Limits trop basses (CPU)

**SymptÃ´mes** :
- Application lente
- Timeouts frÃ©quents
- MÃ©triques montrant un CPU throttling Ã©levÃ©

**Solution** : Augmentez les limits CPU ou retirez-les

## Points clÃ©s Ã  retenir

ğŸ”‘ **Les essentiels** :

1. **Requests** = ressources garanties, utilisÃ©es par le scheduler
2. **Limits** = ressources maximum, protection contre la surconsommation
3. **Toujours dÃ©finir des requests** pour des dÃ©cisions de scheduling optimales
4. **Toujours dÃ©finir une limit mÃ©moire** pour Ã©viter les OOMKilled
5. **CPU est compressible** (ralentissement), **mÃ©moire ne l'est pas** (kill)
6. **Monitorer et ajuster** rÃ©guliÃ¨rement selon l'usage rÃ©el
7. **QoS Guaranteed** pour les applications critiques
8. **QoS Burstable** pour le cas gÃ©nÃ©ral

## Conclusion

Les Requests et Limits sont fondamentaux pour un cluster Kubernetes stable et performant. MÃªme si cela peut sembler complexe au dÃ©but, commencez simplement avec des valeurs raisonnables et affinez au fil du temps grÃ¢ce au monitoring.

**Prochaine Ã©tape** : Une fois que vous maÃ®trisez les Requests et Limits, vous pouvez aller plus loin avec les Resource Quotas (18.2) et LimitRanges (18.3) pour gÃ©rer les ressources au niveau namespace.

N'oubliez pas : il vaut mieux des valeurs approximatives que pas de valeurs du tout !

---

â­ï¸ [Resource Quotas](/18-gestion-des-ressources/02-resource-quotas.md)
