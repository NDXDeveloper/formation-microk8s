üîù Retour au [Sommaire](/SOMMAIRE.md)

# 8.4 Cas d'Usage Pratiques (Backups, ETL, Cleanup)

## Introduction

Dans les sections pr√©c√©dentes, nous avons appris √† utiliser les **Jobs** (8.1), les **CronJobs** (8.2), et √† g√©rer les **√©checs et reprises** (8.3). Maintenant, mettons en pratique ces connaissances avec des exemples concrets et r√©alistes que vous rencontrerez dans votre lab personnel ou en production.

Cette section pr√©sente trois cat√©gories principales de t√¢ches automatis√©es :

1. **Backups (Sauvegardes)** : Prot√©ger vos donn√©es
2. **ETL (Extract, Transform, Load)** : Traiter et transformer des donn√©es
3. **Cleanup (Nettoyage)** : Maintenir un syst√®me propre et performant

Chaque exemple est complet, comment√©, et pr√™t √† √™tre adapt√© √† vos besoins.

## 1. Backups (Sauvegardes)

Les sauvegardes sont essentielles pour prot√©ger vos donn√©es contre les pertes accidentelles, les pannes mat√©rielles, ou les erreurs humaines.

### Principe des Sauvegardes

Une bonne strat√©gie de sauvegarde suit g√©n√©ralement la r√®gle **3-2-1** :
- **3** copies de vos donn√©es
- Sur **2** supports diff√©rents
- Dont **1** copie hors site (offsite)

### 1.1 Sauvegarde de Base de Donn√©es PostgreSQL

C'est l'un des cas d'usage les plus courants. Voici une solution compl√®te pour sauvegarder automatiquement une base PostgreSQL tous les jours.

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-postgresql
  labels:
    app: postgresql
    component: backup
spec:
  # Ex√©cution tous les jours √† 2h du matin
  schedule: "0 2 * * *"

  # Ne jamais ex√©cuter deux sauvegardes en m√™me temps
  concurrencyPolicy: Forbid

  # Garder l'historique des 7 derni√®res sauvegardes r√©ussies
  successfulJobsHistoryLimit: 7

  # Garder l'historique des 2 derniers √©checs pour le d√©bogage
  failedJobsHistoryLimit: 2

  # Si le syst√®me √©tait en panne, rattraper dans les 10 minutes
  startingDeadlineSeconds: 600

  jobTemplate:
    spec:
      # R√©essayer jusqu'√† 2 fois en cas d'√©chec
      backoffLimit: 2

      # Timeout de 30 minutes pour la sauvegarde
      activeDeadlineSeconds: 1800

      template:
        metadata:
          labels:
            app: postgresql
            job: backup
        spec:
          restartPolicy: OnFailure

          containers:
          - name: postgres-backup
            image: postgres:15

            env:
            # Configuration de connexion depuis un Secret
            - name: PGHOST
              value: "postgresql.default.svc.cluster.local"
            - name: PGPORT
              value: "5432"
            - name: PGDATABASE
              value: "production"
            - name: PGUSER
              valueFrom:
                secretKeyRef:
                  name: postgres-credentials
                  key: username
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-credentials
                  key: password

            command:
            - /bin/bash
            - -c
            - |
              set -e  # Arr√™ter en cas d'erreur

              # Variables
              BACKUP_DIR="/backup"
              DATE=$(date +%Y%m%d-%H%M%S)
              BACKUP_FILE="postgres-backup-${DATE}.sql.gz"
              BACKUP_PATH="${BACKUP_DIR}/${BACKUP_FILE}"

              echo "=========================================="
              echo "Sauvegarde PostgreSQL"
              echo "Date: $(date)"
              echo "Base de donn√©es: ${PGDATABASE}"
              echo "Fichier: ${BACKUP_FILE}"
              echo "=========================================="

              # Cr√©er le r√©pertoire de sauvegarde s'il n'existe pas
              mkdir -p ${BACKUP_DIR}

              # V√©rifier la connexion √† la base de donn√©es
              echo "V√©rification de la connexion..."
              if ! pg_isready -h ${PGHOST} -p ${PGPORT}; then
                echo "‚ùå Impossible de se connecter √† PostgreSQL"
                exit 1
              fi
              echo "‚úÖ Connexion r√©ussie"

              # Effectuer la sauvegarde
              echo "Cr√©ation de la sauvegarde..."
              pg_dump --clean --if-exists --verbose \
                | gzip > ${BACKUP_PATH}

              # V√©rifier que le fichier a √©t√© cr√©√©
              if [ ! -f ${BACKUP_PATH} ]; then
                echo "‚ùå √âchec : fichier de sauvegarde non cr√©√©"
                exit 1
              fi

              # Afficher la taille de la sauvegarde
              BACKUP_SIZE=$(du -h ${BACKUP_PATH} | cut -f1)
              echo "‚úÖ Sauvegarde cr√©√©e : ${BACKUP_FILE} (${BACKUP_SIZE})"

              # Tester l'int√©grit√© de l'archive
              echo "V√©rification de l'int√©grit√©..."
              if gzip -t ${BACKUP_PATH}; then
                echo "‚úÖ Archive valide"
              else
                echo "‚ùå Archive corrompue"
                exit 1
              fi

              # Nettoyage des anciennes sauvegardes (garder 30 jours)
              echo "Nettoyage des anciennes sauvegardes..."
              find ${BACKUP_DIR} -name "postgres-backup-*.sql.gz" -mtime +30 -delete

              # Liste des sauvegardes existantes
              echo "Sauvegardes disponibles :"
              ls -lh ${BACKUP_DIR}/postgres-backup-*.sql.gz

              echo "=========================================="
              echo "‚úÖ Sauvegarde termin√©e avec succ√®s"
              echo "Date: $(date)"
              echo "=========================================="

            volumeMounts:
            - name: backup-storage
              mountPath: /backup

            resources:
              requests:
                memory: "256Mi"
                cpu: "100m"
              limits:
                memory: "512Mi"
                cpu: "500m"

          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: postgres-backup-pvc
---
# PersistentVolumeClaim pour stocker les sauvegardes
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-backup-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi  # Adapter selon vos besoins
  storageClassName: hostpath  # Ou votre StorageClass
---
# Secret pour les credentials (√† cr√©er avec vos vraies valeurs)
apiVersion: v1
kind: Secret
metadata:
  name: postgres-credentials
type: Opaque
stringData:
  username: postgres
  password: votre-mot-de-passe-securise
```

**Points importants :**

1. **S√©curit√©** : Les credentials sont dans un Secret, pas en clair
2. **Compression** : Utilisation de `gzip` pour r√©duire l'espace disque
3. **Validation** : V√©rification de l'int√©grit√© de l'archive
4. **Nettoyage** : Suppression automatique des sauvegardes de plus de 30 jours
5. **Logs d√©taill√©s** : Permet de suivre facilement l'ex√©cution
6. **Ressources limit√©es** : √âvite de surcharger le cluster

### 1.2 Sauvegarde de Base de Donn√©es MySQL

Similaire √† PostgreSQL, mais avec les outils MySQL.

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-mysql
spec:
  schedule: "0 3 * * *"  # 3h du matin
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 2

  jobTemplate:
    spec:
      backoffLimit: 2
      activeDeadlineSeconds: 1800

      template:
        spec:
          restartPolicy: OnFailure

          containers:
          - name: mysql-backup
            image: mysql:8.0

            env:
            - name: MYSQL_HOST
              value: "mysql.default.svc.cluster.local"
            - name: MYSQL_DATABASE
              value: "production"
            - name: MYSQL_USER
              valueFrom:
                secretKeyRef:
                  name: mysql-credentials
                  key: username
            - name: MYSQL_PWD  # Variable sp√©ciale MySQL
              valueFrom:
                secretKeyRef:
                  name: mysql-credentials
                  key: password

            command:
            - /bin/bash
            - -c
            - |
              set -e

              BACKUP_DIR="/backup"
              DATE=$(date +%Y%m%d-%H%M%S)
              BACKUP_FILE="mysql-backup-${DATE}.sql.gz"

              echo "D√©but de la sauvegarde MySQL..."

              mkdir -p ${BACKUP_DIR}

              # Sauvegarde avec mysqldump
              mysqldump \
                --host=${MYSQL_HOST} \
                --user=${MYSQL_USER} \
                --single-transaction \
                --routines \
                --triggers \
                --events \
                ${MYSQL_DATABASE} \
                | gzip > ${BACKUP_DIR}/${BACKUP_FILE}

              echo "‚úÖ Sauvegarde cr√©√©e : ${BACKUP_FILE}"
              echo "Taille : $(du -h ${BACKUP_DIR}/${BACKUP_FILE} | cut -f1)"

              # Nettoyage
              find ${BACKUP_DIR} -name "mysql-backup-*.sql.gz" -mtime +30 -delete

              echo "‚úÖ Sauvegarde termin√©e"

            volumeMounts:
            - name: backup-storage
              mountPath: /backup

          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: mysql-backup-pvc
```

### 1.3 Sauvegarde de Volumes Kubernetes

Pour sauvegarder le contenu d'un PersistentVolume (fichiers, donn√©es applicatives).

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-volumes
spec:
  schedule: "0 1 * * *"  # 1h du matin
  concurrencyPolicy: Forbid

  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure

          containers:
          - name: volume-backup
            image: alpine:latest

            command:
            - /bin/sh
            - -c
            - |
              set -e

              apk add --no-cache tar gzip

              BACKUP_DIR="/backup"
              SOURCE_DIR="/data"
              DATE=$(date +%Y%m%d-%H%M%S)
              BACKUP_FILE="volume-backup-${DATE}.tar.gz"

              echo "Sauvegarde du volume..."
              echo "Source : ${SOURCE_DIR}"
              echo "Destination : ${BACKUP_DIR}/${BACKUP_FILE}"

              # Cr√©er l'archive tar compress√©e
              tar czf ${BACKUP_DIR}/${BACKUP_FILE} -C ${SOURCE_DIR} .

              BACKUP_SIZE=$(du -h ${BACKUP_DIR}/${BACKUP_FILE} | cut -f1)
              echo "‚úÖ Archive cr√©√©e : ${BACKUP_FILE} (${BACKUP_SIZE})"

              # V√©rifier l'archive
              if tar tzf ${BACKUP_DIR}/${BACKUP_FILE} > /dev/null; then
                echo "‚úÖ Archive valide"
              else
                echo "‚ùå Archive corrompue"
                exit 1
              fi

              # Nettoyage
              find ${BACKUP_DIR} -name "volume-backup-*.tar.gz" -mtime +14 -delete

              echo "‚úÖ Sauvegarde termin√©e"

            volumeMounts:
            - name: data-to-backup
              mountPath: /data
              readOnly: true  # Lecture seule pour plus de s√©curit√©
            - name: backup-storage
              mountPath: /backup

          volumes:
          - name: data-to-backup
            persistentVolumeClaim:
              claimName: app-data-pvc  # Le volume √† sauvegarder
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc    # O√π stocker les sauvegardes
```

### 1.4 Sauvegarde des Configurations Kubernetes

Sauvegarder les manifestes de tous vos objets Kubernetes.

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-kubernetes-configs
spec:
  schedule: "0 4 * * *"  # 4h du matin

  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: backup-sa  # ServiceAccount avec permissions lecture
          restartPolicy: OnFailure

          containers:
          - name: config-backup
            image: bitnami/kubectl:latest

            command:
            - /bin/bash
            - -c
            - |
              set -e

              BACKUP_DIR="/backup"
              DATE=$(date +%Y%m%d-%H%M%S)
              NAMESPACE="default"  # Ou votre namespace

              echo "Sauvegarde des configurations Kubernetes..."

              mkdir -p ${BACKUP_DIR}/${DATE}
              cd ${BACKUP_DIR}/${DATE}

              # Sauvegarder diff√©rents types de ressources
              echo "Sauvegarde des Deployments..."
              kubectl get deployments -n ${NAMESPACE} -o yaml > deployments.yaml

              echo "Sauvegarde des Services..."
              kubectl get services -n ${NAMESPACE} -o yaml > services.yaml

              echo "Sauvegarde des ConfigMaps..."
              kubectl get configmaps -n ${NAMESPACE} -o yaml > configmaps.yaml

              echo "Sauvegarde des Secrets..."
              kubectl get secrets -n ${NAMESPACE} -o yaml > secrets.yaml

              echo "Sauvegarde des PersistentVolumeClaims..."
              kubectl get pvc -n ${NAMESPACE} -o yaml > pvcs.yaml

              echo "Sauvegarde des Ingress..."
              kubectl get ingress -n ${NAMESPACE} -o yaml > ingress.yaml

              # Cr√©er une archive
              cd ${BACKUP_DIR}
              tar czf kubernetes-config-${DATE}.tar.gz ${DATE}/
              rm -rf ${DATE}

              echo "‚úÖ Configuration sauvegard√©e : kubernetes-config-${DATE}.tar.gz"

              # Nettoyage (garder 60 jours)
              find ${BACKUP_DIR} -name "kubernetes-config-*.tar.gz" -mtime +60 -delete

              echo "‚úÖ Sauvegarde termin√©e"

            volumeMounts:
            - name: backup-storage
              mountPath: /backup

          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: config-backup-pvc
---
# ServiceAccount avec permissions de lecture
apiVersion: v1
kind: ServiceAccount
metadata:
  name: backup-sa
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: backup-role
rules:
- apiGroups: ["", "apps", "networking.k8s.io"]
  resources: ["*"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: backup-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: backup-role
subjects:
- kind: ServiceAccount
  name: backup-sa
```

### 1.5 Sauvegarde vers un Service Cloud (S3)

Pour une vraie strat√©gie de backup, il faut envoyer les sauvegardes hors site.

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-to-s3
spec:
  schedule: "0 5 * * *"  # 5h du matin

  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure

          containers:
          - name: s3-sync
            image: amazon/aws-cli:latest

            env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: access-key-id
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: secret-access-key
            - name: AWS_DEFAULT_REGION
              value: "eu-west-3"  # Paris
            - name: S3_BUCKET
              value: "s3://mon-bucket-backup"

            command:
            - /bin/bash
            - -c
            - |
              set -e

              echo "Synchronisation vers S3..."

              # Synchroniser les sauvegardes vers S3
              aws s3 sync /backup ${S3_BUCKET}/kubernetes-backups/ \
                --storage-class GLACIER_INSTANT_RETRIEVAL \
                --exclude "*" \
                --include "*.sql.gz" \
                --include "*.tar.gz"

              echo "‚úÖ Synchronisation termin√©e"

              # Lister les fichiers sur S3
              echo "Fichiers sur S3 :"
              aws s3 ls ${S3_BUCKET}/kubernetes-backups/ --recursive --human-readable

            volumeMounts:
            - name: backup-storage
              mountPath: /backup
              readOnly: true

          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
```

## 2. ETL (Extract, Transform, Load)

**ETL** signifie **Extract, Transform, Load** (Extraire, Transformer, Charger). C'est un processus classique pour :
1. **Extraire** des donn√©es depuis une source
2. **Transformer** ces donn√©es (nettoyer, agr√©ger, calculer)
3. **Charger** les donn√©es transform√©es dans une destination

### Exemple d'ETL Complet

Imaginons que vous avez un site e-commerce et que vous voulez g√©n√©rer un rapport quotidien des ventes.

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: etl-rapport-ventes
spec:
  schedule: "0 6 * * *"  # 6h du matin
  concurrencyPolicy: Forbid

  jobTemplate:
    spec:
      backoffLimit: 2
      activeDeadlineSeconds: 3600  # 1 heure max

      template:
        spec:
          restartPolicy: OnFailure

          # InitContainer : V√©rifier que la base de donn√©es est pr√™te
          initContainers:
          - name: wait-for-database
            image: postgres:15
            command:
            - sh
            - -c
            - |
              until pg_isready -h postgresql.default.svc.cluster.local -p 5432; do
                echo "En attente de PostgreSQL..."
                sleep 2
              done
              echo "PostgreSQL est pr√™t"

          containers:
          - name: etl-processor
            image: python:3.11

            env:
            - name: DB_HOST
              value: "postgresql.default.svc.cluster.local"
            - name: DB_NAME
              value: "ecommerce"
            - name: DB_USER
              valueFrom:
                secretKeyRef:
                  name: db-credentials
                  key: username
            - name: DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-credentials
                  key: password

            command:
            - python
            - -c
            - |
              import psycopg2
              import json
              import os
              from datetime import datetime, timedelta

              print("="*50)
              print("ETL - Rapport Quotidien des Ventes")
              print(f"Date : {datetime.now()}")
              print("="*50)

              # ===== EXTRACT (Extraction) =====
              print("\n1. EXTRACTION des donn√©es...")

              conn = psycopg2.connect(
                  host=os.environ['DB_HOST'],
                  database=os.environ['DB_NAME'],
                  user=os.environ['DB_USER'],
                  password=os.environ['DB_PASSWORD']
              )
              cursor = conn.cursor()

              # Extraire les ventes de la veille
              hier = datetime.now() - timedelta(days=1)
              date_debut = hier.replace(hour=0, minute=0, second=0)
              date_fin = hier.replace(hour=23, minute=59, second=59)

              query = """
                  SELECT
                      order_id,
                      customer_id,
                      product_id,
                      quantity,
                      price,
                      timestamp
                  FROM orders
                  WHERE timestamp BETWEEN %s AND %s
              """

              cursor.execute(query, (date_debut, date_fin))
              ventes = cursor.fetchall()

              print(f"‚úÖ {len(ventes)} commandes extraites")

              # ===== TRANSFORM (Transformation) =====
              print("\n2. TRANSFORMATION des donn√©es...")

              # Calculer les statistiques
              total_ventes = 0
              total_articles = 0
              ventes_par_produit = {}

              for vente in ventes:
                  order_id, customer_id, product_id, quantity, price, timestamp = vente

                  montant = quantity * price
                  total_ventes += montant
                  total_articles += quantity

                  if product_id not in ventes_par_produit:
                      ventes_par_produit[product_id] = {
                          'quantite': 0,
                          'montant': 0
                      }

                  ventes_par_produit[product_id]['quantite'] += quantity
                  ventes_par_produit[product_id]['montant'] += montant

              # Trouver le produit le plus vendu
              produit_top = max(
                  ventes_par_produit.items(),
                  key=lambda x: x[1]['quantite']
              ) if ventes_par_produit else (None, {'quantite': 0, 'montant': 0})

              print(f"‚úÖ Donn√©es transform√©es")
              print(f"   Total des ventes : {total_ventes:.2f}‚Ç¨")
              print(f"   Total des articles : {total_articles}")
              print(f"   Produit le plus vendu : {produit_top[0]}")

              # ===== LOAD (Chargement) =====
              print("\n3. CHARGEMENT des r√©sultats...")

              # Cr√©er la table de rapports si elle n'existe pas
              cursor.execute("""
                  CREATE TABLE IF NOT EXISTS rapports_quotidiens (
                      id SERIAL PRIMARY KEY,
                      date DATE NOT NULL,
                      total_ventes DECIMAL(10, 2),
                      total_articles INTEGER,
                      nombre_commandes INTEGER,
                      produit_top INTEGER,
                      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                  )
              """)

              # Ins√©rer le rapport
              cursor.execute("""
                  INSERT INTO rapports_quotidiens
                      (date, total_ventes, total_articles, nombre_commandes, produit_top)
                  VALUES (%s, %s, %s, %s, %s)
              """, (
                  hier.date(),
                  total_ventes,
                  total_articles,
                  len(ventes),
                  produit_top[0]
              ))

              conn.commit()

              print("‚úÖ Rapport ins√©r√© dans la base de donn√©es")

              # G√©n√©rer un fichier JSON pour archivage
              rapport = {
                  'date': hier.strftime('%Y-%m-%d'),
                  'total_ventes': float(total_ventes),
                  'total_articles': total_articles,
                  'nombre_commandes': len(ventes),
                  'produit_top': produit_top[0],
                  'ventes_par_produit': {
                      str(k): v for k, v in ventes_par_produit.items()
                  }
              }

              filename = f"/rapports/rapport-{hier.strftime('%Y%m%d')}.json"
              with open(filename, 'w') as f:
                  json.dump(rapport, f, indent=2)

              print(f"‚úÖ Rapport sauvegard√© : {filename}")

              cursor.close()
              conn.close()

              print("\n" + "="*50)
              print("‚úÖ ETL termin√© avec succ√®s")
              print("="*50)

            volumeMounts:
            - name: rapports
              mountPath: /rapports

            resources:
              requests:
                memory: "256Mi"
                cpu: "200m"
              limits:
                memory: "512Mi"
                cpu: "500m"

          volumes:
          - name: rapports
            persistentVolumeClaim:
              claimName: rapports-pvc
```

### 2.2 ETL : Agr√©gation de Logs

Extraire les logs, les analyser, et g√©n√©rer des statistiques.

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: etl-analyse-logs
spec:
  schedule: "0 */6 * * *"  # Toutes les 6 heures

  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure

          containers:
          - name: log-analyzer
            image: python:3.11-slim

            command:
            - python
            - -c
            - |
              import re
              import json
              from collections import Counter
              from datetime import datetime

              print("Analyse des logs d'acc√®s...")

              # ===== EXTRACT =====
              print("1. Lecture des logs...")

              with open('/logs/access.log', 'r') as f:
                  lignes = f.readlines()

              print(f"‚úÖ {len(lignes)} lignes de logs lues")

              # ===== TRANSFORM =====
              print("2. Analyse des logs...")

              # Pattern pour parser les logs Apache/Nginx
              pattern = r'(\S+) \S+ \S+ \[(.*?)\] "(\S+) (\S+) \S+" (\d+) (\d+)'

              ips = []
              status_codes = []
              urls = []
              user_agents = []

              for ligne in lignes:
                  match = re.match(pattern, ligne)
                  if match:
                      ip, timestamp, method, url, status, size = match.groups()
                      ips.append(ip)
                      status_codes.append(status)
                      urls.append(url)

              # Statistiques
              ip_counter = Counter(ips)
              status_counter = Counter(status_codes)
              url_counter = Counter(urls)

              stats = {
                  'total_requetes': len(lignes),
                  'ips_uniques': len(set(ips)),
                  'top_10_ips': dict(ip_counter.most_common(10)),
                  'codes_status': dict(status_counter),
                  'top_10_urls': dict(url_counter.most_common(10)),
                  'timestamp': datetime.now().isoformat()
              }

              print(f"‚úÖ Statistiques calcul√©es")
              print(f"   Total requ√™tes : {stats['total_requetes']}")
              print(f"   IPs uniques : {stats['ips_uniques']}")

              # ===== LOAD =====
              print("3. Sauvegarde des statistiques...")

              output_file = f"/output/log-stats-{datetime.now().strftime('%Y%m%d-%H%M')}.json"
              with open(output_file, 'w') as f:
                  json.dump(stats, f, indent=2)

              print(f"‚úÖ Statistiques sauvegard√©es : {output_file}")

            volumeMounts:
            - name: logs
              mountPath: /logs
              readOnly: true
            - name: output
              mountPath: /output

          volumes:
          - name: logs
            persistentVolumeClaim:
              claimName: app-logs-pvc
          - name: output
            persistentVolumeClaim:
              claimName: stats-pvc
```

### 2.3 ETL : Synchronisation de Donn√©es entre Syst√®mes

Extraire des donn√©es d'une API externe, les transformer, et les charger dans votre base de donn√©es.

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: etl-sync-api-externe
spec:
  schedule: "*/30 * * * *"  # Toutes les 30 minutes
  concurrencyPolicy: Replace  # Remplacer l'ancienne ex√©cution si elle tourne encore

  jobTemplate:
    spec:
      backoffLimit: 3

      template:
        spec:
          restartPolicy: OnFailure

          containers:
          - name: api-sync
            image: python:3.11-slim

            env:
            - name: API_URL
              value: "https://api.example.com/data"
            - name: API_KEY
              valueFrom:
                secretKeyRef:
                  name: api-credentials
                  key: api-key
            - name: DB_URL
              valueFrom:
                secretKeyRef:
                  name: db-credentials
                  key: connection-string

            command:
            - python
            - -c
            - |
              import requests
              import psycopg2
              import json
              import os
              from datetime import datetime

              print("="*50)
              print("ETL - Synchronisation API Externe")
              print("="*50)

              # ===== EXTRACT =====
              print("\n1. EXTRACTION depuis l'API...")

              headers = {'Authorization': f'Bearer {os.environ["API_KEY"]}'}

              try:
                  response = requests.get(
                      os.environ['API_URL'],
                      headers=headers,
                      timeout=30
                  )
                  response.raise_for_status()

                  data = response.json()
                  print(f"‚úÖ {len(data)} enregistrements extraits")

              except requests.exceptions.RequestException as e:
                  print(f"‚ùå Erreur API : {e}")
                  exit(1)

              # ===== TRANSFORM =====
              print("\n2. TRANSFORMATION des donn√©es...")

              transformed_data = []

              for item in data:
                  # Nettoyer et normaliser les donn√©es
                  transformed = {
                      'external_id': item.get('id'),
                      'name': item.get('name', '').strip().upper(),
                      'value': float(item.get('value', 0)),
                      'category': item.get('category', 'UNKNOWN'),
                      'synced_at': datetime.now()
                  }
                  transformed_data.append(transformed)

              print(f"‚úÖ {len(transformed_data)} enregistrements transform√©s")

              # ===== LOAD =====
              print("\n3. CHARGEMENT dans la base de donn√©es...")

              conn = psycopg2.connect(os.environ['DB_URL'])
              cursor = conn.cursor()

              # Cr√©er la table si n√©cessaire
              cursor.execute("""
                  CREATE TABLE IF NOT EXISTS external_data (
                      id SERIAL PRIMARY KEY,
                      external_id INTEGER UNIQUE,
                      name VARCHAR(255),
                      value DECIMAL(10, 2),
                      category VARCHAR(100),
                      synced_at TIMESTAMP,
                      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                      updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                  )
              """)

              # Ins√©rer ou mettre √† jour les donn√©es (UPSERT)
              inserted = 0
              updated = 0

              for item in transformed_data:
                  cursor.execute("""
                      INSERT INTO external_data
                          (external_id, name, value, category, synced_at)
                      VALUES (%s, %s, %s, %s, %s)
                      ON CONFLICT (external_id)
                      DO UPDATE SET
                          name = EXCLUDED.name,
                          value = EXCLUDED.value,
                          category = EXCLUDED.category,
                          synced_at = EXCLUDED.synced_at,
                          updated_at = CURRENT_TIMESTAMP
                      RETURNING (xmax = 0) AS inserted
                  """, (
                      item['external_id'],
                      item['name'],
                      item['value'],
                      item['category'],
                      item['synced_at']
                  ))

                  was_insert = cursor.fetchone()[0]
                  if was_insert:
                      inserted += 1
                  else:
                      updated += 1

              conn.commit()

              print(f"‚úÖ Chargement termin√©")
              print(f"   Nouveaux : {inserted}")
              print(f"   Mis √† jour : {updated}")

              cursor.close()
              conn.close()

              print("\n" + "="*50)
              print("‚úÖ Synchronisation termin√©e avec succ√®s")
              print("="*50)

            resources:
              requests:
                memory: "128Mi"
                cpu: "100m"
              limits:
                memory: "256Mi"
                cpu: "200m"
```

## 3. Cleanup (Nettoyage)

Le nettoyage r√©gulier est essentiel pour maintenir un syst√®me performant et √©viter de manquer d'espace disque.

### 3.1 Nettoyage des Fichiers Temporaires

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cleanup-temp-files
spec:
  schedule: "0 */12 * * *"  # Toutes les 12 heures

  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure

          containers:
          - name: cleaner
            image: busybox

            command:
            - sh
            - -c
            - |
              set -e

              echo "=========================================="
              echo "Nettoyage des fichiers temporaires"
              echo "Date: $(date)"
              echo "=========================================="

              TEMP_DIR="/tmp"

              # Afficher l'espace disque avant nettoyage
              echo "Espace disque AVANT nettoyage :"
              df -h ${TEMP_DIR}

              # Compter les fichiers avant
              BEFORE=$(find ${TEMP_DIR} -type f | wc -l)
              echo "Fichiers temporaires : ${BEFORE}"

              # Supprimer les fichiers de plus de 7 jours
              echo "Suppression des fichiers de plus de 7 jours..."
              find ${TEMP_DIR} -type f -mtime +7 -delete

              # Supprimer les r√©pertoires vides
              echo "Suppression des r√©pertoires vides..."
              find ${TEMP_DIR} -type d -empty -delete

              # Supprimer les fichiers commen√ßant par .tmp
              echo "Suppression des fichiers .tmp*..."
              find ${TEMP_DIR} -type f -name ".tmp*" -delete

              # Compter les fichiers apr√®s
              AFTER=$(find ${TEMP_DIR} -type f | wc -l)
              CLEANED=$((BEFORE - AFTER))

              echo "Fichiers supprim√©s : ${CLEANED}"
              echo "Fichiers restants : ${AFTER}"

              # Afficher l'espace disque apr√®s nettoyage
              echo "Espace disque APR√àS nettoyage :"
              df -h ${TEMP_DIR}

              echo "=========================================="
              echo "‚úÖ Nettoyage termin√©"
              echo "=========================================="

            volumeMounts:
            - name: temp
              mountPath: /tmp

          volumes:
          - name: temp
            persistentVolumeClaim:
              claimName: temp-pvc
```

### 3.2 Nettoyage des Logs Applicatifs

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cleanup-application-logs
spec:
  schedule: "0 3 * * 0"  # Tous les dimanches √† 3h

  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure

          containers:
          - name: log-cleaner
            image: busybox

            command:
            - sh
            - -c
            - |
              set -e

              echo "Nettoyage des logs applicatifs..."

              LOG_DIR="/var/log/app"

              # Espace avant
              SPACE_BEFORE=$(du -sh ${LOG_DIR} | cut -f1)
              echo "Espace utilis√© AVANT : ${SPACE_BEFORE}"

              # Compresser les logs de plus de 7 jours
              echo "Compression des logs de plus de 7 jours..."
              find ${LOG_DIR} -name "*.log" -type f -mtime +7 -exec gzip {} \;

              # Supprimer les logs compress√©s de plus de 30 jours
              echo "Suppression des logs de plus de 30 jours..."
              find ${LOG_DIR} -name "*.log.gz" -type f -mtime +30 -delete

              # Tronquer les logs actifs trop volumineux (> 1GB)
              echo "Troncature des logs volumineux..."
              find ${LOG_DIR} -name "*.log" -type f -size +1G -exec truncate -s 100M {} \;

              # Espace apr√®s
              SPACE_AFTER=$(du -sh ${LOG_DIR} | cut -f1)
              echo "Espace utilis√© APR√àS : ${SPACE_AFTER}"

              # Lister les 10 plus gros fichiers restants
              echo "Les 10 plus gros fichiers :"
              find ${LOG_DIR} -type f -exec du -h {} \; | sort -rh | head -10

              echo "‚úÖ Nettoyage des logs termin√©"

            volumeMounts:
            - name: app-logs
              mountPath: /var/log/app

          volumes:
          - name: app-logs
            persistentVolumeClaim:
              claimName: app-logs-pvc
```

### 3.3 Nettoyage des Images Docker Inutilis√©es

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cleanup-docker-images
spec:
  schedule: "0 2 * * 6"  # Tous les samedis √† 2h

  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure

          # Acc√®s au socket Docker du node
          hostNetwork: true

          containers:
          - name: docker-cleaner
            image: docker:latest

            command:
            - sh
            - -c
            - |
              set -e

              echo "Nettoyage des images Docker..."

              # Afficher l'espace disque avant
              echo "Espace disque AVANT :"
              docker system df

              # Supprimer les images non utilis√©es
              echo "Suppression des images non utilis√©es..."
              docker image prune -a -f --filter "until=168h"  # 7 jours

              # Supprimer les conteneurs arr√™t√©s
              echo "Suppression des conteneurs arr√™t√©s..."
              docker container prune -f --filter "until=24h"

              # Supprimer les volumes non utilis√©s
              echo "Suppression des volumes non utilis√©s..."
              docker volume prune -f

              # Supprimer les r√©seaux non utilis√©s
              echo "Suppression des r√©seaux non utilis√©s..."
              docker network prune -f

              # Afficher l'espace disque apr√®s
              echo "Espace disque APR√àS :"
              docker system df

              echo "‚úÖ Nettoyage Docker termin√©"

            volumeMounts:
            - name: docker-sock
              mountPath: /var/run/docker.sock

            securityContext:
              privileged: true

          volumes:
          - name: docker-sock
            hostPath:
              path: /var/run/docker.sock
              type: Socket
```

**Note de s√©curit√©** : Ce Job n√©cessite des privil√®ges √©lev√©s. Utilisez-le avec pr√©caution et uniquement si vous comprenez les implications de s√©curit√©.

### 3.4 Nettoyage de Base de Donn√©es (Purge des Anciennes Donn√©es)

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cleanup-old-database-records
spec:
  schedule: "0 4 * * 0"  # Tous les dimanches √† 4h

  jobTemplate:
    spec:
      backoffLimit: 1
      activeDeadlineSeconds: 7200  # 2 heures max

      template:
        spec:
          restartPolicy: OnFailure

          containers:
          - name: db-cleaner
            image: postgres:15

            env:
            - name: PGHOST
              value: "postgresql.default.svc.cluster.local"
            - name: PGDATABASE
              value: "production"
            - name: PGUSER
              valueFrom:
                secretKeyRef:
                  name: db-credentials
                  key: username
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-credentials
                  key: password

            command:
            - /bin/bash
            - -c
            - |
              set -e

              echo "=========================================="
              echo "Nettoyage de la base de donn√©es"
              echo "Date: $(date)"
              echo "=========================================="

              # Fonction pour compter les lignes
              count_rows() {
                  psql -t -c "SELECT COUNT(*) FROM $1" | xargs
              }

              # Supprimer les logs de plus de 90 jours
              echo "Suppression des logs anciens..."
              BEFORE=$(count_rows "application_logs")

              psql -c "DELETE FROM application_logs WHERE created_at < NOW() - INTERVAL '90 days'"

              AFTER=$(count_rows "application_logs")
              DELETED=$((BEFORE - AFTER))
              echo "‚úÖ Logs supprim√©s : ${DELETED}"

              # Supprimer les sessions expir√©es
              echo "Suppression des sessions expir√©es..."
              BEFORE=$(count_rows "user_sessions")

              psql -c "DELETE FROM user_sessions WHERE expires_at < NOW()"

              AFTER=$(count_rows "user_sessions")
              DELETED=$((BEFORE - AFTER))
              echo "‚úÖ Sessions supprim√©es : ${DELETED}"

              # Archiver les anciennes commandes (> 2 ans)
              echo "Archivage des anciennes commandes..."
              BEFORE=$(count_rows "orders")

              psql -c "
                  INSERT INTO orders_archive
                  SELECT * FROM orders
                  WHERE created_at < NOW() - INTERVAL '2 years'
              "

              psql -c "DELETE FROM orders WHERE created_at < NOW() - INTERVAL '2 years'"

              AFTER=$(count_rows "orders")
              ARCHIVED=$((BEFORE - AFTER))
              echo "‚úÖ Commandes archiv√©es : ${ARCHIVED}"

              # Vacuum pour r√©cup√©rer l'espace
              echo "Optimisation de la base de donn√©es..."
              psql -c "VACUUM FULL ANALYZE"

              # Afficher les statistiques
              echo "Statistiques des tables :"
              psql -c "
                  SELECT
                      schemaname,
                      tablename,
                      pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
                  FROM pg_tables
                  WHERE schemaname = 'public'
                  ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
                  LIMIT 10
              "

              echo "=========================================="
              echo "‚úÖ Nettoyage termin√©"
              echo "=========================================="

            resources:
              requests:
                memory: "256Mi"
                cpu: "200m"
              limits:
                memory: "512Mi"
                cpu: "500m"
```

## 4. Autres Cas d'Usage Pratiques

### 4.1 G√©n√©ration de Rapports Automatiques

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: generate-weekly-report
spec:
  schedule: "0 9 * * 1"  # Tous les lundis √† 9h

  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure

          containers:
          - name: report-generator
            image: python:3.11

            command:
            - python
            - -c
            - |
              import smtplib
              from email.mime.text import MIMEText
              from email.mime.multipart import MIMEMultipart
              from datetime import datetime, timedelta
              import os

              print("G√©n√©ration du rapport hebdomadaire...")

              # R√©cup√©rer les donn√©es de la semaine pass√©e
              # (simplifi√© pour l'exemple)

              # Cr√©er le rapport HTML
              html_content = f"""
              <html>
                <body>
                  <h1>Rapport Hebdomadaire - Semaine {datetime.now().isocalendar()[1]}</h1>
                  <h2>R√©sum√©</h2>
                  <ul>
                    <li>Nouvelles inscriptions : 150</li>
                    <li>Ventes totales : 45,230‚Ç¨</li>
                    <li>Taux de conversion : 3.2%</li>
                  </ul>
                  <h2>Top Produits</h2>
                  <ol>
                    <li>Produit A - 85 ventes</li>
                    <li>Produit B - 62 ventes</li>
                    <li>Produit C - 41 ventes</li>
                  </ol>
                </body>
              </html>
              """

              # Envoyer par email
              msg = MIMEMultipart('alternative')
              msg['Subject'] = f"Rapport Hebdomadaire - Semaine {datetime.now().isocalendar()[1]}"
              msg['From'] = "reports@monentreprise.com"
              msg['To'] = "direction@monentreprise.com"

              msg.attach(MIMEText(html_content, 'html'))

              # Connexion SMTP (exemple)
              # smtp = smtplib.SMTP(os.environ['SMTP_HOST'], 587)
              # smtp.starttls()
              # smtp.login(os.environ['SMTP_USER'], os.environ['SMTP_PASS'])
              # smtp.send_message(msg)
              # smtp.quit()

              print("‚úÖ Rapport g√©n√©r√© et envoy√©")

            env:
            - name: SMTP_HOST
              value: "smtp.example.com"
            - name: SMTP_USER
              valueFrom:
                secretKeyRef:
                  name: smtp-credentials
                  key: username
            - name: SMTP_PASS
              valueFrom:
                secretKeyRef:
                  name: smtp-credentials
                  key: password
```

### 4.2 V√©rification de Sant√© P√©riodique

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: health-check-services
spec:
  schedule: "*/15 * * * *"  # Toutes les 15 minutes

  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure

          containers:
          - name: health-checker
            image: curlimages/curl:latest

            command:
            - sh
            - -c
            - |
              set -e

              echo "V√©rification de sant√© des services..."

              ERRORS=0

              # V√©rifier l'application web
              if curl -f -s -o /dev/null http://web-app.default.svc.cluster.local/health; then
                echo "‚úÖ Application web : OK"
              else
                echo "‚ùå Application web : ERREUR"
                ERRORS=$((ERRORS + 1))
              fi

              # V√©rifier l'API
              if curl -f -s -o /dev/null http://api.default.svc.cluster.local/healthz; then
                echo "‚úÖ API : OK"
              else
                echo "‚ùå API : ERREUR"
                ERRORS=$((ERRORS + 1))
              fi

              # V√©rifier Redis
              if nc -zv redis.default.svc.cluster.local 6379 2>&1 | grep -q succeeded; then
                echo "‚úÖ Redis : OK"
              else
                echo "‚ùå Redis : ERREUR"
                ERRORS=$((ERRORS + 1))
              fi

              # V√©rifier PostgreSQL
              if nc -zv postgresql.default.svc.cluster.local 5432 2>&1 | grep -q succeeded; then
                echo "‚úÖ PostgreSQL : OK"
              else
                echo "‚ùå PostgreSQL : ERREUR"
                ERRORS=$((ERRORS + 1))
              fi

              if [ $ERRORS -gt 0 ]; then
                echo "‚ö†Ô∏è  ${ERRORS} service(s) en erreur"
                # Ici, vous pourriez envoyer une alerte
                exit 1
              else
                echo "‚úÖ Tous les services sont op√©rationnels"
                exit 0
              fi
```

### 4.3 Rotation des Secrets et Certificats

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: rotate-api-keys
spec:
  schedule: "0 0 1 * *"  # Le 1er de chaque mois √† minuit

  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: secret-rotator-sa
          restartPolicy: OnFailure

          containers:
          - name: key-rotator
            image: bitnami/kubectl:latest

            command:
            - /bin/bash
            - -c
            - |
              set -e

              echo "Rotation des cl√©s API..."

              # G√©n√©rer une nouvelle cl√© API
              NEW_API_KEY=$(openssl rand -hex 32)

              echo "Nouvelle cl√© g√©n√©r√©e"

              # Mettre √† jour le Secret
              kubectl create secret generic api-key \
                --from-literal=key=${NEW_API_KEY} \
                --dry-run=client -o yaml | kubectl apply -f -

              echo "‚úÖ Secret mis √† jour"

              # Red√©marrer les Pods qui utilisent cette cl√©
              kubectl rollout restart deployment api-deployment

              echo "‚úÖ D√©ploiement red√©marr√©"
              echo "Rotation termin√©e avec succ√®s"
```

### 4.4 Mise √† Jour Automatique de DNS

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: update-dynamic-dns
spec:
  schedule: "*/10 * * * *"  # Toutes les 10 minutes

  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure

          containers:
          - name: dns-updater
            image: curlimages/curl:latest

            env:
            - name: DDNS_DOMAIN
              value: "monlab.exemple.com"
            - name: DDNS_TOKEN
              valueFrom:
                secretKeyRef:
                  name: ddns-credentials
                  key: token

            command:
            - sh
            - -c
            - |
              set -e

              echo "Mise √† jour du DNS dynamique..."

              # R√©cup√©rer l'IP publique
              PUBLIC_IP=$(curl -s https://api.ipify.org)

              echo "IP publique : ${PUBLIC_IP}"

              # Mettre √† jour le DNS (exemple avec API g√©n√©rique)
              curl -X POST "https://api.dns-provider.com/update" \
                -H "Authorization: Bearer ${DDNS_TOKEN}" \
                -d "domain=${DDNS_DOMAIN}" \
                -d "ip=${PUBLIC_IP}"

              echo "‚úÖ DNS mis √† jour"
```

## Bonnes Pratiques pour les Cas d'Usage

### 1. Utiliser des Variables d'Environnement

```yaml
env:
- name: RETENTION_DAYS
  value: "30"
- name: MAX_FILE_SIZE
  value: "1G"
```

Facilite la modification des param√®tres sans changer le code.

### 2. Impl√©menter des Notifications

Envoyer des alertes en cas de succ√®s ou d'√©chec.

```yaml
command:
- sh
- -c
- |
  if backup.sh; then
    # Succ√®s - notification optionnelle
    curl -X POST https://api.slack.com/webhook \
      -d '{"text":"‚úÖ Backup r√©ussi"}'
  else
    # √âchec - notification importante
    curl -X POST https://api.slack.com/webhook \
      -d '{"text":"‚ùå Backup √©chou√©"}'
    exit 1
  fi
```

### 3. Documenter les Jobs

```yaml
metadata:
  name: backup-postgresql
  annotations:
    description: "Sauvegarde quotidienne de PostgreSQL avec r√©tention de 30 jours"
    contact: "ops@monentreprise.com"
    runbook: "https://wiki.monentreprise.com/runbooks/postgres-backup"
    schedule-human: "Tous les jours √† 2h du matin (heure Paris)"
```

### 4. Monitorer les M√©triques

```yaml
command:
- sh
- -c
- |
  START_TIME=$(date +%s)

  # Votre code ici
  backup.sh

  END_TIME=$(date +%s)
  DURATION=$((END_TIME - START_TIME))

  echo "Dur√©e : ${DURATION} secondes"

  # Envoyer la m√©trique √† Prometheus (si configur√©)
  # echo "backup_duration_seconds ${DURATION}" | curl --data-binary @- \
  #   http://pushgateway:9091/metrics/job/backup
```

### 5. Tester en Mode "Dry Run"

Avant de d√©ployer en production, testez sans effectuer de modifications r√©elles.

```yaml
env:
- name: DRY_RUN
  value: "true"

command:
- sh
- -c
- |
  if [ "${DRY_RUN}" = "true" ]; then
    echo "MODE DRY RUN - Aucune modification effectu√©e"
    # Simuler les actions
  else
    # Effectuer les vraies actions
  fi
```

### 6. Versionner les Scripts

```yaml
containers:
- name: backup
  image: mon-backup-script:v2.1.0  # Version sp√©cifique
```

Plut√¥t que `:latest`, utilisez des versions sp√©cifiques pour la reproductibilit√©.

### 7. Limiter les Ressources

```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "100m"
  limits:
    memory: "512Mi"
    cpu: "500m"
```

√âvite qu'un Job ne consomme toutes les ressources du cluster.

### 8. Utiliser des Init Containers pour les Pr√©requis

```yaml
initContainers:
- name: check-dependencies
  image: busybox
  command:
  - sh
  - -c
  - |
    until nc -z database 5432; do
      echo "En attente de la base de donn√©es..."
      sleep 2
    done
```

## Patterns de Planification Recommand√©s

### Heures Creuses pour les T√¢ches Lourdes

```yaml
# Sauvegardes lourdes : la nuit
schedule: "0 2 * * *"  # 2h du matin

# ETL intensifs : t√¥t le matin
schedule: "0 5 * * *"  # 5h du matin

# Rapports : d√©but de journ√©e
schedule: "0 8 * * 1-5"  # 8h, du lundi au vendredi
```

### √âviter les Conflits de Ressources

```yaml
# Backup DB : 2h
schedule: "0 2 * * *"

# Cleanup : 3h (apr√®s le backup)
schedule: "0 3 * * *"

# ETL : 5h (apr√®s le cleanup)
schedule: "0 5 * * *"
```

### Planification par Type de T√¢che

| Type de T√¢che | Fr√©quence Recommand√©e | Exemple |
|---------------|----------------------|---------|
| **Backup critique** | Quotidien | `0 2 * * *` |
| **Backup incr√©mental** | Toutes les 6h | `0 */6 * * *` |
| **ETL** | Quotidien ou horaire | `0 * * * *` |
| **Cleanup logs** | Hebdomadaire | `0 3 * * 0` |
| **Cleanup fichiers temp** | Quotidien | `0 1 * * *` |
| **Rapports** | Hebdomadaire | `0 9 * * 1` |
| **Health checks** | 15 minutes | `*/15 * * * *` |
| **Sync donn√©es** | 30 minutes | `*/30 * * * *` |

## R√©sum√©

Cette section a pr√©sent√© des cas d'usage pratiques r√©els pour Jobs et CronJobs :

### Backups (Sauvegardes)
‚úÖ Bases de donn√©es (PostgreSQL, MySQL)
‚úÖ Volumes Kubernetes
‚úÖ Configurations Kubernetes
‚úÖ Synchronisation vers le cloud (S3)

### ETL (Extract, Transform, Load)
‚úÖ Rapports quotidiens
‚úÖ Analyse de logs
‚úÖ Synchronisation avec APIs externes
‚úÖ Agr√©gation et transformation de donn√©es

### Cleanup (Nettoyage)
‚úÖ Fichiers temporaires
‚úÖ Logs applicatifs
‚úÖ Images Docker
‚úÖ Anciennes donn√©es en base

### Autres Cas d'Usage
‚úÖ G√©n√©ration de rapports
‚úÖ V√©rifications de sant√©
‚úÖ Rotation de secrets
‚úÖ Mise √† jour DNS dynamique

**Points cl√©s √† retenir :**

1. **Automatiser ce qui est r√©p√©titif** : Backups, cleanups, rapports
2. **Utiliser des Secrets** pour les informations sensibles
3. **Impl√©menter des v√©rifications** : Tester l'int√©grit√© des backups
4. **Documenter** : Annotations, logs clairs, runbooks
5. **Monitorer** : Alertes en cas d'√©chec, m√©triques de dur√©e
6. **Tester** : Mode dry-run avant production
7. **Planifier intelligemment** : Heures creuses, √©viter les conflits

Ces patterns sont la base pour construire une infrastructure Kubernetes fiable et automatis√©e. Adaptez-les √† vos besoins sp√©cifiques !

Dans les prochaines sections, nous verrons comment exposer vos applications avec **MetalLB** (section 9) et configurer le **routage avec Ingress** (section 10).

‚è≠Ô∏è [Load Balancing avec MetalLB](/09-load-balancing-avec-metallb/README.md)
