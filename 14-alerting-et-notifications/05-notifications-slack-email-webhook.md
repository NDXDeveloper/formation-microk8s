üîù Retour au [Sommaire](/SOMMAIRE.md)

# 14.5 Notifications (Slack, email, webhook)

## Introduction

Les **receivers** (r√©cepteurs) dans Alertmanager sont les canaux par lesquels vous recevez vos notifications. Chaque receiver repr√©sente une destination sp√©cifique : un canal Slack, une adresse email, un webhook HTTP, ou une int√©gration avec un service tiers.

Dans cette section, nous allons explorer en d√©tail comment configurer les trois types de notifications les plus courants :
- **Email** : Le classique, fiable et universel
- **Slack** : Communication d'√©quipe en temps r√©el
- **Webhook** : Int√©gration personnalis√©e avec vos propres syst√®mes

Chaque type a ses avantages et ses cas d'usage. Souvent, vous utiliserez plusieurs types en parall√®le pour diff√©rents niveaux d'alertes.

## Vue d'Ensemble des Receivers

### Receivers Disponibles

Alertmanager supporte nativement de nombreux types de receivers :

**Communication** :
- Email (SMTP)
- Slack
- Microsoft Teams
- Discord
- Telegram

**Incident Management** :
- PagerDuty
- OpsGenie
- VictorOps

**G√©n√©rique** :
- Webhook (HTTP/HTTPS)

**Autres** :
- WeChat
- Pushover
- SNS (AWS)

### Anatomie d'un Receiver

Un receiver est d√©fini dans la section `receivers` de la configuration Alertmanager :

```yaml
receivers:
  - name: 'identifiant-unique'
    type_configs:
      - param√®tre1: valeur1
        param√®tre2: valeur2
```

**name** : Identifiant unique du receiver (utilis√© dans le routing)

**type_configs** : Configuration sp√©cifique au type (email_configs, slack_configs, etc.)

### Configuration de Base

```yaml
receivers:
  - name: 'team-email'
    email_configs:
      - to: 'team@example.com'

  - name: 'team-slack'
    slack_configs:
      - channel: '#alerts'
        api_url: 'webhook-url'

  - name: 'custom-webhook'
    webhook_configs:
      - url: 'http://mon-service/alerts'
```

## Notifications par Email

L'email est le canal de notification le plus universel. Tout le monde a une adresse email, et les emails peuvent contenir des informations riches et d√©taill√©es.

### Pr√©requis : Configuration SMTP Globale

Avant de configurer les receivers email, vous devez d√©finir les param√®tres SMTP globaux :

```yaml
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alertmanager@example.com'
  smtp_auth_username: 'alertmanager@example.com'
  smtp_auth_password: 'votre-mot-de-passe-application'
  smtp_require_tls: true
```

**Explication** :
- `smtp_smarthost` : Serveur SMTP et port (587 pour TLS, 465 pour SSL)
- `smtp_from` : Adresse email de l'exp√©diteur
- `smtp_auth_username` : Identifiant SMTP (souvent identique √† smtp_from)
- `smtp_auth_password` : Mot de passe SMTP
- `smtp_require_tls` : Utiliser TLS (recommand√© pour la s√©curit√©)

### Configuration avec Gmail

Gmail n√©cessite un "mot de passe d'application" sp√©cifique :

**√âtapes pour cr√©er un mot de passe d'application** :
1. Aller sur votre compte Google
2. S√©curit√© ‚Üí Validation en 2 √©tapes (l'activer si pas d√©j√† fait)
3. Mots de passe des applications
4. Cr√©er un nouveau mot de passe pour "Alertmanager"
5. Utiliser ce mot de passe dans la configuration

```yaml
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'votre-email@gmail.com'
  smtp_auth_username: 'votre-email@gmail.com'
  smtp_auth_password: 'xxxx xxxx xxxx xxxx'  # Mot de passe d'application
  smtp_require_tls: true
```

### Configuration avec d'Autres Fournisseurs

**Office 365 / Outlook** :
```yaml
global:
  smtp_smarthost: 'smtp.office365.com:587'
  smtp_from: 'alertmanager@votredomaine.com'
  smtp_auth_username: 'alertmanager@votredomaine.com'
  smtp_auth_password: 'votre-mot-de-passe'
  smtp_require_tls: true
```

**SendGrid** :
```yaml
global:
  smtp_smarthost: 'smtp.sendgrid.net:587'
  smtp_from: 'alertmanager@votredomaine.com'
  smtp_auth_username: 'apikey'
  smtp_auth_password: 'votre-api-key-sendgrid'
  smtp_require_tls: true
```

**Serveur SMTP Local** :
```yaml
global:
  smtp_smarthost: 'localhost:25'
  smtp_from: 'alertmanager@example.com'
  # Pas d'authentification n√©cessaire pour un serveur local
```

### Receiver Email Simple

Configuration minimale d'un receiver email :

```yaml
receivers:
  - name: 'team-email'
    email_configs:
      - to: 'team@example.com'
```

**Utilisation** :
```yaml
route:
  receiver: 'team-email'
```

### Receiver Email avec Plusieurs Destinataires

```yaml
receivers:
  - name: 'multiple-emails'
    email_configs:
      - to: 'admin@example.com, team@example.com, oncall@example.com'
```

Ou avec plusieurs configurations :

```yaml
receivers:
  - name: 'multiple-emails'
    email_configs:
      - to: 'admin@example.com'
      - to: 'team@example.com'
      - to: 'oncall@example.com'
```

### Personnalisation des Emails

Vous pouvez personnaliser l'objet, le corps et les headers :

```yaml
receivers:
  - name: 'custom-email'
    email_configs:
      - to: 'team@example.com'
        send_resolved: true
        headers:
          Subject: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
          From: 'Alertmanager Kubernetes <alertmanager@example.com>'
        html: |
          <!DOCTYPE html>
          <html>
            <head>
              <style>
                body { font-family: Arial, sans-serif; }
                .critical { background-color: #ff4444; color: white; }
                .warning { background-color: #ffaa00; color: white; }
                table { border-collapse: collapse; width: 100%; }
                th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
                th { background-color: #4CAF50; color: white; }
              </style>
            </head>
            <body>
              <h2>Alertes Kubernetes - {{ .Status | toUpper }}</h2>
              <p><strong>Nombre d'alertes:</strong> {{ .Alerts | len }}</p>

              <table>
                <tr>
                  <th>Alerte</th>
                  <th>S√©v√©rit√©</th>
                  <th>Description</th>
                  <th>D√©but</th>
                </tr>
                {{ range .Alerts }}
                <tr class="{{ .Labels.severity }}">
                  <td>{{ .Labels.alertname }}</td>
                  <td>{{ .Labels.severity }}</td>
                  <td>{{ .Annotations.description }}</td>
                  <td>{{ .StartsAt.Format "2006-01-02 15:04:05" }}</td>
                </tr>
                {{ end }}
              </table>

              <p><a href="{{ .ExternalURL }}">Voir dans Alertmanager</a></p>
            </body>
          </html>
```

**Explication** :
- `send_resolved` : Envoie aussi un email quand l'alerte est r√©solue
- `headers` : Personnalise les en-t√™tes de l'email (Subject, From, etc.)
- `html` : Corps de l'email au format HTML
- Templates Go pour ins√©rer des valeurs dynamiques

### Email en Texte Brut

Si vous pr√©f√©rez le texte brut au HTML :

```yaml
receivers:
  - name: 'text-email'
    email_configs:
      - to: 'team@example.com'
        headers:
          Subject: '[{{ .Status }}] {{ .GroupLabels.alertname }}'
        text: |
          Alerte Kubernetes

          Statut: {{ .Status | toUpper }}
          Nombre d'alertes: {{ .Alerts | len }}

          D√©tails:
          {{ range .Alerts }}
          - Alerte: {{ .Labels.alertname }}
            S√©v√©rit√©: {{ .Labels.severity }}
            Description: {{ .Annotations.description }}
            D√©but: {{ .StartsAt }}
          {{ end }}

          Lien: {{ .ExternalURL }}
```

### Configuration Compl√®te Email

```yaml
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alertmanager@example.com'
  smtp_auth_username: 'alertmanager@example.com'
  smtp_auth_password: 'xxxx-xxxx-xxxx-xxxx'
  smtp_require_tls: true

receivers:
  - name: 'production-critical'
    email_configs:
      - to: 'oncall@example.com'
        send_resolved: true
        headers:
          Subject: '[CRITICAL] {{ .GroupLabels.alertname }} - PRODUCTION'
          Priority: 'urgent'
        html: |
          <h1 style="color: red;">ALERTE CRITIQUE PRODUCTION</h1>
          <p>Action imm√©diate requise</p>
          {{ range .Alerts }}
          <div style="border: 2px solid red; padding: 10px; margin: 10px;">
            <h3>{{ .Labels.alertname }}</h3>
            <p>{{ .Annotations.description }}</p>
            <p><strong>Runbook:</strong> <a href="{{ .Annotations.runbook_url }}">{{ .Annotations.runbook_url }}</a></p>
          </div>
          {{ end }}
```

## Notifications Slack

Slack est devenu le standard pour la communication d'√©quipe. Les notifications Slack sont instantan√©es, visibles par toute l'√©quipe, et peuvent √™tre enrichies avec des couleurs et des boutons.

### Pr√©requis : Cr√©er un Webhook Slack

Avant de configurer Alertmanager, vous devez cr√©er un Webhook Incoming dans Slack :

**√âtapes** :
1. Aller sur https://api.slack.com/apps
2. Cr√©er une nouvelle app ou utiliser une existante
3. Activer **Incoming Webhooks**
4. Cliquer sur **Add New Webhook to Workspace**
5. Choisir le canal de destination
6. Copier l'URL du webhook (format : `https://hooks.slack.com/services/XXX/YYY/ZZZ`)

### Configuration Slack Simple

```yaml
receivers:
  - name: 'slack-alerts'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXX'
        channel: '#alerts'
```

**Note** : Vous pouvez aussi d√©finir l'URL globalement :

```yaml
global:
  slack_api_url: 'https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXX'

receivers:
  - name: 'slack-alerts'
    slack_configs:
      - channel: '#alerts'
```

### Personnalisation des Messages Slack

```yaml
receivers:
  - name: 'slack-custom'
    slack_configs:
      - api_url: 'webhook-url'
        channel: '#alerts'
        send_resolved: true
        username: 'Alertmanager'
        icon_emoji: ':fire:'
        title: '{{ .Status | toUpper }}: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alerte:* {{ .Labels.alertname }}
          *S√©v√©rit√©:* {{ .Labels.severity }}
          *Description:* {{ .Annotations.description }}
          *Namespace:* {{ .Labels.namespace }}
          *Pod:* {{ .Labels.pod }}
          {{ end }}
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
```

**Explication** :
- `send_resolved` : Envoie aussi un message quand l'alerte est r√©solue
- `username` : Nom affich√© dans Slack
- `icon_emoji` : Emoji √† afficher (`:fire:`, `:warning:`, `:white_check_mark:`)
- `title` : Titre du message
- `text` : Corps du message (supporte le markdown Slack)
- `color` : Couleur de la barre lat√©rale (`danger`=rouge, `warning`=orange, `good`=vert)

### Messages Slack avec Formatting Riche

Slack supporte un formatting markdown sp√©cifique :

```yaml
receivers:
  - name: 'slack-rich'
    slack_configs:
      - channel: '#alerts'
        title: '{{ .Status | toUpper }}: {{ .GroupLabels.alertname }}'
        text: |
          *R√©sum√©:* {{ len .Alerts }} alerte(s) en cours
          *Cluster:* {{ .GroupLabels.cluster }}

          {{ range .Alerts }}
          ---
          *{{ .Labels.alertname }}* ({{ .Labels.severity }})
          ‚Ä¢ *Description:* {{ .Annotations.description }}
          ‚Ä¢ *Namespace:* `{{ .Labels.namespace }}`
          ‚Ä¢ *Pod:* `{{ .Labels.pod }}`
          ‚Ä¢ *Depuis:* {{ .StartsAt.Format "15:04:05" }}
          {{ if .Annotations.runbook_url }}
          ‚Ä¢ *Runbook:* <{{ .Annotations.runbook_url }}|Voir la documentation>
          {{ end }}
          {{ end }}

          <{{ .ExternalURL }}|Voir dans Alertmanager>
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
```

**Formatting Slack** :
- `*texte*` : Gras
- `_texte_` : Italique
- `` `code` `` : Code inline
- `<url|texte>` : Lien cliquable

### Slack avec Plusieurs Canaux

Envoyez les alertes vers diff√©rents canaux selon le contexte :

```yaml
receivers:
  - name: 'slack-critical'
    slack_configs:
      - channel: '#critical-alerts'
        title: 'üö® ALERTE CRITIQUE'
        color: 'danger'

  - name: 'slack-warnings'
    slack_configs:
      - channel: '#warnings'
        title: '‚ö†Ô∏è Warning'
        color: 'warning'

  - name: 'slack-info'
    slack_configs:
      - channel: '#info-alerts'
        title: '‚ÑπÔ∏è Info'
        color: 'good'
```

### Slack avec Messages Threads

Pour regrouper les mises √† jour d'une m√™me alerte :

```yaml
receivers:
  - name: 'slack-threaded'
    slack_configs:
      - channel: '#alerts'
        title: '{{ .GroupLabels.alertname }}'
        # Les mises √† jour du m√™me groupe seront en thread
```

**Note** : Le threading est automatique - les mises √† jour d'un m√™me groupe d'alertes apparaissent comme r√©ponses au message initial.

### Configuration Slack Compl√®te

```yaml
receivers:
  - name: 'slack-production'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/XXX/YYY/ZZZ'
        channel: '#prod-alerts'
        send_resolved: true
        username: 'Alertmanager Production'
        icon_emoji: '{{ if eq .Status "firing" }}:fire:{{ else }}:white_check_mark:{{ end }}'
        title: |
          {{ if eq .Status "firing" }}üö®{{ else }}‚úÖ{{ end }}
          {{ .Status | toUpper }}: {{ .GroupLabels.alertname }}
        title_link: '{{ .ExternalURL }}'
        text: |
          *Cluster:* {{ .GroupLabels.cluster | toUpper }}
          *Environnement:* {{ .CommonLabels.environment }}
          *Nombre d'alertes:* {{ .Alerts | len }}

          {{ if eq .Status "firing" }}
          {{ range .Alerts }}
          ---
          *üî¥ {{ .Labels.alertname }}* | S√©v√©rit√©: *{{ .Labels.severity }}*
          {{ if .Annotations.summary }}üìù {{ .Annotations.summary }}{{ end }}
          {{ if .Annotations.description }}
          üìã {{ .Annotations.description }}
          {{ end }}

          *D√©tails:*
          ‚Ä¢ Namespace: `{{ .Labels.namespace }}`
          {{ if .Labels.pod }}‚Ä¢ Pod: `{{ .Labels.pod }}`{{ end }}
          {{ if .Labels.instance }}‚Ä¢ Instance: `{{ .Labels.instance }}`{{ end }}
          ‚Ä¢ D√©but: {{ .StartsAt.Format "2006-01-02 15:04:05" }}

          {{ if .Annotations.runbook_url }}
          üìñ <{{ .Annotations.runbook_url }}|Consulter le runbook>
          {{ end }}
          {{ if .Annotations.dashboard_url }}
          üìä <{{ .Annotations.dashboard_url }}|Voir le dashboard>
          {{ end }}
          {{ end }}
          {{ else }}
          ‚úÖ *Toutes les alertes ont √©t√© r√©solues*
          {{ end }}
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
        footer: 'Alertmanager Kubernetes'
```

## Notifications par Webhook

Les webhooks permettent d'envoyer les alertes vers vos propres syst√®mes ou services personnalis√©s via HTTP.

### Configuration Webhook Simple

```yaml
receivers:
  - name: 'custom-webhook'
    webhook_configs:
      - url: 'http://mon-service.example.com:8080/alerts'
        send_resolved: true
```

**Explication** :
- `url` : URL de votre endpoint qui recevra les alertes
- `send_resolved` : Envoie aussi les notifications de r√©solution

### Format du Payload Webhook

Alertmanager envoie un POST JSON avec cette structure :

```json
{
  "version": "4",
  "groupKey": "{}:{alertname=\"TestAlert\"}",
  "truncatedAlerts": 0,
  "status": "firing",
  "receiver": "custom-webhook",
  "groupLabels": {
    "alertname": "TestAlert"
  },
  "commonLabels": {
    "alertname": "TestAlert",
    "severity": "critical"
  },
  "commonAnnotations": {
    "description": "Test alert"
  },
  "externalURL": "http://alertmanager:9093",
  "alerts": [
    {
      "status": "firing",
      "labels": {
        "alertname": "TestAlert",
        "severity": "critical",
        "instance": "server1"
      },
      "annotations": {
        "description": "Test alert",
        "summary": "This is a test"
      },
      "startsAt": "2025-01-15T10:00:00Z",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://prometheus:9090/graph?g0.expr=..."
    }
  ]
}
```

### Webhook avec Headers Personnalis√©s

Pour ajouter des headers HTTP (authentification, etc.) :

```yaml
receivers:
  - name: 'authenticated-webhook'
    webhook_configs:
      - url: 'https://api.example.com/alerts'
        send_resolved: true
        http_config:
          bearer_token: 'votre-token-secret'
```

Ou avec Basic Auth :

```yaml
receivers:
  - name: 'basic-auth-webhook'
    webhook_configs:
      - url: 'https://api.example.com/alerts'
        http_config:
          basic_auth:
            username: 'alertmanager'
            password: 'secret-password'
```

Ou avec headers personnalis√©s :

```yaml
receivers:
  - name: 'custom-headers-webhook'
    webhook_configs:
      - url: 'https://api.example.com/alerts'
        http_config:
          headers:
            X-API-Key: 'your-api-key'
            X-Custom-Header: 'custom-value'
```

### Webhook avec TLS

Pour des connexions HTTPS s√©curis√©es :

```yaml
receivers:
  - name: 'secure-webhook'
    webhook_configs:
      - url: 'https://secure-api.example.com/alerts'
        http_config:
          tls_config:
            ca_file: /etc/alertmanager/ca.crt
            cert_file: /etc/alertmanager/client.crt
            key_file: /etc/alertmanager/client.key
            insecure_skip_verify: false
```

### Exemple de Serveur Webhook en Python

Voici un exemple simple de serveur qui re√ßoit les webhooks :

```python
from flask import Flask, request, jsonify
import json
from datetime import datetime

app = Flask(__name__)

@app.route('/alerts', methods=['POST'])
def receive_alerts():
    data = request.get_json()

    print(f"Received webhook at {datetime.now()}")
    print(f"Status: {data['status']}")
    print(f"Number of alerts: {len(data['alerts'])}")

    for alert in data['alerts']:
        print(f"\nAlert: {alert['labels']['alertname']}")
        print(f"  Severity: {alert['labels'].get('severity', 'unknown')}")
        print(f"  Description: {alert['annotations'].get('description', 'N/A')}")
        print(f"  Status: {alert['status']}")

    # Ici vous pouvez traiter les alertes comme vous voulez:
    # - Les enregistrer en base de donn√©es
    # - Les envoyer vers d'autres syst√®mes
    # - Cr√©er des tickets automatiquement
    # - D√©clencher des actions de remediation

    return jsonify({"status": "success"}), 200

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

### Exemple de Serveur Webhook en Go

```go
package main

import (
    "encoding/json"
    "fmt"
    "log"
    "net/http"
    "time"
)

type WebhookData struct {
    Version  string  `json:"version"`
    Status   string  `json:"status"`
    Alerts   []Alert `json:"alerts"`
}

type Alert struct {
    Status      string            `json:"status"`
    Labels      map[string]string `json:"labels"`
    Annotations map[string]string `json:"annotations"`
    StartsAt    time.Time         `json:"startsAt"`
}

func alertHandler(w http.ResponseWriter, r *http.Request) {
    var data WebhookData

    if err := json.NewDecoder(r.Body).Decode(&data); err != nil {
        http.Error(w, err.Error(), http.StatusBadRequest)
        return
    }

    log.Printf("Received %d alerts with status: %s\n", len(data.Alerts), data.Status)

    for _, alert := range data.Alerts {
        log.Printf("Alert: %s | Severity: %s | Description: %s\n",
            alert.Labels["alertname"],
            alert.Labels["severity"],
            alert.Annotations["description"])
    }

    w.WriteHeader(http.StatusOK)
    fmt.Fprintf(w, "OK")
}

func main() {
    http.HandleFunc("/alerts", alertHandler)
    log.Println("Webhook server listening on :8080")
    log.Fatal(http.ListenAndServe(":8080", nil))
}
```

### Webhook vers des Services Tiers

**Discord** :
```yaml
receivers:
  - name: 'discord'
    webhook_configs:
      - url: 'https://discord.com/api/webhooks/YOUR_WEBHOOK_ID/YOUR_WEBHOOK_TOKEN'
        send_resolved: true
```

**Microsoft Teams** (n√©cessite un format sp√©cial) :
```yaml
receivers:
  - name: 'teams'
    webhook_configs:
      - url: 'https://outlook.office.com/webhook/YOUR_WEBHOOK_URL'
```

**Mattermost** :
```yaml
receivers:
  - name: 'mattermost'
    webhook_configs:
      - url: 'https://mattermost.example.com/hooks/YOUR_WEBHOOK_ID'
```

## Int√©grations avec Services d'Incident Management

### PagerDuty

PagerDuty est un service d'astreinte et de gestion d'incidents populaire.

```yaml
global:
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

receivers:
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: 'votre-integration-key'
        routing_key: 'votre-routing-key'
        description: '{{ .GroupLabels.alertname }}'
        severity: '{{ if eq .GroupLabels.severity "critical" }}critical{{ else }}warning{{ end }}'
        details:
          firing: '{{ .Alerts.Firing | len }}'
          resolved: '{{ .Alerts.Resolved | len }}'
          num_alerts: '{{ .Alerts | len }}'
        links:
          - href: '{{ .ExternalURL }}'
            text: 'View in Alertmanager'
```

**Obtenir les cl√©s** :
1. Dans PagerDuty, aller dans **Services**
2. Cr√©er ou s√©lectionner un service
3. Onglet **Integrations**
4. Ajouter une int√©gration **Prometheus** ou **Generic Webhook**
5. Copier l'**Integration Key**

### OpsGenie

OpsGenie est un autre service de gestion d'incidents.

```yaml
receivers:
  - name: 'opsgenie'
    opsgenie_configs:
      - api_key: 'votre-api-key'
        api_url: 'https://api.opsgenie.com/'
        message: '{{ .GroupLabels.alertname }}'
        description: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        priority: '{{ if eq .GroupLabels.severity "critical" }}P1{{ else }}P3{{ end }}'
        teams: 'backend-team,infra-team'
        tags: 'kubernetes,{{ .GroupLabels.cluster }}'
```

### VictorOps (Splunk On-Call)

```yaml
receivers:
  - name: 'victorops'
    victorops_configs:
      - api_key: 'votre-api-key'
        routing_key: 'your-routing-key'
        message_type: '{{ if eq .Status "firing" }}CRITICAL{{ else }}RECOVERY{{ end }}'
        entity_display_name: '{{ .GroupLabels.alertname }}'
        state_message: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
```

## Templates Avanc√©s

### Variables Disponibles dans les Templates

**Variables de base** :
- `{{ .Status }}` : √âtat du groupe ("firing" ou "resolved")
- `{{ .Alerts }}` : Liste de toutes les alertes
- `{{ .Alerts.Firing }}` : Alertes en cours
- `{{ .Alerts.Resolved }}` : Alertes r√©solues
- `{{ .GroupLabels }}` : Labels de grouping
- `{{ .CommonLabels }}` : Labels communs √† toutes les alertes
- `{{ .CommonAnnotations }}` : Annotations communes
- `{{ .ExternalURL }}` : URL d'Alertmanager

**Pour chaque alerte** :
- `{{ .Status }}` : √âtat de l'alerte
- `{{ .Labels.xxx }}` : Acc√®s aux labels
- `{{ .Annotations.xxx }}` : Acc√®s aux annotations
- `{{ .StartsAt }}` : Date de d√©but
- `{{ .EndsAt }}` : Date de fin (si r√©solue)
- `{{ .GeneratorURL }}` : URL vers Prometheus

### Fonctions de Template Utiles

**Formatage de texte** :
```yaml
{{ .Status | toUpper }}        # FIRING
{{ .Status | toLower }}        # firing
{{ .Status | title }}          # Firing
```

**Conditions** :
```yaml
{{ if eq .Status "firing" }}
  Alerte en cours!
{{ else }}
  Alerte r√©solue
{{ end }}
```

**Boucles** :
```yaml
{{ range .Alerts }}
  - {{ .Labels.alertname }}
{{ end }}
```

**Comptage** :
```yaml
{{ .Alerts | len }}            # Nombre d'alertes
{{ .Alerts.Firing | len }}     # Nombre d'alertes actives
```

**Formatage de nombres** :
```yaml
{{ $value | humanize }}        # 1234567 ‚Üí 1.234567M
{{ $value | humanizePercentage }} # 0.85 ‚Üí 85%
{{ $value | humanizeDuration }}   # 3665 ‚Üí 1h1m5s
```

**Formatage de dates** :
```yaml
{{ .StartsAt.Format "2006-01-02 15:04:05" }}
{{ .StartsAt.Format "15:04" }}
```

### Template R√©utilisable

Vous pouvez d√©finir des templates r√©utilisables :

```yaml
templates:
  - '/etc/alertmanager/templates/*.tmpl'

receivers:
  - name: 'slack-with-template'
    slack_configs:
      - channel: '#alerts'
        title: '{{ template "slack.title" . }}'
        text: '{{ template "slack.text" . }}'
```

**Fichier /etc/alertmanager/templates/slack.tmpl** :

```go
{{ define "slack.title" }}
[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}]
{{ .GroupLabels.alertname }}
{{ end }}

{{ define "slack.text" }}
{{ if eq .Status "firing" }}
üî¥ *Alertes actives*
{{ range .Alerts.Firing }}
‚Ä¢ *{{ .Labels.alertname }}* ({{ .Labels.severity }})
  {{ .Annotations.description }}
  Depuis: {{ .StartsAt.Format "15:04:05" }}
{{ end }}
{{ else }}
‚úÖ *Alertes r√©solues*
{{ range .Alerts.Resolved }}
‚Ä¢ {{ .Labels.alertname }}
  R√©solue √†: {{ .EndsAt.Format "15:04:05" }}
{{ end }}
{{ end }}
{{ end }}
```

## Combinaisons de Receivers

### Receiver avec Plusieurs Canaux

Un receiver peut utiliser plusieurs types de notifications :

```yaml
receivers:
  - name: 'multi-channel'
    email_configs:
      - to: 'team@example.com'
    slack_configs:
      - channel: '#alerts'
    webhook_configs:
      - url: 'http://logger:8080/alerts'
```

Toutes ces notifications seront envoy√©es pour chaque alerte rout√©e vers ce receiver.

### Escalade Progressive

Utilisez plusieurs receivers avec diff√©rents d√©lais :

```yaml
route:
  receiver: 'first-notification'
  routes:
    - match:
        severity: 'critical'
      receiver: 'immediate-pagerduty'
      repeat_interval: 5m

      routes:
        # Si pas d'acquittement apr√®s 15 minutes, escalader
        - match: {}
          receiver: 'escalated-oncall-manager'
          group_wait: 15m
```

**Note** : L'escalade automatique n√©cessite g√©n√©ralement des outils externes ou des int√©grations PagerDuty/OpsGenie qui g√®rent cela nativement.

### Notification Conditionnelle

Envoyez vers diff√©rents canaux selon les conditions :

```yaml
receivers:
  - name: 'conditional'
    slack_configs:
      # Slack pour tous
      - channel: '#alerts'

    email_configs:
      # Email uniquement pour critical
      - to: 'oncall@example.com'
        send_resolved: true
```

Ou utilisez le routing pour plus de contr√¥le :

```yaml
route:
  routes:
    - match:
        severity: 'critical'
      receiver: 'critical-all-channels'

    - match:
        severity: 'warning'
      receiver: 'warning-slack-only'

receivers:
  - name: 'critical-all-channels'
    pagerduty_configs:
      - service_key: 'xxx'
    slack_configs:
      - channel: '#alerts'
    email_configs:
      - to: 'oncall@example.com'

  - name: 'warning-slack-only'
    slack_configs:
      - channel: '#alerts'
```

## Troubleshooting

### Probl√®me : Les Emails ne Sont Pas Envoy√©s

**Diagnostic** :

1. V√©rifier les logs d'Alertmanager :
```bash
microk8s kubectl logs -n monitoring alertmanager-0 | grep -i email
```

2. Erreurs communes :
```
level=error msg="Notify failed" err="dial tcp: lookup smtp.gmail.com: no such host"
‚Üí Probl√®me DNS ou connectivit√© r√©seau

level=error msg="Notify failed" err="535 5.7.8 Username and Password not accepted"
‚Üí Identifiants SMTP incorrects

level=error msg="Notify failed" err="tls: first record does not look like a TLS handshake"
‚Üí Mauvaise configuration TLS (v√©rifier le port)
```

**Solutions** :

‚úì V√©rifier les identifiants SMTP
‚úì Utiliser un mot de passe d'application (Gmail)
‚úì V√©rifier le port (587 pour TLS, 465 pour SSL, 25 pour non-s√©curis√©)
‚úì Tester la connectivit√© : `telnet smtp.gmail.com 587`
‚úì V√©rifier les pare-feu

### Probl√®me : Les Messages Slack ne Sont Pas Envoy√©s

**Diagnostic** :

```bash
microk8s kubectl logs -n monitoring alertmanager-0 | grep -i slack
```

Erreurs communes :
```
level=error msg="Notify failed" receiver=slack err="webhook error: HTTP 404"
‚Üí URL du webhook invalide

level=error msg="Notify failed" receiver=slack err="invalid_payload"
‚Üí Probl√®me dans le template du message
```

**Solutions** :

‚úì V√©rifier que l'URL du webhook est correcte
‚úì V√©rifier que le canal existe (avec le # : `#alerts`)
‚úì Tester le webhook manuellement :
```bash
curl -X POST 'votre-webhook-url' \
  -H 'Content-Type: application/json' \
  -d '{"text": "Test message"}'
```
‚úì V√©rifier que l'app Slack a les permissions n√©cessaires

### Probl√®me : Les Webhooks √âchouent

**Diagnostic** :

```bash
microk8s kubectl logs -n monitoring alertmanager-0 | grep webhook
```

Erreurs communes :
```
level=error msg="Notify failed" receiver=webhook err="connection refused"
‚Üí Service webhook inaccessible

level=error msg="Notify failed" receiver=webhook err="context deadline exceeded"
‚Üí Timeout - le service est trop lent

level=error msg="Notify failed" receiver=webhook err="HTTP 401"
‚Üí Probl√®me d'authentification
```

**Solutions** :

‚úì V√©rifier que le service webhook est accessible depuis le pod Alertmanager
‚úì Tester la connectivit√© :
```bash
microk8s kubectl exec -n monitoring alertmanager-0 -- wget -O- http://mon-service:8080/health
```
‚úì V√©rifier les credentials et headers d'authentification
‚úì Augmenter le timeout si n√©cessaire
‚úì V√©rifier les logs du service webhook

### Probl√®me : Trop de Notifications

**Sympt√¥mes** :
- Spam de notifications
- Notifications r√©p√©t√©es trop souvent
- Canal Slack inond√©

**Solutions** :

‚úì Augmenter `group_interval` et `repeat_interval`
```yaml
group_interval: 10m
repeat_interval: 4h
```

‚úì Am√©liorer le grouping
```yaml
group_by: ['alertname', 'namespace', 'cluster']
```

‚úì Ajouter des inhibitions pour supprimer les alertes redondantes

‚úì Revoir les seuils de vos alertes dans Prometheus

### Tester les Notifications

**Envoyer une alerte de test** :

```bash
curl -X POST http://localhost:9093/api/v2/alerts \
  -H 'Content-Type: application/json' \
  -d '[
    {
      "labels": {
        "alertname": "TestNotification",
        "severity": "warning",
        "instance": "test-server",
        "team": "platform"
      },
      "annotations": {
        "summary": "Ceci est un test",
        "description": "Test de notification Alertmanager"
      },
      "startsAt": "2025-01-15T10:00:00Z",
      "endsAt": "0001-01-01T00:00:00Z"
    }
  ]'
```

V√©rifiez que vous recevez la notification sur tous vos canaux configur√©s.

## Bonnes Pratiques

### 1. S√©curiser les Credentials

Ne stockez jamais les mots de passe en clair dans vos fichiers de configuration. Utilisez des Secrets Kubernetes :

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-secrets
  namespace: monitoring
type: Opaque
stringData:
  smtp-password: "votre-mot-de-passe"
  slack-webhook: "https://hooks.slack.com/services/XXX/YYY/ZZZ"
  pagerduty-key: "votre-integration-key"
```

R√©f√©rencez-les dans votre ConfigMap :

```yaml
global:
  smtp_auth_password: ${SMTP_PASSWORD}
```

### 2. Tester R√©guli√®rement

Configurez des alertes de test automatiques pour v√©rifier que vos notifications fonctionnent :

```yaml
# Dans Prometheus
- alert: WeeklyNotificationTest
  expr: day_of_week() == 1 and hour() == 9
  for: 0m
  labels:
    severity: info
  annotations:
    summary: "Test hebdomadaire des notifications"
    description: "Ceci est un test automatique"
```

### 3. Documenter les Canaux

Maintenez une documentation claire de vos receivers :

```yaml
receivers:
  # Production Critical - PagerDuty 24/7
  # Propri√©taire: √âquipe SRE
  # Contact: sre@example.com
  # Rotation: https://pagerduty.com/schedules/xxx
  - name: 'prod-critical-pagerduty'
    pagerduty_configs:
      - service_key: 'xxx'
```

### 4. Utilisez des Templates R√©utilisables

Cr√©ez des templates partag√©s pour maintenir la coh√©rence :

```
/alertmanager/
‚îú‚îÄ‚îÄ config.yml
‚îî‚îÄ‚îÄ templates/
    ‚îú‚îÄ‚îÄ email.tmpl
    ‚îú‚îÄ‚îÄ slack.tmpl
    ‚îî‚îÄ‚îÄ common.tmpl
```

### 5. Monitorer les Notifications Elles-m√™mes

Cr√©ez des alertes pour surveiller votre syst√®me de notifications :

```yaml
- alert: NotificationFailureRate
  expr: |
    rate(alertmanager_notifications_failed_total[5m])
    /
    rate(alertmanager_notifications_total[5m]) > 0.1
  for: 10m
  labels:
    severity: warning
  annotations:
    summary: "Taux d'√©chec des notifications √©lev√©"
```

### 6. Adaptez le Canal √† la S√©v√©rit√©

- **Critical** : PagerDuty/OpsGenie + Slack + Email
- **Warning** : Slack + Email
- **Info** : Email uniquement (digest quotidien)

### 7. Respectez les Limites de Rate

Slack, email et autres services ont des limites de d√©bit. Configurez vos grouping/repeat_interval en cons√©quence pour √©viter d'√™tre bloqu√©.

## Conclusion

Les notifications sont le pont entre vos alertes et les actions humaines. En configurant correctement vos receivers, vous assurez que :

- Les bonnes personnes sont notifi√©es
- Au bon moment
- Avec les bonnes informations
- Via les canaux appropri√©s

Une configuration bien pens√©e des notifications transforme le monitoring passif en syst√®me proactif qui prot√®ge vos services tout en respectant la tranquillit√© de vos √©quipes.

## Points Cl√©s √† Retenir

‚úì Email : universel et riche, n√©cessite configuration SMTP

‚úì Slack : instantan√© et collaboratif, utilise des webhooks

‚úì Webhook : flexible pour int√©grations personnalis√©es

‚úì S√©curisez vos credentials avec des Secrets Kubernetes

‚úì Personnalisez les messages avec des templates Go

‚úì Combinez plusieurs canaux pour les alertes critiques

‚úì Testez r√©guli√®rement vos notifications

‚úì Adaptez le canal √† la s√©v√©rit√© de l'alerte

‚úì Surveillez les √©checs de notification

‚úì Documentez vos receivers et leurs propri√©taires

---

**Prochaine section** : 14.6 Silences et inhibitions - Nous verrons comment g√©rer intelligemment les alertes pendant les maintenances et √©viter les notifications redondantes.

‚è≠Ô∏è [Silences et inhibitions](/14-alerting-et-notifications/06-silences-et-inhibitions.md)
