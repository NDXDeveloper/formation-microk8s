ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 3.3 Services (ClusterIP, NodePort, LoadBalancer)

## Introduction

Dans les sections prÃ©cÃ©dentes, nous avons appris Ã  crÃ©er des Pods avec des Deployments. Maintenant, un nouveau problÃ¨me se pose : **comment accÃ©der Ã  ces Pods de maniÃ¨re fiable ?**

Les **Services** sont la solution Kubernetes pour exposer vos applications et permettre la communication rÃ©seau de maniÃ¨re stable et prÃ©visible.

## Le problÃ¨me : Pods Ã©phÃ©mÃ¨res et IPs changeantes

### ScÃ©nario problÃ©matique

Imaginez que vous avez dÃ©ployÃ© une application web avec 3 Pods :

```
Pod 1: 10.1.5.23
Pod 2: 10.1.5.24
Pod 3: 10.1.5.25
```

**ProblÃ¨mes rencontrÃ©s :**

1. **IPs changeantes** : Quand un Pod meurt et est remplacÃ©, il obtient une nouvelle IP
   ```
   Pod 1 meurt â†’ Pod 4 crÃ©Ã© avec IP 10.1.5.99
   ```

2. **Quelle IP utiliser ?** : Si vous avez 3 Pods, comment savoir vers lequel envoyer les requÃªtes ?

3. **Load balancing** : Comment rÃ©partir le trafic Ã©quitablement entre les 3 Pods ?

4. **DÃ©couverte de service** : Comment les autres applications trouvent-elles votre service ?

### Exemple concret du problÃ¨me

Vous avez :
- Un **frontend** (application web) avec 3 Pods
- Un **backend** (API) qui doit appeler le frontend

**Sans Service** :
```yaml
# Dans le backend, vous devriez faire quelque chose comme :
http://10.1.5.23/api  # Mais cette IP peut changer !
```

Si le Pod avec l'IP `10.1.5.23` meurt, votre backend ne peut plus accÃ©der au frontend. C'est ingÃ©rable !

## Qu'est-ce qu'un Service ?

### DÃ©finition simple

Un **Service** est une abstraction qui dÃ©finit un ensemble logique de Pods et une politique pour y accÃ©der. Il fournit une **IP stable** et un **nom DNS** pour accÃ©der Ã  vos Pods.

### Analogie : le standard tÃ©lÃ©phonique

Imaginez un **standard tÃ©lÃ©phonique** d'une entreprise :
- Vous appelez un **numÃ©ro unique** (le Service)
- Le standard **redirige** votre appel vers un employÃ© disponible (un Pod)
- Si un employÃ© quitte l'entreprise (Pod qui meurt), le standard redirige vers un autre
- Vous n'avez **pas besoin de connaÃ®tre** le numÃ©ro direct de chaque employÃ© (IP des Pods)

Le Service fonctionne exactement de cette maniÃ¨re !

### Fonctionnement d'un Service

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Service "frontend"                â”‚
â”‚                                             â”‚
â”‚  IP stable: 10.96.100.50                    â”‚
â”‚  DNS: frontend.default.svc.cluster.local    â”‚
â”‚                                             â”‚
â”‚  SÃ©lectionne les Pods avec: app=frontend    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Load balancing automatique
               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚        â”‚        â”‚
      v        v        v
   â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
   â”‚Pod 1â”‚ â”‚Pod 2â”‚ â”‚Pod 3â”‚
   â”‚10.1 â”‚ â”‚10.1 â”‚ â”‚10.1 â”‚
   â”‚.5.23â”‚ â”‚.5.24â”‚ â”‚.5.25â”‚
   â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜
```

**Avantages** :
- **IP stable** : Le Service garde toujours la mÃªme IP
- **Nom DNS** : Vous pouvez utiliser un nom plutÃ´t qu'une IP
- **Load balancing** : Le trafic est rÃ©parti automatiquement
- **Service discovery** : Les applications se trouvent facilement

## Les trois types de Services principaux

Kubernetes propose trois types de Services pour diffÃ©rents cas d'usage :

1. **ClusterIP** (par dÃ©faut) : Accessible uniquement depuis l'intÃ©rieur du cluster
2. **NodePort** : Accessible depuis l'extÃ©rieur via un port sur chaque nÅ“ud
3. **LoadBalancer** : Accessible depuis l'extÃ©rieur via un load balancer externe

CommenÃ§ons par le plus simple : ClusterIP.

## 1. Service ClusterIP

### Description

**ClusterIP** est le type de Service **par dÃ©faut**. Il expose votre application uniquement Ã  l'intÃ©rieur du cluster Kubernetes. Les Pods peuvent communiquer entre eux via ce Service, mais il n'est **pas accessible depuis l'extÃ©rieur**.

### Cas d'usage

- Communication entre microservices internes
- Bases de donnÃ©es accessibles uniquement par les applications internes
- APIs internes
- Services backend qui ne doivent pas Ãªtre exposÃ©s publiquement

### SchÃ©ma de fonctionnement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Cluster Kubernetes                       â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚  â”‚  Service         â”‚                                 â”‚
â”‚  â”‚  Type: ClusterIP â”‚                                 â”‚
â”‚  â”‚  IP: 10.96.1.50  â”‚                                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚           â”‚ Accessible uniquement dans le cluster     â”‚
â”‚           â”‚                                           â”‚
â”‚      â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”                                      â”‚
â”‚      v    v    v                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”                                  â”‚
â”‚   â”‚Pod1â”‚â”‚Pod2â”‚â”‚Pod3â”‚                                  â”‚
â”‚   â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘
         â”‚ âŒ Pas accessible depuis l'extÃ©rieur
         â”‚
    Internet/Utilisateurs externes
```

### Manifeste YAML d'un Service ClusterIP

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mon-service-backend
  labels:
    app: backend
spec:
  type: ClusterIP              # Type de Service (peut Ãªtre omis car c'est le dÃ©faut)
  selector:                    # SÃ©lectionne les Pods Ã  exposer
    app: backend
    tier: api
  ports:
  - name: http                 # Nom du port (optionnel mais recommandÃ©)
    protocol: TCP              # Protocole (TCP par dÃ©faut)
    port: 80                   # Port du Service
    targetPort: 8080           # Port sur le conteneur du Pod
```

### Explication dÃ©taillÃ©e

- **type: ClusterIP** : DÃ©finit le type de Service (peut Ãªtre omis car c'est la valeur par dÃ©faut)

- **selector** :
  - DÃ©finit quels Pods font partie de ce Service
  - Tous les Pods avec les labels `app: backend` et `tier: api` seront exposÃ©s par ce Service
  - Les labels doivent correspondre Ã  ceux dÃ©finis dans votre Deployment

- **ports** :
  - **port: 80** : Port sur lequel le Service Ã©coute (les clients se connectent sur ce port)
  - **targetPort: 8080** : Port sur lequel les Pods Ã©coutent rÃ©ellement
  - **protocol: TCP** : Protocole utilisÃ© (TCP ou UDP)

### SchÃ©ma de redirection des ports

```
Client interne         Service              Pod
     â”‚                   â”‚                   â”‚
     â”‚  GET :80          â”‚                   â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                   â”‚
     â”‚                   â”‚  GET :8080        â”‚
     â”‚                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
     â”‚                   â”‚                   â”‚
     â”‚                   â”‚  Response         â”‚
     â”‚                   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚  Response         â”‚                   â”‚
     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
```

### AccÃ¨s au Service depuis un Pod

Une fois le Service crÃ©Ã©, il est accessible via :

**1. Par IP** :
```bash
curl http://10.96.1.50:80
```

**2. Par nom DNS (recommandÃ©)** :
```bash
# Format: <nom-service>.<namespace>.svc.cluster.local
curl http://mon-service-backend.default.svc.cluster.local:80

# Ou plus simplement (dans le mÃªme namespace) :
curl http://mon-service-backend:80
```

### Exemple complet : Frontend et Backend

**Backend Deployment + Service** :

```yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: api
        image: mon-api:v1
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  type: ClusterIP
  selector:
    app: backend
  ports:
  - port: 80
    targetPort: 8080
```

**Frontend qui accÃ¨de au Backend** :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: web
        image: mon-frontend:v1
        env:
        - name: BACKEND_URL
          value: "http://backend-service:80"    # Utilise le nom DNS du Service
```

Le frontend peut maintenant appeler le backend via `http://backend-service:80` sans se soucier des IPs des Pods !

## 2. Service NodePort

### Description

**NodePort** expose votre Service sur un port statique de **chaque nÅ“ud** du cluster. Cela rend votre Service accessible depuis l'extÃ©rieur du cluster en utilisant `<IP-du-noeud>:<NodePort>`.

### Cas d'usage

- Exposer une application pour des tests depuis votre machine locale
- Environnements de dÃ©veloppement
- Clusters simples sans load balancer externe
- AccÃ¨s temporaire depuis l'extÃ©rieur

### SchÃ©ma de fonctionnement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Cluster Kubernetes                        â”‚
â”‚                                                        â”‚
â”‚  NÅ“ud 1 (192.168.1.10)      NÅ“ud 2 (192.168.1.11)      â”‚
â”‚    :30080 â”€â”€â”€â”€â”                :30080 â”€â”€â”€â”€â”            â”‚
â”‚               â”‚                           â”‚            â”‚
â”‚               v                           v            â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚         â”‚  Service (NodePort)              â”‚           â”‚
â”‚         â”‚  ClusterIP: 10.96.1.50           â”‚           â”‚
â”‚         â”‚  NodePort: 30080                 â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                      â”‚                                 â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”                            â”‚
â”‚                 v    v    v                            â”‚
â”‚              â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”                        â”‚
â”‚              â”‚Pod1â”‚â”‚Pod2â”‚â”‚Pod3â”‚                        â”‚
â”‚              â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†‘                      â†‘
              â”‚                      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           Accessible depuis l'extÃ©rieur via :
           http://192.168.1.10:30080 ou
           http://192.168.1.11:30080
```

### Manifeste YAML d'un Service NodePort

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mon-service-web
spec:
  type: NodePort              # Type de Service : NodePort
  selector:
    app: web
  ports:
  - name: http
    protocol: TCP
    port: 80                  # Port du Service (ClusterIP)
    targetPort: 8080          # Port sur le Pod
    nodePort: 30080           # Port exposÃ© sur chaque nÅ“ud (30000-32767)
```

### Explication des ports

Un Service NodePort utilise **trois ports** :

1. **targetPort: 8080** : Port sur lequel le conteneur Ã©coute dans le Pod
2. **port: 80** : Port du Service (ClusterIP) accessible depuis l'intÃ©rieur du cluster
3. **nodePort: 30080** : Port exposÃ© sur chaque nÅ“ud du cluster pour l'accÃ¨s externe

### SchÃ©ma des trois niveaux de ports

```
Externe         NÅ“ud          Service         Pod
   â”‚              â”‚              â”‚              â”‚
   â”‚ :30080       â”‚              â”‚              â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚              â”‚              â”‚
   â”‚              â”‚ :80          â”‚              â”‚
   â”‚              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚              â”‚
   â”‚              â”‚              â”‚ :8080        â”‚
   â”‚              â”‚              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
```

### Plage de ports NodePort

Les ports NodePort doivent Ãªtre dans la plage **30000-32767** par dÃ©faut.

**SpÃ©cifier un port spÃ©cifique** :
```yaml
nodePort: 30080    # Port choisi manuellement
```

**Laisser Kubernetes choisir automatiquement** :
```yaml
# Omettez simplement nodePort, Kubernetes en attribuera un
ports:
- port: 80
  targetPort: 8080
  # nodePort sera attribuÃ© automatiquement
```

### AccÃ¨s au Service NodePort

**Depuis l'intÃ©rieur du cluster** :
```bash
curl http://mon-service-web:80
```

**Depuis l'extÃ©rieur du cluster** :
```bash
# Via l'IP de n'importe quel nÅ“ud du cluster
curl http://192.168.1.10:30080
curl http://192.168.1.11:30080    # MÃªme rÃ©sultat
```

### Exemple pratique : Application web simple

```yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - name: nginx
        image: nginx:1.25
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webapp-service
spec:
  type: NodePort
  selector:
    app: webapp
  ports:
  - port: 80
    targetPort: 80
    nodePort: 30100
```

AprÃ¨s dÃ©ploiement, vous pouvez accÃ©der Ã  votre application via :
```bash
# Depuis votre navigateur ou terminal
http://<IP-de-votre-noeud>:30100
```

### Limitations de NodePort

1. **Plage de ports limitÃ©e** : 30000-32767 seulement
2. **Ports peu intuitifs** : Les utilisateurs doivent connaÃ®tre le port spÃ©cifique
3. **Un port par Service** : Peut vite devenir compliquÃ© avec beaucoup de services
4. **Pas de vrai load balancing externe** : Vous devez gÃ©rer vous-mÃªme la rÃ©partition entre nÅ“uds
5. **Exposition directe des nÅ“uds** : ProblÃ¨mes de sÃ©curitÃ© potentiels

## 3. Service LoadBalancer

### Description

**LoadBalancer** provisionne un load balancer externe (fourni par le cloud provider ou une solution comme MetalLB) qui expose votre Service avec une IP externe dÃ©diÃ©e.

### Cas d'usage

- Applications production accessibles depuis Internet
- Exposition publique d'APIs
- Applications web grand public
- Tout service nÃ©cessitant une IP externe stable

### PrÃ©requis

Pour utiliser un Service LoadBalancer avec MicroK8s, vous devez activer **MetalLB** :

```bash
microk8s enable metallb
```

Vous devrez configurer une plage d'IPs que MetalLB peut utiliser (voir le chapitre 9 pour plus de dÃ©tails).

### SchÃ©ma de fonctionnement

```
                    Internet
                       â”‚
                       â”‚ RequÃªtes HTTP
                       â”‚
                       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Load Balancer Externe                     â”‚
â”‚            IP Publique: 203.0.113.50                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cluster Kubernetesâ”‚                                â”‚
â”‚                     v                                â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚              â”‚  Service       â”‚                      â”‚
â”‚              â”‚  Type: LB      â”‚                      â”‚
â”‚              â”‚  ClusterIP:    â”‚                      â”‚
â”‚              â”‚  10.96.1.50    â”‚                      â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                       â”‚                              â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”                         â”‚
â”‚                  v    v    v                         â”‚
â”‚               â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”                     â”‚
â”‚               â”‚Pod1â”‚â”‚Pod2â”‚â”‚Pod3â”‚                     â”‚
â”‚               â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Manifeste YAML d'un Service LoadBalancer

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mon-service-public
spec:
  type: LoadBalancer          # Type de Service : LoadBalancer
  selector:
    app: web
  ports:
  - name: http
    protocol: TCP
    port: 80                  # Port exposÃ© par le load balancer
    targetPort: 8080          # Port sur le Pod
  # Optionnel : spÃ©cifier une IP externe spÃ©cifique (si supportÃ©)
  # loadBalancerIP: 203.0.113.50
```

### Ce qui se passe lors de la crÃ©ation

1. **Kubernetes crÃ©e le Service** avec le type LoadBalancer
2. **Un load balancer externe est provisionnÃ©** (par MetalLB dans notre cas)
3. **Une IP externe est attribuÃ©e** au Service
4. **Le trafic est routÃ©** depuis l'IP externe vers les Pods

### VÃ©rifier l'IP externe attribuÃ©e

```bash
microk8s kubectl get service mon-service-public
```

Sortie exemple :
```
NAME                 TYPE           CLUSTER-IP    EXTERNAL-IP     PORT(S)        AGE
mon-service-public   LoadBalancer   10.96.1.50    192.168.1.100   80:31234/TCP   2m
```

L'**EXTERNAL-IP** `192.168.1.100` est l'adresse par laquelle votre service est accessible depuis l'extÃ©rieur.

### AccÃ¨s au Service LoadBalancer

**Depuis l'extÃ©rieur** :
```bash
curl http://192.168.1.100
```

**Depuis l'intÃ©rieur du cluster** :
```bash
curl http://mon-service-public:80
```

### Exemple complet : Application web publique

```yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: site-web
spec:
  replicas: 4
  selector:
    matchLabels:
      app: site-web
  template:
    metadata:
      labels:
        app: site-web
    spec:
      containers:
      - name: nginx
        image: nginx:1.25
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: site-web-public
spec:
  type: LoadBalancer
  selector:
    app: site-web
  ports:
  - name: http
    port: 80
    targetPort: 80
  - name: https
    port: 443
    targetPort: 443
```

Ce Service expose votre site web sur les ports 80 (HTTP) et 443 (HTTPS) via une IP externe.

### LoadBalancer vs NodePort

Le Service LoadBalancer **inclut** toutes les fonctionnalitÃ©s de NodePort :
- Il crÃ©e Ã©galement un NodePort automatiquement
- Le load balancer externe redirige vers ce NodePort
- Vous pouvez toujours accÃ©der via `<IP-noeud>:<NodePort>` si besoin

```
HiÃ©rarchie des types de Services :
LoadBalancer âŠƒ NodePort âŠƒ ClusterIP

LoadBalancer = ClusterIP + NodePort + Load Balancer externe
NodePort = ClusterIP + Port sur les nÅ“uds
ClusterIP = Service de base
```

### Avec MetalLB (MicroK8s)

MetalLB fournit une implÃ©mentation de LoadBalancer pour les clusters "bare metal" (sans cloud provider) :

```bash
# Activer MetalLB
microk8s enable metallb

# Configurer la plage d'IPs (exemple)
# RÃ©pondez avec une plage d'IPs disponibles sur votre rÃ©seau
# Par exemple : 192.168.1.200-192.168.1.250
```

Ensuite, tous vos Services de type LoadBalancer recevront automatiquement une IP de cette plage.

## Comparaison des trois types de Services

| CaractÃ©ristique | ClusterIP | NodePort | LoadBalancer |
|----------------|-----------|----------|--------------|
| **Accessible depuis l'intÃ©rieur du cluster** | âœ“ | âœ“ | âœ“ |
| **Accessible depuis l'extÃ©rieur** | âœ— | âœ“ (via NodePort) | âœ“ (via IP externe) |
| **IP stable interne** | âœ“ | âœ“ | âœ“ |
| **IP externe dÃ©diÃ©e** | âœ— | âœ— | âœ“ |
| **Port exposÃ©** | Port standard | 30000-32767 | Port standard (80, 443, etc.) |
| **Load balancing externe** | âœ— | âœ— | âœ“ |
| **Cas d'usage typique** | Communication interne | Dev/Test | Production publique |
| **ComplexitÃ©** | Simple | Moyenne | Ã‰levÃ©e (nÃ©cessite LB externe) |

## DNS et dÃ©couverte de services

### RÃ©solution DNS automatique

Kubernetes crÃ©e automatiquement des entrÃ©es DNS pour chaque Service :

**Format complet** :
```
<nom-service>.<namespace>.svc.cluster.local
```

**Exemples** :
```bash
# Service "backend" dans le namespace "default"
backend.default.svc.cluster.local

# Service "database" dans le namespace "production"
database.production.svc.cluster.local
```

### Raccourcis DNS

**Depuis le mÃªme namespace** :
```bash
# Simplement le nom du service
curl http://backend

# Ou avec le namespace
curl http://backend.default
```

**Depuis un autre namespace** :
```bash
# Doit inclure le namespace
curl http://backend.production
```

### Exemple pratique

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  template:
    spec:
      containers:
      - name: web
        image: mon-frontend:v1
        env:
        - name: API_URL
          value: "http://backend:8080/api"    # Utilise le nom DNS du Service
        - name: DB_HOST
          value: "postgres.database:5432"     # Service dans un autre namespace
```

## Endpoints : les coulisses du Service

### Qu'est-ce qu'un Endpoint ?

Un **Endpoint** est un objet Kubernetes qui liste les IPs des Pods sÃ©lectionnÃ©s par un Service.

Quand vous crÃ©ez un Service, Kubernetes crÃ©e automatiquement un objet Endpoint correspondant.

### Voir les Endpoints

```bash
microk8s kubectl get endpoints mon-service-backend
```

Sortie exemple :
```
NAME                 ENDPOINTS                                      AGE
mon-service-backend  10.1.5.23:8080,10.1.5.24:8080,10.1.5.25:8080  5m
```

Cela montre les IPs et ports des trois Pods backend accessibles via ce Service.

### SchÃ©ma : Service â†’ Endpoints â†’ Pods

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Service    â”‚
â”‚ backend:80   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ sÃ©lectionne les Pods avec app=backend
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Endpoints      â”‚
â”‚  10.1.5.23:8080  â”‚
â”‚  10.1.5.24:8080  â”‚  â† Liste mise Ã  jour automatiquement
â”‚  10.1.5.25:8080  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
   Pods rÃ©els
```

### Debugging : vÃ©rifier les Endpoints

Si votre Service ne fonctionne pas, vÃ©rifiez les Endpoints :

```bash
microk8s kubectl describe endpoints mon-service-backend
```

**ProblÃ¨me courant** : Endpoints vide
```
Endpoints:  <none>
```

**Cause** : Les labels du Service ne correspondent Ã  aucun Pod. VÃ©rifiez :
- Les labels dans `selector` du Service
- Les labels dans `template.metadata.labels` du Deployment

## Sessions Affinity : clients persistants

### ProblÃ¨me

Par dÃ©faut, Kubernetes rÃ©partit les requÃªtes de maniÃ¨re alÃ©atoire entre les Pods. Cela peut poser problÃ¨me pour :
- Sessions utilisateur (cookies)
- WebSockets
- Applications stateful

### Solution : Session Affinity

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mon-service
spec:
  type: ClusterIP
  selector:
    app: web
  sessionAffinity: ClientIP         # Active la session affinity
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800         # DurÃ©e de la persistance (3 heures)
  ports:
  - port: 80
    targetPort: 8080
```

**Comportement** :
- Les requÃªtes provenant de la mÃªme IP client seront toujours dirigÃ©es vers le mÃªme Pod
- Valable pendant la durÃ©e dÃ©finie dans `timeoutSeconds`

### Cas d'usage

- Applications web avec sessions
- Applications nÃ©cessitant une connexion persistante
- Caches locaux dans les Pods

## Services sans sÃ©lecteur

### Cas d'usage

Parfois, vous voulez crÃ©er un Service qui pointe vers :
- Une base de donnÃ©es externe (hors cluster)
- Un service dans un autre cluster
- Un service en cours de migration

### Service sans sÃ©lecteur

```yaml
apiVersion: v1
kind: Service
metadata:
  name: base-donnees-externe
spec:
  type: ClusterIP
  ports:
  - port: 3306
    targetPort: 3306
  # Pas de selector !
```

### Endpoints manuels

Vous devez crÃ©er manuellement l'objet Endpoints :

```yaml
apiVersion: v1
kind: Endpoints
metadata:
  name: base-donnees-externe      # MÃªme nom que le Service
subsets:
- addresses:
  - ip: 192.168.50.10             # IP de la base externe
  ports:
  - port: 3306
```

Maintenant, les Pods peuvent accÃ©der Ã  cette base externe via :
```bash
mysql -h base-donnees-externe -P 3306
```

## Bonnes pratiques

### 1. Choisir le bon type de Service

**Pour la communication interne** :
```yaml
type: ClusterIP    # Toujours prÃ©fÃ©rer ClusterIP pour l'interne
```

**Pour le dÃ©veloppement/test** :
```yaml
type: NodePort     # Pratique pour des tests rapides
```

**Pour la production publique** :
```yaml
type: LoadBalancer # Avec MetalLB ou un cloud provider
```

### 2. Utiliser des noms de ports

```yaml
ports:
- name: http        # Nomme vos ports
  port: 80
  targetPort: 8080
- name: https
  port: 443
  targetPort: 8443
```

**Avantage** : ClartÃ© et possibilitÃ© de rÃ©fÃ©rencer par nom plutÃ´t que par numÃ©ro.

### 3. Utiliser le DNS, pas les IPs

**âŒ Mauvais** :
```yaml
env:
- name: BACKEND_URL
  value: "http://10.96.1.50:80"
```

**âœ… Bon** :
```yaml
env:
- name: BACKEND_URL
  value: "http://backend-service:80"
```

### 4. Grouper Services et Deployments dans le mÃªme fichier

```yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mon-app
# ...
---
apiVersion: v1
kind: Service
metadata:
  name: mon-app-service
# ...
```

Utilisez `---` pour sÃ©parer les ressources dans un mÃªme fichier YAML.

### 5. VÃ©rifier la correspondance des labels

Les labels dans le `selector` du Service DOIVENT correspondre aux labels des Pods :

```yaml
# Deployment
template:
  metadata:
    labels:
      app: backend      # â† Ces labels
      version: v1

# Service
selector:
  app: backend          # â† Doivent correspondre
```

### 6. Exposer plusieurs ports si nÃ©cessaire

```yaml
ports:
- name: http
  port: 80
  targetPort: 8080
- name: metrics
  port: 9090
  targetPort: 9090
```

### 7. Utiliser des annotations pour la documentation

```yaml
metadata:
  name: mon-service
  annotations:
    description: "Service backend pour l'API REST"
    owner: "equipe-backend@example.com"
    version: "v1.2.0"
```

## DÃ©pannage des Services

### ProblÃ¨me 1 : Service crÃ©Ã© mais pas accessible

**VÃ©rifications** :

```bash
# 1. VÃ©rifier que le Service existe
microk8s kubectl get service mon-service

# 2. VÃ©rifier les Endpoints
microk8s kubectl get endpoints mon-service

# 3. VÃ©rifier les Pods
microk8s kubectl get pods -l app=backend

# 4. Voir les dÃ©tails du Service
microk8s kubectl describe service mon-service
```

**Causes courantes** :
- Labels ne correspondent pas (Service selector â‰  Pod labels)
- Aucun Pod en Ã©tat "Ready"
- Mauvais port targetPort

### ProblÃ¨me 2 : Endpoints vide

```bash
microk8s kubectl describe endpoints mon-service
```

Si `Endpoints: <none>`, vÃ©rifiez :

```bash
# Labels du Service
microk8s kubectl get service mon-service -o yaml | grep -A 5 selector

# Labels des Pods
microk8s kubectl get pods --show-labels
```

**Solution** : Corriger les labels pour qu'ils correspondent.

### ProblÃ¨me 3 : Service LoadBalancer bloquÃ© en "Pending"

```bash
microk8s kubectl get service
```

```
NAME         TYPE           EXTERNAL-IP   PORT(S)
mon-service  LoadBalancer   <pending>     80:30123/TCP
```

**Causes** :
- MetalLB n'est pas activÃ©
- Pas d'IPs disponibles dans le pool MetalLB
- ProblÃ¨me de configuration MetalLB

**Solution** :
```bash
# VÃ©rifier si MetalLB est activÃ©
microk8s status

# Activer MetalLB si nÃ©cessaire
microk8s enable metallb
```

### ProblÃ¨me 4 : Connexion refuse (Connection refused)

**Test de connectivitÃ©** :

```bash
# Depuis un Pod de test
microk8s kubectl run test-pod --image=busybox --rm -it -- sh
/ # wget -O- http://mon-service:80
```

Si "Connection refused" :
- VÃ©rifier que les Pods Ã©coutent sur le bon port (targetPort)
- VÃ©rifier les readiness probes
- VÃ©rifier les logs des Pods

### ProblÃ¨me 5 : Timeout

Si la connexion timeout (pas de rÃ©ponse) :
- VÃ©rifier les Network Policies (si activÃ©es)
- VÃ©rifier le firewall des nÅ“uds
- VÃ©rifier que le port est bien exposÃ© dans le conteneur

## Architecture multi-tiers complÃ¨te

Voici un exemple d'architecture complÃ¨te avec les trois types de Services :

```yaml
# ===== FRONTEND (accessible publiquement) =====
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
      tier: web
  template:
    metadata:
      labels:
        app: frontend
        tier: web
    spec:
      containers:
      - name: nginx
        image: nginx:1.25
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
spec:
  type: LoadBalancer         # Accessible depuis Internet
  selector:
    app: frontend
    tier: web
  ports:
  - port: 80
    targetPort: 80

# ===== BACKEND API (accessible uniquement en interne) =====
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: backend
      tier: api
  template:
    metadata:
      labels:
        app: backend
        tier: api
    spec:
      containers:
      - name: api
        image: mon-api:v1
        ports:
        - containerPort: 8080
        env:
        - name: DATABASE_HOST
          value: "database-service:5432"
---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  type: ClusterIP            # Accessible uniquement en interne
  selector:
    app: backend
    tier: api
  ports:
  - port: 80
    targetPort: 8080

# ===== DATABASE (accessible uniquement en interne) =====
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: database
spec:
  replicas: 1
  selector:
    matchLabels:
      app: database
      tier: data
  template:
    metadata:
      labels:
        app: database
        tier: data
    spec:
      containers:
      - name: postgres
        image: postgres:15
        ports:
        - containerPort: 5432
---
apiVersion: v1
kind: Service
metadata:
  name: database-service
spec:
  type: ClusterIP            # Accessible uniquement en interne
  selector:
    app: database
    tier: data
  ports:
  - port: 5432
    targetPort: 5432
```

**Architecture rÃ©sultante** :

```
Internet
   â”‚
   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LoadBalancer        â”‚ â† IP publique
â”‚ (frontend-service)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cluster  v                                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚    â”‚ Frontend â”‚                              â”‚
â”‚    â”‚ Pods     â”‚                              â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚         â”‚ appelle backend-service:80         â”‚
â”‚         v                                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚    â”‚ Backend  â”‚                              â”‚
â”‚    â”‚ Pods     â”‚                              â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚         â”‚ appelle database-service:5432      â”‚
â”‚         v                                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚    â”‚ Database â”‚                              â”‚
â”‚    â”‚ Pod      â”‚                              â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## RÃ©sumÃ© des points clÃ©s

- Les **Services** fournissent une IP stable et un nom DNS pour accÃ©der aux Pods
- **ClusterIP** (dÃ©faut) : accessible uniquement depuis l'intÃ©rieur du cluster
- **NodePort** : accessible depuis l'extÃ©rieur via `<IP-noeud>:<NodePort>`
- **LoadBalancer** : accessible depuis l'extÃ©rieur via une IP externe dÃ©diÃ©e
- Les Services utilisent les **labels** pour sÃ©lectionner les Pods Ã  exposer
- Le **DNS** automatique permet d'utiliser des noms plutÃ´t que des IPs
- Les **Endpoints** listent les IPs rÃ©elles des Pods derriÃ¨re un Service
- **Session affinity** permet de maintenir un client sur le mÃªme Pod
- Pour la production, utilisez **LoadBalancer** avec MetalLB sur MicroK8s

## Prochaines Ã©tapes

Maintenant que vous maÃ®trisez les Services, vous Ãªtes prÃªt Ã  dÃ©couvrir :
- **Les Namespaces** : comment organiser et isoler vos ressources
- **Les ConfigMaps** : comment gÃ©rer la configuration de vos applications
- **Les Secrets** : comment stocker et utiliser des donnÃ©es sensibles

Les Services sont essentiels pour toute architecture Kubernetes. Ils permettent de crÃ©er des applications modulaires, scalables et rÃ©silientes !

â­ï¸ [Namespaces](/03-concepts-kubernetes-essentiels/04-namespaces.md)
