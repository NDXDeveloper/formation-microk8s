üîù Retour au [Sommaire](/SOMMAIRE.md)

# 22.6 Tests de restauration

## Introduction

**Une sauvegarde non test√©e n'est pas une sauvegarde.** C'est la r√®gle d'or de toute strat√©gie de sauvegarde. Vous pouvez avoir les meilleurs outils, les processus les plus automatis√©s, mais si vous ne testez jamais que vos restaurations fonctionnent r√©ellement, vous d√©couvrirez le probl√®me au pire moment possible : quand vous en avez vraiment besoin.

Cette section vous guide √† travers la mise en place de tests de restauration r√©guliers et efficaces pour votre cluster MicroK8s.

### Pourquoi les tests de restauration sont cruciaux

Imaginez ces sc√©narios :

**Sc√©nario 1 - La mauvaise surprise** :
```
Votre serveur tombe en panne.
Vous essayez de restaurer depuis vos backups.
ERREUR : Le backup est corrompu.
ERREUR : Il manque des fichiers critiques.
ERREUR : Les secrets ne sont pas dans le backup.
R√©sultat : Perte de donn√©es et plusieurs jours de reconstruction manuelle.
```

**Sc√©nario 2 - La bonne pratique** :
```
Vous testez vos restaurations tous les mois.
Vous d√©couvrez que les volumes ne sont pas sauvegard√©s correctement.
Vous corrigez le probl√®me.
Quand le serveur tombe vraiment en panne, la restauration fonctionne parfaitement.
R√©sultat : Remise en service en quelques heures, aucune perte de donn√©es.
```

### Ce que vous d√©couvrez en testant

Les tests de restauration r√©v√®lent souvent :

1. **Sauvegardes incompl√®tes** : Des ressources manquantes (ConfigMaps, Secrets, PVCs)
2. **Erreurs de configuration** : Mauvais backup-location, credentials invalides
3. **Probl√®mes de d√©pendances** : L'ordre de restauration est important
4. **Volumes non sauvegard√©s** : Oubli d'activer `--default-volumes-to-fs-backup`
5. **Incompatibilit√©s de versions** : Diff√©rences entre clusters source et destination
6. **Temps de restauration** : D√©couvrir qu'une restauration prend 8 heures au lieu de 2
7. **Lacunes dans la documentation** : La proc√©dure √©crite est incompl√®te ou erron√©e

### Analogie simple

Pensez aux tests de restauration comme √† :

- **Exercice d'incendie** : Vous ne voulez pas d√©couvrir que les issues de secours sont bloqu√©es pendant un vrai incendie
- **Roue de secours** : Vous v√©rifiez qu'elle est gonfl√©e avant d'avoir une crevaison
- **Plan d'√©vacuation** : Vous le pratiquez avant l'urgence r√©elle

Les tests de restauration, c'est exactement √ßa pour vos donn√©es : s'assurer que tout fonctionne avant le jour o√π vous en aurez vraiment besoin.

## Types de tests de restauration

Il existe plusieurs niveaux de tests, du plus simple au plus complet.

### 1. Test de validation de backup

**Objectif** : V√©rifier que la sauvegarde s'est bien cr√©√©e et est accessible.

**Ce qu'on teste** :
- Le backup existe
- Il est marqu√© comme "Completed"
- Il contient des donn√©es
- Il est accessible depuis le stockage

**Quand** : Apr√®s chaque sauvegarde automatique

**Dur√©e** : 1-2 minutes

**Exemple avec Velero** :

```bash
#!/bin/bash
# validate-backup.sh

BACKUP_NAME=$1

echo "=== Validation du backup: $BACKUP_NAME ==="

# V√©rifier que le backup existe
if ! velero backup get $BACKUP_NAME &>/dev/null; then
  echo "‚ùå ERREUR: Le backup n'existe pas"
  exit 1
fi

# V√©rifier le statut
STATUS=$(velero backup describe $BACKUP_NAME --details | grep "Phase:" | awk '{print $2}')
if [ "$STATUS" != "Completed" ]; then
  echo "‚ùå ERREUR: Status = $STATUS (attendu: Completed)"
  exit 1
fi

# V√©rifier qu'il contient des ressources
TOTAL=$(velero backup describe $BACKUP_NAME --details | grep "Total items to be backed up:" | awk '{print $6}')
if [ "$TOTAL" -lt 1 ]; then
  echo "‚ùå ERREUR: Aucune ressource sauvegard√©e"
  exit 1
fi

echo "‚úì Backup valide"
echo "  Status: $STATUS"
echo "  Ressources: $TOTAL"
```

### 2. Test de restauration partielle

**Objectif** : Restaurer une seule application ou namespace pour v√©rifier que √ßa fonctionne.

**Ce qu'on teste** :
- La commande de restauration fonctionne
- Les ressources sont recr√©√©es
- Les pods d√©marrent correctement
- Les volumes sont restaur√©s avec leurs donn√©es

**Quand** : Hebdomadaire ou bi-hebdomadaire

**Dur√©e** : 10-30 minutes

**Exemple** :

```bash
#!/bin/bash
# test-partial-restore.sh

BACKUP_NAME="daily-backup-latest"
TEST_NAMESPACE="restore-test"

echo "=== Test de restauration partielle ==="

# 1. Cr√©er un namespace de test
kubectl create namespace $TEST_NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

# 2. Restaurer une application sp√©cifique
velero restore create test-restore-$(date +%Y%m%d-%H%M%S) \
  --from-backup $BACKUP_NAME \
  --include-namespaces webapp \
  --namespace-mappings webapp:$TEST_NAMESPACE

# 3. Attendre la fin de la restauration
echo "Attente de la restauration..."
sleep 30

# 4. V√©rifier que les pods d√©marrent
PODS=$(kubectl get pods -n $TEST_NAMESPACE --no-headers | wc -l)
RUNNING=$(kubectl get pods -n $TEST_NAMESPACE --field-selector=status.phase=Running --no-headers | wc -l)

echo "Pods restaur√©s: $PODS"
echo "Pods running: $RUNNING"

# 5. Nettoyage
echo "Nettoyage..."
kubectl delete namespace $TEST_NAMESPACE

if [ "$RUNNING" -gt 0 ]; then
  echo "‚úì Test r√©ussi"
  exit 0
else
  echo "‚ùå Test √©chou√©"
  exit 1
fi
```

### 3. Test de restauration compl√®te

**Objectif** : Restaurer l'int√©gralit√© d'un environnement sur un cluster vide.

**Ce qu'on teste** :
- Restauration de tous les namespaces
- Toutes les applications red√©marrent
- Les donn√©es sont intactes
- Les services sont accessibles
- Le temps total de restauration

**Quand** : Mensuel ou trimestriel

**Dur√©e** : 1-4 heures

**Exemple** :

```bash
#!/bin/bash
# test-full-restore.sh

BACKUP_NAME="weekly-full-backup"

echo "=== Test de restauration compl√®te ==="
echo "ATTENTION: Ce test restaure TOUT sur ce cluster"
read -p "Continuer? (yes/no): " CONFIRM

if [ "$CONFIRM" != "yes" ]; then
  echo "Test annul√©"
  exit 0
fi

START_TIME=$(date +%s)

# 1. Sauvegarder l'√©tat actuel (au cas o√π)
echo "Sauvegarde de s√©curit√©..."
velero backup create pre-restore-safety-backup --wait

# 2. Restaurer depuis le backup
echo "Restauration compl√®te..."
velero restore create full-restore-test-$(date +%Y%m%d-%H%M%S) \
  --from-backup $BACKUP_NAME \
  --wait

# 3. V√©rifier tous les namespaces
echo "V√©rification des namespaces..."
NAMESPACES=$(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}' | tr ' ' '\n' | grep -v 'kube-\|default')

for ns in $NAMESPACES; do
  echo "  Namespace: $ns"
  PODS=$(kubectl get pods -n $ns --no-headers 2>/dev/null | wc -l)
  RUNNING=$(kubectl get pods -n $ns --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
  echo "    Pods: $RUNNING/$PODS running"
done

# 4. Calculer le temps
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))
MINUTES=$((DURATION / 60))

echo ""
echo "‚úì Test termin√© en $MINUTES minutes"
```

### 4. Test de r√©cup√©ration d'un fichier sp√©cifique

**Objectif** : V√©rifier qu'on peut r√©cup√©rer des donn√©es sp√©cifiques depuis un volume.

**Ce qu'on teste** :
- Restauration d'un volume persistant
- Acc√®s aux fichiers
- Int√©grit√© des donn√©es

**Quand** : Mensuel

**Dur√©e** : 15-30 minutes

**Exemple** :

```bash
#!/bin/bash
# test-file-recovery.sh

BACKUP_NAME="database-backup"
NAMESPACE="production"
PVC_NAME="postgres-data"

echo "=== Test de r√©cup√©ration de fichier ==="

# 1. Cr√©er un namespace temporaire
TEST_NS="file-recovery-test"
kubectl create namespace $TEST_NS

# 2. Restaurer le PVC
velero restore create file-recovery-$(date +%Y%m%d-%H%M%S) \
  --from-backup $BACKUP_NAME \
  --include-namespaces $NAMESPACE \
  --include-resources pvc,pv \
  --namespace-mappings $NAMESPACE:$TEST_NS

sleep 30

# 3. Cr√©er un pod pour acc√©der aux donn√©es
kubectl run file-checker -n $TEST_NS \
  --image=busybox \
  --restart=Never \
  --command -- sleep 3600

# 4. Monter le volume
kubectl patch pod file-checker -n $TEST_NS -p '
{
  "spec": {
    "volumes": [{
      "name": "data",
      "persistentVolumeClaim": {"claimName": "'$PVC_NAME'"}
    }],
    "containers": [{
      "name": "file-checker",
      "volumeMounts": [{
        "name": "data",
        "mountPath": "/data"
      }]
    }]
  }
}'

sleep 10

# 5. V√©rifier les fichiers
echo "Contenu du volume:"
kubectl exec -n $TEST_NS file-checker -- ls -lh /data

# 6. Nettoyage
kubectl delete namespace $TEST_NS

echo "‚úì Test termin√©"
```

### 5. Test de restauration de base de donn√©es

**Objectif** : V√©rifier l'int√©grit√© d'une base de donn√©es restaur√©e.

**Ce qu'on teste** :
- La base de donn√©es d√©marre
- Les donn√©es sont pr√©sentes
- Les requ√™tes fonctionnent
- Aucune corruption

**Quand** : Hebdomadaire pour les bases critiques

**Dur√©e** : 20-45 minutes

**Exemple pour PostgreSQL** :

```bash
#!/bin/bash
# test-database-restore.sh

BACKUP_NAME="postgres-backup"
NAMESPACE="database"
TEST_NS="db-restore-test"

echo "=== Test de restauration PostgreSQL ==="

# 1. Cr√©er namespace de test
kubectl create namespace $TEST_NS

# 2. Restaurer la base de donn√©es
velero restore create postgres-restore-test \
  --from-backup $BACKUP_NAME \
  --include-namespaces $NAMESPACE \
  --namespace-mappings $NAMESPACE:$TEST_NS \
  --wait

# 3. Attendre que PostgreSQL soit pr√™t
echo "Attente du d√©marrage de PostgreSQL..."
kubectl wait --for=condition=ready pod -l app=postgres -n $TEST_NS --timeout=300s

# 4. Tests basiques
POD=$(kubectl get pod -l app=postgres -n $TEST_NS -o jsonpath='{.items[0].metadata.name}')

echo "V√©rification de la connexion..."
kubectl exec -n $TEST_NS $POD -- psql -U postgres -c "SELECT version();" > /dev/null
if [ $? -eq 0 ]; then
  echo "‚úì Connexion OK"
else
  echo "‚ùå √âchec de connexion"
  kubectl delete namespace $TEST_NS
  exit 1
fi

echo "V√©rification des tables..."
TABLES=$(kubectl exec -n $TEST_NS $POD -- psql -U postgres -d mydb -c "\dt" | wc -l)
echo "  Tables trouv√©es: $TABLES"

echo "Test d'une requ√™te..."
kubectl exec -n $TEST_NS $POD -- psql -U postgres -d mydb -c "SELECT COUNT(*) FROM users;" > /dev/null
if [ $? -eq 0 ]; then
  echo "‚úì Requ√™te OK"
else
  echo "‚ùå √âchec de requ√™te"
fi

# 5. Nettoyage
kubectl delete namespace $TEST_NS

echo "‚úì Test de restauration BDD termin√©"
```

## Environnements de test

### Option 1 : Cluster de test d√©di√©

**Avantage** : Isolation compl√®te, pas de risque pour la production.

**Mise en place** :

```bash
# Installer un second MicroK8s pour les tests
# (Sur une VM ou un autre serveur)

# Configuration similaire √† production
microk8s enable dns storage registry

# Connecter au m√™me stockage de backups (MinIO)
velero install \
  --provider aws \
  --bucket velero-backups \
  --prefix test-cluster \
  --secret-file ./credentials-velero \
  ...
```

### Option 2 : Namespace de test sur le m√™me cluster

**Avantage** : Simple, pas besoin de cluster suppl√©mentaire.

**Mise en place** :

```bash
# Cr√©er un namespace d√©di√© aux tests
kubectl create namespace restore-testing

# Label pour isolation
kubectl label namespace restore-testing purpose=testing
```

### Option 3 : Snapshot du cluster avant test

**Avantage** : Permet de tester destructivement puis revenir en arri√®re.

**Mise en place** :

```bash
# Sur un syst√®me avec ZFS
sudo zfs snapshot mypool/microk8s@before-restore-test

# Pour revenir en arri√®re apr√®s le test
sudo zfs rollback mypool/microk8s@before-restore-test
```

### Option 4 : Cluster √©ph√©m√®re

**Avantage** : Totalement propre √† chaque test, pas de pollution.

**Mise en place avec Multipass** :

```bash
#!/bin/bash
# create-test-cluster.sh

# Cr√©er une VM temporaire
multipass launch --name test-cluster --cpus 2 --mem 4G --disk 20G

# Installer MicroK8s
multipass exec test-cluster -- sudo snap install microk8s --classic

# Installer Velero et configurer le backup-location
# ... (m√™me config que production)

echo "Cluster de test pr√™t"
echo "Pour d√©truire: multipass delete test-cluster && multipass purge"
```

## M√©thodologie de test compl√®te

Voici une approche syst√©matique pour tester vos restaurations.

### Phase 1 : Pr√©paration (5 minutes)

**Checklist** :

```markdown
- [ ] Identifier le backup √† tester
- [ ] V√©rifier que l'environnement de test est pr√™t
- [ ] Documenter l'√©tat actuel (nombre de ressources, versions)
- [ ] Pr√©parer les outils de v√©rification
- [ ] Informer l'√©quipe (si applicable)
```

**Script** :

```bash
#!/bin/bash
# prepare-test.sh

BACKUP_NAME=$1
TEST_ENV=$2  # test-cluster ou test-namespace

echo "=== Pr√©paration du test de restauration ==="
echo "Backup: $BACKUP_NAME"
echo "Environnement: $TEST_ENV"

# V√©rifier le backup
velero backup describe $BACKUP_NAME

# Documenter l'√©tat
cat > test-report-$(date +%Y%m%d-%H%M%S).md <<EOF
# Test de restauration

**Date:** $(date)
**Backup:** $BACKUP_NAME
**Environnement:** $TEST_ENV

## √âtat du backup

\`\`\`
$(velero backup describe $BACKUP_NAME)
\`\`\`

## Tests pr√©vus

- [ ] Restauration des ressources
- [ ] V√©rification des pods
- [ ] Tests de connectivit√©
- [ ] V√©rification des donn√©es

EOF

echo "‚úì Pr√©paration termin√©e"
```

### Phase 2 : Restauration (variable)

**Actions** :

1. Lancer la restauration
2. Surveiller la progression
3. Noter les erreurs
4. Mesurer le temps

**Script** :

```bash
#!/bin/bash
# execute-restore.sh

BACKUP_NAME=$1
TEST_NS=${2:-"restore-test"}

echo "=== Ex√©cution de la restauration ==="

START=$(date +%s)

# Cr√©er le namespace de test
kubectl create namespace $TEST_NS --dry-run=client -o yaml | kubectl apply -f -

# Restaurer
RESTORE_NAME="test-restore-$(date +%Y%m%d-%H%M%S)"
velero restore create $RESTORE_NAME \
  --from-backup $BACKUP_NAME \
  --namespace-mappings "production:$TEST_NS"

# Suivre la progression
echo "Suivi de la restauration..."
while true; do
  STATUS=$(velero restore describe $RESTORE_NAME | grep "Phase:" | awk '{print $2}')
  echo "  Status: $STATUS"

  if [ "$STATUS" = "Completed" ] || [ "$STATUS" = "Failed" ] || [ "$STATUS" = "PartiallyFailed" ]; then
    break
  fi

  sleep 10
done

END=$(date +%s)
DURATION=$((END - START))

echo ""
echo "‚úì Restauration termin√©e en $DURATION secondes"
echo "  Status final: $STATUS"

# Afficher les d√©tails
velero restore describe $RESTORE_NAME --details
```

### Phase 3 : V√©rification (10-30 minutes)

**Checklist de v√©rification** :

```markdown
## V√©rifications techniques

- [ ] Tous les namespaces sont pr√©sents
- [ ] Tous les deployments sont cr√©√©s
- [ ] Tous les pods sont en √©tat Running
- [ ] Tous les services sont cr√©√©s
- [ ] Les PVCs sont li√©s
- [ ] Les volumes contiennent des donn√©es
- [ ] Les ConfigMaps sont pr√©sents
- [ ] Les Secrets sont pr√©sents
- [ ] Les Ingress sont configur√©s

## V√©rifications fonctionnelles

- [ ] Les applications web r√©pondent
- [ ] Les bases de donn√©es sont accessibles
- [ ] Les APIs fonctionnent
- [ ] Les donn√©es sont coh√©rentes
- [ ] Pas de corruption visible

## V√©rifications de performance

- [ ] Temps de d√©marrage acceptable
- [ ] Ressources CPU/RAM normales
- [ ] Pas de red√©marrages r√©p√©t√©s
```

**Script automatis√©** :

```bash
#!/bin/bash
# verify-restore.sh

TEST_NS=$1

echo "=== V√©rification de la restauration ==="
echo "Namespace: $TEST_NS"

ERRORS=0

# 1. V√©rifier les pods
echo -e "\n1. V√©rification des pods"
TOTAL_PODS=$(kubectl get pods -n $TEST_NS --no-headers 2>/dev/null | wc -l)
RUNNING_PODS=$(kubectl get pods -n $TEST_NS --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)

echo "  Pods running: $RUNNING_PODS/$TOTAL_PODS"

if [ $RUNNING_PODS -eq $TOTAL_PODS ]; then
  echo "  ‚úì Tous les pods sont en running"
else
  echo "  ‚ùå Des pods ne sont pas en running"
  ERRORS=$((ERRORS + 1))
  kubectl get pods -n $TEST_NS | grep -v Running
fi

# 2. V√©rifier les PVCs
echo -e "\n2. V√©rification des PVCs"
TOTAL_PVC=$(kubectl get pvc -n $TEST_NS --no-headers 2>/dev/null | wc -l)
BOUND_PVC=$(kubectl get pvc -n $TEST_NS --field-selector=status.phase=Bound --no-headers 2>/dev/null | wc -l)

echo "  PVCs bound: $BOUND_PVC/$TOTAL_PVC"

if [ $BOUND_PVC -eq $TOTAL_PVC ]; then
  echo "  ‚úì Tous les PVCs sont li√©s"
else
  echo "  ‚ùå Des PVCs ne sont pas li√©s"
  ERRORS=$((ERRORS + 1))
fi

# 3. V√©rifier les services
echo -e "\n3. V√©rification des services"
SERVICES=$(kubectl get services -n $TEST_NS --no-headers 2>/dev/null | wc -l)
echo "  Services: $SERVICES"

if [ $SERVICES -gt 0 ]; then
  echo "  ‚úì Services pr√©sents"
else
  echo "  ‚ö† Aucun service trouv√©"
fi

# 4. V√©rifier les ConfigMaps
echo -e "\n4. V√©rification des ConfigMaps"
CMS=$(kubectl get configmaps -n $TEST_NS --no-headers 2>/dev/null | wc -l)
echo "  ConfigMaps: $CMS"

# 5. Test de connectivit√© (si applicable)
echo -e "\n5. Test de connectivit√©"
if kubectl get service -n $TEST_NS webapp &>/dev/null; then
  POD=$(kubectl get pod -n $TEST_NS -l app=webapp -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
  if [ -n "$POD" ]; then
    kubectl exec -n $TEST_NS $POD -- wget -q -O- http://localhost:80 &>/dev/null
    if [ $? -eq 0 ]; then
      echo "  ‚úì Application web r√©pond"
    else
      echo "  ‚ùå Application web ne r√©pond pas"
      ERRORS=$((ERRORS + 1))
    fi
  fi
fi

# R√©sum√©
echo -e "\n=== R√©sum√© ==="
if [ $ERRORS -eq 0 ]; then
  echo "‚úì Tous les tests ont r√©ussi"
  exit 0
else
  echo "‚ùå $ERRORS erreurs d√©tect√©es"
  exit 1
fi
```

### Phase 4 : Nettoyage (2-5 minutes)

**Actions** :

```bash
#!/bin/bash
# cleanup-test.sh

TEST_NS=$1

echo "=== Nettoyage apr√®s test ==="

# Sauvegarder les logs si n√©cessaire
mkdir -p ./test-logs
kubectl get all -n $TEST_NS -o yaml > ./test-logs/final-state.yaml

# Supprimer le namespace de test
kubectl delete namespace $TEST_NS --wait

echo "‚úì Nettoyage termin√©"
```

### Phase 5 : Documentation (5-10 minutes)

**Compl√©ter le rapport** :

```bash
#!/bin/bash
# finalize-report.sh

REPORT_FILE=$1
SUCCESS=$2  # "pass" ou "fail"

cat >> $REPORT_FILE <<EOF

## R√©sultats

**Status:** $SUCCESS
**Date de fin:** $(date)

### Observations

- Temps de restauration: XX minutes
- Pods restaur√©s: XX/XX
- Probl√®mes rencontr√©s:
  - [ Liste des probl√®mes ]

### Actions correctives

- [ Liste des actions √† prendre ]

### Prochains tests

- Date du prochain test: [date]

---

**Testeur:** $(whoami)
**Signature:** _______________
EOF

echo "‚úì Rapport compl√©t√©: $REPORT_FILE"
```

## Plan de tests r√©guliers

### Calendrier recommand√©

**Pour un lab personnel** :

```
Quotidien:
  - Validation automatique des backups

Hebdomadaire:
  - Test de restauration partielle (une application)

Mensuel:
  - Test de restauration compl√®te
  - Test de restauration de base de donn√©es

Trimestriel:
  - Test de disaster recovery complet
  - Simulation de migration vers nouveau cluster

Annuel:
  - Audit complet de la strat√©gie de sauvegarde
  - Test avec toute l'√©quipe (si applicable)
```

**Pour un environnement de production** :

```
Quotidien:
  - Validation automatique des backups
  - Alertes sur √©checs

Hebdomadaire:
  - Test de restauration partielle
  - Test de r√©cup√©ration de fichiers

Bi-hebdomadaire:
  - Test de restauration de BDD

Mensuel:
  - Test de restauration compl√®te
  - Test de failover
  - Revue des m√©triques

Trimestriel:
  - Exercice de disaster recovery
  - Test de RTO/RPO
  - Mise √† jour de la documentation

Annuel:
  - Audit externe (si requis)
  - Formation de l'√©quipe
```

### Script de planification

```bash
#!/bin/bash
# schedule-tests.sh

# Cr√©er des CronJobs pour automatiser les tests

cat <<EOF | kubectl apply -f -
---
# Validation quotidienne des backups
apiVersion: batch/v1
kind: CronJob
metadata:
  name: daily-backup-validation
  namespace: velero
spec:
  schedule: "0 3 * * *"  # 3h du matin
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: validator
            image: bitnami/kubectl:latest
            command:
            - /bin/bash
            - -c
            - |
              # Valider le dernier backup
              LATEST=\$(velero backup get --output=name | sort | tail -1)
              STATUS=\$(velero backup describe \$LATEST | grep "Phase:" | awk '{print \$2}')

              if [ "\$STATUS" != "Completed" ]; then
                echo "‚ùå ALERTE: Backup \$LATEST en √©chec!"
                # Envoyer une notification (webhook, email, etc.)
                exit 1
              fi

              echo "‚úì Backup valid√©: \$LATEST"
          restartPolicy: OnFailure
---
# Test de restauration hebdomadaire
apiVersion: batch/v1
kind: CronJob
metadata:
  name: weekly-restore-test
  namespace: velero
spec:
  schedule: "0 2 * * 0"  # Dimanche √† 2h
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: velero
          containers:
          - name: restore-tester
            image: bitnami/kubectl:latest
            command:
            - /bin/bash
            - -c
            - |
              # Test de restauration partielle
              echo "=== Test de restauration hebdomadaire ==="

              # Cr√©er namespace de test
              kubectl create namespace restore-test-weekly

              # Restaurer une application
              LATEST=\$(velero backup get --output=name | sort | tail -1)
              velero restore create weekly-test-\$(date +%Y%m%d) \\
                --from-backup \$LATEST \\
                --include-namespaces webapp \\
                --namespace-mappings webapp:restore-test-weekly

              # Attendre et v√©rifier
              sleep 60
              PODS=\$(kubectl get pods -n restore-test-weekly --field-selector=status.phase=Running --no-headers | wc -l)

              # Nettoyage
              kubectl delete namespace restore-test-weekly

              echo "‚úì Test termin√© - \$PODS pods ont d√©marr√©"
          restartPolicy: OnFailure
EOF

echo "‚úì Tests automatiques planifi√©s"
```

## M√©triques et KPIs

### M√©triques √† suivre

**Temps de restauration (RTO - Recovery Time Objective)** :

```bash
#!/bin/bash
# measure-rto.sh

echo "=== Mesure du RTO ==="

BACKUP_NAME=$1
START=$(date +%s)

# Restauration
velero restore create rto-test \
  --from-backup $BACKUP_NAME \
  --wait

END=$(date +%s)
RTO=$((END - START))
RTO_MINUTES=$((RTO / 60))

echo "RTO mesur√©: $RTO_MINUTES minutes"

# Enregistrer dans un fichier
echo "$(date),$BACKUP_NAME,$RTO_MINUTES" >> rto-metrics.csv

# Si d√©passe l'objectif, alerter
RTO_OBJECTIVE=120  # 2 heures
if [ $RTO_MINUTES -gt $RTO_OBJECTIVE ]; then
  echo "‚ö† ALERTE: RTO d√©passe l'objectif ($RTO_OBJECTIVE min)"
fi
```

**Taux de r√©ussite des restaurations** :

```bash
#!/bin/bash
# calculate-success-rate.sh

TOTAL=$(velero restore get --output=json | jq '.items | length')
COMPLETED=$(velero restore get --output=json | jq '[.items[] | select(.status.phase=="Completed")] | length')

SUCCESS_RATE=$((COMPLETED * 100 / TOTAL))

echo "Taux de r√©ussite: $SUCCESS_RATE%"
echo "  Completed: $COMPLETED"
echo "  Total: $TOTAL"

if [ $SUCCESS_RATE -lt 95 ]; then
  echo "‚ö† ALERTE: Taux de r√©ussite trop faible"
fi
```

**Int√©grit√© des donn√©es** :

```bash
#!/bin/bash
# verify-data-integrity.sh

echo "=== V√©rification de l'int√©grit√© des donn√©es ==="

# Cr√©er un checksum avant backup
kubectl exec -n production postgres-0 -- \
  psql -U postgres -d mydb -c "SELECT COUNT(*), SUM(id) FROM users;" \
  > /tmp/before.txt

# Restaurer dans un namespace de test
# ... (restauration)

# Cr√©er un checksum apr√®s restore
kubectl exec -n restore-test postgres-0 -- \
  psql -U postgres -d mydb -c "SELECT COUNT(*), SUM(id) FROM users;" \
  > /tmp/after.txt

# Comparer
if diff /tmp/before.txt /tmp/after.txt; then
  echo "‚úì Donn√©es identiques"
else
  echo "‚ùå Diff√©rence d√©tect√©e dans les donn√©es"
fi
```

### Dashboard de suivi

Cr√©ez un fichier de tracking :

```csv
Date,Type de test,Backup,Dur√©e (min),R√©sultat,Notes
2025-01-15,Validation,daily-backup,1,Pass,
2025-01-14,Partiel,daily-backup,15,Pass,
2025-01-10,Complet,weekly-backup,120,Pass,
2025-01-08,BDD,postgres-backup,25,Fail,Timeout connexion
```

Script de g√©n√©ration de rapport :

```bash
#!/bin/bash
# generate-report.sh

cat <<EOF
# Rapport de tests de restauration

**P√©riode:** $(date -d '30 days ago' +%Y-%m-%d) √† $(date +%Y-%m-%d)

## Statistiques

\`\`\`
$(awk -F',' 'NR>1 {
  total++;
  if($5=="Pass") pass++
}
END {
  print "Total tests: " total;
  print "R√©ussis: " pass;
  print "Taux de r√©ussite: " (pass*100/total) "%"
}' test-tracking.csv)
\`\`\`

## Tests par type

\`\`\`
$(awk -F',' 'NR>1 {count[$2]++} END {for (type in count) print type ": " count[type]}' test-tracking.csv)
\`\`\`

## Dur√©e moyenne

\`\`\`
$(awk -F',' 'NR>1 {
  if($2=="Complet") {sum+=$4; count++}
}
END {
  if(count>0) print "Restauration compl√®te: " (sum/count) " minutes"
}' test-tracking.csv)
\`\`\`

## Probl√®mes identifi√©s

$(awk -F',' 'NR>1 && $5=="Fail" {print "- " $1 ": " $6}' test-tracking.csv)

EOF
```

## Troubleshooting pendant les tests

### Probl√®me 1 : Restauration bloqu√©e

**Sympt√¥mes** : La restauration reste en "InProgress" ind√©finiment.

**Diagnostic** :

```bash
# V√©rifier les logs Velero
kubectl logs -n velero deployment/velero

# V√©rifier les logs du restore
velero restore logs restore-name

# V√©rifier les events
kubectl get events -n target-namespace --sort-by='.lastTimestamp'
```

**Solutions courantes** :

```bash
# Supprimer et recommencer
velero restore delete problematic-restore
velero restore create new-attempt --from-backup same-backup

# V√©rifier les ressources du node
kubectl top nodes

# V√©rifier si c'est un probl√®me de PVC
kubectl get pvc -n target-namespace
```

### Probl√®me 2 : Pods en CrashLoopBackOff

**Diagnostic** :

```bash
# Voir les logs du pod
kubectl logs -n test-namespace pod-name --previous

# D√©crire le pod
kubectl describe pod -n test-namespace pod-name

# V√©rifier les volumes
kubectl get pvc -n test-namespace
```

**Solutions** :

```bash
# V√©rifier les ConfigMaps/Secrets
kubectl get configmaps,secrets -n test-namespace

# V√©rifier les d√©pendances (BDD, services externes)
kubectl get services -n test-namespace

# Augmenter les ressources temporairement
kubectl patch deployment app-name -n test-namespace -p '
{
  "spec": {
    "template": {
      "spec": {
        "containers": [{
          "name": "container-name",
          "resources": {
            "requests": {
              "memory": "512Mi",
              "cpu": "500m"
            }
          }
        }]
      }
    }
  }
}'
```

### Probl√®me 3 : Donn√©es manquantes apr√®s restauration

**Diagnostic** :

```bash
# V√©rifier si les volumes ont √©t√© restaur√©s
velero restore describe restore-name --details | grep "Restic"

# V√©rifier le contenu d'un volume
kubectl run -n test-namespace debug-pod --rm -it --image=busybox -- sh
# Dans le pod:
ls -la /data
```

**Solutions** :

```bash
# V√©rifier que --default-volumes-to-fs-backup √©tait activ√©
velero backup describe backup-name

# Relancer avec restauration des volumes explicite
velero restore create new-restore \
  --from-backup backup-name \
  --restore-volumes=true
```

### Probl√®me 4 : Erreurs de permissions

**Diagnostic** :

```bash
# V√©rifier les ServiceAccounts
kubectl get serviceaccounts -n test-namespace

# V√©rifier les Roles/RoleBindings
kubectl get roles,rolebindings -n test-namespace
```

**Solutions** :

```bash
# Restaurer aussi les ressources RBAC
velero restore create rbac-restore \
  --from-backup backup-name \
  --include-resources serviceaccounts,roles,rolebindings

# Ou cr√©er manuellement
kubectl create serviceaccount app-sa -n test-namespace
```

## Documentation des tests

### Template de rapport de test

```markdown
# Rapport de test de restauration

**Date:** [date]
**Testeur:** [nom]
**Type de test:** [Validation/Partiel/Complet/BDD]

## Informations du backup

- **Nom:** [backup-name]
- **Date de cr√©ation:** [date]
- **Taille:** [size]
- **Ressources:** [count]

## Environnement de test

- **Cluster:** [test/production]
- **Namespace:** [namespace]
- **Version MicroK8s:** [version]

## Proc√©dure suivie

1. [√âtape 1]
2. [√âtape 2]
3. [√âtape 3]

## R√©sultats

### M√©triques

- **Dur√©e de restauration:** [XX] minutes
- **Pods restaur√©s:** [XX/XX]
- **PVCs li√©s:** [XX/XX]
- **Services cr√©√©s:** [XX]

### Tests fonctionnels

- [ ] Application web accessible
- [ ] Base de donn√©es r√©pond
- [ ] Donn√©es intactes
- [ ] Pas de corruption

## Probl√®mes rencontr√©s

1. [Probl√®me 1] - [R√©solution]
2. [Probl√®me 2] - [R√©solution]

## Actions correctives

- [ ] [Action 1]
- [ ] [Action 2]

## Conclusion

**Status:** ‚úì PASS / ‚ùå FAIL

**Recommandations:**
- [Recommandation 1]
- [Recommandation 2]

**Prochain test:** [date]

---

**Signature:** _______________
```

### Script de g√©n√©ration de rapport

```bash
#!/bin/bash
# generate-test-report.sh

BACKUP_NAME=$1
TEST_TYPE=$2
RESULT=$3  # pass/fail

REPORT_FILE="test-report-$(date +%Y%m%d-%H%M%S).md"

cat > $REPORT_FILE <<EOF
# Rapport de test de restauration

**Date:** $(date)
**Testeur:** $(whoami)
**Type de test:** $TEST_TYPE
**R√©sultat:** $RESULT

## Backup test√©

\`\`\`
$(velero backup describe $BACKUP_NAME)
\`\`\`

## √âtat du cluster apr√®s restauration

### Namespaces
\`\`\`
$(kubectl get namespaces)
\`\`\`

### Pods
\`\`\`
$(kubectl get pods --all-namespaces | grep -v kube-system)
\`\`\`

### Services
\`\`\`
$(kubectl get services --all-namespaces | grep -v kube-system)
\`\`\`

## Logs de restauration

\`\`\`
$(velero restore logs latest --namespace velero)
\`\`\`

## Conclusion

**Status:** $RESULT

---
EOF

echo "Rapport g√©n√©r√©: $REPORT_FILE"
```

## Checklist compl√®te de test

```markdown
# Checklist de test de restauration

## Avant le test

- [ ] Choisir le backup √† tester
- [ ] Pr√©parer l'environnement de test
- [ ] V√©rifier que le backup est Completed
- [ ] Documenter l'√©tat actuel
- [ ] Pr√©venir l'√©quipe (si applicable)

## Pendant le test

- [ ] D√©marrer le chronom√®tre
- [ ] Lancer la restauration
- [ ] Surveiller les logs Velero
- [ ] Noter toute erreur ou warning
- [ ] V√©rifier la progression r√©guli√®rement

## Apr√®s restauration

- [ ] V√©rifier tous les namespaces
- [ ] Compter les pods (total vs running)
- [ ] V√©rifier les PVCs (total vs bound)
- [ ] Tester les services
- [ ] V√©rifier les donn√©es
- [ ] Tester la connectivit√©
- [ ] Mesurer le temps total

## V√©rifications fonctionnelles

- [ ] Application web r√©pond
- [ ] API accessible
- [ ] Base de donn√©es fonctionne
- [ ] Requ√™tes SQL OK
- [ ] Fichiers pr√©sents dans les volumes
- [ ] Pas de corruption d√©tect√©e

## Nettoyage

- [ ] Sauvegarder les logs
- [ ] Exporter l'√©tat final
- [ ] Supprimer le namespace de test
- [ ] Nettoyer les ressources temporaires

## Documentation

- [ ] Compl√©ter le rapport de test
- [ ] Enregistrer les m√©triques
- [ ] Noter les probl√®mes rencontr√©s
- [ ] Lister les actions correctives
- [ ] Planifier le prochain test
- [ ] Archiver tous les documents

## Suivi

- [ ] Impl√©menter les corrections
- [ ] Mettre √† jour la documentation
- [ ] Informer l'√©quipe des r√©sultats
- [ ] Planifier le test suivant
```

## Conclusion

Les tests de restauration sont le pilier d'une strat√©gie de sauvegarde efficace. Sans tests r√©guliers, vous travaillez avec un faux sentiment de s√©curit√©.

### Points cl√©s √† retenir

‚úÖ **Tester r√©guli√®rement** : Minimum mensuel, id√©alement hebdomadaire
‚úÖ **Varier les tests** : Validation, partiel, complet, sp√©cifique
‚úÖ **Documenter tout** : Chaque test doit g√©n√©rer un rapport
‚úÖ **Mesurer les m√©triques** : RTO, taux de r√©ussite, int√©grit√©
‚úÖ **Automatiser** : Scripts et CronJobs pour tests r√©currents
‚úÖ **Corriger rapidement** : Chaque probl√®me d√©tect√© = action imm√©diate
‚úÖ **Former l'√©quipe** : Tout le monde doit savoir restaurer

### Les 3 r√®gles d'or

1. **Une sauvegarde non test√©e n'est pas une sauvegarde**
2. **Testez avant d'en avoir besoin**
3. **Documentez comme si quelqu'un d'autre devait restaurer**

### Prochaines √©tapes

Dans la section suivante (22.7), nous verrons comment cr√©er un plan de reprise d'activit√© (DRP - Disaster Recovery Plan) complet qui int√®gre tous les aspects de sauvegarde et de restauration dans une strat√©gie globale.

---

**Checklist finale** :

- [ ] D√©finir une fr√©quence de tests adapt√©e
- [ ] Cr√©er des scripts de test automatis√©s
- [ ] Mettre en place un environnement de test
- [ ] √âtablir des m√©triques de r√©f√©rence (RTO, RPO)
- [ ] Documenter la proc√©dure de test
- [ ] Former les personnes concern√©es
- [ ] Planifier les tests dans un calendrier
- [ ] Cr√©er des alertes sur √©checs
- [ ] Maintenir un journal des tests
- [ ] R√©viser et am√©liorer r√©guli√®rement

‚è≠Ô∏è [Plan de reprise d'activit√© (DRP)](/22-sauvegarde-et-restauration/07-plan-de-reprise-dactivite-drp.md)
