ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 22.7 Plan de reprise d'activitÃ© (DRP)

## Introduction

Un **Plan de Reprise d'ActivitÃ©** (DRP - Disaster Recovery Plan) est un document structurÃ© qui dÃ©crit exactement quoi faire quand tout va mal. C'est votre plan B, votre bouÃ©e de sauvetage, votre manuel de survie pour votre infrastructure Kubernetes.

Pensez-y comme au **plan d'Ã©vacuation d'un bÃ¢timent** : vous espÃ©rez ne jamais en avoir besoin, mais quand l'alarme incendie retentit, vous Ãªtes content qu'il existe et que tout le monde sache quoi faire.

### Pourquoi un DRP est essentiel

Sans DRP, voici ce qui arrive lors d'un dÃ©sastre :

**Scenario sans DRP** :
```
3h00 : Le serveur tombe en panne
3h15 : Panique. OÃ¹ sont les sauvegardes ?
3h30 : On trouve des sauvegardes, mais lesquelles utiliser ?
4h00 : On essaie de restaurer. Ã‰chec. Pourquoi ?
5h00 : On appelle quelqu'un pour aider
6h00 : On dÃ©couvre que les secrets ne sont pas sauvegardÃ©s
8h00 : On reconstruit Ã  la main
12h00 : On dÃ©couvre qu'il manque des donnÃ©es
RÃ©sultat : 9 heures de downtime, stress maximum, donnÃ©es perdues
```

**Scenario avec DRP** :
```
3h00 : Le serveur tombe en panne
3h05 : On ouvre le DRP, section "Panne serveur complÃ¨te"
3h10 : On exÃ©cute le script de restauration documentÃ©
3h30 : Le cluster est restaurÃ©, tests en cours
3h45 : Services remis en ligne
RÃ©sultat : 45 minutes de downtime, procÃ©dure calme et maÃ®trisÃ©e
```

### Ce qu'un DRP n'est PAS

âŒ Un simple document technique ignorÃ© dans un tiroir
âŒ Une procÃ©dure Ã©crite une fois et jamais mise Ã  jour
âŒ Une responsabilitÃ© d'une seule personne
âŒ Une garantie que rien ne peut mal tourner

### Ce qu'un DRP EST

âœ… Un guide pratique testÃ© rÃ©guliÃ¨rement
âœ… Un document vivant mis Ã  jour continuellement
âœ… Une responsabilitÃ© partagÃ©e par toute l'Ã©quipe
âœ… Un moyen de minimiser l'impact des dÃ©sastres

## Concepts fondamentaux

Avant de crÃ©er votre DRP, vous devez comprendre quelques concepts clÃ©s.

### RPO (Recovery Point Objective)

**DÃ©finition simple** : Combien de donnÃ©es pouvez-vous vous permettre de perdre ?

**Analogie** : Imaginez que vous Ã©crivez un roman. Si votre ordinateur plante, combien de chapitres Ãªtes-vous prÃªt Ã  rÃ©Ã©crire ?
- Sauvegarde toutes les heures â†’ RPO de 1 heure (vous rÃ©Ã©crivez 1 heure de travail)
- Sauvegarde quotidienne â†’ RPO de 24 heures (vous rÃ©Ã©crivez une journÃ©e)

**Exemples pour MicroK8s** :
- **Blog personnel** : RPO = 24h (un article par jour, acceptable)
- **Application de notes** : RPO = 1h (donnÃ©es frÃ©quentes, important)
- **SystÃ¨me de monitoring** : RPO = 5 minutes (mÃ©triques critiques)
- **Serveur de dÃ©veloppement** : RPO = 1 semaine (peu critique)

**Comment dÃ©finir votre RPO** :

```markdown
Question : Si je perds les X derniÃ¨res heures de donnÃ©es, quel est l'impact ?

Impact minimal (pas grave) â†’ RPO = 24h
Impact modÃ©rÃ© (gÃªnant) â†’ RPO = 4h
Impact important (problÃ©matique) â†’ RPO = 1h
Impact critique (inacceptable) â†’ RPO = 15min
```

### RTO (Recovery Time Objective)

**DÃ©finition simple** : Combien de temps pouvez-vous rester hors service ?

**Analogie** : Si votre voiture tombe en panne, combien de temps pouvez-vous attendre avant d'en avoir absolument besoin ?
- Voiture de loisir â†’ RTO = plusieurs jours
- Voiture pour aller au travail â†’ RTO = quelques heures
- Ambulance â†’ RTO = quelques minutes

**Exemples pour MicroK8s** :
- **Lab d'apprentissage** : RTO = 1 semaine (pas urgent)
- **Blog personnel** : RTO = 48 heures (gÃªnant mais gÃ©rable)
- **Service interne d'Ã©quipe** : RTO = 4 heures (impact sur productivitÃ©)
- **Application critique** : RTO = 30 minutes (impact business important)

**Comment dÃ©finir votre RTO** :

```markdown
Question : Combien de temps puis-je rester sans ce service ?

Plusieurs jours acceptable â†’ RTO = 48-72h
Une journÃ©e acceptable â†’ RTO = 8-24h
Quelques heures maximum â†’ RTO = 2-4h
Doit Ãªtre rapide â†’ RTO = 30min-1h
Quasi immÃ©diat â†’ RTO = 5-15min
```

### Relation RPO/RTO et stratÃ©gie de backup

Plus vos objectifs RPO/RTO sont stricts, plus votre stratÃ©gie doit Ãªtre sophistiquÃ©e :

```
RPO/RTO Relaxed (24h/48h):
â†’ Backups quotidiens
â†’ Restauration manuelle
â†’ Documentation simple

RPO/RTO ModÃ©rÃ© (4h/8h):
â†’ Backups plusieurs fois par jour
â†’ Scripts de restauration semi-automatiques
â†’ Tests mensuels

RPO/RTO Strict (1h/2h):
â†’ Backups horaires + rÃ©plication
â†’ Restauration automatisÃ©e
â†’ Tests hebdomadaires
â†’ Haute disponibilitÃ©

RPO/RTO Critique (<15min/<30min):
â†’ RÃ©plication continue
â†’ Failover automatique
â†’ Cluster multi-node HA
â†’ Tests quotidiens
```

### Types de dÃ©sastres

Votre DRP doit couvrir diffÃ©rents scÃ©narios :

**Niveau 1 - Incident mineur** :
- Pod qui crashe
- Service indisponible temporairement
- Erreur de configuration

**Impact** : Faible, localisÃ©
**FrÃ©quence** : RÃ©gulier
**RÃ©ponse** : RedÃ©marrage, rollback simple

**Niveau 2 - Incident majeur** :
- Node qui tombe
- Application complÃ¨te down
- Base de donnÃ©es corrompue

**Impact** : ModÃ©rÃ©, un service complet
**FrÃ©quence** : Occasionnel
**RÃ©ponse** : Restauration depuis backup, rÃ©paration

**Niveau 3 - DÃ©sastre local** :
- Serveur complet HS
- Disque dur dÃ©faillant
- Corruption du cluster

**Impact** : Important, tout le cluster
**FrÃ©quence** : Rare
**RÃ©ponse** : Restauration complÃ¨te, migration

**Niveau 4 - DÃ©sastre majeur** :
- Incendie du datacenter
- Catastrophe naturelle
- Cyberattaque majeure

**Impact** : Critique, perte totale
**FrÃ©quence** : TrÃ¨s rare
**RÃ©ponse** : Reprise sur site distant, activation du DRP complet

## Structure d'un DRP

Voici comment structurer votre plan de reprise d'activitÃ©.

### 1. Page de garde et informations essentielles

```markdown
# Plan de Reprise d'ActivitÃ©
## Cluster MicroK8s - [Nom du projet]

**Version:** 2.1
**Date de crÃ©ation:** 15 janvier 2025
**DerniÃ¨re mise Ã  jour:** 15 janvier 2025
**Prochain test:** 1er fÃ©vrier 2025

**PropriÃ©taire:** [Votre nom]
**Contacts d'urgence:**
- PropriÃ©taire principal: [Nom] - [Email] - [TÃ©lÃ©phone]
- Backup: [Nom] - [Email] - [TÃ©lÃ©phone]
- Support technique: [Contact]

**Emplacement des sauvegardes:**
- Local: /mnt/backups/microk8s
- Cloud: s3://mon-bucket-backup/microk8s
- Archive: Google Drive - dossier "MicroK8s Backups"

**AccÃ¨s critiques:**
- MinIO: http://minio.example.com (credentials dans 1Password)
- Velero: kubectl (config dans ~/.kube)
- Serveur: SSH user@server.example.com

**Classification:**
- RPO: 4 heures
- RTO: 8 heures
```

### 2. Vue d'ensemble du systÃ¨me

```markdown
## Architecture du cluster

### Infrastructure
- **Type:** MicroK8s single-node
- **OS:** Ubuntu 22.04 LTS
- **Serveur:** Dell PowerEdge / Home Lab
- **CPU:** 8 cores
- **RAM:** 32 GB
- **Stockage:** 500 GB SSD

### Applications hÃ©bergÃ©es

| Application | Namespace | CriticitÃ© | RPO | RTO |
|-------------|-----------|-----------|-----|-----|
| Blog WordPress | production | Moyenne | 24h | 8h |
| Base PostgreSQL | database | Haute | 4h | 4h |
| GitLab | devops | Haute | 2h | 4h |
| Monitoring | monitoring | Faible | 24h | 24h |

### DÃ©pendances externes
- DNS: Cloudflare
- Certificats: Let's Encrypt via cert-manager
- Storage: MinIO (local)
- Registry: Docker Hub + registry local
```

### 3. StratÃ©gie de sauvegarde

```markdown
## StratÃ©gie de sauvegarde actuelle

### Backups automatiques

**Quotidien (2h00):**
- Backup complet avec Velero
- RÃ©tention: 7 jours
- Inclut: Tous les namespaces utilisateurs + volumes
- Destination: MinIO local + S3

**Hebdomadaire (Dimanche 1h00):**
- Backup archive
- RÃ©tention: 90 jours
- Destination: S3 uniquement

**Horaire (applications critiques):**
- GitLab: toutes les 2h
- PostgreSQL: toutes les heures (pg_dump)
- RÃ©tention: 24 heures

### Backups manuels

**Avant maintenance:**
- Backup complet avant toute mise Ã  jour majeure
- RÃ©tention: Jusqu'Ã  confirmation succÃ¨s

**Configurations:**
- Export Git quotidien des manifestes
- Repository: github.com/user/k8s-configs
```

### 4. Inventaire des ressources

```markdown
## Inventaire des ressources critiques

### Namespaces

- `production`: Applications web en production
- `database`: Bases de donnÃ©es PostgreSQL, MySQL
- `devops`: GitLab, Jenkins, registre Docker
- `monitoring`: Prometheus, Grafana, Alertmanager

### PersistentVolumes critiques

| PV Name | Application | Taille | DonnÃ©es |
|---------|-------------|--------|---------|
| postgres-data-pv | PostgreSQL | 50Gi | Base de donnÃ©es production |
| gitlab-data-pv | GitLab | 100Gi | Repos Git, artifacts |
| wordpress-pv | WordPress | 20Gi | MÃ©dia, uploads |

### Secrets critiques

- `postgres-credentials`: AccÃ¨s base de donnÃ©es
- `gitlab-secrets`: ClÃ©s GitLab, OAuth
- `tls-certificates`: Certificats SSL wildcard
- `registry-auth`: Authentification registre Docker
- `minio-credentials`: AccÃ¨s stockage backups

**Emplacement des secrets hors cluster:**
- 1Password vault: "MicroK8s Production"
- Fichier chiffrÃ©: secrets-backup.gpg (sur disque externe)
```

### 5. ProcÃ©dures de restauration

C'est le cÅ“ur du DRP. Chaque scÃ©nario doit avoir une procÃ©dure dÃ©taillÃ©e.

#### ProcÃ©dure 1 : Restauration d'une application unique

```markdown
## ProcÃ©dure: Restauration d'une application unique

**ScÃ©nario:** Une application (ex: WordPress) est corrompue ou supprimÃ©e

**PrÃ©requis:**
- AccÃ¨s kubectl au cluster
- Backup rÃ©cent disponible
- 15-30 minutes

**Ã‰tapes:**

1. Identifier le dernier backup valide
   ```bash
   velero backup get | grep wordpress
   ```

2. CrÃ©er un namespace temporaire pour tests
   ```bash
   kubectl create namespace wordpress-restore-test
   ```

3. Restaurer l'application
   ```bash
   velero restore create wordpress-restore-$(date +%Y%m%d) \
     --from-backup [BACKUP_NAME] \
     --include-namespaces production \
     --include-resources deployment,service,pvc,configmap,secret \
     --selector app=wordpress \
     --namespace-mappings production:wordpress-restore-test
   ```

4. Attendre la fin de la restauration
   ```bash
   velero restore describe wordpress-restore-[DATE]
   ```

5. VÃ©rifier que l'application dÃ©marre
   ```bash
   kubectl get pods -n wordpress-restore-test
   kubectl logs -n wordpress-restore-test [POD_NAME]
   ```

6. Tester l'accÃ¨s
   ```bash
   kubectl port-forward -n wordpress-restore-test service/wordpress 8080:80
   # Ouvrir http://localhost:8080
   ```

7. Si OK, restaurer en production
   ```bash
   # Supprimer l'ancienne version
   kubectl delete all -n production -l app=wordpress

   # Restaurer en production
   velero restore create wordpress-prod-restore \
     --from-backup [BACKUP_NAME] \
     --include-namespaces production \
     --selector app=wordpress
   ```

8. Nettoyer le namespace de test
   ```bash
   kubectl delete namespace wordpress-restore-test
   ```

**Temps estimÃ©:** 20-30 minutes

**Points d'attention:**
- VÃ©rifier que les PVCs sont bien bound
- VÃ©rifier les secrets (passwords)
- Tester l'accÃ¨s avant de supprimer l'ancien
```

#### ProcÃ©dure 2 : Restauration complÃ¨te du cluster

```markdown
## ProcÃ©dure: Restauration complÃ¨te du cluster

**ScÃ©nario:** Le serveur complet est perdu, reconstruction nÃ©cessaire

**PrÃ©requis:**
- Nouveau serveur ou machine disponible
- AccÃ¨s aux backups (MinIO/S3)
- Fichier de credentials Velero
- 2-4 heures

**Phase 1 - Installation du systÃ¨me de base (30 min)**

1. Installer Ubuntu Server 22.04
   ```bash
   # Installation standard
   # Configurer le rÃ©seau
   # Mettre Ã  jour le systÃ¨me
   sudo apt update && sudo apt upgrade -y
   ```

2. Installer MicroK8s
   ```bash
   sudo snap install microk8s --classic --channel=1.28/stable
   sudo usermod -aG microk8s $USER
   sudo chown -R $USER ~/.kube
   newgrp microk8s
   ```

3. Activer les addons essentiels
   ```bash
   microk8s enable dns storage
   microk8s status --wait-ready
   ```

4. Configurer kubectl
   ```bash
   mkdir -p ~/.kube
   microk8s config > ~/.kube/config
   ```

**Phase 2 - Installation de Velero (15 min)**

1. TÃ©lÃ©charger Velero CLI
   ```bash
   wget https://github.com/vmware-tanzu/velero/releases/download/v1.12.0/velero-v1.12.0-linux-amd64.tar.gz
   tar -xvzf velero-v1.12.0-linux-amd64.tar.gz
   sudo mv velero-v1.12.0-linux-amd64/velero /usr/local/bin/
   ```

2. RÃ©cupÃ©rer le fichier de credentials
   ```bash
   # Depuis la sauvegarde sÃ©curisÃ©e (USB, 1Password, etc.)
   cat > credentials-velero <<EOF
   [default]
   aws_access_key_id = [ACCESS_KEY]
   aws_secret_access_key = [SECRET_KEY]
   EOF
   ```

3. Installer Velero
   ```bash
   velero install \
     --provider aws \
     --plugins velero/velero-plugin-for-aws:v1.8.0 \
     --bucket velero-backups \
     --secret-file ./credentials-velero \
     --use-node-agent \
     --backup-location-config region=minio,s3ForcePathStyle="true",s3Url=http://[MINIO_URL]:9000
   ```

4. VÃ©rifier l'accÃ¨s aux backups
   ```bash
   velero backup get
   ```

**Phase 3 - Restauration (1-2h selon la taille)**

1. Identifier le backup Ã  restaurer
   ```bash
   velero backup get
   # Choisir le plus rÃ©cent en status "Completed"
   ```

2. Restaurer les ressources cluster
   ```bash
   velero restore create full-restore-$(date +%Y%m%d) \
     --from-backup [BACKUP_NAME] \
     --wait
   ```

3. Surveiller la progression
   ```bash
   watch kubectl get pods --all-namespaces
   ```

4. VÃ©rifier les namespaces
   ```bash
   kubectl get namespaces
   ```

5. VÃ©rifier les PVCs
   ```bash
   kubectl get pvc --all-namespaces
   ```

**Phase 4 - VÃ©rification et tests (30 min)**

1. VÃ©rifier chaque application critique
   ```bash
   # Pour chaque application
   kubectl get pods -n [NAMESPACE]
   kubectl logs -n [NAMESPACE] [POD]
   kubectl describe pod -n [NAMESPACE] [POD]
   ```

2. Tester la connectivitÃ©
   ```bash
   # Tester les services
   kubectl get services --all-namespaces

   # Tester les ingress
   kubectl get ingress --all-namespaces
   ```

3. VÃ©rifier les bases de donnÃ©es
   ```bash
   # PostgreSQL
   kubectl exec -n database postgres-0 -- psql -U postgres -c "\l"

   # MySQL
   kubectl exec -n database mysql-0 -- mysql -u root -p[PASSWORD] -e "SHOW DATABASES;"
   ```

4. Tester l'accÃ¨s externe
   ```bash
   # VÃ©rifier DNS
   nslookup myapp.example.com

   # Tester HTTPS
   curl https://myapp.example.com
   ```

**Phase 5 - Remise en production (30 min)**

1. RÃ©activer les addons nÃ©cessaires
   ```bash
   microk8s enable prometheus
   microk8s enable cert-manager
   microk8s enable metallb:[IP_RANGE]
   ```

2. Mettre Ã  jour les DNS si nÃ©cessaire
   ```bash
   # Pointer vers la nouvelle IP
   ```

3. RÃ©activer les sauvegardes automatiques
   ```bash
   velero schedule get
   # VÃ©rifier que les schedules sont actifs
   ```

4. Documentation
   ```bash
   # Noter les changements
   echo "$(date): Restauration complÃ¨te effectuÃ©e depuis backup [BACKUP_NAME]" >> /var/log/drp-history.log
   ```

**Temps total estimÃ©:** 3-4 heures

**Checklist finale:**
- [ ] Tous les namespaces restaurÃ©s
- [ ] Tous les pods running
- [ ] PVCs bound
- [ ] Services accessibles
- [ ] DNS configurÃ©
- [ ] Certificats SSL valides
- [ ] Monitoring actif
- [ ] Backups rÃ©activÃ©s
- [ ] Documentation mise Ã  jour
```

#### ProcÃ©dure 3 : Restauration de base de donnÃ©es

```markdown
## ProcÃ©dure: Restauration d'une base de donnÃ©es

**ScÃ©nario:** Base de donnÃ©es corrompue, suppression accidentelle

**PrÃ©requis:**
- Backup de la base disponible
- AccÃ¨s au cluster
- 30-60 minutes

**Pour PostgreSQL:**

1. Identifier le backup
   ```bash
   velero backup get | grep postgres
   ```

2. Mettre l'application en maintenance
   ```bash
   # Scaler Ã  0 les applications qui utilisent la BDD
   kubectl scale deployment webapp -n production --replicas=0
   ```

3. CrÃ©er un namespace temporaire
   ```bash
   kubectl create namespace postgres-restore
   ```

4. Restaurer PostgreSQL dans le namespace temporaire
   ```bash
   velero restore create postgres-test-restore \
     --from-backup [BACKUP_NAME] \
     --include-namespaces database \
     --namespace-mappings database:postgres-restore \
     --wait
   ```

5. Attendre que PostgreSQL dÃ©marre
   ```bash
   kubectl wait --for=condition=ready pod -l app=postgres -n postgres-restore --timeout=300s
   ```

6. Extraire un dump de la BDD restaurÃ©e
   ```bash
   POD=$(kubectl get pod -l app=postgres -n postgres-restore -o jsonpath='{.items[0].metadata.name}')

   kubectl exec -n postgres-restore $POD -- \
     pg_dump -U postgres mydb > /tmp/restored-db.sql
   ```

7. Restaurer dans la BDD de production
   ```bash
   POD_PROD=$(kubectl get pod -l app=postgres -n database -o jsonpath='{.items[0].metadata.name}')

   # Backup de sÃ©curitÃ©
   kubectl exec -n database $POD_PROD -- \
     pg_dump -U postgres mydb > /tmp/before-restore-backup.sql

   # Drop et recrÃ©er
   kubectl exec -n database $POD_PROD -- \
     psql -U postgres -c "DROP DATABASE mydb;"
   kubectl exec -n database $POD_PROD -- \
     psql -U postgres -c "CREATE DATABASE mydb;"

   # Importer
   cat /tmp/restored-db.sql | \
     kubectl exec -i -n database $POD_PROD -- \
     psql -U postgres mydb
   ```

8. VÃ©rifier les donnÃ©es
   ```bash
   kubectl exec -n database $POD_PROD -- \
     psql -U postgres mydb -c "SELECT COUNT(*) FROM users;"
   ```

9. RedÃ©marrer les applications
   ```bash
   kubectl scale deployment webapp -n production --replicas=3
   ```

10. Nettoyer
    ```bash
    kubectl delete namespace postgres-restore
    ```

**Temps estimÃ©:** 45-60 minutes

**Points d'attention:**
- Toujours faire un backup avant la restauration
- VÃ©rifier l'intÃ©gritÃ© des donnÃ©es aprÃ¨s restauration
- Tester avec une requÃªte sur les donnÃ©es critiques
```

### 6. ScÃ©narios de dÃ©sastre et rÃ©ponses

```markdown
## Matrice des scÃ©narios

| ScÃ©nario | ProbabilitÃ© | Impact | DÃ©tection | Temps de rÃ©ponse | ProcÃ©dure |
|----------|-------------|--------|-----------|------------------|-----------|
| Pod crashe | Haute | Faible | Automatique | ImmÃ©diat | Auto-restart |
| Node down | Moyenne | Moyen | Monitoring | 5 min | Proc. 1 |
| Serveur HS | Faible | Ã‰levÃ© | Manuel | 15 min | Proc. 2 |
| Corruption BDD | Faible | Ã‰levÃ© | Application | 30 min | Proc. 3 |
| Disque plein | Moyenne | Moyen | Monitoring | 15 min | Proc. 4 |
| Ransomware | TrÃ¨s faible | Critique | Manuel | Variable | Proc. 5 |
| Incendie | TrÃ¨s faible | Critique | Manuel | Variable | Proc. 6 |

### Arbre de dÃ©cision

```
PROBLÃˆME DÃ‰TECTÃ‰
    â”‚
    â”œâ”€ Application spÃ©cifique down?
    â”‚   â”œâ”€ OUI â†’ Proc. 1: Restauration app
    â”‚   â””â”€ NON â†’ Continuer
    â”‚
    â”œâ”€ Node accessible?
    â”‚   â”œâ”€ NON â†’ Proc. 2: Restauration complÃ¨te
    â”‚   â””â”€ OUI â†’ Continuer
    â”‚
    â”œâ”€ Base de donnÃ©es affectÃ©e?
    â”‚   â”œâ”€ OUI â†’ Proc. 3: Restauration BDD
    â”‚   â””â”€ NON â†’ Continuer
    â”‚
    â”œâ”€ Espace disque critique?
    â”‚   â”œâ”€ OUI â†’ Proc. 4: LibÃ©ration espace
    â”‚   â””â”€ NON â†’ Continuer
    â”‚
    â””â”€ Cause inconnue?
        â””â”€ Investigation approfondie
```
```

### 7. Tests et maintenance du DRP

```markdown
## Planning de tests

### Tests mensuels (1er de chaque mois)

**Test de validation des backups (30 min):**
- VÃ©rifier tous les backups du mois
- Confirmer leur statut "Completed"
- VÃ©rifier la taille (cohÃ©rence)
- Tester l'accÃ¨s au stockage

**Test de restauration partielle (1h):**
- Restaurer une application non-critique
- VÃ©rifier le fonctionnement
- Documenter le temps
- Noter les problÃ¨mes

### Tests trimestriels (15 de mars, juin, sept, dÃ©c)

**Test de restauration complÃ¨te (4h):**
- Restaurer le cluster entier sur VM de test
- Valider toutes les applications
- Mesurer RTO rÃ©el
- Mettre Ã  jour la documentation

**Drill de disaster recovery (2h):**
- Simulation sans prÃ©avis
- Chaque membre de l'Ã©quipe participe
- ChronomÃ©trer chaque Ã©tape
- DÃ©briefing et amÃ©lioration

### Tests annuels (Janvier)

**Audit complet (1 journÃ©e):**
- Revue complÃ¨te du DRP
- Test de tous les scÃ©narios
- Mise Ã  jour de tous les contacts
- Formation/recyclage Ã©quipe
- Validation avec stakeholders

### Maintenance continue

**AprÃ¨s chaque changement majeur:**
- Mise Ã  jour du DRP
- Test de la nouvelle configuration
- Communication Ã  l'Ã©quipe

**Hebdomadaire:**
- VÃ©rification automatique des backups
- Revue des alertes

**Documentation:**
- Journal des tests dans `drp-test-log.md`
- Rapport aprÃ¨s chaque test
- Actions correctives suivies
```

### 8. Contacts et escalade

```markdown
## Contacts d'urgence

### Niveau 1 - Premier contact

**Admin systÃ¨me principal:**
- Nom: Jean Dupont
- Email: jean.dupont@example.com
- TÃ©lÃ©phone: +33 6 12 34 56 78
- DisponibilitÃ©: 24/7
- ResponsabilitÃ©s: Toutes opÃ©rations DRP

### Niveau 2 - Escalade

**Admin backup:**
- Nom: Marie Martin
- Email: marie.martin@example.com
- TÃ©lÃ©phone: +33 6 98 76 54 32
- DisponibilitÃ©: Heures ouvrables + astreinte
- ResponsabilitÃ©s: Velero, stockage, backups

**DÃ©veloppeur lead:**
- Nom: Pierre Durand
- Email: pierre.durand@example.com
- TÃ©lÃ©phone: +33 6 11 22 33 44
- DisponibilitÃ©: Heures ouvrables
- ResponsabilitÃ©s: Applications, bases de donnÃ©es

### Niveau 3 - Support externe

**Support hÃ©bergeur:**
- Contact: support@hosting-provider.com
- TÃ©lÃ©phone: 01 23 45 67 89
- Contrat: #123456
- DisponibilitÃ©: 24/7

**Consultant Kubernetes:**
- Contact: expert@k8s-consulting.com
- TÃ©lÃ©phone: +33 6 55 66 77 88
- Tarif: 200â‚¬/h
- DisponibilitÃ©: Sur demande

### ProcÃ©dure d'escalade

```
Incident dÃ©tectÃ©
    â†“
Niveau 1 notifiÃ© immÃ©diatement
    â†“
Si pas de rÃ©ponse en 15 min
    â†“
Niveau 2 notifiÃ©
    â†“
Si problÃ¨me non rÃ©solu en 2h
    â†“
Niveau 3 contactÃ©
    â†“
Communication aux stakeholders
```

### Communication

**Stakeholders Ã  informer:**
- Direction: direction@example.com
- Utilisateurs: via page status.example.com
- Ã‰quipe technique: Slack #incidents

**Templates de communication:**

**Incident dÃ©tectÃ©:**
```
INCIDENT - [Niveau] - [Timestamp]
Service affectÃ©: [Nom]
Impact: [Description]
Actions en cours: [Liste]
Temps estimÃ© de rÃ©solution: [DurÃ©e]
Prochaine mise Ã  jour: [Timestamp]
```

**Incident rÃ©solu:**
```
RÃ‰SOLU - [Timestamp]
Service: [Nom]
DurÃ©e du downtime: [DurÃ©e]
Cause: [Description]
Actions prises: [Liste]
PrÃ©vention: [Mesures]
Post-mortem: [Date]
```
```

### 9. Outils et ressources

```markdown
## Outils nÃ©cessaires

### Logiciels requis

- **kubectl**: Client Kubernetes
  - Installation: `snap install kubectl --classic`
  - Config: `~/.kube/config`

- **velero**: CLI de backup
  - Installation: Voir section 22.2
  - Config: credentials dans `/root/.velero/`

- **yq**: Manipulation YAML
  - Installation: `snap install yq`

- **jq**: Manipulation JSON
  - Installation: `apt install jq`

### AccÃ¨s critiques

**Serveur principal:**
```bash
ssh admin@server.example.com
# ClÃ© SSH: ~/.ssh/microk8s_prod
```

**MinIO (stockage backups):**
```bash
URL: http://minio.example.com:9000
User: minio-admin
Pass: [Voir 1Password]
```

**Cloud S3:**
```bash
Region: eu-west-1
Bucket: microk8s-backups
Access Key: [Voir 1Password]
```

### Documentation de rÃ©fÃ©rence

**Interne:**
- Architecture: `docs/architecture.md`
- Runbooks: `docs/runbooks/`
- Configurations: `git@github.com:user/k8s-configs.git`

**Externe:**
- MicroK8s: https://microk8s.io/docs
- Velero: https://velero.io/docs
- Kubernetes: https://kubernetes.io/docs

### Ã‰quipements

**Disques de secours:**
- USB 1TB: Backups mensuels offline
- Emplacement: Coffre-fort bureau
- DerniÃ¨re mise Ã  jour: [Date]

**Machine de spare:**
- Dell OptiPlex 7080
- Emplacement: Armoire serveur
- Ã‰tat: PrÃªt Ã  l'emploi, OS prÃ©installÃ©
```

## CrÃ©ation de votre DRP

Maintenant que vous comprenez la structure, crÃ©ons votre DRP Ã©tape par Ã©tape.

### Ã‰tape 1 : Analyse de risques

Identifiez vos risques spÃ©cifiques :

```markdown
## Analyse de risques - Mon cluster MicroK8s

| Risque | ProbabilitÃ© | Impact | Mitigation actuelle | Ã€ amÃ©liorer |
|--------|-------------|--------|---------------------|-------------|
| Panne disque | Moyenne | Ã‰levÃ© | Backups quotidiens | RAID |
| Erreur humaine | Haute | Moyen | Git pour configs | Formation |
| Coupure Ã©lectrique | Moyenne | Ã‰levÃ© | Aucune | UPS |
| Ransomware | Faible | Critique | Backups offline | 2FA |
| Mise Ã  jour ratÃ©e | Moyenne | Moyen | Backup avant MAJ | Tests staging |
```

### Ã‰tape 2 : DÃ©finir RPO/RTO par application

```markdown
## Objectifs de rÃ©cupÃ©ration

| Application | Type | CriticitÃ© | RPO | RTO | Justification |
|-------------|------|-----------|-----|-----|---------------|
| Blog WordPress | Web | Moyenne | 24h | 8h | Trafic modÃ©rÃ©, pas de transactions |
| GitLab | Dev | Haute | 2h | 4h | Code source critique |
| PostgreSQL prod | BDD | Critique | 1h | 2h | DonnÃ©es business importantes |
| Prometheus | Monitoring | Faible | 24h | 24h | MÃ©triques reconstituables |
| Jenkins | CI/CD | Moyenne | 4h | 8h | Pipelines rejouables |
```

### Ã‰tape 3 : Documenter l'existant

```bash
#!/bin/bash
# document-current-state.sh

cat > drp-inventory-$(date +%Y%m%d).md <<EOF
# Inventaire du cluster - $(date)

## Namespaces
\`\`\`
$(kubectl get namespaces)
\`\`\`

## Applications par namespace
$(for ns in $(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}' | tr ' ' '\n' | grep -v 'kube-\|default'); do
  echo "### Namespace: $ns"
  echo "\`\`\`"
  kubectl get all -n $ns
  echo "\`\`\`"
  echo ""
done)

## Volumes persistants
\`\`\`
$(kubectl get pv,pvc --all-namespaces)
\`\`\`

## Ingress
\`\`\`
$(kubectl get ingress --all-namespaces)
\`\`\`

## Configuration Velero
\`\`\`
$(velero backup-location get)
$(velero schedule get)
\`\`\`

EOF

echo "Inventaire crÃ©Ã©: drp-inventory-$(date +%Y%m%d).md"
```

### Ã‰tape 4 : RÃ©diger les procÃ©dures

Utilisez ce template pour chaque procÃ©dure :

```markdown
## ProcÃ©dure: [Nom]

**DÃ©clencheurs:**
- [Condition 1]
- [Condition 2]

**PrÃ©requis:**
- [ ] [Ressource 1]
- [ ] [Ressource 2]
- [ ] [AccÃ¨s nÃ©cessaire]

**Temps estimÃ©:** [DurÃ©e]

**Ã‰tapes dÃ©taillÃ©es:**

### Ã‰tape 1: [Nom]
**Action:**
```bash
[commande]
```

**RÃ©sultat attendu:**
```
[sortie attendue]
```

**Si Ã©chec:**
- [Action corrective]

### Ã‰tape 2: [Nom]
[...]

**VÃ©rification finale:**
- [ ] [Check 1]
- [ ] [Check 2]

**Rollback si Ã©chec:**
[ProcÃ©dure de retour arriÃ¨re]
```

### Ã‰tape 5 : Tester et affiner

```bash
#!/bin/bash
# test-drp.sh

echo "=== Test du DRP - $(date) ==="

# 1. Test de validation backup
echo "1. Validation des backups..."
./scripts/validate-backups.sh
if [ $? -ne 0 ]; then
  echo "âŒ Ã‰chec validation backups"
  exit 1
fi

# 2. Test de restauration partielle
echo "2. Test de restauration..."
./scripts/test-restore.sh
if [ $? -ne 0 ]; then
  echo "âŒ Ã‰chec test restauration"
  exit 1
fi

# 3. GÃ©nÃ©rer le rapport
./scripts/generate-drp-report.sh

echo "âœ“ Test DRP terminÃ©"
```

## Automatisation du DRP

Certaines parties du DRP peuvent Ãªtre automatisÃ©es pour gagner du temps.

### Scripts d'aide Ã  la dÃ©cision

```bash
#!/bin/bash
# drp-assistant.sh - Assistant interactif DRP

echo "=== Assistant DRP ==="
echo "Quel est le problÃ¨me rencontrÃ© ?"
echo ""
echo "1) Une application ne rÃ©pond plus"
echo "2) Le serveur est inaccessible"
echo "3) Une base de donnÃ©es est corrompue"
echo "4) Perte de donnÃ©es (suppression accidentelle)"
echo "5) Le cluster entier est down"
echo "6) Autre / Je ne sais pas"
echo ""

read -p "Choix (1-6): " CHOICE

case $CHOICE in
  1)
    echo ""
    echo "â†’ ProcÃ©dure recommandÃ©e: Restauration d'application"
    echo "   Fichier: procedures/restore-single-app.md"
    echo ""
    read -p "Quelle application? " APP
    echo "Backup le plus rÃ©cent pour $APP:"
    velero backup get | grep $APP | head -5
    echo ""
    read -p "Lancer la procÃ©dure? (y/n) " CONFIRM
    if [ "$CONFIRM" = "y" ]; then
      ./procedures/restore-single-app.sh $APP
    fi
    ;;

  2)
    echo ""
    echo "â†’ SITUATION CRITIQUE"
    echo "   ProcÃ©dure: Restauration complÃ¨te"
    echo "   Temps estimÃ©: 3-4 heures"
    echo "   Fichier: procedures/full-cluster-restore.md"
    echo ""
    echo "Contacts d'urgence:"
    cat contacts.txt
    echo ""
    echo "Ã‰tapes initiales:"
    echo "1. PrÃ©parer nouveau serveur"
    echo "2. Installer MicroK8s"
    echo "3. Installer Velero"
    echo "4. Lancer restauration"
    ;;

  3)
    echo ""
    echo "â†’ ProcÃ©dure recommandÃ©e: Restauration BDD"
    echo "   Fichier: procedures/restore-database.md"
    echo ""
    read -p "Quelle BDD? (postgres/mysql/mongodb) " DB
    ./procedures/restore-database.sh $DB
    ;;

  4)
    echo ""
    echo "â†’ Deux options:"
    echo "   A) Restaurer depuis backup rÃ©cent"
    echo "   B) RÃ©cupÃ©rer fichiers spÃ©cifiques"
    echo ""
    read -p "Choix (A/B): " OPTION
    if [ "$OPTION" = "A" ]; then
      velero backup get
    else
      ./procedures/recover-specific-files.sh
    fi
    ;;

  5)
    echo ""
    echo "â†’ URGENCE MAXIMALE"
    echo "   RTO: 2-4 heures"
    echo "   Contacter immÃ©diatement:"
    cat contacts.txt | head -5
    echo ""
    echo "ProcÃ©dure: procedures/disaster-recovery-full.md"
    ;;

  6)
    echo ""
    echo "â†’ Diagnostic nÃ©cessaire"
    echo "   ExÃ©cution des vÃ©rifications..."
    ./scripts/diagnose.sh
    ;;
esac
```

### Monitoring et alertes

```yaml
# alertmanager-drp-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-drp
  namespace: monitoring
data:
  alertmanager.yml: |
    route:
      receiver: 'drp-team'
      routes:
      - match:
          severity: critical
        receiver: 'drp-escalation'

    receivers:
    - name: 'drp-team'
      email_configs:
      - to: 'team@example.com'
        send_resolved: true

    - name: 'drp-escalation'
      email_configs:
      - to: 'oncall@example.com'
        headers:
          Priority: urgent
      webhook_configs:
      - url: 'https://hooks.slack.com/services/YOUR/WEBHOOK'
```

### Dashboards de santÃ©

```yaml
# grafana-drp-dashboard.json
{
  "dashboard": {
    "title": "DRP Health Status",
    "panels": [
      {
        "title": "Backup Success Rate",
        "targets": [{
          "expr": "sum(velero_backup_success_total) / sum(velero_backup_total) * 100"
        }]
      },
      {
        "title": "Time Since Last Backup",
        "targets": [{
          "expr": "(time() - velero_backup_last_successful_timestamp{schedule=\"daily\"}) / 3600"
        }]
      },
      {
        "title": "Backup Size Trend",
        "targets": [{
          "expr": "velero_backup_size_bytes"
        }]
      },
      {
        "title": "RTO Simulation",
        "targets": [{
          "expr": "avg(velero_restore_duration_seconds)"
        }]
      }
    ]
  }
}
```

## AmÃ©lioration continue

Un DRP n'est jamais terminÃ©. Il doit Ã©voluer constamment.

### Processus d'amÃ©lioration

```markdown
## Cycle d'amÃ©lioration continue

1. **Test** â†’ Identifier les faiblesses
2. **Analyse** â†’ Comprendre les causes
3. **Correction** â†’ AmÃ©liorer le DRP
4. **Documentation** â†’ Mettre Ã  jour les procÃ©dures
5. **Formation** â†’ Partager les learnings
6. **Retour au test** â†’ Valider les amÃ©liorations
```

### Post-mortem aprÃ¨s incident

```markdown
# Template Post-Mortem

**Incident:** [Description courte]
**Date:** [Date]
**DurÃ©e:** [DurÃ©e totale]
**Impact:** [Description impact]

## Chronologie

| Heure | Ã‰vÃ©nement |
|-------|-----------|
| 14:00 | Incident dÃ©tectÃ© |
| 14:05 | Ã‰quipe notifiÃ©e |
| 14:15 | Diagnostic dÃ©marrÃ© |
| 14:30 | Restauration lancÃ©e |
| 16:00 | Service restaurÃ© |
| 16:30 | Validation complÃ¨te |

## Cause racine

[Description dÃ©taillÃ©e de la cause]

## Ce qui a bien fonctionnÃ©

- [Point 1]
- [Point 2]

## Ce qui n'a pas fonctionnÃ©

- [Point 1] â†’ Action: [Solution]
- [Point 2] â†’ Action: [Solution]

## Actions correctives

| Action | Responsable | Date cible | Status |
|--------|-------------|------------|--------|
| [Action 1] | [Nom] | [Date] | [ ] |
| [Action 2] | [Nom] | [Date] | [ ] |

## Mises Ã  jour du DRP

- [ ] ProcÃ©dure X mise Ã  jour
- [ ] Contact Y ajoutÃ©
- [ ] Script Z crÃ©Ã©

**Prochaine revue:** [Date]
```

### MÃ©triques de performance du DRP

```bash
#!/bin/bash
# drp-metrics.sh

cat > drp-metrics-$(date +%Y%m).md <<EOF
# MÃ©triques DRP - $(date +%B\ %Y)

## Indicateurs clÃ©s

**Backups:**
- Total effectuÃ©s: $(velero backup get | wc -l)
- Taux de rÃ©ussite: $(echo "scale=2; $(velero backup get | grep Completed | wc -l) * 100 / $(velero backup get | wc -l)" | bc)%
- Taille moyenne: $(velero backup get -o json | jq '[.items[].status.backupSizeBytes] | add / length / 1024 / 1024 / 1024' | xargs printf "%.2f GB\n")

**Tests:**
- Tests effectuÃ©s: $(cat drp-test-log.csv | grep $(date +%Y-%m) | wc -l)
- Tests rÃ©ussis: $(cat drp-test-log.csv | grep $(date +%Y-%m) | grep Pass | wc -l)
- RTO moyen: $(cat drp-test-log.csv | grep $(date +%Y-%m) | awk -F',' '{sum+=$4; n++} END {print sum/n}') min

**Incidents:**
- Incidents: $(cat incident-log.csv | grep $(date +%Y-%m) | wc -l)
- DRP activÃ©: $(cat incident-log.csv | grep $(date +%Y-%m) | grep "DRP activated" | wc -l)
- Temps moyen de rÃ©solution: [Ã€ calculer]

## Objectifs vs RÃ©alisÃ©

| MÃ©trique | Objectif | RÃ©alisÃ© | Status |
|----------|----------|---------|--------|
| RPO | 4h | [CalculÃ©] | [âœ“/âœ—] |
| RTO | 8h | [MesurÃ©] | [âœ“/âœ—] |
| Tests/mois | 2 | $(cat drp-test-log.csv | grep $(date +%Y-%m) | wc -l) | [âœ“/âœ—] |
| Taux rÃ©ussite backups | 98% | [CalculÃ©] | [âœ“/âœ—] |

## Recommandations

- [Recommandation 1]
- [Recommandation 2]

EOF
```

## Checklist de mise en Å“uvre

Pour crÃ©er et maintenir votre DRP :

```markdown
## Phase 1 : CrÃ©ation (1-2 semaines)

- [ ] Analyser les risques spÃ©cifiques
- [ ] DÃ©finir RPO/RTO pour chaque application
- [ ] Documenter l'architecture actuelle
- [ ] Inventorier toutes les ressources
- [ ] Lister les dÃ©pendances
- [ ] Identifier les contacts clÃ©s
- [ ] RÃ©diger les procÃ©dures principales
- [ ] CrÃ©er les scripts d'automatisation
- [ ] PrÃ©parer les templates

## Phase 2 : Validation (1 semaine)

- [ ] Relecture par l'Ã©quipe
- [ ] Test des procÃ©dures critiques
- [ ] Validation des accÃ¨s et credentials
- [ ] VÃ©rification des backups
- [ ] Test de restauration partielle
- [ ] Corrections et ajustements

## Phase 3 : DÃ©ploiement (1 semaine)

- [ ] Formation de l'Ã©quipe
- [ ] Distribution du DRP
- [ ] Configuration des alertes
- [ ] Mise en place du monitoring
- [ ] Communication aux stakeholders
- [ ] Premier test grandeur nature

## Phase 4 : Maintenance continue

**Mensuel:**
- [ ] Test de validation
- [ ] Revue des mÃ©triques
- [ ] Mise Ã  jour si nÃ©cessaire

**Trimestriel:**
- [ ] Test de restauration complÃ¨te
- [ ] Drill d'Ã©quipe
- [ ] Revue approfondie du document

**Annuel:**
- [ ] Audit complet
- [ ] RÃ©vision des RPO/RTO
- [ ] Formation/recyclage
- [ ] Mise Ã  jour majeure
```

## Conclusion

Un Plan de Reprise d'ActivitÃ© solide est votre meilleure assurance contre les dÃ©sastres. C'est la diffÃ©rence entre quelques heures de downtime organisÃ© et plusieurs jours de panique et de perte de donnÃ©es.

### Les piliers d'un bon DRP

âœ… **Complet** : Couvre tous les scÃ©narios de disaster
âœ… **Clair** : ProcÃ©dures Ã©tape par Ã©tape, sans ambiguÃ¯tÃ©
âœ… **TestÃ©** : ValidÃ© rÃ©guliÃ¨rement en conditions rÃ©elles
âœ… **Accessible** : Disponible mÃªme si le cluster est down
âœ… **Ã€ jour** : Maintenu Ã  jour avec l'infrastructure
âœ… **PartagÃ©** : Connu et compris par toute l'Ã©quipe

### Erreurs Ã  Ã©viter

âŒ **DRP thÃ©orique jamais testÃ©** : DÃ©couvrir qu'il ne fonctionne pas pendant un vrai incident
âŒ **Documentation obsolÃ¨te** : ProcÃ©dures qui ne correspondent plus Ã  la rÃ©alitÃ©
âŒ **Une seule personne sait** : Point de dÃ©faillance unique
âŒ **Pas de maintenance** : Le DRP n'Ã©volue pas avec l'infra
âŒ **Trop complexe** : Impossible Ã  suivre sous stress
âŒ **StockÃ© uniquement en ligne** : Inaccessible quand on en a besoin

### Vos premiers pas

Si vous n'avez pas encore de DRP :

1. **Commencez simple** : Document Word de 5 pages avec les procÃ©dures essentielles
2. **Testez-le rapidement** : Validation de base dans la semaine
3. **ItÃ©rez** : AmÃ©liorez aprÃ¨s chaque test
4. **Partagez** : Mettez-le sur Google Drive, GitHub, USB

Si vous avez dÃ©jÃ  un DRP :

1. **Testez-le maintenant** : Trouvez les failles avant qu'elles ne comptent
2. **Mettez-le Ã  jour** : ReflÃ¨te-t-il vraiment votre infra actuelle ?
3. **Automatisez** : Scripts pour gagner du temps
4. **Formez** : Tout le monde doit savoir

### La rÃ¨gle d'or

**Le meilleur moment pour crÃ©er/tester votre DRP Ã©tait hier.
Le deuxiÃ¨me meilleur moment est maintenant.**

N'attendez pas le dÃ©sastre pour rÃ©aliser que vous n'Ãªtes pas prÃ©parÃ©.

---

**Checklist finale DRP** :

- [ ] DRP Ã©crit et structurÃ©
- [ ] ProcÃ©dures dÃ©taillÃ©es pour chaque scÃ©nario
- [ ] RPO/RTO dÃ©finis et documentÃ©s
- [ ] Contacts d'urgence Ã  jour
- [ ] AccÃ¨s et credentials documentÃ©s
- [ ] Scripts d'automatisation crÃ©Ã©s
- [ ] Premier test effectuÃ©
- [ ] Ã‰quipe formÃ©e
- [ ] Planning de maintenance Ã©tabli
- [ ] Backups offsite configurÃ©s
- [ ] Monitoring et alertes en place
- [ ] Post-mortem template prÃªt

**N'oubliez jamais : Le but du DRP n'est pas d'empÃªcher les dÃ©sastres, mais de s'assurer que vous pouvez vous en remettre rapidement et efficacement.**

â­ï¸ [Automatisation des sauvegardes](/22-sauvegarde-et-restauration/08-automatisation-des-sauvegardes.md)
