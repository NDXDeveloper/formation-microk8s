ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 25.6 Machine Learning sur Kubernetes

## Introduction : Machine Learning et Kubernetes, pourquoi ?

### Qu'est-ce que le Machine Learning ?

Le **Machine Learning** (apprentissage automatique) est une branche de l'intelligence artificielle oÃ¹ les ordinateurs "apprennent" Ã  partir de donnÃ©es sans Ãªtre explicitement programmÃ©s pour chaque tÃ¢che.

**Analogie simple** :
```
Programmation traditionnelle :
  Si tempÃ©rature > 30Â°C â†’ Allumer climatisation
  (RÃ¨gle Ã©crite par un humain)

Machine Learning :
  Donner 1000 exemples de tempÃ©ratures et actions
  â†’ Le modÃ¨le apprend tout seul Ã  dÃ©cider
  â†’ Peut s'adapter Ã  de nouveaux cas
```

**Exemples concrets** :
- Reconnaissance d'images (dÃ©tection de visages, objets)
- Traduction automatique
- Recommandations (Netflix, Spotify)
- DÃ©tection de fraude bancaire
- Maintenance prÃ©dictive (prÃ©voir les pannes)
- Assistant vocal (Siri, Alexa)

### Le cycle de vie d'un projet ML

Un projet de Machine Learning n'est pas juste "entraÃ®ner un modÃ¨le", c'est un **pipeline complet** :

```
1. Collecte de donnÃ©es
   â†“
2. PrÃ©paration et nettoyage (Feature Engineering)
   â†“
3. EntraÃ®nement du modÃ¨le (Training)
   â†“
4. Ã‰valuation et validation
   â†“
5. DÃ©ploiement en production (Serving)
   â†“
6. Monitoring des performances
   â†“
7. RÃ©-entraÃ®nement pÃ©riodique
   (retour Ã  l'Ã©tape 1)
```

Chaque Ã©tape peut nÃ©cessiter :
- **Des ressources diffÃ©rentes** (CPU, GPU, mÃ©moire)
- **Des outils diffÃ©rents** (Python, Jupyter, TensorFlow, PyTorch)
- **Du scaling** (entraÃ®nement sur plusieurs GPU)

C'est lÃ  que **Kubernetes entre en jeu** !

### Pourquoi Kubernetes pour le Machine Learning ?

#### ProblÃ¨mes sans Kubernetes

```
Data Scientist 1 : "J'ai besoin d'un serveur GPU pour 2h"
Admin : "DÃ©solÃ©, tous pris"

Data Scientist 2 : "Mon entraÃ®nement a plantÃ© aprÃ¨s 5h"
Admin : "Il faut tout recommencer"

Data Scientist 3 : "Mon modÃ¨le fonctionne sur mon laptop mais pas en prod"
Admin : "Dependencies diffÃ©rentes..."

Data Scientist 4 : "Je veux comparer 10 configurations"
Admin : "Ã‡a va prendre 20 jours en sÃ©quentiel"
```

#### Solutions avec Kubernetes

**âœ… Partage de ressources** :
```yaml
# Data Scientist 1 demande un GPU pour 2h
apiVersion: batch/v1
kind: Job
metadata:
  name: training-job-1
spec:
  template:
    spec:
      containers:
      - name: training
        resources:
          limits:
            nvidia.com/gpu: 1
      restartPolicy: Never
  backoffLimit: 3
  ttlSecondsAfterFinished: 7200  # Nettoie aprÃ¨s 2h
```

Les ressources sont libÃ©rÃ©es automatiquement !

**âœ… RÃ©silience et retry** :
```yaml
spec:
  backoffLimit: 3  # RÃ©essaye automatiquement 3 fois
  activeDeadlineSeconds: 18000  # Timeout aprÃ¨s 5h
```

**âœ… ReproductibilitÃ©** :
```yaml
containers:
- name: training
  image: myml/training:v1.2.3  # Image Docker versionnÃ©e
  env:
  - name: RANDOM_SEED
    value: "42"  # RÃ©sultats reproductibles
```

**âœ… ParallÃ©lisation** :
```yaml
# Lancer 10 entraÃ®nements en parallÃ¨le
apiVersion: batch/v1
kind: Job
metadata:
  name: hyperparameter-tuning
spec:
  parallelism: 10  # 10 configurations en mÃªme temps
  completions: 10
```

## Architecture ML sur Kubernetes

### Les trois phases principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 1 : TRAINING                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Data Prep   â”‚ â†’  â”‚   Training   â”‚ â†’  â”‚  Model   â”‚   â”‚
â”‚  â”‚  (CPU)       â”‚    â”‚   (GPU)      â”‚    â”‚  Storage â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 2 : SERVING                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Model      â”‚ â†’  â”‚  Inference   â”‚ â†’  â”‚  API     â”‚   â”‚
â”‚  â”‚   Loading    â”‚    â”‚  Server      â”‚    â”‚  Gateway â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PHASE 3 : MONITORING                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Prediction  â”‚ â†’  â”‚  Model       â”‚ â†’  â”‚ Retrain  â”‚   â”‚
â”‚  â”‚  Logging     â”‚    â”‚  Drift Alert â”‚    â”‚ Trigger  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants typiques

#### 1. Notebooks interactifs (Jupyter)

Les data scientists adorent Jupyter pour explorer les donnÃ©es :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jupyter-notebook
spec:
  replicas: 1
  selector:
    matchLabels:
      app: jupyter
  template:
    metadata:
      labels:
        app: jupyter
    spec:
      containers:
      - name: jupyter
        image: jupyter/tensorflow-notebook:latest
        ports:
        - containerPort: 8888
        env:
        - name: JUPYTER_ENABLE_LAB
          value: "yes"
        volumeMounts:
        - name: notebooks
          mountPath: /home/jovyan/work
        - name: datasets
          mountPath: /data
      volumes:
      - name: notebooks
        persistentVolumeClaim:
          claimName: jupyter-notebooks
      - name: datasets
        persistentVolumeClaim:
          claimName: shared-datasets
```

#### 2. Jobs d'entraÃ®nement

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: train-image-classifier
spec:
  template:
    spec:
      containers:
      - name: trainer
        image: myml/image-classifier-train:v1
        command: ["python", "train.py"]
        args:
        - "--epochs=100"
        - "--batch-size=32"
        - "--learning-rate=0.001"
        resources:
          limits:
            nvidia.com/gpu: 1
            memory: "16Gi"
          requests:
            memory: "8Gi"
            cpu: "4"
        volumeMounts:
        - name: dataset
          mountPath: /data
        - name: models
          mountPath: /models
      restartPolicy: OnFailure
      volumes:
      - name: dataset
        persistentVolumeClaim:
          claimName: training-dataset
      - name: models
        persistentVolumeClaim:
          claimName: model-storage
```

#### 3. Inference Server

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-inference
spec:
  replicas: 3
  selector:
    matchLabels:
      app: inference
  template:
    spec:
      containers:
      - name: server
        image: tensorflow/serving:latest
        ports:
        - containerPort: 8501
        env:
        - name: MODEL_NAME
          value: "image_classifier"
        volumeMounts:
        - name: models
          mountPath: /models
          readOnly: true
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: model-storage
---
apiVersion: v1
kind: Service
metadata:
  name: inference-service
spec:
  type: LoadBalancer
  selector:
    app: inference
  ports:
  - port: 80
    targetPort: 8501
```

## GPU sur Kubernetes

### Pourquoi les GPU pour le ML ?

Les **GPU (Graphics Processing Units)** sont essentiels pour le Deep Learning car ils excellent dans les calculs parallÃ¨les.

**Analogie** :
```
CPU : 1 ouvrier trÃ¨s qualifiÃ© et rapide
  â†’ Parfait pour des tÃ¢ches complexes sÃ©quentielles

GPU : 1000 ouvriers moyennement qualifiÃ©s travaillant ensemble
  â†’ Parfait pour des tÃ¢ches rÃ©pÃ©titives en parallÃ¨le (matrices)
```

**Performance** :
- EntraÃ®nement d'un modÃ¨le sur CPU : 10 jours
- MÃªme modÃ¨le sur GPU : 10 heures
- MÃªme modÃ¨le sur 8 GPU : 2 heures

### Support GPU dans Kubernetes

#### Installation du NVIDIA Device Plugin

```bash
# Sur votre cluster MicroK8s avec GPU NVIDIA
kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.14.0/nvidia-device-plugin.yml

# VÃ©rifier que les GPU sont dÃ©tectÃ©s
kubectl get nodes -o json | jq '.items[].status.capacity'

# Vous devriez voir :
# "nvidia.com/gpu": "1"  (ou le nombre de GPU disponibles)
```

#### Utiliser un GPU dans un Pod

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: gpu-test
spec:
  containers:
  - name: cuda-test
    image: nvidia/cuda:11.8.0-base-ubuntu22.04
    command: ["nvidia-smi"]
    resources:
      limits:
        nvidia.com/gpu: 1  # Demander 1 GPU
```

#### Partage de GPU (MIG - Multi-Instance GPU)

Les GPU modernes (NVIDIA A100, H100) peuvent Ãªtre partitionnÃ©s :

```yaml
resources:
  limits:
    nvidia.com/gpu: 1
    nvidia.com/mig-1g.10gb: 1  # 1/7 d'un A100
```

Cela permet Ã  plusieurs petits jobs de partager un GPU coÃ»teux.

### Scheduler intelligent pour GPU

**Time-slicing** : Partager un GPU entre plusieurs Pods :

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: time-slicing-config
  namespace: gpu-operator
data:
  any: |-
    version: v1
    sharing:
      timeSlicing:
        replicas: 4  # 4 Pods peuvent partager 1 GPU
```

## Kubeflow : La plateforme ML sur Kubernetes

### Qu'est-ce que Kubeflow ?

**Kubeflow** est une plateforme complÃ¨te pour dÃ©ployer des workflows de Machine Learning sur Kubernetes. C'est le "standard" pour ML sur K8s.

```
Kubeflow = Jupyter + Pipelines + Training + Serving + Monitoring
```

### Architecture Kubeflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Kubeflow Dashboard (UI)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                  â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚ Notebooks  â”‚  â”‚   Pipelines     â”‚  â”‚  Training  â”‚
â”‚ (Jupyter)  â”‚  â”‚   (Argo/Tekton) â”‚  â”‚  Operators â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                  â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚  Serving   â”‚  â”‚   AutoML/       â”‚  â”‚ Monitoring â”‚
â”‚  (KServe)  â”‚  â”‚   Katib         â”‚  â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Installation de Kubeflow

#### Option 1 : Installation complÃ¨te (lourd)

```bash
# PrÃ©requis : Cluster K8s avec 32 GB RAM minimum
# Installer kustomize
curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh" | bash

# Clone Kubeflow manifests
git clone https://github.com/kubeflow/manifests.git
cd manifests

# Installer tout
while ! kustomize build example | kubectl apply -f -; do echo "Retrying to apply resources"; sleep 10; done

# Attendre que tout soit prÃªt (peut prendre 10-20 minutes)
kubectl wait --for=condition=Ready pods --all -n kubeflow --timeout=600s
```

#### Option 2 : MiniKF (pour lab/test)

```bash
# Version lÃ©gÃ¨re de Kubeflow pour tester
vagrant init arrikto/minikf
vagrant up
```

#### Option 3 : Composants individuels (recommandÃ© pour dÃ©buter)

Installer uniquement ce dont vous avez besoin :

```bash
# 1. Notebooks Jupyter uniquement
kubectl apply -k "github.com/kubeflow/kubeflow/components/notebook-controller/config/overlays/kubeflow?ref=v1.8.0"

# 2. KServe pour le serving
kubectl apply -f https://github.com/kserve/kserve/releases/download/v0.11.0/kserve.yaml

# 3. Katib pour hyperparameter tuning
kubectl apply -k "github.com/kubeflow/katib/manifests/v1beta1/installs/katib-standalone?ref=v0.16.0"
```

### Kubeflow Notebooks

Interface web pour crÃ©er et gÃ©rer des Jupyter Notebooks :

```yaml
apiVersion: kubeflow.org/v1
kind: Notebook
metadata:
  name: my-ml-notebook
  namespace: kubeflow-user
spec:
  template:
    spec:
      containers:
      - name: notebook
        image: kubeflownotebookswg/jupyter-tensorflow-cuda:v1.8.0
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
          limits:
            nvidia.com/gpu: 1
        volumeMounts:
        - name: workspace
          mountPath: /home/jovyan
      volumes:
      - name: workspace
        persistentVolumeClaim:
          claimName: my-workspace
```

AccÃ¨s via : `http://kubeflow.example.com/notebook/kubeflow-user/my-ml-notebook`

### Kubeflow Pipelines

DÃ©finir des workflows ML complexes comme du code :

```python
# pipeline.py
from kfp import dsl
from kfp import compiler

@dsl.component
def preprocess_data(input_data: str, output_data: dsl.Output[dsl.Dataset]):
    """PrÃ©traitement des donnÃ©es"""
    import pandas as pd
    # Charger et nettoyer les donnÃ©es
    df = pd.read_csv(input_data)
    df_clean = df.dropna()
    df_clean.to_csv(output_data.path, index=False)

@dsl.component
def train_model(dataset: dsl.Input[dsl.Dataset], model: dsl.Output[dsl.Model]):
    """EntraÃ®nement du modÃ¨le"""
    import pandas as pd
    from sklearn.ensemble import RandomForestClassifier
    import joblib

    df = pd.read_csv(dataset.path)
    X = df.drop('target', axis=1)
    y = df['target']

    clf = RandomForestClassifier(n_estimators=100)
    clf.fit(X, y)

    joblib.dump(clf, model.path)

@dsl.component
def evaluate_model(model: dsl.Input[dsl.Model], metrics: dsl.Output[dsl.Metrics]):
    """Ã‰valuation du modÃ¨le"""
    import joblib
    from sklearn.metrics import accuracy_score

    clf = joblib.load(model.path)
    # Ã‰valuer sur test set
    accuracy = 0.95  # Exemple

    metrics.log_metric('accuracy', accuracy)

@dsl.pipeline(
    name='ML Training Pipeline',
    description='Pipeline complet d\'entraÃ®nement'
)
def ml_pipeline(data_path: str):
    """Pipeline principal"""
    preprocess_task = preprocess_data(input_data=data_path)
    train_task = train_model(dataset=preprocess_task.outputs['output_data'])
    evaluate_task = evaluate_model(model=train_task.outputs['model'])

# Compiler le pipeline
compiler.Compiler().compile(
    pipeline_func=ml_pipeline,
    package_path='ml_pipeline.yaml'
)
```

DÃ©ployer :
```bash
# Upload et run le pipeline via UI Kubeflow
# ou via CLI :
kfp run create --experiment-name my-experiment --pipeline-file ml_pipeline.yaml
```

### Katib : Hyperparameter Tuning

**Katib** automatise la recherche des meilleurs hyperparamÃ¨tres :

```yaml
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  name: random-forest-tuning
spec:
  algorithm:
    algorithmName: random
  parallelTrialCount: 5  # 5 essais en parallÃ¨le
  maxTrialCount: 20      # 20 essais au total
  maxFailedTrialCount: 3

  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: accuracy

  parameters:
  - name: n_estimators
    parameterType: int
    feasibleSpace:
      min: "10"
      max: "200"
  - name: max_depth
    parameterType: int
    feasibleSpace:
      min: "5"
      max: "30"
  - name: learning_rate
    parameterType: double
    feasibleSpace:
      min: "0.001"
      max: "0.1"

  trialTemplate:
    primaryContainerName: training
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
            - name: training
              image: myml/training:v1
              command:
              - "python"
              - "train.py"
              - "--n-estimators=${trialParameters.nEstimators}"
              - "--max-depth=${trialParameters.maxDepth}"
              - "--learning-rate=${trialParameters.learningRate}"
            restartPolicy: Never
```

Katib va tester automatiquement 20 combinaisons et trouver la meilleure !

## Model Serving : DÃ©ployer des modÃ¨les en production

### KServe (anciennement KFServing)

**KServe** est le standard pour servir des modÃ¨les ML sur Kubernetes.

#### Architecture KServe

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Ingress / Gateway               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚             â”‚             â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”
â”‚ Model A â”‚   â”‚ Model B â”‚   â”‚Model C â”‚
â”‚ (v1)    â”‚   â”‚ (v1)    â”‚   â”‚ (v2)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### InferenceService

```yaml
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: sklearn-iris
spec:
  predictor:
    sklearn:
      storageUri: "gs://kfserving-examples/models/sklearn/iris"
      resources:
        requests:
          memory: "1Gi"
          cpu: "1"
        limits:
          memory: "2Gi"
          cpu: "2"
```

KServe crÃ©e automatiquement :
- Un Deployment avec autoscaling
- Un Service
- Des routes Ingress
- Monitoring Prometheus

#### Canary Deployment avec KServe

DÃ©ployer progressivement une nouvelle version :

```yaml
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: sklearn-iris
spec:
  predictor:
    sklearn:
      storageUri: "gs://models/sklearn/iris/v1"
      # 90% du trafic sur v1
  canaryTrafficPercent: 10
  canaryPredictor:
    sklearn:
      storageUri: "gs://models/sklearn/iris/v2"
      # 10% du trafic sur v2 (canary)
```

Si v2 fonctionne bien, augmentez progressivement le trafic.

### TensorFlow Serving

Solution spÃ©cialisÃ©e pour modÃ¨les TensorFlow :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tensorflow-serving
spec:
  replicas: 3
  selector:
    matchLabels:
      app: tf-serving
  template:
    metadata:
      labels:
        app: tf-serving
    spec:
      containers:
      - name: tensorflow-serving
        image: tensorflow/serving:latest
        ports:
        - containerPort: 8501
          name: http
        - containerPort: 8500
          name: grpc
        env:
        - name: MODEL_NAME
          value: "my_model"
        volumeMounts:
        - name: model-storage
          mountPath: /models/my_model
        resources:
          requests:
            memory: "2Gi"
            cpu: "2"
          limits:
            memory: "4Gi"
            cpu: "4"
        livenessProbe:
          httpGet:
            path: /v1/models/my_model
            port: 8501
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /v1/models/my_model
            port: 8501
          initialDelaySeconds: 10
          periodSeconds: 5
      volumes:
      - name: model-storage
        persistentVolumeClaim:
          claimName: models-pvc
```

#### Client Python pour TensorFlow Serving

```python
import requests
import json

# PrÃ©parer les donnÃ©es
data = {
    "instances": [[5.1, 3.5, 1.4, 0.2]]
}

# Appeler le modÃ¨le
response = requests.post(
    'http://tf-serving-service/v1/models/my_model:predict',
    json=data
)

# RÃ©sultat
prediction = response.json()
print(f"PrÃ©diction : {prediction['predictions']}")
```

### Triton Inference Server (NVIDIA)

Solution haute performance pour GPU :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: triton-server
spec:
  replicas: 2
  selector:
    matchLabels:
      app: triton
  template:
    spec:
      containers:
      - name: triton
        image: nvcr.io/nvidia/tritonserver:23.10-py3
        ports:
        - containerPort: 8000
          name: http
        - containerPort: 8001
          name: grpc
        - containerPort: 8002
          name: metrics
        resources:
          limits:
            nvidia.com/gpu: 1
        volumeMounts:
        - name: models
          mountPath: /models
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: models-pvc
```

Triton supporte TensorFlow, PyTorch, ONNX, TensorRT simultanÃ©ment !

## EntraÃ®nement distribuÃ©

### Pourquoi l'entraÃ®nement distribuÃ© ?

Pour des modÃ¨les trÃ¨s grands ou des datasets massifs, un seul GPU ne suffit pas :

```
Dataset : 1 TB
Temps sur 1 GPU : 30 jours
Temps sur 8 GPU : 4 jours
Temps sur 64 GPU : 12 heures
```

### PyTorch Distributed avec TorchElastic

```yaml
apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: pytorch-distributed
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          containers:
          - name: pytorch
            image: pytorch/pytorch:2.0.0-cuda11.8-cudnn8-runtime
            command:
            - python
            - train.py
            resources:
              limits:
                nvidia.com/gpu: 1

    Worker:
      replicas: 7  # 7 workers + 1 master = 8 GPU
      restartPolicy: OnFailure
      template:
        spec:
          containers:
          - name: pytorch
            image: pytorch/pytorch:2.0.0-cuda11.8-cudnn8-runtime
            command:
            - python
            - train.py
            resources:
              limits:
                nvidia.com/gpu: 1
```

Le code d'entraÃ®nement :

```python
# train.py
import torch
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

def setup():
    """Initialiser le groupe de processus distribuÃ©"""
    dist.init_process_group(backend='nccl')
    torch.cuda.set_device(int(os.environ['LOCAL_RANK']))

def train():
    setup()

    # CrÃ©er le modÃ¨le
    model = MyModel().cuda()

    # Wrapper pour distribution
    model = DDP(model)

    # EntraÃ®nement normal
    for epoch in range(100):
        for batch in dataloader:
            loss = model(batch)
            loss.backward()
            optimizer.step()

if __name__ == '__main__':
    train()
```

### TensorFlow Distributed avec TFJob

```yaml
apiVersion: kubeflow.org/v1
kind: TFJob
metadata:
  name: tensorflow-distributed
spec:
  tfReplicaSpecs:
    Chief:
      replicas: 1
      template:
        spec:
          containers:
          - name: tensorflow
            image: tensorflow/tensorflow:2.13.0-gpu
            command:
            - python
            - train.py
            resources:
              limits:
                nvidia.com/gpu: 1

    Worker:
      replicas: 3
      template:
        spec:
          containers:
          - name: tensorflow
            image: tensorflow/tensorflow:2.13.0-gpu
            command:
            - python
            - train.py
            resources:
              limits:
                nvidia.com/gpu: 1

    PS:  # Parameter Server
      replicas: 2
      template:
        spec:
          containers:
          - name: tensorflow
            image: tensorflow/tensorflow:2.13.0-gpu
            command:
            - python
            - train.py
```

## MLOps : DevOps pour le Machine Learning

### Qu'est-ce que le MLOps ?

**MLOps** = ML + DevOps = Bonnes pratiques DevOps appliquÃ©es au Machine Learning

```
DevOps traditionnel :
Code â†’ Build â†’ Test â†’ Deploy â†’ Monitor

MLOps :
Data + Code â†’ Train â†’ Validate â†’ Deploy Model â†’ Monitor Performance
    â†‘                                                      â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Retrain si drift â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Versioning des modÃ¨les

#### MLflow pour le tracking

```python
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier

# DÃ©marrer une expÃ©rience
mlflow.set_experiment("iris-classification")

# Logger un run
with mlflow.start_run():
    # HyperparamÃ¨tres
    n_estimators = 100
    max_depth = 10
    mlflow.log_param("n_estimators", n_estimators)
    mlflow.log_param("max_depth", max_depth)

    # EntraÃ®ner le modÃ¨le
    clf = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth
    )
    clf.fit(X_train, y_train)

    # MÃ©triques
    accuracy = clf.score(X_test, y_test)
    mlflow.log_metric("accuracy", accuracy)

    # Sauvegarder le modÃ¨le
    mlflow.sklearn.log_model(clf, "model")

    print(f"Model logged with accuracy: {accuracy}")
```

MLflow sur Kubernetes :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mlflow-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mlflow
  template:
    spec:
      containers:
      - name: mlflow
        image: python:3.9
        command:
        - sh
        - -c
        - |
          pip install mlflow psycopg2-binary boto3
          mlflow server \
            --backend-store-uri postgresql://user:pass@postgres:5432/mlflow \
            --default-artifact-root s3://mlflow-artifacts/ \
            --host 0.0.0.0 \
            --port 5000
        ports:
        - containerPort: 5000
        env:
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: aws-credentials
              key: access-key-id
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: aws-credentials
              key: secret-access-key
```

### Model Registry

GÃ©rer le cycle de vie des modÃ¨les :

```
Development â†’ Staging â†’ Production â†’ Archived

Model v1.0 : Production
Model v1.1 : Staging (en test)
Model v2.0 : Development
Model v0.9 : Archived
```

```python
import mlflow
from mlflow.tracking import MlflowClient

client = MlflowClient()

# Enregistrer un modÃ¨le
model_uri = "runs:/<run-id>/model"
mv = mlflow.register_model(model_uri, "iris-classifier")

# Transition vers staging
client.transition_model_version_stage(
    name="iris-classifier",
    version=mv.version,
    stage="Staging"
)

# AprÃ¨s validation, transition vers production
client.transition_model_version_stage(
    name="iris-classifier",
    version=mv.version,
    stage="Production"
)
```

### CI/CD pour ML

Pipeline GitOps pour ML :

```yaml
# .github/workflows/ml-pipeline.yml
name: ML Training Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  train:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt

    - name: Run data validation
      run: |
        python validate_data.py

    - name: Train model
      run: |
        python train.py

    - name: Evaluate model
      run: |
        python evaluate.py

    - name: Check performance threshold
      run: |
        python check_metrics.py --min-accuracy 0.90

    - name: Push model to registry
      if: github.ref == 'refs/heads/main'
      run: |
        python push_model.py

    - name: Deploy to staging
      if: github.ref == 'refs/heads/main'
      run: |
        kubectl apply -f k8s/staging/
```

### Monitoring de modÃ¨les en production

#### DÃ©tection de drift

Le **drift** est la dÃ©gradation des performances d'un modÃ¨le dans le temps :

```
ModÃ¨le entraÃ®nÃ© en 2023 :
  Accuracy sur donnÃ©es 2023 : 95%

1 an plus tard (2024) :
  Accuracy sur donnÃ©es 2024 : 75%  â† DRIFT !

Pourquoi ? Les donnÃ©es ont changÃ© :
  - Nouvelles tendances
  - Changements de comportement utilisateurs
  - Ã‰volution du marchÃ©
```

#### Prometheus pour monitoring ML

```yaml
apiVersion: v1
kind: ServiceMonitor
metadata:
  name: model-serving-metrics
spec:
  selector:
    matchLabels:
      app: inference
  endpoints:
  - port: metrics
    interval: 30s
```

MÃ©triques Ã  surveiller :

```python
from prometheus_client import Counter, Histogram, Gauge

# Compteur de prÃ©dictions
predictions_total = Counter(
    'model_predictions_total',
    'Total number of predictions',
    ['model_name', 'model_version']
)

# Latence
prediction_latency = Histogram(
    'model_prediction_latency_seconds',
    'Prediction latency in seconds',
    ['model_name']
)

# Accuracy en temps rÃ©el (si ground truth disponible)
model_accuracy = Gauge(
    'model_accuracy',
    'Current model accuracy',
    ['model_name', 'model_version']
)

# Dans votre code de serving
def predict(data):
    start = time.time()

    # Faire la prÃ©diction
    prediction = model.predict(data)

    # MÃ©triques
    latency = time.time() - start
    prediction_latency.labels(model_name='iris').observe(latency)
    predictions_total.labels(
        model_name='iris',
        model_version='v1.2'
    ).inc()

    return prediction
```

#### Alertes sur drift

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: model-drift-alerts
spec:
  groups:
  - name: ml-models
    interval: 30s
    rules:
    # Alerte si accuracy descend sous 85%
    - alert: ModelAccuracyDegraded
      expr: model_accuracy < 0.85
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Model accuracy below threshold"
        description: "Model {{ $labels.model_name }} accuracy is {{ $value }}"

    # Alerte si latence trop Ã©levÃ©e
    - alert: ModelLatencyHigh
      expr: histogram_quantile(0.95, rate(model_prediction_latency_seconds_bucket[5m])) > 1.0
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Model latency too high"
        description: "95th percentile latency is {{ $value }}s"
```

## Stockage de donnÃ©es pour ML

### DÃ©fis du stockage ML

Les datasets ML sont souvent :
- **TrÃ¨s volumineux** (tÃ©raoctets, pÃ©taoctets)
- **Nombreux fichiers** (millions d'images)
- **AccÃ¨s intensif** (lecture rapide pour entraÃ®nement)

### Solutions de stockage

#### 1. S3 / Object Storage

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: training-with-s3
spec:
  containers:
  - name: trainer
    image: myml/trainer:v1
    env:
    - name: AWS_ACCESS_KEY_ID
      valueFrom:
        secretKeyRef:
          name: aws-creds
          key: access-key
    - name: AWS_SECRET_ACCESS_KEY
      valueFrom:
        secretKeyRef:
          name: aws-creds
          key: secret-key
    command:
    - python
    - train.py
    - --data-path=s3://my-bucket/datasets/imagenet/
```

#### 2. PVC avec StorageClass rapide

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: training-dataset
spec:
  accessModes:
  - ReadWriteMany  # AccÃ¨s simultanÃ© par plusieurs Pods
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 500Gi
```

#### 3. Pachyderm pour versioning de donnÃ©es

**Pachyderm** = Git pour les donnÃ©es

```bash
# Installer Pachyderm
helm repo add pachyderm https://helm.pachyderm.com
helm install pachyderm pachyderm/pachyderm

# CrÃ©er un repository de donnÃ©es
pachctl create repo images

# Ajouter des donnÃ©es (versionnÃ©)
pachctl put file images@master:/cat1.jpg -f cat1.jpg
pachctl put file images@master:/cat2.jpg -f cat2.jpg

# CrÃ©er un pipeline qui rÃ©agit aux changements
pachctl create pipeline -f pipeline.json
```

Pipeline Pachyderm :

```json
{
  "pipeline": {
    "name": "preprocess"
  },
  "input": {
    "pfs": {
      "repo": "images",
      "glob": "/*.jpg"
    }
  },
  "transform": {
    "cmd": [ "python", "preprocess.py" ],
    "image": "myml/preprocess:v1"
  }
}
```

## Alternatives lÃ©gÃ¨res pour MicroK8s

### MLflow seul (sans Kubeflow)

Pour un lab, Kubeflow est souvent trop lourd. Utilisez juste MLflow :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mlflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mlflow
  template:
    spec:
      containers:
      - name: mlflow
        image: python:3.9
        command:
        - sh
        - -c
        - |
          pip install mlflow
          mlflow server --host 0.0.0.0 --port 5000
        ports:
        - containerPort: 5000
        volumeMounts:
        - name: mlflow-data
          mountPath: /mlflow
      volumes:
      - name: mlflow-data
        persistentVolumeClaim:
          claimName: mlflow-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: mlflow
spec:
  selector:
    app: mlflow
  ports:
  - port: 80
    targetPort: 5000
  type: LoadBalancer
```

### Jupyter + TensorFlow/PyTorch simple

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: ml-workspace
spec:
  containers:
  - name: jupyter
    image: jupyter/tensorflow-notebook:latest
    ports:
    - containerPort: 8888
    resources:
      limits:
        nvidia.com/gpu: 1  # Si GPU disponible
        memory: "8Gi"
      requests:
        memory: "4Gi"
        cpu: "2"
    volumeMounts:
    - name: workspace
      mountPath: /home/jovyan/work
  volumes:
  - name: workspace
    persistentVolumeClaim:
      claimName: jupyter-workspace
```

### FastAPI pour serving simple

Au lieu de KServe complexe, un simple FastAPI :

```python
# serve.py
from fastapi import FastAPI
import joblib
import numpy as np
from pydantic import BaseModel

app = FastAPI()

# Charger le modÃ¨le au dÃ©marrage
model = joblib.load('model.pkl')

class PredictionRequest(BaseModel):
    features: list[float]

@app.post("/predict")
def predict(request: PredictionRequest):
    """Endpoint de prÃ©diction"""
    features = np.array(request.features).reshape(1, -1)
    prediction = model.predict(features)

    return {
        "prediction": int(prediction[0])
    }

@app.get("/health")
def health():
    """Health check"""
    return {"status": "ok"}
```

Dockerfile :

```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY serve.py model.pkl ./

CMD ["uvicorn", "serve:app", "--host", "0.0.0.0", "--port", "8000"]
```

DÃ©ploiement :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: model-api
  template:
    spec:
      containers:
      - name: api
        image: myregistry/model-api:v1
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 10
```

## Bonnes pratiques ML sur Kubernetes

### 1. SÃ©parer entraÃ®nement et serving

```
Cluster Training (GPU) :
  - Jobs batch d'entraÃ®nement
  - Notebooks Jupyter
  - Hyperparameter tuning

Cluster Serving (CPU ou petit GPU) :
  - Inference servers
  - APIs de prÃ©diction
  - Monitoring
```

Ou au minimum, des namespaces sÃ©parÃ©s :

```bash
kubectl create namespace ml-training
kubectl create namespace ml-serving
```

### 2. Utiliser des Resource Quotas

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: ml-training-quota
  namespace: ml-training
spec:
  hard:
    requests.nvidia.com/gpu: "4"  # Max 4 GPU simultanÃ©s
    requests.memory: "128Gi"
    requests.cpu: "32"
```

### 3. Limiter les durÃ©es de jobs

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: training-job
spec:
  activeDeadlineSeconds: 86400  # Max 24h
  ttlSecondsAfterFinished: 3600  # Nettoie aprÃ¨s 1h
  backoffLimit: 1  # Ne rÃ©essaye qu'une fois
```

### 4. Checkpointing

Sauvegarder rÃ©guliÃ¨rement l'Ã©tat :

```python
# Dans votre code d'entraÃ®nement
for epoch in range(100):
    train_epoch()

    # Checkpoint tous les 10 epochs
    if epoch % 10 == 0:
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': loss,
        }, f'/checkpoints/checkpoint_epoch_{epoch}.pt')
```

Volume pour checkpoints :

```yaml
volumes:
- name: checkpoints
  persistentVolumeClaim:
    claimName: training-checkpoints
```

### 5. Monitoring des ressources

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: training
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8000"
spec:
  containers:
  - name: trainer
    image: myml/trainer:v1
    # Exporter des mÃ©triques custom
    env:
    - name: PROMETHEUS_PORT
      value: "8000"
```

## Exemple complet : Pipeline de classification d'images

### Architecture

```
1. Upload Images â†’ S3
2. Preprocessing Job â†’ Nettoie et augmente
3. Training Job (GPU) â†’ EntraÃ®ne ResNet50
4. Evaluation â†’ Valide sur test set
5. Model Registry â†’ Enregistre si accuracy > 90%
6. Serving â†’ DÃ©ploie avec KServe
7. Monitoring â†’ Prometheus + Grafana
```

### 1. Preprocessing Job

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: image-preprocessing
spec:
  template:
    spec:
      containers:
      - name: preprocess
        image: myml/image-preprocess:v1
        command:
        - python
        - preprocess.py
        args:
        - --input-path=s3://mybucket/raw-images/
        - --output-path=s3://mybucket/processed-images/
        - --augmentation=true
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
      restartPolicy: OnFailure
```

### 2. Training Job

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: resnet50-training
spec:
  template:
    spec:
      containers:
      - name: training
        image: myml/resnet-training:v1
        command:
        - python
        - train.py
        args:
        - --data-path=s3://mybucket/processed-images/
        - --model-name=resnet50
        - --epochs=50
        - --batch-size=32
        resources:
          limits:
            nvidia.com/gpu: 2
            memory: "32Gi"
          requests:
            memory: "16Gi"
            cpu: "8"
        env:
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow-service:5000"
        volumeMounts:
        - name: checkpoints
          mountPath: /checkpoints
      volumes:
      - name: checkpoints
        persistentVolumeClaim:
          claimName: training-checkpoints
      restartPolicy: OnFailure
  backoffLimit: 2
  activeDeadlineSeconds: 172800  # 48h max
```

### 3. Serving

```yaml
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: image-classifier
spec:
  predictor:
    pytorch:
      storageUri: "s3://mybucket/models/resnet50-v1/"
      resources:
        requests:
          memory: "2Gi"
          cpu: "1"
        limits:
          memory: "4Gi"
          cpu: "2"
      env:
      - name: WORKERS_PER_CORE
        value: "2"
  scaleTarget: 10  # Target 10 requÃªtes par pod
  scaleMetric: concurrency
```

### 4. Client d'infÃ©rence

```python
import requests
import json
from PIL import Image
import base64
import io

def classify_image(image_path, api_url):
    """Classifier une image via l'API"""
    # Charger l'image
    with open(image_path, 'rb') as f:
        image_bytes = f.read()

    # Encoder en base64
    image_b64 = base64.b64encode(image_bytes).decode('utf-8')

    # PrÃ©parer la requÃªte
    data = {
        "instances": [{
            "image": image_b64
        }]
    }

    # Appeler l'API
    response = requests.post(
        f"{api_url}/v1/models/image-classifier:predict",
        json=data
    )

    # Parser la rÃ©ponse
    predictions = response.json()
    return predictions

# Utilisation
result = classify_image(
    'cat.jpg',
    'http://image-classifier.default.example.com'
)
print(f"Classe prÃ©dite : {result['predictions'][0]['class']}")
print(f"Confiance : {result['predictions'][0]['confidence']}")
```

## Conclusion

Le **Machine Learning sur Kubernetes** transforme la maniÃ¨re dont les modÃ¨les ML sont dÃ©veloppÃ©s, dÃ©ployÃ©s et maintenus. Kubernetes apporte au ML ce qu'il a apportÃ© aux applications traditionnelles : **scalabilitÃ©, rÃ©silience, et gestion efficace des ressources**.

### Points clÃ©s Ã  retenir

1. **ML sur K8s** = RÃ©soudre les dÃ©fis de ressources, reproducibilitÃ©, scaling
2. **GPU essentiels** pour Deep Learning, bien supportÃ©s par Kubernetes
3. **Kubeflow** = Plateforme complÃ¨te mais lourde, alternatives lÃ©gÃ¨res existent
4. **Three phases** : Training (GPU) â†’ Serving (CPU/petit GPU) â†’ Monitoring
5. **MLOps** = DevOps adaptÃ© au ML, essentiel pour la production
6. **Model Serving** : KServe, TF Serving, Triton selon vos besoins
7. **Distributed Training** : NÃ©cessaire pour gros modÃ¨les et datasets
8. **Monitoring crucial** : DÃ©tecter le drift, surveiller les performances

### Recommandations pour MicroK8s

**Pour apprendre le ML sur K8s** :
- Commencez sans GPU (CPU suffit pour dÃ©buter)
- Jupyter notebook simple pour expÃ©rimenter
- MLflow pour tracking (plus lÃ©ger que Kubeflow)
- FastAPI pour serving (plus simple que KServe)

**Si vous avez un GPU** :
- Installez le NVIDIA Device Plugin
- Testez l'entraÃ®nement de petits modÃ¨les
- Explorez PyTorch/TensorFlow sur GPU
- Mesurez les gains de performance

**Pour aller en production** :
- Investissez dans Kubeflow ou alternatives (Metaflow, ZenML)
- ImplÃ©mentez CI/CD pour ML
- Monitoring obligatoire (drift detection)
- Model registry pour versioning

**Limitations de MicroK8s pour ML** :
- GPU unique (pas de multi-GPU distribuÃ© facilement)
- Ressources limitÃ©es pour gros modÃ¨les
- Pas idÃ©al pour production Ã  grande Ã©chelle
- Parfait pour learning, prototyping, edge ML

### Ã‰volution du ML sur Kubernetes

**Tendances actuelles** :
- **LLMs (Large Language Models)** : GPT, LLaMA sur K8s
- **AutoML** : Automatisation complÃ¨te (Katib, Ray)
- **Edge ML** : ModÃ¨les lÃ©gers dÃ©ployÃ©s en edge avec K3s
- **ML sur WASM** : WebAssembly pour ML ultra-portable
- **Federated Learning** : EntraÃ®nement distribuÃ© prÃ©servant la vie privÃ©e

**Outils Ã©mergents** :
- **Ray** : Framework distribuÃ© pour ML et RL
- **Seldon Core** : Alternative Ã  KServe
- **BentoML** : Packaging et dÃ©ploiement de modÃ¨les
- **ZenML** : Pipeline ML/MLOps moderne
- **Weights & Biases** : ExpÃ©rimentation et collaboration ML

### Quand utiliser Kubernetes pour ML ?

**âœ… OUI si** :
- Ã‰quipe ML de 3+ personnes
- Besoin de partager des GPU
- Multiples projets ML simultanÃ©s
- Besoin de reproductibilitÃ©
- DÃ©ploiement de modÃ¨les en production
- EntraÃ®nement distribuÃ© nÃ©cessaire

**âŒ NON si** :
- Projet ML solo et exploratoire
- Budget serrÃ© (GPU cloud)
- ModÃ¨les simples (scikit-learn)
- DÃ©ploiement occasionnel
- Pas de compÃ©tences DevOps/K8s

### Alternatives Ã  K8s pour ML

- **Vertex AI** (Google) : ML managÃ©
- **SageMaker** (AWS) : Plateforme ML complÃ¨te
- **Azure ML** : Solution Microsoft
- **Databricks** : Pour big data + ML
- **Paperspace Gradient** : GPU cloud simple
- **Lambda Labs** : GPU cloud abordable

### Prochaines Ã©tapes

AprÃ¨s avoir explorÃ© le ML sur Kubernetes, vous pourriez vous intÃ©resser Ã  :
- **25.5 Edge computing** : DÃ©ployer des modÃ¨les ML en edge
- **19. Scaling et Autoscaling** : Optimiser les ressources ML
- **22. Sauvegarde et Restauration** : ProtÃ©ger vos modÃ¨les et donnÃ©es

---

**Ressources complÃ©mentaires** :

- Kubeflow Documentation : https://www.kubeflow.org/docs/
- KServe : https://kserve.github.io/website/
- MLflow : https://mlflow.org/docs/
- PyTorch on Kubernetes : https://pytorch.org/ecosystem/
- TensorFlow on Kubernetes : https://www.tensorflow.org/tfx
- NVIDIA GPU Operator : https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/
- ML Engineering Book : https://www.mlebook.com/
- Made With ML : https://madewithml.com/

â­ï¸ [Tendances et Ã©volutions](/25-aller-plus-loin/07-tendances-et-evolutions.md)
