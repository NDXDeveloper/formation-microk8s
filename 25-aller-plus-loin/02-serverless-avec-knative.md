üîù Retour au [Sommaire](/SOMMAIRE.md)

# 25.2 Serverless avec Knative

## Introduction : Qu'est-ce que le Serverless ?

Le terme "serverless" (sans serveur) est un peu trompeur : il y a toujours des serveurs, mais **vous n'avez plus √† vous en soucier**. C'est une approche o√π vous vous concentrez uniquement sur votre code, et l'infrastructure s'occupe automatiquement de tout le reste.

### Le probl√®me traditionnel

Imaginons que vous avez d√©velopp√© une API de traitement d'images. Avec une approche traditionnelle :

1. Vous devez **provisionner des serveurs** (ou des Pods dans Kubernetes)
2. Votre application **tourne en permanence**, m√™me sans requ√™tes
3. Vous payez pour ces ressources **24h/24, 7j/7**
4. Si vous avez un pic de trafic, vous devez **scaler manuellement** (ou configurer l'autoscaling)
5. Si vous n'avez plus de trafic, vos Pods **continuent de consommer des ressources**

### La promesse du Serverless

Avec le serverless :

1. Votre code **ne s'ex√©cute que lorsqu'il est sollicit√©** (event-driven)
2. Quand il n'y a pas de requ√™tes, **il ne consomme aucune ressource**
3. L'infrastructure **scale automatiquement** de 0 √† N instances
4. Vous ne payez que pour le **temps d'ex√©cution r√©el**
5. D√©marrage tr√®s rapide (**scale to zero** en quelques secondes)

```
Approche traditionnelle :
[3 Pods actifs] ‚Üí Consomment toujours des ressources, m√™me sans trafic

Approche serverless :
Pas de trafic    : [0 Pod]  ‚Üí Aucune ressource consomm√©e ‚úÖ
Requ√™te arrive   : [1 Pod]  ‚Üí D√©marre automatiquement en <1s
10 requ√™tes      : [10 Pods] ‚Üí Scale automatiquement
Fin du trafic    : [0 Pod]  ‚Üí Retour √† z√©ro apr√®s inactivit√©
```

## Knative : Le Serverless sur Kubernetes

**Knative** (prononc√© "kay-native") est une plateforme open-source qui apporte les capacit√©s serverless √† Kubernetes. D√©velopp√© initialement par Google, elle est maintenant un projet de la Cloud Native Computing Foundation (CNCF).

### Pourquoi Knative ?

Au lieu d'utiliser des services serverless propri√©taires (AWS Lambda, Azure Functions, Google Cloud Functions), Knative vous permet de :

- **Rester sur Kubernetes** : Pas de migration vers une autre plateforme
- **√âviter le vendor lock-in** : Votre code fonctionne partout o√π Kubernetes tourne
- **Utiliser vos comp√©tences existantes** : M√™me concepts que Kubernetes
- **Avoir le contr√¥le** : Vous g√©rez votre infrastructure
- **√âconomiser** : Scale to zero = pas de gaspillage de ressources

### Les deux faces de Knative

Knative se compose de deux modules principaux (qu'on peut installer s√©par√©ment) :

#### 1. Knative Serving

C'est le c≈ìur du serverless sur Kubernetes. Il permet de :
- D√©ployer des applications qui **scale automatiquement**
- G√©rer le **scale-to-zero** (r√©duction √† z√©ro instance)
- Router le trafic intelligemment
- G√©rer les r√©visions et le **d√©ploiement progressif**

**Cas d'usage typiques** :
- APIs REST qui ont du trafic variable
- Webhooks
- Applications web avec traffic fluctuant
- Traitements d√©clench√©s par des √©v√©nements

#### 2. Knative Eventing

Gestion des √©v√©nements pour construire des architectures event-driven :
- **Sources d'√©v√©nements** : Kafka, Google Cloud Pub/Sub, GitHub, etc.
- **Brokers** : Distribution des √©v√©nements
- **Triggers** : D√©clenchement de fonctions sur √©v√©nements
- **Channels** : Canaux de communication entre composants

**Cas d'usage typiques** :
- Traitement de flux de donn√©es
- R√©action √† des √©v√©nements externes (nouveau fichier, webhook GitHub)
- Architectures de microservices r√©actifs

## Concepts cl√©s de Knative Serving

### 1. Service Knative (KService)

Un Service Knative est une abstraction de haut niveau qui encapsule tout ce dont vous avez besoin :

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: hello-world
spec:
  template:
    spec:
      containers:
      - image: gcr.io/knative-samples/helloworld-go
        env:
        - name: TARGET
          value: "Monde"
```

Avec ce simple manifeste, Knative cr√©e automatiquement :
- Une **Route** : Point d'entr√©e HTTP(S) pour votre service
- Une **Configuration** : D√©finit l'√©tat d√©sir√© de votre application
- Une ou plusieurs **R√©visions** : Snapshots immuables de votre code
- Un **Deployment** : Gestion des Pods sous-jacents

### 2. R√©visions : Versioning automatique

Chaque fois que vous mettez √† jour votre Service Knative, une nouvelle **R√©vision** est cr√©√©e automatiquement :

```
Service "mon-api"
‚îú‚îÄ‚îÄ R√©vision v1 (100% du trafic) ‚Üí D√©ploy√©e le 01/10/2025
‚îú‚îÄ‚îÄ R√©vision v2 (0% du trafic)   ‚Üí D√©ploy√©e le 15/10/2025
‚îî‚îÄ‚îÄ R√©vision v3 (0% du trafic)   ‚Üí D√©ploy√©e le 25/10/2025 (actuelle)
```

Vous pouvez :
- **Garder plusieurs r√©visions actives** simultan√©ment
- **Router le trafic** entre diff√©rentes r√©visions (canary, blue-green)
- **Revenir en arri√®re** instantan√©ment vers une r√©vision pr√©c√©dente
- **Tester une nouvelle version** avant de basculer le trafic

### 3. Autoscaling intelligent

Knative Serving inclut un autoscaler sophistiqu√© appel√© **KPA (Knative Pod Autoscaler)** :

#### Scale-to-Zero
Quand il n'y a pas de requ√™tes pendant un certain temps (par d√©faut 60 secondes), Knative r√©duit le nombre de Pods √† z√©ro :

```
Minute 0-5  : [3 Pods] ‚Üí Traitement de requ√™tes
Minute 5-6  : [2 Pods] ‚Üí Trafic diminue
Minute 6-7  : [1 Pod]  ‚Üí Peu de requ√™tes
Minute 7+   : [0 Pod]  ‚Üí Aucune requ√™te = Scale to zero ‚úÖ
```

#### Cold Start et Activation

Quand une requ√™te arrive sur un service √† z√©ro instance :

```
1. Requ√™te HTTP arrive
2. Activator Knative intercepte la requ√™te
3. Un Pod d√©marre rapidement (<3 secondes g√©n√©ralement)
4. Requ√™te transmise au Pod
5. R√©ponse envoy√©e au client
```

Ce d√©lai de d√©marrage s'appelle un **"cold start"**. Knative l'optimise au maximum.

#### Scale-Up automatique

Knative surveille plusieurs m√©triques pour d√©cider du scaling :

- **Concurrency** : Nombre de requ√™tes simultan√©es par Pod
- **RPS** (Requests Per Second) : Requ√™tes par seconde
- **CPU/Memory** : Utilisation des ressources

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: mon-api
spec:
  template:
    metadata:
      annotations:
        # Cible : 10 requ√™tes simultan√©es par Pod max
        autoscaling.knative.dev/target: "10"
        # Scale to zero apr√®s 30s d'inactivit√©
        autoscaling.knative.dev/scale-to-zero-pod-retention-period: "30s"
        # Minimum 0 Pods (scale to zero activ√©)
        autoscaling.knative.dev/min-scale: "0"
        # Maximum 50 Pods
        autoscaling.knative.dev/max-scale: "50"
    spec:
      containers:
      - image: mon-image:v1
```

### 4. Traffic Splitting : D√©ploiement progressif

Une fonctionnalit√© puissante de Knative est le **traffic splitting** (r√©partition du trafic) entre r√©visions :

#### Canary Deployment
D√©ployer progressivement une nouvelle version :

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: mon-service
spec:
  traffic:
  - revisionName: mon-service-v1
    percent: 90       # 90% du trafic sur v1
  - revisionName: mon-service-v2
    percent: 10       # 10% du trafic sur v2 (canary)
```

#### Blue-Green Deployment
Basculement instantan√© entre deux versions :

```yaml
spec:
  traffic:
  - revisionName: mon-service-blue
    percent: 100      # Tout le trafic sur blue
  - revisionName: mon-service-green
    percent: 0        # Green pr√™t mais pas de trafic
    tag: staging      # Accessible via URL distincte
```

La r√©vision "green" est accessible via une URL sp√©ciale (https://staging-mon-service...) pour tester.

## Knative Eventing : Architecture √©v√©nementielle

### Qu'est-ce qu'une architecture √©v√©nementielle ?

Au lieu d'appeler directement des services (approche synchrone), les composants **√©mettent et consomment des √©v√©nements** (approche asynchrone) :

```
Approche traditionnelle (synchrone) :
Service A ‚Üí appelle directement ‚Üí Service B

Approche √©v√©nementielle (asynchrone) :
Service A ‚Üí √©met √©v√©nement ‚Üí [Broker] ‚Üí d√©clenche ‚Üí Service B
```

**Avantages** :
- **D√©couplage** : Les services ne se connaissent pas directement
- **R√©silience** : Si B est down, l'√©v√©nement est conserv√©
- **Scalabilit√©** : Plusieurs consommateurs peuvent traiter en parall√®le
- **Flexibilit√©** : Ajouter de nouveaux consommateurs sans modifier A

### Composants de Knative Eventing

#### 1. Event Sources (Sources d'√©v√©nements)

Les sources g√©n√®rent des √©v√©nements depuis des syst√®mes externes :

- **KafkaSource** : √âv√©nements depuis Apache Kafka
- **GitHub Source** : Webhooks GitHub (push, pull request, issue)
- **CronJobSource** : √âv√©nements planifi√©s (comme un cron)
- **PingSource** : √âv√©nements r√©guliers simples
- **ContainerSource** : √âv√©nements depuis n'importe quel conteneur

Exemple conceptuel :
```yaml
apiVersion: sources.knative.dev/v1
kind: PingSource
metadata:
  name: heartbeat
spec:
  schedule: "*/5 * * * *"  # Toutes les 5 minutes
  data: '{"message": "Hello every 5 minutes!"}'
  sink:
    ref:
      apiVersion: serving.knative.dev/v1
      kind: Service
      name: mon-service-handler
```

#### 2. Brokers

Un **Broker** est un hub central qui re√ßoit tous les √©v√©nements et les distribue :

```
[Source 1] ‚îÄ‚îÄ‚îê
[Source 2] ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚Üí [Broker] ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚Üí [Service A]
[Source 3] ‚îÄ‚îÄ‚îò               ‚îú‚îÄ‚îÄ‚Üí [Service B]
                             ‚îî‚îÄ‚îÄ‚Üí [Service C]
```

#### 3. Triggers

Les **Triggers** d√©finissent quels √©v√©nements vont vers quels services :

```yaml
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
  name: mon-trigger-github
spec:
  broker: default
  filter:
    attributes:
      type: dev.knative.github.push  # Ne r√©agir qu'aux "push"
      source: github.com/mon-repo    # Depuis ce repo uniquement
  subscriber:
    ref:
      apiVersion: serving.knative.dev/v1
      kind: Service
      name: build-on-push
```

#### 4. Channels et Subscriptions

Alternative aux Brokers, les **Channels** permettent une communication point-√†-point ou pub/sub :

```yaml
apiVersion: messaging.knative.dev/v1
kind: Channel
metadata:
  name: ma-chaine
spec:
  channelTemplate:
    apiVersion: messaging.knative.dev/v1
    kind: InMemoryChannel
```

## Cas d'usage pratiques

### 1. API web avec trafic variable

**Sc√©nario** : Vous avez une API qui re√ßoit beaucoup de requ√™tes pendant la journ√©e, mais tr√®s peu la nuit.

**Avec Knative** :
- La nuit : 0 Pod ‚Üí Aucune ressource consomm√©e
- Le matin : Scale automatique progressif
- Pic de midi : 20 Pods
- Apr√®s-midi : 15 Pods
- Soir√©e : 5 Pods
- Nuit : Retour √† 0 Pod

**√âconomie** : Au lieu de maintenir 20 Pods 24h/24, vous ne payez que pour l'utilisation r√©elle.

### 2. Traitement d'images √† la demande

**Sc√©nario** : Les utilisateurs uploadent des images que vous devez redimensionner.

```
1. Utilisateur uploade une image ‚Üí [Stockage S3]
2. S3 √©met un √©v√©nement ‚Üí [Knative EventSource]
3. √âv√©nement rout√© ‚Üí [Broker Knative]
4. Trigger d√©clenche ‚Üí [Service de traitement d'images]
5. Service scale automatiquement selon le nombre d'images
6. Apr√®s traitement ‚Üí Retour √† 0 Pod
```

### 3. Webhooks et int√©grations

**Sc√©nario** : Recevoir des webhooks de services externes (Stripe, GitHub, etc.)

**Avec Knative** :
- Service √† 0 Pod en attente
- Webhook arrive ‚Üí D√©marre un Pod en <1s
- Traite le webhook
- Retourne √† 0 Pod apr√®s 30s d'inactivit√©

**Avantage** : Pas besoin de maintenir un service actif en permanence pour des √©v√©nements sporadiques.

### 4. T√¢ches planifi√©es (Cron Jobs am√©lior√©s)

**Sc√©nario** : Ex√©cuter des rapports quotidiens, des backups, du nettoyage.

```yaml
apiVersion: sources.knative.dev/v1
kind: CronJobSource
metadata:
  name: backup-quotidien
spec:
  schedule: "0 2 * * *"  # Tous les jours √† 2h du matin
  data: '{"type": "daily-backup"}'
  sink:
    ref:
      apiVersion: serving.knative.dev/v1
      kind: Service
      name: backup-service
```

Le service de backup :
- N'existe pas (0 Pod) sauf √† 2h du matin
- D√©marre automatiquement quand l'√©v√©nement arrive
- Effectue le backup
- S'arr√™te apr√®s ex√©cution

### 5. Architecture de microservices √©v√©nementielle

**Sc√©nario** : E-commerce avec plusieurs services d√©coupl√©s.

```
√âv√©nement "OrderPlaced" √©mis par le service Order
    ‚Üì
[Broker Knative]
    ‚Üì
    ‚îú‚îÄ‚îÄ‚Üí [Trigger 1] ‚Üí Service Inventory (d√©duire le stock)
    ‚îú‚îÄ‚îÄ‚Üí [Trigger 2] ‚Üí Service Payment (traiter le paiement)
    ‚îú‚îÄ‚îÄ‚Üí [Trigger 3] ‚Üí Service Notification (email au client)
    ‚îî‚îÄ‚îÄ‚Üí [Trigger 4] ‚Üí Service Analytics (statistiques)
```

Chaque service :
- Scale ind√©pendamment
- Peut √™tre d√©velopp√© dans une techno diff√©rente
- D√©marre seulement quand n√©cessaire
- Ne conna√Æt pas les autres services

## Installation de Knative sur MicroK8s

### Pr√©requis

Knative n√©cessite :
- **Kubernetes 1.28+** (v√©rifiez avec `microk8s version`)
- Au moins **4 GB de RAM** disponibles
- **Un Ingress controller** (NGINX recommand√©)

### Installation pas √† pas

#### √âtape 1 : Pr√©parer le cluster

```bash
# Activer les addons n√©cessaires
microk8s enable dns
microk8s enable ingress
microk8s enable storage

# Cr√©er un alias kubectl pour simplifier
alias kubectl='microk8s kubectl'
```

#### √âtape 2 : Installer les CRDs Knative

```bash
# Installer les Custom Resource Definitions de Knative Serving
kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.12.0/serving-crds.yaml

# Installer le core de Knative Serving
kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.12.0/serving-core.yaml
```

#### √âtape 3 : Installer un r√©seau pour Knative

Knative n√©cessite une couche r√©seau. Plusieurs options existent, **Kourier** est la plus simple :

```bash
# Installer Kourier (networking layer)
kubectl apply -f https://github.com/knative/net-kourier/releases/download/knative-v1.12.0/kourier.yaml

# Configurer Knative pour utiliser Kourier
kubectl patch configmap/config-network \
  --namespace knative-serving \
  --type merge \
  --patch '{"data":{"ingress-class":"kourier.ingress.networking.knative.dev"}}'
```

#### √âtape 4 : Configurer le DNS (pour un lab)

Pour un environnement de lab, utilisez **Magic DNS** (sslip.io) :

```bash
kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.12.0/serving-default-domain.yaml
```

Vos services seront accessibles via des URLs comme :
`http://mon-service.default.127.0.0.1.sslip.io`

#### √âtape 5 : V√©rifier l'installation

```bash
# V√©rifier que tous les pods Knative sont Running
kubectl get pods -n knative-serving

# Vous devriez voir :
# - activator
# - autoscaler
# - controller
# - webhook
# - net-kourier-controller (si vous utilisez Kourier)
```

#### √âtape 6 (Optionnel) : Installer Knative Eventing

Si vous voulez utiliser la partie √©v√©nementielle :

```bash
# Installer les CRDs Eventing
kubectl apply -f https://github.com/knative/eventing/releases/download/knative-v1.12.0/eventing-crds.yaml

# Installer le core Eventing
kubectl apply -f https://github.com/knative/eventing/releases/download/knative-v1.12.0/eventing-core.yaml

# Installer un syst√®me de messaging (InMemoryChannel pour d√©buter)
kubectl apply -f https://github.com/knative/eventing/releases/download/knative-v1.12.0/in-memory-channel.yaml

# Installer un broker par d√©faut
kubectl apply -f https://github.com/knative/eventing/releases/download/knative-v1.12.0/mt-channel-broker.yaml
```

### D√©ployer votre premier service Knative

```bash
# Cr√©er un fichier hello.yaml
cat <<EOF > hello.yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: hello
spec:
  template:
    spec:
      containers:
      - image: gcr.io/knative-samples/helloworld-go
        env:
        - name: TARGET
          value: "Knative sur MicroK8s"
EOF

# D√©ployer
kubectl apply -f hello.yaml

# Attendre que le service soit pr√™t
kubectl get ksvc hello

# R√©cup√©rer l'URL du service
kubectl get ksvc hello -o jsonpath='{.status.url}'

# Tester le service
curl $(kubectl get ksvc hello -o jsonpath='{.status.url}')
```

Vous devriez voir : `Hello Knative sur MicroK8s!`

Observer le scale-to-zero :
```bash
# Voir les Pods
kubectl get pods

# Attendre 60-90 secondes sans envoyer de requ√™tes
# Puis v√©rifier √† nouveau
kubectl get pods
# Les Pods du service hello ont disparu ! (scale to zero)

# Envoyer une nouvelle requ√™te
curl $(kubectl get ksvc hello -o jsonpath='{.status.url}')

# V√©rifier imm√©diatement les Pods
kubectl get pods
# Un nouveau Pod vient d'appara√Ætre (cold start)
```

## Knative CLI : kn

Knative fournit une CLI d√©di√©e **kn** qui simplifie grandement les op√©rations :

### Installation de kn

```bash
# T√©l√©charger la derni√®re version
curl -L https://github.com/knative/client/releases/download/knative-v1.12.0/kn-linux-amd64 -o kn

# Rendre ex√©cutable
chmod +x kn

# D√©placer dans le PATH
sudo mv kn /usr/local/bin/

# V√©rifier
kn version
```

### Commandes essentielles

```bash
# Lister tous les services Knative
kn service list

# D√©crire un service
kn service describe hello

# Cr√©er un service en une commande
kn service create mon-api \
  --image gcr.io/knative-samples/helloworld-go \
  --env TARGET="Mon API" \
  --scale-min 0 \
  --scale-max 10

# Mettre √† jour un service
kn service update mon-api --env TARGET="API v2"

# Router le trafic (canary deployment)
kn service update mon-api \
  --traffic hello-00001=50 \
  --traffic hello-00002=50

# Voir les r√©visions
kn revision list

# Supprimer un service
kn service delete mon-api

# Voir les logs en temps r√©el
kn service logs mon-api -f
```

La CLI **kn** est beaucoup plus intuitive que de manipuler des fichiers YAML !

## Performance et optimisation

### Optimiser le Cold Start

Le **cold start** (temps de d√©marrage d'un Pod) peut √™tre r√©duit :

#### 1. Utiliser des images l√©g√®res

```dockerfile
# Mauvais : Image lourde (1 GB)
FROM ubuntu:latest

# Bon : Image alpine l√©g√®re (5 MB)
FROM alpine:latest

# Excellent : Image distroless (2 MB)
FROM gcr.io/distroless/static
```

#### 2. Pr√©configurer le scale-min

Pour des services critiques, √©viter le scale-to-zero :

```yaml
metadata:
  annotations:
    autoscaling.knative.dev/min-scale: "1"  # Toujours 1 Pod minimum
```

#### 3. Utiliser des readiness probes optimis√©es

```yaml
spec:
  containers:
  - image: mon-image
    readinessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 1  # D√©marrage tr√®s rapide
      periodSeconds: 1
```

### Optimiser la concurrence

Ajuster le nombre de requ√™tes simultan√©es par Pod :

```yaml
metadata:
  annotations:
    # Faible concurrence pour CPU-intensive
    autoscaling.knative.dev/target: "5"

    # Haute concurrence pour I/O-bound
    autoscaling.knative.dev/target: "100"
```

### Limiter les ressources

D√©finir des limites pour √©viter le gaspillage :

```yaml
spec:
  containers:
  - image: mon-image
    resources:
      requests:
        memory: "64Mi"
        cpu: "100m"
      limits:
        memory: "128Mi"
        cpu: "200m"
```

## Monitoring et observabilit√©

### M√©triques Knative

Knative expose automatiquement des m√©triques Prometheus :

- **Request Count** : Nombre total de requ√™tes
- **Request Latency** : Latence des requ√™tes (p50, p95, p99)
- **Request Errors** : Taux d'erreur
- **Pod Count** : Nombre de Pods actifs
- **Cold Start Duration** : Dur√©e des cold starts

### Int√©gration avec Prometheus et Grafana

Si vous avez Prometheus install√© :

```bash
# Activer le monitoring sur MicroK8s
microk8s enable prometheus

# Les m√©triques Knative sont automatiquement scrap√©es
```

Dashboards Grafana recommand√©s :
- **Knative Serving - Revision HTTP Requests** : M√©triques par r√©vision
- **Knative Serving - Scaling** : Visualisation du scaling

### Logs

```bash
# Logs d'un service Knative
kubectl logs -l serving.knative.dev/service=mon-service -c user-container

# Avec kn CLI (plus simple)
kn service logs mon-service -f

# Logs de l'autoscaler
kubectl logs -n knative-serving -l app=autoscaler
```

## Limitations et consid√©rations

### ‚ùå Quand Knative n'est PAS adapt√©

1. **Applications stateful** : Bases de donn√©es, cache, sessions utilisateur
2. **Long-running processes** : Traitement de donn√©es qui prend des heures
3. **WebSockets persistantes** : Connexions longue dur√©e
4. **Tr√®s haute performance** : Le cold start ajoute toujours un peu de latence

### ‚ö†Ô∏è Points de vigilance

1. **Cold Start** : Toujours quelques secondes de latence √† la premi√®re requ√™te
2. **Complexit√©** : N√©cessite de bien comprendre l'architecture √©v√©nementielle
3. **Ressources** : Knative lui-m√™me consomme ~300-500 Mo de RAM
4. **Debugging** : Plus complexe qu'un Deployment classique

### ‚úÖ Quand Knative est id√©al

1. **APIs sporadiques** : Webhooks, int√©grations, traitements ponctuels
2. **Microservices √©v√©nementiels** : Architecture d√©coupl√©e
3. **√âconomie de ressources** : Lab personnel, environnement de dev/test
4. **Prototypage rapide** : Tester rapidement des id√©es
5. **Background jobs** : Traitement d'images, g√©n√©ration de rapports, etc.

## Comparaison avec d'autres solutions

| Crit√®re | Knative | AWS Lambda | OpenFaaS | Kubeless |
|---------|---------|------------|----------|----------|
| **Plateforme** | Kubernetes | AWS | Kubernetes | Kubernetes |
| **Vendor Lock-in** | ‚ùå Aucun | ‚ö†Ô∏è √âlev√© | ‚ùå Aucun | ‚ùå Aucun |
| **Maturit√©** | Mature | Tr√®s mature | Mature | Archiv√© |
| **Communaut√©** | Grande | √ânorme | Moyenne | Petite |
| **Complexit√©** | Moyenne | Faible | Faible | Moyenne |
| **Scale to zero** | ‚úÖ Oui | ‚úÖ Oui | ‚úÖ Oui | ‚úÖ Oui |
| **Cold start** | ~1-3s | ~100-500ms | ~1-2s | ~1-3s |
| **Eventing natif** | ‚úÖ Oui | ‚úÖ Oui | ‚ùå Non | ‚ö†Ô∏è Limit√© |
| **Multi-cloud** | ‚úÖ Oui | ‚ùå Non | ‚úÖ Oui | ‚úÖ Oui |
| **Co√ªt** | Gratuit | Pay-per-use | Gratuit | Gratuit |

## Bonnes pratiques

### 1. Design des services

```yaml
# ‚úÖ BON : Service stateless, traitement rapide
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: image-resizer
spec:
  template:
    spec:
      containers:
      - image: mon-resizer:v1
        env:
        - name: MAX_IMAGE_SIZE
          value: "10MB"

# ‚ùå MAUVAIS : Service stateful
# N'utilisez pas Knative pour √ßa
apiVersion: apps/v1
kind: StatefulSet  # Utilisez un StatefulSet classique
```

### 2. Configuration du scaling

```yaml
metadata:
  annotations:
    # D√©finir clairement les limites
    autoscaling.knative.dev/min-scale: "0"
    autoscaling.knative.dev/max-scale: "20"
    # Ajuster selon votre charge
    autoscaling.knative.dev/target: "10"
    # Temps avant scale-to-zero
    autoscaling.knative.dev/scale-to-zero-pod-retention-period: "60s"
```

### 3. Gestion des r√©visions

```yaml
spec:
  template:
    metadata:
      # Donner des noms explicites aux r√©visions
      name: mon-api-v2-canary
    spec:
      containers:
      - image: mon-api:v2
  traffic:
  - revisionName: mon-api-v1
    percent: 90
  - revisionName: mon-api-v2-canary
    percent: 10
    tag: canary  # URL d√©di√©e pour tester
```

### 4. Monitoring et alerting

```yaml
# Ajouter des labels pour Prometheus
metadata:
  labels:
    team: backend
    service: api
    environment: production
```

### 5. S√©curit√©

```yaml
spec:
  template:
    spec:
      # Limiter les privil√®ges
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
      containers:
      - image: mon-image
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
```

## Conclusion

Knative apporte les capacit√©s serverless √† Kubernetes, permettant de cr√©er des applications qui **scalent automatiquement de 0 √† N** en fonction de la demande. C'est particuli√®rement pertinent pour un lab MicroK8s o√π les ressources sont limit√©es.

### Points cl√©s √† retenir

1. **Serverless ‚â† Sans serveur** : C'est une abstraction qui cache la gestion des serveurs
2. **Scale-to-zero** : La killer feature qui √©conomise les ressources
3. **Knative Serving** : Pour les applications HTTP qui scalent automatiquement
4. **Knative Eventing** : Pour les architectures √©v√©nementielles d√©coupl√©es
5. **R√©visions** : Versioning automatique et traffic splitting natif
6. **Cold Start** : Il y a toujours un petit d√©lai au d√©marrage (1-3s)
7. **Pas pour tout** : R√©servez Knative aux cas d'usage appropri√©s

### Recommandations pour MicroK8s

**Pour apprendre** :
- Installez Knative Serving uniquement pour commencer
- Utilisez la CLI **kn** pour la simplicit√©
- D√©ployez quelques services simples pour comprendre le scale-to-zero
- Observez les m√©triques avec Prometheus/Grafana

**Pour un usage productif** :
- Identifiez les services qui ont un trafic variable
- Commencez par 1-2 services non-critiques
- Configurez des min-scale pour les services critiques (√©viter cold start)
- Monitorer attentivement les cold starts et ajuster

**Cas d'usage parfaits pour un lab** :
- Webhooks (GitHub, Discord, Slack)
- APIs de d√©veloppement
- T√¢ches planifi√©es (rapports, backups)
- Environnements de test

### Prochaines √©tapes

Apr√®s avoir explor√© Knative, vous pourriez vous int√©resser √† :
- **25.3 Operators et Custom Resources** : √âtendre Kubernetes
- **17.5 ArgoCD pour GitOps** : D√©ploiement d√©claratif et automatis√©
- **25.1 Service Mesh** : Combiner Knative avec Istio/Linkerd pour plus de contr√¥le

---

**Ressources compl√©mentaires** :

- Documentation officielle Knative : https://knative.dev/docs/
- Knative Cookbook : https://knative.dev/docs/samples/
- Knative CLI (kn) : https://knative.dev/docs/client/
- Awesome Knative : Liste de ressources communautaires
- Cloud Native Computing Foundation : Projets serverless

‚è≠Ô∏è [Operators et Custom Resources](/25-aller-plus-loin/03-operators-et-custom-resources.md)
