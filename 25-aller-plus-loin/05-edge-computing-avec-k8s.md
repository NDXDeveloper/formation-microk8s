ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 25.5 Edge computing avec K8s

## Introduction : Qu'est-ce que l'Edge Computing ?

### L'analogie du restaurant

Pour comprendre l'edge computing, imaginez cette analogie :

**ModÃ¨le Cloud (centralisÃ©)** :
```
Vous Ãªtes dans un restaurant
   â†“
Vous commandez un plat
   â†“
La cuisine centrale prÃ©pare (Ã  500 km de lÃ )
   â†“
Le plat est livrÃ© par avion
   â†“
Vous mangez (2 heures plus tard)
```

**ModÃ¨le Edge (distribuÃ©)** :
```
Vous Ãªtes dans un restaurant
   â†“
Vous commandez un plat
   â†“
La cuisine locale prÃ©pare (dans le restaurant)
   â†“
Le plat arrive sur votre table
   â†“
Vous mangez (5 minutes plus tard)
```

L'edge computing, c'est **rapprocher la puissance de calcul de lÃ  oÃ¹ les donnÃ©es sont gÃ©nÃ©rÃ©es et consommÃ©es**.

### DÃ©finition formelle

L'**Edge Computing** (informatique en pÃ©riphÃ©rie) est un paradigme oÃ¹ le traitement des donnÃ©es se fait :
- **Au plus prÃ¨s de la source** de gÃ©nÃ©ration des donnÃ©es
- **Localement**, plutÃ´t que dans un datacenter distant
- **En temps rÃ©el** ou quasi-temps rÃ©el

```
Cloud Computing :        Edge Computing :

[Capteurs]              [Capteurs]
    â†“                       â†“
[Internet]              [Edge Device]
    â†“                       â†“
[Datacenter Cloud]      [Traitement local]
    â†“                       â†“
[Traitement]            [Action immÃ©diate]
    â†“
[RÃ©sultat]
```

### Pourquoi l'Edge Computing ?

#### 1. Latence rÃ©duite

**ProblÃ¨me Cloud** : Les donnÃ©es font des allers-retours vers le datacenter.
```
CamÃ©ra de sÃ©curitÃ© â†’ Cloud (500 ms) â†’ Analyse â†’ Alerte (500 ms) â†’ Total : 1 seconde
```

**Solution Edge** : Le traitement se fait localement.
```
CamÃ©ra de sÃ©curitÃ© â†’ Edge Device (10 ms) â†’ Analyse â†’ Alerte (10 ms) â†’ Total : 20 ms
```

Pour une voiture autonome, 1 seconde = 30 mÃ¨tres parcourus Ã  100 km/h !

#### 2. Bande passante Ã©conomisÃ©e

**Sans Edge** :
- 100 camÃ©ras Ã— 1080p Ã— 24h/jour = **tÃ©raoctets** de donnÃ©es vers le cloud
- CoÃ»ts de transfert importants

**Avec Edge** :
- Traitement local des vidÃ©os
- Envoi uniquement des alertes et statistiques au cloud
- Ã‰conomie de **99% de bande passante**

#### 3. Fonctionnement offline

Si la connexion internet est coupÃ©e :
- **Cloud** : SystÃ¨me inopÃ©rant âŒ
- **Edge** : Continue de fonctionner localement âœ…

#### 4. ConformitÃ© et vie privÃ©e

DonnÃ©es sensibles (mÃ©dicales, vidÃ©osurveillance) :
- **Cloud** : Transit sur Internet, stockage distant
- **Edge** : DonnÃ©es traitÃ©es localement, ne quittent jamais le site

## Le spectre Cloud â†’ Edge â†’ Device

L'informatique moderne n'est pas binaire (cloud OU edge), c'est un **continuum** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  [Cloud]        [Regional Edge]      [Local Edge]      [Device]  â”‚
â”‚  Datacenter     Mini-datacenter      Box locale        Capteur   â”‚
â”‚                                                                  â”‚
â”‚  Latence:       Latence:             Latence:          Latence:  â”‚
â”‚  100-500 ms     20-50 ms             5-20 ms           <5 ms     â”‚
â”‚                                                                  â”‚
â”‚  Puissance:     Puissance:           Puissance:        Puissance:â”‚
â”‚  TrÃ¨s haute     Haute                Moyenne           Faible    â”‚
â”‚                                                                  â”‚
â”‚  Exemples:      Exemples:            Exemples:         Exemples: â”‚
â”‚  AWS            Cloudflare           Raspberry Pi      ESP32     â”‚
â”‚  Azure          Edge locations       NVIDIA Jetson     Sensors   â”‚
â”‚  GCP            5G MEC               Intel NUC         Cameras   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### OÃ¹ Kubernetes intervient-il ?

Kubernetes (et ses variantes lÃ©gÃ¨res) peut orchestrer des applications sur :
- **Regional Edge** : Petits datacenters en bordure de rÃ©seau
- **Local Edge** : Serveurs dans les usines, magasins, vÃ©hicules

## Cas d'usage de l'Edge Computing

### 1. Industrie 4.0 (Smart Manufacturing)

**ScÃ©nario** : Une usine avec 1000 capteurs IoT sur les machines.

**Sans Edge** :
- Tous les capteurs envoient leurs donnÃ©es au cloud
- Analyse centralisÃ©e
- Latence : 500 ms
- ProblÃ¨me : En cas de dÃ©faillance machine, la dÃ©tection arrive trop tard

**Avec Edge** :
- Kubernetes en edge dans l'usine
- Analyse en temps rÃ©el des donnÃ©es capteurs
- Latence : 10 ms
- Avantage : ArrÃªt automatique de la machine dÃ©faillante en <1 seconde

```yaml
# Application edge de monitoring industriel
apiVersion: apps/v1
kind: Deployment
metadata:
  name: machine-monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: machine-monitor
  template:
    spec:
      containers:
      - name: monitor
        image: factory/machine-monitor:v1
        env:
        - name: SENSOR_ENDPOINT
          value: "http://localhost:9090/metrics"
        - name: ALERT_THRESHOLD
          value: "85"  # TempÃ©rature critique
        resources:
          requests:
            memory: "256Mi"
            cpu: "500m"
```

### 2. Retail (Commerce de dÃ©tail)

**ScÃ©nario** : ChaÃ®ne de 500 magasins avec analyse vidÃ©o.

**Architecture Edge** :
```
Chaque magasin :
â”œâ”€â”€ 20 camÃ©ras
â”œâ”€â”€ 1 serveur edge avec Kubernetes
â””â”€â”€ Applications :
    â”œâ”€â”€ Comptage de personnes
    â”œâ”€â”€ DÃ©tection de vol
    â”œâ”€â”€ Analyse de parcours clients
    â””â”€â”€ Gestion des stocks en temps rÃ©el

Cloud centralisÃ© :
â””â”€â”€ AgrÃ©gation des statistiques
    â””â”€â”€ Business Intelligence
```

**BÃ©nÃ©fices** :
- Analyse instantanÃ©e (alerte vol en temps rÃ©el)
- 99% de rÃ©duction de bande passante
- Respect RGPD (vidÃ©os ne quittent pas le magasin)

### 3. VÃ©hicules connectÃ©s

**ScÃ©nario** : Flottes de vÃ©hicules autonomes ou semi-autonomes.

```
Chaque vÃ©hicule :
â”œâ”€â”€ Kubernetes lÃ©ger (K3s)
â”œâ”€â”€ Applications :
â”‚   â”œâ”€â”€ Traitement des images (camÃ©ras)
â”‚   â”œâ”€â”€ Fusion de capteurs (LIDAR, radar)
â”‚   â”œâ”€â”€ Prise de dÃ©cision locale
â”‚   â””â”€â”€ Maintenance prÃ©dictive
â””â”€â”€ Synchro cloud quand WiFi disponible
```

**Pourquoi Edge ?** : Une voiture ne peut pas dÃ©pendre d'une connexion 4G/5G pour freiner !

### 4. SantÃ© connectÃ©e

**ScÃ©nario** : HÃ´pital avec Ã©quipements mÃ©dicaux connectÃ©s.

```
Edge cluster dans l'hÃ´pital :
â”œâ”€â”€ Monitoring patient temps rÃ©el
â”œâ”€â”€ Analyse ECG locale
â”œâ”€â”€ Alertes critiques instantanÃ©es
â”œâ”€â”€ DonnÃ©es sensibles restent sur site
â””â”€â”€ Anonymisation avant envoi au cloud
```

**ConformitÃ©** : DonnÃ©es mÃ©dicales traitÃ©es localement (HIPAA, RGPD).

### 5. TÃ©lÃ©communications (5G Edge)

**ScÃ©nario** : Multi-access Edge Computing (MEC) dans les antennes 5G.

```
Antenne 5G :
â”œâ”€â”€ Edge computing node
â”œâ”€â”€ Applications Ã  ultra-faible latence :
â”‚   â”œâ”€â”€ Gaming cloud (<10 ms)
â”‚   â”œâ”€â”€ AR/VR streaming
â”‚   â”œâ”€â”€ VidÃ©o 4K/8K
â”‚   â””â”€â”€ Conduite assistÃ©e
```

**Avantage** : Latence rÃ©duite de 100 ms (cloud) Ã  5-10 ms (edge).

### 6. Agriculture de prÃ©cision

**ScÃ©nario** : Ferme connectÃ©e avec capteurs et drones.

```
Edge device (Raspberry Pi + K3s) :
â”œâ”€â”€ Collecte donnÃ©es capteurs (humiditÃ©, tempÃ©rature)
â”œâ”€â”€ Traitement images drones
â”œâ”€â”€ DÃ©cision d'irrigation automatique
â”œâ”€â”€ DÃ©tection prÃ©coce de maladies
â””â”€â”€ Fonctionnement mÃªme sans Internet
```

### 7. Smart Cities

**ScÃ©nario** : Ville intelligente avec infrastructure connectÃ©e.

```
Edge nodes par quartier :
â”œâ”€â”€ Gestion du trafic (feux intelligents)
â”œâ”€â”€ Ã‰clairage public adaptatif
â”œâ”€â”€ DÃ©tection d'incidents
â”œâ”€â”€ QualitÃ© de l'air en temps rÃ©el
â””â”€â”€ AgrÃ©gation vers le cloud municipal
```

## DÃ©fis spÃ©cifiques de l'Edge

### 1. Ressources limitÃ©es

Les edge devices ont moins de puissance qu'un datacenter cloud :

```
Cloud Server :          Edge Device :
- 64 GB RAM            - 4-8 GB RAM
- 32 CPU cores         - 4 CPU cores
- SSD illimitÃ©         - 256 GB SSD
- RÃ©seau 10 Gbps       - RÃ©seau 100 Mbps
```

**ConsÃ©quences** :
- Kubernetes standard est trop lourd
- Besoin de distributions lÃ©gÃ¨res (K3s, MicroK8s)
- Applications doivent Ãªtre optimisÃ©es

### 2. ConnectivitÃ© intermittente

Les edge devices peuvent perdre la connexion :

```
Edge Device en mer sur un bateau :
â”œâ”€â”€ 80% du temps : Pas de connexion satellite
â”œâ”€â”€ 15% du temps : Connexion satellite lente
â””â”€â”€ 5% du temps : Connexion au port

â†’ Doit fonctionner en mode autonome !
```

### 3. Gestion Ã  grande Ã©chelle

GÃ©rer 1000 edge locations vs 3 datacenters cloud :

```
Datacenter Cloud :
- 3 clusters Ã  gÃ©rer
- AccÃ¨s SSH facile
- Ã‰quipe IT sur place

Edge :
- 1000 edge devices Ã  gÃ©rer
- AccÃ¨s physique difficile
- Souvent aucun IT sur place
- Mises Ã  jour OTA (Over The Air) obligatoires
```

### 4. HÃ©tÃ©rogÃ©nÃ©itÃ© du matÃ©riel

```
Edge Device 1 : Raspberry Pi 4 (ARM)
Edge Device 2 : Intel NUC (x86)
Edge Device 3 : NVIDIA Jetson (ARM + GPU)
Edge Device 4 : PC industriel (x86)

â†’ Images Docker multi-arch nÃ©cessaires
```

### 5. SÃ©curitÃ© physique

Un edge device peut Ãªtre physiquement accessible :
- Vol du device
- AccÃ¨s USB direct
- RedÃ©marrage avec autre OS

**Mitigations** :
- Chiffrement du disque
- Secure boot
- TPM (Trusted Platform Module)
- DÃ©tection de tampering

### 6. Conditions environnementales

Edge devices opÃ¨rent dans des environnements variÃ©s :
```
- Usine : Chaleur, poussiÃ¨re, vibrations
- ExtÃ©rieur : Froid, humiditÃ©, tempÃ©rature extrÃªme
- VÃ©hicule : Vibrations, variations de tension
```

**Solutions** :
- MatÃ©riel industriel (ruggedized)
- Refroidissement passif
- Watchdog matÃ©riel

## Distributions Kubernetes pour l'Edge

### 1. K3s : Le champion de l'Edge

**K3s** (prononcÃ© "K-three-s") est une distribution Kubernetes ultra-lÃ©gÃ¨re par Rancher.

#### CaractÃ©ristiques

- **Binaire unique** : ~70 MB (vs 1+ GB pour Kubernetes standard)
- **Faible empreinte** : ~512 MB RAM minimum
- **SQLite par dÃ©faut** : Pas besoin d'etcd
- **Architecture ARM** : Parfait pour Raspberry Pi
- **Installation en 30 secondes** : `curl -sfL https://get.k3s.io | sh -`

#### Ce qui est retirÃ© de K3s vs Kubernetes

- Drivers cloud propriÃ©taires (AWS, Azure, GCP)
- Composants alpha/beta non essentiels
- Plugins de stockage legacy

#### Ce qui est inclus par dÃ©faut

- âœ… Traefik Ingress Controller
- âœ… ServiceLB (simple load balancer)
- âœ… Local Path Provisioner (stockage)
- âœ… CoreDNS
- âœ… Metrics Server

#### Installation de K3s

```bash
# Sur un Raspberry Pi, Ubuntu, ou n'importe quel Linux

# Installation simple (single node)
curl -sfL https://get.k3s.io | sh -

# VÃ©rifier
sudo k3s kubectl get nodes

# Alias pour kubectl
alias kubectl='sudo k3s kubectl'

# Installation sans Traefik (si vous voulez NGINX)
curl -sfL https://get.k3s.io | sh -s - --disable traefik

# Installation en mode agent (pour un cluster)
curl -sfL https://get.k3s.io | K3S_URL=https://server:6443 K3S_TOKEN=xxx sh -
```

#### K3s en mode High Availability

```bash
# Server 1
curl -sfL https://get.k3s.io | sh -s - server \
  --cluster-init \
  --tls-san=k3s.example.com

# Server 2 et 3
curl -sfL https://get.k3s.io | sh -s - server \
  --server https://server1:6443 \
  --token=xxx
```

### 2. MicroK8s : SimplicitÃ© et addons

**MicroK8s** (que vous connaissez dÃ©jÃ  !) est Ã©galement excellent pour l'edge :

**Avantages pour l'Edge** :
- Installation via snap (simple)
- Addons activables en un clic
- Mises Ã  jour automatiques
- Fonctionne sur ARM (Raspberry Pi)

**Installation sur Raspberry Pi** :

```bash
sudo snap install microk8s --classic --channel=1.28/stable

# Sur Raspberry Pi, limiter les ressources
microk8s enable dns storage

# DÃ©sactiver les addons non essentiels pour Ã©conomiser RAM
```

### 3. KubeEdge : Kubernetes natif pour l'Edge

**KubeEdge** est un projet CNCF spÃ©cifiquement conÃ§u pour l'edge computing.

#### Architecture KubeEdge

```
Cloud (Hub) :
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kubernetes        â”‚
â”‚  + CloudCore       â”‚ â† Composant KubeEdge
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Connexion Internet (peut Ãªtre intermittente)
         â”‚
Edge :   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EdgeCore          â”‚ â† Agent lÃ©ger KubeEdge
â”‚  + Edge Runtime    â”‚
â”‚  + Pods            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### FonctionnalitÃ©s uniques

- **Mode autonome** : Edge fonctionne mÃªme si la connexion cloud est coupÃ©e
- **Device management** : Gestion native de devices IoT (MQTT, Modbus)
- **Edge mesh** : Communication entre edge nodes sans passer par le cloud
- **Bandwidth optimization** : MÃ©tadonnÃ©es synchronisÃ©es, pas de verbositÃ©

#### Installation KubeEdge

```bash
# Sur le cloud cluster (hub)
kubectl apply -f https://raw.githubusercontent.com/kubeedge/kubeedge/master/build/crds/devices/devices_v1alpha2_device.yaml
keadm init --advertise-address=<cloud-ip> --kubeedge-version=v1.15.0

# Sur l'edge node
keadm join --cloudcore-ipport=<cloud-ip>:10000 --token=<token>
```

### 4. K0s : Zero Friction Kubernetes

**K0s** (prononcÃ© "k-zero-s") est une autre distribution lÃ©gÃ¨re.

```bash
# Installation
curl -sSLf https://get.k0s.sh | sudo sh

# DÃ©marrer
sudo k0s install controller --single

# kubectl intÃ©grÃ©
sudo k0s kubectl get nodes
```

**CaractÃ©ristiques** :
- Binaire unique (~300 MB)
- Zero dÃ©pendances (tout inclus)
- Support multi-plateforme
- Bon pour l'edge et pour le lab

### 5. Comparaison des distributions Edge

| CritÃ¨re | K3s | MicroK8s | KubeEdge | K0s |
|---------|-----|----------|----------|-----|
| **Taille** | 70 MB | 200 MB | Core: 50 MB | 300 MB |
| **RAM min** | 512 MB | 512 MB | 256 MB | 512 MB |
| **Installation** | cURL | Snap | keadm | cURL |
| **ARM support** | âœ… Excellent | âœ… Bon | âœ… Excellent | âœ… Bon |
| **Offline** | âš ï¸ LimitÃ© | âš ï¸ LimitÃ© | âœ… Natif | âš ï¸ LimitÃ© |
| **IoT devices** | âŒ | âŒ | âœ… Natif | âŒ |
| **HA natif** | âœ… Oui | âœ… Oui | âš ï¸ Complexe | âœ… Oui |
| **MaturitÃ©** | TrÃ¨s mature | Mature | Jeune | Jeune |
| **CommunautÃ©** | Grande | Moyenne | Moyenne | Petite |
| **IdÃ©al pour** | Edge gÃ©nÃ©ral | Lab/Dev | IoT Edge | Lab/Edge |

## Architecture Edge avec Kubernetes

### ModÃ¨le Hub and Spoke

L'architecture la plus commune pour l'edge :

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Cloud Hub     â”‚
                    â”‚   (Kubernetes)  â”‚
                    â”‚                 â”‚
                    â”‚  - Gestion      â”‚
                    â”‚  - Monitoring   â”‚
                    â”‚  - AgrÃ©gation   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              â”‚              â”‚
         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”
         â”‚ Edge 1  â”‚    â”‚ Edge 2  â”‚   â”‚ Edge 3  â”‚
         â”‚ (K3s)   â”‚    â”‚ (K3s)   â”‚   â”‚ (K3s)   â”‚
         â”‚         â”‚    â”‚         â”‚   â”‚         â”‚
         â”‚ Usine A â”‚    â”‚ Magasin â”‚   â”‚ VÃ©hiculeâ”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
              â”‚              â”‚              â”‚
         [Capteurs]     [CamÃ©ras]      [GPS/Sensors]
```

### ModÃ¨le Regional Edge

HiÃ©rarchie Ã  plusieurs niveaux :

```
                    [Cloud Central]
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚               â”‚               â”‚
    [Regional Edge]  [Regional Edge]  [Regional Edge]
     (EU-West)        (US-East)        (Asia)
          â”‚               â”‚               â”‚
    â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”
[Edge 1][Edge 2] [Edge 3][Edge 4] [Edge 5][Edge 6]
```

**Avantages** :
- RÃ©duction de latence multi-niveaux
- AgrÃ©gation rÃ©gionale avant envoi au cloud central
- RÃ©silience (si cloud central down, regional edge continue)

### ModÃ¨le Mesh

Les edge nodes communiquent entre eux :

```
     [Edge 1] â†â†’ [Edge 2]
         â†•  â•²    â•±  â†•
         â†•    â•²â•±    â†•
         â†•    â•±â•²    â†•
         â†•  â•±    â•²  â†•
     [Edge 3] â†â†’ [Edge 4]
```

**Cas d'usage** :
- VÃ©hicules communiquant entre eux (V2V)
- Drones en essaim
- Robots collaboratifs

## Gestion centralisÃ©e de l'Edge

### 1. Rancher + Fleet pour l'Edge

**Fleet** est le systÃ¨me de GitOps de Rancher optimisÃ© pour l'edge.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Rancher Server (Cloud)     â”‚
â”‚   + Fleet Controller         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        Git Repository
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          â”‚          â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
â”‚ Fleet â”‚  â”‚ Fleet â”‚  â”‚ Fleet â”‚
â”‚ Agent â”‚  â”‚ Agent â”‚  â”‚ Agent â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ K3s 1 â”‚  â”‚ K3s 2 â”‚  â”‚ K3s 3 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### DÃ©ployer avec Fleet

```yaml
# fleet.yaml dans votre Git repo
defaultNamespace: apps

targetCustomizations:
# Configuration pour les edge devices ARM
- name: arm
  clusterSelector:
    matchLabels:
      arch: arm64
  helm:
    values:
      image:
        repository: myapp/arm64
        tag: v1.0.0

# Configuration pour les edge devices x86
- name: x86
  clusterSelector:
    matchLabels:
      arch: amd64
  helm:
    values:
      image:
        repository: myapp/amd64
        tag: v1.0.0
```

Fleet dÃ©ploie automatiquement la bonne version selon l'architecture !

### 2. ArgoCD pour l'Edge

ArgoCD peut gÃ©rer des edge clusters, mais nÃ©cessite une connexion :

```yaml
apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: edge-deployments
spec:
  generators:
  - clusters:
      selector:
        matchLabels:
          environment: edge
  template:
    metadata:
      name: '{{name}}-app'
    spec:
      project: default
      source:
        repoURL: https://github.com/myorg/edge-apps
        path: 'apps/{{metadata.labels.location}}'
      destination:
        server: '{{server}}'
        namespace: default
```

### 3. Flux pour l'Edge

Flux supporte bien l'edge car il fonctionne en "pull" :

```bash
# Sur chaque edge cluster
flux bootstrap github \
  --owner=myorg \
  --repository=edge-fleet \
  --branch=main \
  --path=clusters/{{cluster-name}}
```

Chaque edge cluster "tire" sa configuration depuis Git.

## Stockage Ã  l'Edge

### DÃ©fis du stockage Edge

Les edge devices ont des contraintes de stockage :
- âš ï¸ Espace limitÃ© (souvent <256 GB)
- âš ï¸ Pas de SAN/NAS disponible
- âš ï¸ Disques locaux peuvent tomber en panne

### Solutions de stockage

#### 1. Local Path Provisioner

Stockage local simple (inclus dans K3s) :

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: local-storage
spec:
  accessModes:
  - ReadWriteOnce
  storageClassName: local-path
  resources:
    requests:
      storage: 10Gi
```

#### 2. Longhorn pour l'Edge

Si vous avez plusieurs edge nodes proches :

```bash
# Installer Longhorn sur K3s
kubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/master/deploy/longhorn.yaml
```

Longhorn rÃ©plique les donnÃ©es entre nodes pour rÃ©silience.

#### 3. Edge CSI Drivers

Pour du matÃ©riel spÃ©cifique :
- USB drives : local-path
- SD cards : local-path avec prÃ©cautions
- Industrial SATA : standard CSI drivers

#### 4. Stockage Ã©phÃ©mÃ¨re

Pour des donnÃ©es temporaires :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: edge-processor
spec:
  containers:
  - name: processor
    image: myapp:v1
    volumeMounts:
    - name: temp-storage
      mountPath: /tmp/data
  volumes:
  - name: temp-storage
    emptyDir:
      sizeLimit: 5Gi
```

DonnÃ©es perdues au redÃ©marrage du Pod (acceptable pour du traitement temporaire).

## RÃ©seau et connectivitÃ©

### 1. Gestion de la connectivitÃ© intermittente

Les applications edge doivent gÃ©rer la perte de connexion :

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: edge-config
data:
  connectivity.yaml: |
    # Mode de fonctionnement
    mode: hybrid

    # Quand connectÃ© au cloud
    online:
      sync_interval: 5m
      send_telemetry: true
      fetch_updates: true

    # Quand offline
    offline:
      buffer_data: true
      buffer_max_size: 1GB
      local_processing_only: true

    # Transition online â†’ offline
    on_disconnect:
      - save_state
      - buffer_queue
      - local_mode

    # Transition offline â†’ online
    on_reconnect:
      - sync_buffered_data
      - fetch_missed_updates
      - resume_cloud_sync
```

### 2. VPN/Tunnel pour accÃ¨s sÃ©curisÃ©

AccÃ©der Ã  vos edge devices depuis le cloud :

#### Option 1 : WireGuard

```bash
# Sur chaque edge device
apt install wireguard

# Configuration WireGuard
cat > /etc/wireguard/wg0.conf <<EOF
[Interface]
PrivateKey = <edge-private-key>
Address = 10.200.1.2/24

[Peer]
PublicKey = <cloud-public-key>
Endpoint = cloud.example.com:51820
AllowedIPs = 10.200.0.0/16
PersistentKeepalive = 25
EOF

# DÃ©marrer
wg-quick up wg0
```

#### Option 2 : Tailscale

Solution plus simple (mais service tiers) :

```bash
# Sur chaque edge device
curl -fsSL https://tailscale.com/install.sh | sh
tailscale up

# AccÃ¨s automatique via rÃ©seau mesh chiffrÃ©
```

### 3. Service Mesh pour l'Edge

#### Linkerd Edge

Linkerd fonctionne bien sur l'edge (lÃ©ger) :

```bash
# Sur cluster edge K3s
linkerd install --crds | kubectl apply -f -
linkerd install | kubectl apply -f -
```

#### K8s Gateway API pour l'Edge

```yaml
apiVersion: gateway.networking.k8s.io/v1beta1
kind: Gateway
metadata:
  name: edge-gateway
spec:
  gatewayClassName: traefik
  listeners:
  - name: http
    protocol: HTTP
    port: 80
```

## Monitoring et ObservabilitÃ© Edge

### DÃ©fis du monitoring Edge

- 1000 edge locations = 1000 dashboards Ã  surveiller ?
- DonnÃ©es de monitoring volumineuses
- Besoin d'agrÃ©gation intelligente

### Architecture de monitoring

```
Edge Devices :
[Prometheus Agent] â”€â”€â”
[Prometheus Agent] â”€â”€â”¼â”€â”€â†’ Remote Write â†’ [Prometheus Central]
[Prometheus Agent] â”€â”€â”˜                            â”‚
                                                  â†“
                                            [Grafana]
```

#### Configuration Prometheus Agent Mode

Sur chaque edge device :

```yaml
# prometheus-agent.yaml
global:
  external_labels:
    edge_location: 'factory-paris'
    edge_id: 'edge-001'

remote_write:
- url: https://prometheus-central.example.com/api/v1/write
  queue_config:
    capacity: 10000
    max_samples_per_send: 1000
    batch_send_deadline: 5s
  # Retry en cas de perte de connexion
  queue_config:
    max_shards: 10
    min_shards: 1
```

### Monitoring local et alertes critiques

Pour les alertes critiques, ne dÃ©pendez pas du cloud :

```yaml
# Alertmanager local sur l'edge
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
data:
  alertmanager.yml: |
    route:
      receiver: 'edge-local'
      routes:
      # Alertes critiques â†’ Action locale immÃ©diate
      - match:
          severity: critical
        receiver: 'local-action'
        continue: true
      # Toutes les alertes â†’ Envoi au cloud (si connectÃ©)
      - receiver: 'cloud-hub'

    receivers:
    - name: 'local-action'
      webhook_configs:
      - url: 'http://emergency-handler:8080/alert'

    - name: 'cloud-hub'
      webhook_configs:
      - url: 'https://alerting-hub.example.com/edge-alerts'
        send_resolved: true
```

### Logs Edge

#### Option 1 : Loki avec agrÃ©gation

```yaml
# Promtail sur edge (collecte logs)
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
spec:
  template:
    spec:
      containers:
      - name: promtail
        image: grafana/promtail:latest
        args:
        - -config.file=/etc/promtail/promtail.yaml
        volumeMounts:
        - name: config
          mountPath: /etc/promtail
        - name: varlog
          mountPath: /var/log
```

Configuration Promtail pour buffer offline :

```yaml
positions:
  filename: /tmp/positions.yaml

clients:
- url: https://loki-central.example.com/loki/api/v1/push
  # Buffer important pour gÃ©rer les dÃ©connexions
  batchwait: 5s
  batchsize: 102400
  timeout: 10s
  # Retry
  backoff_config:
    min_period: 500ms
    max_period: 5m
    max_retries: 10
```

#### Option 2 : Logs locaux rotatifs

Pour environnements trÃ¨s contraints :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: myapp:v1
    volumeMounts:
    - name: logs
      mountPath: /var/log/app
  # Sidecar pour rotation de logs
  - name: log-rotator
    image: busybox
    command:
    - sh
    - -c
    - |
      while true; do
        find /var/log/app -name "*.log" -size +50M -delete
        sleep 3600
      done
    volumeMounts:
    - name: logs
      mountPath: /var/log/app
  volumes:
  - name: logs
    emptyDir:
      sizeLimit: 500Mi
```

## SÃ©curitÃ© Ã  l'Edge

### DÃ©fis de sÃ©curitÃ© Edge

Les edge devices sont plus vulnÃ©rables :
- âŒ AccÃ¨s physique possible
- âŒ RÃ©seau local potentiellement non sÃ©curisÃ©
- âŒ Difficile Ã  superviser en temps rÃ©el
- âŒ Mises Ã  jour compliquÃ©es

### Bonnes pratiques de sÃ©curitÃ©

#### 1. Chiffrement des donnÃ©es au repos

```bash
# Chiffrer le disque avec LUKS
cryptsetup luksFormat /dev/sda1
cryptsetup luksOpen /dev/sda1 encrypted-disk
```

#### 2. Secure Boot et Attestation

```bash
# VÃ©rifier que Secure Boot est activÃ©
mokutil --sb-state

# Configuration TPM pour attestation
tpm2_getrandom 16 --hex
```

#### 3. Network Policies strictes

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: edge-security
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Autoriser uniquement le trafic local
  - from:
    - podSelector: {}
  egress:
  # Autoriser uniquement cloud hub et DNS
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
  - to:
    - podSelector: {}
  - to:
    - ipBlock:
        cidr: 203.0.113.0/24  # IP du cloud hub
    ports:
    - protocol: TCP
      port: 443
```

#### 4. Secrets chiffrÃ©s

Utiliser Sealed Secrets ou SOPS :

```bash
# Chiffrer un secret avec SOPS
sops --encrypt --gcp-kms projects/my-project/locations/global/keyRings/my-ring/cryptoKeys/my-key \
  secret.yaml > secret.enc.yaml

# DÃ©ployer sur edge
kubectl apply -f secret.enc.yaml
```

#### 5. Read-only filesystem

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: secure-edge-app
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
  containers:
  - name: app
    image: myapp:v1
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
    volumeMounts:
    - name: tmp
      mountPath: /tmp
  volumes:
  - name: tmp
    emptyDir: {}
```

#### 6. Surveillance des intrusions

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: falco
spec:
  template:
    spec:
      containers:
      - name: falco
        image: falcosecurity/falco:latest
        securityContext:
          privileged: true
        volumeMounts:
        - name: docker-socket
          mountPath: /var/run/docker.sock
```

## Mise Ã  jour et maintenance Edge

### StratÃ©gies de mise Ã  jour

#### 1. Over-The-Air (OTA) Updates

Mise Ã  jour sans intervention physique :

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: edge-updater
data:
  update-policy.yaml: |
    schedule: "0 3 * * 0"  # Dimanche Ã  3h du matin

    strategy:
      type: rolling
      max_unavailable: 20%  # Max 20% des edges en update simultanÃ©ment

    pre_update:
      - health_check
      - backup_config
      - notify_hub

    post_update:
      - verify_version
      - smoke_tests
      - report_status

    rollback:
      auto: true
      on_failure: true
      timeout: 30m
```

#### 2. Canary Updates

Tester d'abord sur un sous-ensemble :

```yaml
# Fleet GitOps
apiVersion: fleet.cattle.io/v1alpha1
kind: GitRepo
metadata:
  name: edge-apps
spec:
  repo: https://github.com/myorg/edge-fleet
  branch: main

  # DÃ©ploiement progressif
  targets:
  # Phase 1: 5% des edges (canary)
  - name: canary
    clusterSelector:
      matchLabels:
        canary: "true"

  # Phase 2: 25% aprÃ¨s 24h
  - name: rollout-25
    clusterSelector:
      matchLabels:
        wave: "1"

  # Phase 3: 100% aprÃ¨s 48h
  - name: rollout-all
    clusterSelector:
      matchLabels:
        edge: "true"
```

#### 3. Atomic Updates avec OSTree

Pour les mises Ã  jour systÃ¨me complÃ¨tes :

```bash
# Utiliser Flatcar Linux ou Fedora CoreOS
rpm-ostree status
rpm-ostree upgrade
systemctl reboot
```

Si problÃ¨me â†’ rollback automatique au boot.

## Exemple complet : SystÃ¨me Edge de dÃ©tection d'intrusion

### Architecture

```
Edge Location (Usine):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Intel NUC avec K3s                â”‚
â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  CamÃ©ras IP (10x)            â”‚  â”‚
â”‚  â”‚    â†“                         â”‚  â”‚
â”‚  â”‚  Video Ingestion Service     â”‚  â”‚
â”‚  â”‚    â†“                         â”‚  â”‚
â”‚  â”‚  AI Detection (TensorFlow)   â”‚  â”‚
â”‚  â”‚    â†“                         â”‚  â”‚
â”‚  â”‚  Alert Manager               â”‚  â”‚
â”‚  â”‚    â†“                         â”‚  â”‚
â”‚  â”‚  â”œâ”€â†’ Local Actions           â”‚  â”‚
â”‚  â”‚  â””â”€â†’ Cloud Notification      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â”‚
â”‚  Prometheus + Grafana (local)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Manifestes Kubernetes

#### 1. Video Ingestion

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: video-ingestion
spec:
  replicas: 1
  selector:
    matchLabels:
      app: video-ingestion
  template:
    metadata:
      labels:
        app: video-ingestion
    spec:
      containers:
      - name: ingestion
        image: myapp/video-ingestion:v1
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        env:
        - name: CAMERA_URLS
          valueFrom:
            configMapKeyRef:
              name: camera-config
              key: urls
        - name: FRAME_RATE
          value: "5"  # 5 FPS pour Ã©conomiser CPU
        volumeMounts:
        - name: video-buffer
          mountPath: /tmp/frames
      volumes:
      - name: video-buffer
        emptyDir:
          sizeLimit: 2Gi
```

#### 2. AI Detection

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-detection
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ai-detection
  template:
    metadata:
      labels:
        app: ai-detection
    spec:
      # Affinity pour GPU si disponible
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: nvidia.com/gpu
                operator: Exists
      containers:
      - name: detector
        image: myapp/ai-detector:v1
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
            nvidia.com/gpu: 1  # Si GPU disponible
        env:
        - name: MODEL_PATH
          value: "/models/intrusion-detection-v2.pb"
        - name: CONFIDENCE_THRESHOLD
          value: "0.85"
        volumeMounts:
        - name: models
          mountPath: /models
          readOnly: true
        - name: video-buffer
          mountPath: /tmp/frames
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: ai-models
      - name: video-buffer
        emptyDir:
          sizeLimit: 2Gi
```

#### 3. Alert Manager

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alert-manager
spec:
  replicas: 1
  selector:
    matchLabels:
      app: alert-manager
  template:
    spec:
      containers:
      - name: alerter
        image: myapp/alert-manager:v1
        env:
        - name: ALERT_WEBHOOK_LOCAL
          value: "http://local-siren:8080/trigger"
        - name: ALERT_WEBHOOK_CLOUD
          valueFrom:
            secretKeyRef:
              name: cloud-credentials
              key: webhook-url
        - name: OFFLINE_MODE
          value: "true"  # Continue en mode offline
```

#### 4. Configuration des camÃ©ras

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: camera-config
data:
  urls: |
    rtsp://camera1.local:554/stream
    rtsp://camera2.local:554/stream
    rtsp://camera3.local:554/stream
    rtsp://camera4.local:554/stream
    rtsp://camera5.local:554/stream
```

### DÃ©ploiement et gestion

```bash
# DÃ©ploiement initial
kubectl apply -f edge-intrusion-detection/

# Monitoring
kubectl get pods
kubectl logs -f deployment/ai-detection

# Mise Ã  jour du modÃ¨le AI
kubectl cp nouveau-model.pb ai-detection-xxx:/models/

# RedÃ©marrage pour charger nouveau modÃ¨le
kubectl rollout restart deployment/ai-detection
```

## Conclusion

L'**Edge Computing avec Kubernetes** reprÃ©sente l'avenir de nombreux secteurs industriels. En rapprochant le traitement des donnÃ©es de leur source, vous obtenez des latences ultra-faibles, une rÃ©silience accrue et une meilleure utilisation de la bande passante.

### Points clÃ©s Ã  retenir

1. **Edge Computing** = Traitement local, prÃ¨s de la source de donnÃ©es
2. **Kubernetes lÃ©ger** : K3s, MicroK8s pour ressources limitÃ©es
3. **Architecture Hub & Spoke** : Gestion centralisÃ©e, exÃ©cution distribuÃ©e
4. **RÃ©silience offline** : Les edge devices doivent fonctionner sans cloud
5. **GitOps** : Fleet, ArgoCD pour dÃ©ploiement Ã  grande Ã©chelle
6. **Monitoring hiÃ©rarchique** : Local pour critique, agrÃ©gÃ© pour tendances
7. **SÃ©curitÃ© renforcÃ©e** : AccÃ¨s physique possible = protections accrues
8. **Mises Ã  jour OTA** : Essentielles pour maintenir 1000+ devices

### Recommandations pour MicroK8s en Edge

**Pour apprendre l'edge** :
- Installez MicroK8s sur un Raspberry Pi
- Simulez une perte de connexion (dÃ©branchez Ethernet)
- Testez que vos apps continuent de fonctionner
- Explorez K3s pour comparer

**Pour un lab edge** :
- 2-3 Raspberry Pi ou Intel NUC
- Un cluster "hub" pour la gestion
- GitOps avec Fleet ou ArgoCD
- Monitoring avec Prometheus/Grafana

**Cas d'usage rÃ©alistes** :
- Home automation (domotique)
- Lab de surveillance vidÃ©o
- Monitoring de capteurs IoT
- Traitement local de donnÃ©es

### Ã‰volution future de l'Edge

**Tendances Ã©mergentes** :
- **5G MEC** : Edge computing intÃ©grÃ© aux antennes 5G
- **WebAssembly** : Alternative aux conteneurs pour l'edge ultra-lÃ©ger
- **Edge AI** : ModÃ¨les ML optimisÃ©s pour edge devices
- **Serverless Edge** : Fonctions edge sans serveur (Cloudflare Workers)
- **Edge native apps** : Applications conÃ§ues dÃ¨s le dÃ©part pour l'edge

### Quand choisir l'Edge ?

**âœ… OUI si** :
- Latence <50ms critique
- Bande passante limitÃ©e/coÃ»teuse
- Besoin de fonctionnement offline
- DonnÃ©es sensibles (vie privÃ©e)
- IoT avec nombreux capteurs

**âŒ NON si** :
- Latence de 500ms acceptable
- Bande passante illimitÃ©e
- Connexion stable garantie
- Pas de contraintes de donnÃ©es
- ComplexitÃ© opÃ©rationnelle Ã  Ã©viter

### Prochaines Ã©tapes

AprÃ¨s avoir explorÃ© l'Edge Computing, vous pourriez vous intÃ©resser Ã  :
- **25.6 Machine Learning sur Kubernetes** : IntÃ©gration de ML/AI dans K8s
- **25.3 Operators** : Automatiser la gestion d'apps complexes en edge
- **19. Scaling et Autoscaling** : Adapter aux ressources limitÃ©es

---

**Ressources complÃ©mentaires** :

- K3s Documentation : https://docs.k3s.io/
- KubeEdge : https://kubeedge.io/
- CNCF Edge Computing Landscape : https://landscape.cncf.io/card-mode?category=edge-computing
- Rancher Fleet : https://fleet.rancher.io/
- Edge Native Working Group : https://github.com/cncf/tag-runtime/tree/master/wg-edge-native
- Awesome Edge Computing : https://github.com/qijianpeng/awesome-edge-computing

â­ï¸ [Machine Learning sur Kubernetes](/25-aller-plus-loin/06-machine-learning-sur-kubernetes.md)
