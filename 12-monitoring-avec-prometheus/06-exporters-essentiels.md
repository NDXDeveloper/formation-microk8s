üîù Retour au [Sommaire](/SOMMAIRE.md)

# 12.6 Exporters essentiels (node, kube-state, cAdvisor)

## Introduction

Dans les sections pr√©c√©dentes, nous avons appris √† utiliser PromQL pour interroger des m√©triques. Mais d'o√π viennent toutes ces m√©triques ? Comment Prometheus sait-il combien de CPU utilise un pod, combien de m√©moire consomme un node, ou combien de pods sont en cours d'ex√©cution ?

C'est le r√¥le des **exporters** : des programmes sp√©cialis√©s qui collectent des informations depuis diff√©rentes sources et les exposent dans un format que Prometheus peut comprendre.

Lorsque vous avez install√© Prometheus avec MicroK8s, trois exporters essentiels ont √©t√© automatiquement d√©ploy√©s :

1. **Node Exporter** : M√©triques du syst√®me d'exploitation et du mat√©riel
2. **kube-state-metrics** : √âtat des objets Kubernetes
3. **cAdvisor** : M√©triques de performance des conteneurs

Ces trois exporters forment la **triade fondamentale** du monitoring Kubernetes. Ensemble, ils fournissent une vue compl√®te de votre cluster.

## Comprendre les exporters

### Qu'est-ce qu'un exporter ?

Un **exporter** est un programme qui :
1. Collecte des informations depuis une source (syst√®me, base de donn√©es, API)
2. Les transforme au format Prometheus
3. Les expose sur un endpoint HTTP (g√©n√©ralement `/metrics`)
4. Attend que Prometheus vienne les r√©cup√©rer (scraping)

### Analogie simple

Imaginez un traducteur dans une r√©union internationale :
- **La source** : Une personne qui parle japonais (le syst√®me d'exploitation)
- **L'exporter** : Le traducteur qui convertit en anglais (format Prometheus)
- **Prometheus** : La personne anglophone qui √©coute (scraping)

Sans le traducteur, Prometheus ne pourrait pas comprendre ce que dit le syst√®me.

### Format des m√©triques Prometheus

Les exporters exposent des m√©triques dans un format texte simple :

```
# HELP node_cpu_seconds_total Seconds the CPUs spent in each mode.
# TYPE node_cpu_seconds_total counter
node_cpu_seconds_total{cpu="0",mode="idle"} 123456.78
node_cpu_seconds_total{cpu="0",mode="user"} 12345.67
node_cpu_seconds_total{cpu="1",mode="idle"} 123450.12

# HELP node_memory_MemTotal_bytes Total memory in bytes.
# TYPE node_memory_MemTotal_bytes gauge
node_memory_MemTotal_bytes 8589934592
```

**√âl√©ments** :
- `# HELP` : Description de la m√©trique
- `# TYPE` : Type (counter, gauge, histogram, summary)
- Ligne de m√©trique : `nom{labels} valeur`

## Node Exporter : Les m√©triques syst√®me

### Qu'est-ce que Node Exporter ?

**Node Exporter** collecte les m√©triques au niveau du **syst√®me d'exploitation** et du **mat√©riel** de chaque node (serveur) de votre cluster Kubernetes.

**Analogie** : C'est comme un m√©decin qui prend les signes vitaux d'un patient (temp√©rature, pression, pouls). Node Exporter prend les "signes vitaux" de chaque serveur.

### D√©ploiement dans MicroK8s

Node Exporter est d√©ploy√© comme un **DaemonSet**, ce qui signifie qu'il y a exactement **un pod par node**.

V√©rifiez son √©tat :

```bash
microk8s kubectl get daemonset node-exporter -n monitoring
```

R√©sultat attendu :

```
NAME            DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR
node-exporter   1         1         1       1            1           <none>
```

**DESIRED = nombre de nodes** : Si vous avez 3 nodes, vous aurez 3 pods node-exporter.

### Cat√©gories de m√©triques Node Exporter

Node Exporter collecte des centaines de m√©triques regroup√©es en cat√©gories :

#### 1. CPU (Processeur)

**M√©trique principale** : `node_cpu_seconds_total`

C'est un **counter** qui compte le temps CPU cumul√© pass√© dans diff√©rents modes.

**Modes CPU** :
- **idle** : Inactif (le CPU ne fait rien)
- **user** : Temps pass√© √† ex√©cuter des applications utilisateur
- **system** : Temps pass√© dans le noyau Linux (kernel)
- **iowait** : Temps pass√© √† attendre des I/O (disque, r√©seau)
- **irq** : Temps pass√© √† g√©rer les interruptions mat√©rielles
- **nice** : Temps pass√© sur des processus basse priorit√©
- **steal** : Temps "vol√©" (en environnement virtualis√©)

**Requ√™tes PromQL utiles** :

```promql
# Utilisation CPU en % (moyenne de tous les cores)
100 - (avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# Utilisation CPU par core
100 - (rate(node_cpu_seconds_total{mode="idle"}[5m]) * 100)

# Temps d'attente I/O (peut indiquer un probl√®me de disque)
rate(node_cpu_seconds_total{mode="iowait"}[5m]) * 100

# CPU utilis√© par les applications
rate(node_cpu_seconds_total{mode="user"}[5m]) * 100
```

#### 2. M√©moire (RAM)

Node Exporter expose de nombreuses m√©triques m√©moire issues de `/proc/meminfo`.

**M√©triques principales** :

```
node_memory_MemTotal_bytes       # Total de RAM
node_memory_MemFree_bytes        # RAM libre
node_memory_MemAvailable_bytes   # RAM disponible (mieux que MemFree)
node_memory_Buffers_bytes        # RAM utilis√©e pour les buffers
node_memory_Cached_bytes         # RAM utilis√©e pour le cache
node_memory_SwapTotal_bytes      # Total swap
node_memory_SwapFree_bytes       # Swap libre
```

**Diff√©rence importante** :
- **MemFree** : RAM compl√®tement inutilis√©e (souvent faible, c'est normal)
- **MemAvailable** : RAM effectivement disponible pour de nouveaux processus (inclut cache lib√©rable)

**Requ√™tes PromQL utiles** :

```promql
# M√©moire utilis√©e en bytes
node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes

# M√©moire utilis√©e en %
((node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) /
 node_memory_MemTotal_bytes) * 100

# M√©moire disponible en GB
node_memory_MemAvailable_bytes / 1024 / 1024 / 1024

# Swap utilis√© (alerte si > 0, c'est souvent mauvais signe)
node_memory_SwapTotal_bytes - node_memory_SwapFree_bytes

# Utilisation du cache (normal qu'elle soit √©lev√©e)
node_memory_Cached_bytes / 1024 / 1024 / 1024
```

#### 3. Disque (Stockage)

**M√©triques filesystem** :

```
node_filesystem_size_bytes       # Taille totale
node_filesystem_free_bytes       # Espace libre
node_filesystem_avail_bytes      # Espace disponible (peut √™tre < free)
node_filesystem_files             # Nombre total d'inodes
node_filesystem_files_free        # Inodes libres
```

**Labels importants** :
- `mountpoint` : Point de montage (ex: `/`, `/home`, `/mnt/data`)
- `fstype` : Type de syst√®me de fichiers (ext4, xfs, etc.)

**Requ√™tes PromQL utiles** :

```promql
# Espace disque utilis√© en %
(node_filesystem_size_bytes - node_filesystem_avail_bytes) /
node_filesystem_size_bytes * 100

# Espace libre en GB
node_filesystem_avail_bytes / 1024 / 1024 / 1024

# Filesystems √† plus de 80% d'utilisation
((node_filesystem_size_bytes - node_filesystem_avail_bytes) /
 node_filesystem_size_bytes) > 0.8

# Utilisation par mountpoint
((node_filesystem_size_bytes - node_filesystem_avail_bytes) /
 node_filesystem_size_bytes * 100) and
 node_filesystem_mountpoint != ""
```

**M√©triques I/O disque** :

```
node_disk_read_bytes_total       # Octets lus (counter)
node_disk_written_bytes_total    # Octets √©crits (counter)
node_disk_reads_completed_total  # Nombre de lectures
node_disk_writes_completed_total # Nombre d'√©critures
node_disk_io_time_seconds_total  # Temps pass√© en I/O
```

**Requ√™tes PromQL utiles** :

```promql
# Taux de lecture en MB/s
rate(node_disk_read_bytes_total[5m]) / 1024 / 1024

# Taux d'√©criture en MB/s
rate(node_disk_written_bytes_total[5m]) / 1024 / 1024

# I/O total (lecture + √©criture)
(rate(node_disk_read_bytes_total[5m]) +
 rate(node_disk_written_bytes_total[5m])) / 1024 / 1024

# IOPS (op√©rations I/O par seconde)
rate(node_disk_reads_completed_total[5m]) +
rate(node_disk_writes_completed_total[5m])
```

#### 4. R√©seau

**M√©triques r√©seau** :

```
node_network_receive_bytes_total    # Octets re√ßus (counter)
node_network_transmit_bytes_total   # Octets transmis (counter)
node_network_receive_packets_total  # Paquets re√ßus
node_network_transmit_packets_total # Paquets transmis
node_network_receive_errs_total     # Erreurs en r√©ception
node_network_transmit_errs_total    # Erreurs en transmission
node_network_receive_drop_total     # Paquets dropp√©s en r√©ception
node_network_transmit_drop_total    # Paquets dropp√©s en transmission
```

**Label important** :
- `device` : Interface r√©seau (eth0, ens160, wlan0, lo, etc.)

**Requ√™tes PromQL utiles** :

```promql
# Trafic entrant en MB/s
rate(node_network_receive_bytes_total[5m]) / 1024 / 1024

# Trafic sortant en MB/s
rate(node_network_transmit_bytes_total[5m]) / 1024 / 1024

# Bande passante totale (entr√©e + sortie)
(rate(node_network_receive_bytes_total[5m]) +
 rate(node_network_transmit_bytes_total[5m])) / 1024 / 1024

# Erreurs r√©seau (mauvais signe si > 0)
rate(node_network_receive_errs_total[5m]) +
rate(node_network_transmit_errs_total[5m])

# Paquets dropp√©s
rate(node_network_receive_drop_total[5m]) +
rate(node_network_transmit_drop_total[5m])
```

#### 5. Load Average (Charge syst√®me)

**M√©triques** :

```
node_load1   # Load average sur 1 minute
node_load5   # Load average sur 5 minutes
node_load15  # Load average sur 15 minutes
```

**Qu'est-ce que le load average ?**

Le load average repr√©sente le **nombre moyen de processus en attente d'ex√©cution** (dans la file d'attente du CPU).

**Interpr√©tation** :
- **Load < nombre de CPUs** : ‚úÖ Syst√®me pas surcharg√©
- **Load = nombre de CPUs** : ‚ö†Ô∏è Syst√®me √† pleine charge
- **Load > nombre de CPUs** : ‚ùå Syst√®me surcharg√© (processus en attente)

**Exemple** :
- Serveur avec 4 CPUs et load de 2.0 ‚Üí OK, seulement 50% utilis√©
- Serveur avec 4 CPUs et load de 8.0 ‚Üí Probl√®me, 2x trop de charge

**Requ√™tes PromQL utiles** :

```promql
# Load average 1 minute
node_load1

# Load par CPU (pour normaliser)
node_load1 / count(node_cpu_seconds_total{mode="idle"}) without (cpu, mode)

# Alerte si load > 80% de la capacit√© CPU
node_load1 / count(node_cpu_seconds_total{mode="idle"}) without (cpu, mode) > 0.8
```

#### 6. Uptime et boot time

```
node_boot_time_seconds  # Timestamp du dernier d√©marrage
node_time_seconds       # Heure actuelle du syst√®me
```

**Requ√™tes PromQL utiles** :

```promql
# Uptime en secondes
time() - node_boot_time_seconds

# Uptime en heures
(time() - node_boot_time_seconds) / 3600

# Uptime en jours
(time() - node_boot_time_seconds) / 86400

# Nodes red√©marr√©s r√©cemment (moins de 1h)
(time() - node_boot_time_seconds) < 3600
```

### Acc√©der directement aux m√©triques Node Exporter

Vous pouvez consulter les m√©triques expos√©es par Node Exporter :

```bash
# Port-forward vers node-exporter
microk8s kubectl port-forward -n monitoring daemonset/node-exporter 9100:9100

# Dans un autre terminal, r√©cup√©rez les m√©triques
curl http://localhost:9100/metrics
```

Vous verrez des centaines de lignes de m√©triques au format Prometheus.

## kube-state-metrics : L'√©tat de Kubernetes

### Qu'est-ce que kube-state-metrics ?

**kube-state-metrics** est un service qui interroge l'**API Kubernetes** et expose l'**√©tat des objets** comme des m√©triques Prometheus.

**Diff√©rence cl√©** :
- **Node Exporter** : M√©triques du syst√®me d'exploitation (niveau infrastructure)
- **kube-state-metrics** : M√©triques Kubernetes (niveau orchestration)

**Analogie** : Si Kubernetes √©tait une entreprise :
- **Node Exporter** : Surveille l'√©tat des bureaux (√©lectricit√©, climatisation, etc.)
- **kube-state-metrics** : Surveille l'organisation (combien d'employ√©s, qui est en cong√©, quels projets sont actifs, etc.)

### D√©ploiement dans MicroK8s

kube-state-metrics est d√©ploy√© comme un **Deployment** (g√©n√©ralement 1 r√©plica).

V√©rifiez son √©tat :

```bash
microk8s kubectl get deployment kube-state-metrics -n monitoring
```

### Cat√©gories de m√©triques kube-state-metrics

#### 1. Pods

**M√©triques principales** :

```
kube_pod_info                           # Informations g√©n√©rales sur les pods
kube_pod_status_phase                   # Phase du pod (Running, Pending, Failed, etc.)
kube_pod_status_ready                   # Statut ready du pod
kube_pod_container_status_ready         # Statut ready de chaque conteneur
kube_pod_container_status_restarts_total # Nombre de restarts
kube_pod_container_status_waiting       # Conteneur en attente
kube_pod_container_status_terminated    # Conteneur termin√©
```

**Labels importants** :
- `namespace` : Namespace du pod
- `pod` : Nom du pod
- `container` : Nom du conteneur
- `phase` : Phase actuelle (Running, Pending, Failed, Succeeded, Unknown)

**Requ√™tes PromQL utiles** :

```promql
# Nombre total de pods
count(kube_pod_info)

# Pods par namespace
count(kube_pod_info) by (namespace)

# Pods running
count(kube_pod_status_phase{phase="Running"})

# Pods en erreur (Failed ou Unknown)
count(kube_pod_status_phase{phase=~"Failed|Unknown"})

# Pods avec restarts √©lev√©s (> 5)
kube_pod_container_status_restarts_total > 5

# Top 10 des pods avec le plus de restarts
topk(10, kube_pod_container_status_restarts_total)

# Pods not ready
kube_pod_status_ready{condition="false"}
```

#### 2. Deployments

**M√©triques principales** :

```
kube_deployment_status_replicas              # Nombre de replicas souhait√©
kube_deployment_status_replicas_available    # Replicas disponibles
kube_deployment_status_replicas_unavailable  # Replicas indisponibles
kube_deployment_status_replicas_updated      # Replicas √† jour
kube_deployment_spec_replicas                # Replicas sp√©cifi√©s dans le spec
```

**Requ√™tes PromQL utiles** :

```promql
# Deployments avec des replicas manquants
kube_deployment_status_replicas_available < kube_deployment_spec_replicas

# Ratio de disponibilit√©
kube_deployment_status_replicas_available / kube_deployment_spec_replicas

# Deployments non √† jour (rolling update en cours)
kube_deployment_status_replicas_updated < kube_deployment_spec_replicas

# Liste des deployments incomplets
kube_deployment_status_replicas{namespace="production"} !=
kube_deployment_status_replicas_available{namespace="production"}
```

#### 3. Nodes

**M√©triques principales** :

```
kube_node_info                    # Informations sur les nodes
kube_node_status_condition        # Conditions des nodes (Ready, MemoryPressure, etc.)
kube_node_status_allocatable      # Ressources allocables (CPU, m√©moire)
kube_node_status_capacity         # Capacit√© totale
kube_node_spec_unschedulable      # Node marqu√© comme non planifiable
```

**Conditions importantes** :
- **Ready** : Node pr√™t √† accepter des pods
- **MemoryPressure** : M√©moire faible
- **DiskPressure** : Disque faible
- **PIDPressure** : Trop de processus
- **NetworkUnavailable** : R√©seau indisponible

**Requ√™tes PromQL utiles** :

```promql
# Nombre de nodes ready
count(kube_node_status_condition{condition="Ready", status="true"})

# Nodes not ready
kube_node_status_condition{condition="Ready", status="false"}

# Nodes avec pression m√©moire
kube_node_status_condition{condition="MemoryPressure", status="true"}

# Capacit√© CPU totale du cluster
sum(kube_node_status_capacity{resource="cpu"})

# Capacit√© m√©moire totale du cluster (en GB)
sum(kube_node_status_capacity{resource="memory"}) / 1024 / 1024 / 1024
```

#### 4. Services

**M√©triques principales** :

```
kube_service_info            # Informations sur les services
kube_service_spec_type       # Type de service (ClusterIP, NodePort, LoadBalancer)
kube_service_status_load_balancer_ingress  # Ingress du LoadBalancer
```

**Requ√™tes PromQL utiles** :

```promql
# Nombre total de services
count(kube_service_info)

# Services par type
count(kube_service_info) by (type)

# Services LoadBalancer
kube_service_spec_type{type="LoadBalancer"}
```

#### 5. PersistentVolumes et PersistentVolumeClaims

**M√©triques principales** :

```
kube_persistentvolume_status_phase              # Phase du PV (Available, Bound, Released, Failed)
kube_persistentvolumeclaim_status_phase         # Phase du PVC
kube_persistentvolume_capacity_bytes            # Capacit√© du PV
kube_persistentvolumeclaim_resource_requests_storage_bytes  # Stockage demand√©
```

**Requ√™tes PromQL utiles** :

```promql
# PVCs non bound
kube_persistentvolumeclaim_status_phase{phase!="Bound"}

# Capacit√© totale de stockage disponible
sum(kube_persistentvolume_capacity_bytes) / 1024 / 1024 / 1024

# PVs par phase
count(kube_persistentvolume_status_phase) by (phase)
```

#### 6. Jobs et CronJobs

**M√©triques principales** :

```
kube_job_status_succeeded        # Job r√©ussi
kube_job_status_failed           # Job √©chou√©
kube_job_complete                # Job termin√©
kube_cronjob_next_schedule_time  # Prochaine ex√©cution du CronJob
```

**Requ√™tes PromQL utiles** :

```promql
# Jobs √©chou√©s
kube_job_status_failed > 0

# Jobs actifs
kube_job_status_active

# Temps avant la prochaine ex√©cution d'un CronJob (en minutes)
(kube_cronjob_next_schedule_time - time()) / 60
```

#### 7. Namespaces

**M√©triques principales** :

```
kube_namespace_status_phase      # Phase du namespace (Active, Terminating)
kube_namespace_labels            # Labels du namespace
```

**Requ√™tes PromQL utiles** :

```promql
# Nombre de namespaces
count(kube_namespace_status_phase)

# Namespaces en cours de suppression
kube_namespace_status_phase{phase="Terminating"}
```

#### 8. Resource Quotas et LimitRanges

**M√©triques principales** :

```
kube_resourcequota                    # Quotas de ressources
kube_resourcequota_used               # Utilisation des quotas
kube_limitrange                       # LimitRanges configur√©s
```

**Requ√™tes PromQL utiles** :

```promql
# Utilisation des quotas en %
(kube_resourcequota_used / kube_resourcequota) * 100

# Namespaces proches de leurs limites de quota
(kube_resourcequota_used / kube_resourcequota) > 0.9
```

### Acc√©der directement aux m√©triques kube-state-metrics

```bash
# Port-forward vers kube-state-metrics
microk8s kubectl port-forward -n monitoring deployment/kube-state-metrics 8080:8080

# Dans un autre terminal
curl http://localhost:8080/metrics
```

## cAdvisor : M√©triques de performance des conteneurs

### Qu'est-ce que cAdvisor ?

**cAdvisor** (Container Advisor) collecte les **m√©triques de performance** des conteneurs : utilisation CPU, m√©moire, r√©seau, I/O.

**Particularit√©** : cAdvisor est **int√©gr√© dans Kubelet**, le composant Kubernetes qui s'ex√©cute sur chaque node. Vous n'avez donc pas besoin de le d√©ployer s√©par√©ment.

**Diff√©rences avec les autres exporters** :

| Exporter | Focus | Niveau |
|----------|-------|--------|
| Node Exporter | M√©triques syst√®me/mat√©riel | Infrastructure (OS) |
| kube-state-metrics | √âtat des objets K8s | Orchestration (K8s API) |
| cAdvisor | Performance des conteneurs | Runtime (conteneurs) |

**Analogie** : Si votre cluster √©tait une ville :
- **Node Exporter** : Surveille l'√©tat des routes, de l'√©lectricit√©, de l'eau
- **kube-state-metrics** : Surveille le cadastre (quels b√¢timents, o√π, dans quel √©tat)
- **cAdvisor** : Surveille l'activit√© dans chaque b√¢timent (consommation √©lectrique, occupation)

### M√©triques cAdvisor

#### 1. CPU des conteneurs

**M√©trique principale** : `container_cpu_usage_seconds_total`

Type : **Counter** (temps CPU cumul√© en secondes)

**Labels importants** :
- `namespace` : Namespace Kubernetes
- `pod` : Nom du pod
- `container` : Nom du conteneur
- `image` : Image du conteneur

**Requ√™tes PromQL utiles** :

```promql
# Utilisation CPU par conteneur (en cores)
rate(container_cpu_usage_seconds_total[5m])

# En pourcentage (supposant 1 core)
rate(container_cpu_usage_seconds_total[5m]) * 100

# Top 10 des conteneurs utilisant le plus de CPU
topk(10, rate(container_cpu_usage_seconds_total{container!=""}[5m]))

# Moyenne CPU par namespace
avg(rate(container_cpu_usage_seconds_total{container!=""}[5m])) by (namespace)

# CPU utilis√© vs limite
rate(container_cpu_usage_seconds_total[5m]) /
on(namespace,pod,container) container_spec_cpu_quota * 100000
```

#### 2. M√©moire des conteneurs

**M√©triques principales** :

```
container_memory_usage_bytes          # Utilisation m√©moire actuelle
container_memory_working_set_bytes    # M√©moire de travail (plus pr√©cis)
container_memory_rss                  # Resident Set Size
container_memory_cache                # M√©moire cache
container_memory_swap                 # Swap utilis√©
```

**Diff√©rence importante** :
- `container_memory_usage_bytes` : Inclut le cache
- `container_memory_working_set_bytes` : M√©moire r√©ellement utilis√©e (recommand√©)

**Requ√™tes PromQL utiles** :

```promql
# Utilisation m√©moire actuelle
container_memory_working_set_bytes

# En megabytes
container_memory_working_set_bytes / 1024 / 1024

# Top 10 des conteneurs utilisant le plus de m√©moire
topk(10, container_memory_working_set_bytes{container!=""})

# Utilisation vs limite (en %)
(container_memory_working_set_bytes / container_spec_memory_limit_bytes) * 100

# Conteneurs d√©passant 80% de leur limite
(container_memory_working_set_bytes / container_spec_memory_limit_bytes) > 0.8

# M√©moire totale utilis√©e par namespace
sum(container_memory_working_set_bytes{container!=""}) by (namespace) / 1024 / 1024 / 1024
```

#### 3. R√©seau des conteneurs

**M√©triques principales** :

```
container_network_receive_bytes_total     # Octets re√ßus (counter)
container_network_transmit_bytes_total    # Octets transmis (counter)
container_network_receive_packets_total   # Paquets re√ßus
container_network_transmit_packets_total  # Paquets transmis
container_network_receive_errors_total    # Erreurs en r√©ception
container_network_transmit_errors_total   # Erreurs en transmission
```

**Requ√™tes PromQL utiles** :

```promql
# Trafic entrant en MB/s
rate(container_network_receive_bytes_total[5m]) / 1024 / 1024

# Trafic sortant en MB/s
rate(container_network_transmit_bytes_total[5m]) / 1024 / 1024

# Bande passante totale par pod
sum(rate(container_network_receive_bytes_total[5m]) +
    rate(container_network_transmit_bytes_total[5m])) by (pod) / 1024 / 1024

# Erreurs r√©seau
rate(container_network_receive_errors_total[5m]) +
rate(container_network_transmit_errors_total[5m])
```

#### 4. I/O disque des conteneurs

**M√©triques principales** :

```
container_fs_reads_bytes_total   # Octets lus
container_fs_writes_bytes_total  # Octets √©crits
container_fs_usage_bytes         # Espace disque utilis√©
container_fs_limit_bytes         # Limite d'espace disque
```

**Requ√™tes PromQL utiles** :

```promql
# Taux de lecture en MB/s
rate(container_fs_reads_bytes_total[5m]) / 1024 / 1024

# Taux d'√©criture en MB/s
rate(container_fs_writes_bytes_total[5m]) / 1024 / 1024

# Utilisation disque en %
(container_fs_usage_bytes / container_fs_limit_bytes) * 100

# Conteneurs avec utilisation disque > 80%
(container_fs_usage_bytes / container_fs_limit_bytes) > 0.8
```

#### 5. Ressources requests et limits

**M√©triques principales** :

```
container_spec_cpu_quota          # CPU quota (limite)
container_spec_cpu_shares         # CPU shares (requests)
container_spec_memory_limit_bytes # Limite m√©moire
container_spec_memory_reservation_bytes # Requests m√©moire
```

**Requ√™tes PromQL utiles** :

```promql
# Ratio utilisation / limite CPU
rate(container_cpu_usage_seconds_total[5m]) /
(container_spec_cpu_quota / 100000)

# Ratio utilisation / limite m√©moire
container_memory_working_set_bytes / container_spec_memory_limit_bytes

# Conteneurs sans limites (dangereux)
container_memory_working_set_bytes and
on(namespace,pod,container) container_spec_memory_limit_bytes == 0
```

### Acc√©der aux m√©triques cAdvisor

cAdvisor est accessible via Kubelet :

```bash
# cAdvisor √©coute sur le port 10250 de Kubelet
# Les m√©triques sont disponibles via l'endpoint /metrics/cadvisor
```

Dans MicroK8s, Prometheus est automatiquement configur√© pour scraper cAdvisor.

## Comparaison des trois exporters

### Tableau r√©capitulatif

| Aspect | Node Exporter | kube-state-metrics | cAdvisor |
|--------|---------------|-------------------|----------|
| **Focus** | Syst√®me/Mat√©riel | √âtat K8s | Performance conteneurs |
| **Source** | /proc, /sys | API Kubernetes | Cgroups |
| **D√©ploiement** | DaemonSet | Deployment | Int√©gr√© (Kubelet) |
| **Type m√©triques** | Gauge, Counter | Gauge principalement | Counter, Gauge |
| **Exemples** | CPU host, RAM, disque | Pods ready, Deployments | CPU pod, RAM pod |

### Quelle m√©trique utiliser ?

**Pour surveiller le node (machine physique/VM)** :
‚Üí **Node Exporter**
```promql
# CPU du node
node_cpu_seconds_total
# RAM du node
node_memory_MemAvailable_bytes
```

**Pour surveiller l'√©tat des objets Kubernetes** :
‚Üí **kube-state-metrics**
```promql
# Nombre de pods
kube_pod_status_phase
# √âtat des deployments
kube_deployment_status_replicas_available
```

**Pour surveiller la performance des conteneurs/pods** :
‚Üí **cAdvisor**
```promql
# CPU du pod
container_cpu_usage_seconds_total
# RAM du pod
container_memory_working_set_bytes
```

### Exemple de requ√™te combin√©e

Souvent, vous combinerez des m√©triques de diff√©rents exporters :

```promql
# Ratio : CPU pods / CPU total du node
sum(rate(container_cpu_usage_seconds_total{container!=""}[5m])) /
sum(rate(node_cpu_seconds_total{mode!="idle"}[5m]))

# M√©moire utilis√©e par les pods vs capacit√© du node
sum(container_memory_working_set_bytes{container!=""}) /
node_memory_MemTotal_bytes
```

## V√©rifier que les exporters fonctionnent

### Via l'interface Prometheus

1. Acc√©dez √† Prometheus : `http://localhost:9090`
2. Allez dans **Status > Targets**
3. V√©rifiez que les targets sont **UP** :

```
monitoring/node-exporter/0        ‚úÖ UP
monitoring/kube-state-metrics/0   ‚úÖ UP
monitoring/kubelet/0              ‚úÖ UP (cAdvisor)
```

### Via des requ√™tes PromQL

**Test Node Exporter** :

```promql
up{job="node-exporter"}
```

Devrait retourner `1` si actif.

**Test kube-state-metrics** :

```promql
up{job="kube-state-metrics"}
```

**Test cAdvisor** :

```promql
up{job="kubelet"}
```

### Via kubectl

**V√©rifier les pods** :

```bash
microk8s kubectl get pods -n monitoring
```

Tous les pods doivent √™tre en √©tat `Running`.

**Logs des exporters** :

```bash
# Node Exporter
microk8s kubectl logs -n monitoring daemonset/node-exporter

# kube-state-metrics
microk8s kubectl logs -n monitoring deployment/kube-state-metrics
```

## Bonnes pratiques

### 1. Ne filtrez pas les m√©triques trop t√¥t

Au d√©but, laissez tous les exporters collecter toutes leurs m√©triques. Vous pourrez filtrer plus tard si n√©cessaire pour r√©duire la cardinalit√©.

### 2. Utilisez les bons agr√©gateurs

```promql
# ‚úÖ Bon : sum pour additionner
sum(container_memory_usage_bytes)

# ‚úÖ Bon : avg pour moyenner
avg(node_cpu_seconds_total)

# ‚ùå Mauvais : sum sur un gauge peut donner des r√©sultats absurdes
sum(node_load1)  # Additionner des load averages n'a pas de sens
```

### 3. Attention aux labels vides

cAdvisor expose des m√©triques pour les conteneurs syst√®me avec `container=""`. Filtrez-les souvent :

```promql
# Sans filtre : inclut les conteneurs syst√®me
container_memory_usage_bytes

# ‚úÖ Filtr√© : uniquement vos conteneurs
container_memory_usage_bytes{container!=""}

# Encore mieux : exclure aussi POD
container_memory_usage_bytes{container!="",container!="POD"}
```

### 4. Comprenez requests vs limits

```promql
# Utilisation vs requests (ce que vous avez demand√©)
container_memory_working_set_bytes /
container_spec_memory_reservation_bytes

# Utilisation vs limits (maximum autoris√©)
container_memory_working_set_bytes /
container_spec_memory_limit_bytes
```

### 5. Utilisez les m√©triques appropri√©es

Pour la **m√©moire des conteneurs**, utilisez `container_memory_working_set_bytes` plut√¥t que `container_memory_usage_bytes` car c'est ce que Kubernetes utilise pour les d√©cisions d'OOM (Out of Memory).

### 6. Documentez vos requ√™tes

Gardez un document avec vos requ√™tes favorites annot√©es :

```promql
# Top 10 pods par utilisation CPU
# Utile pour identifier les pods gourmands
topk(10, rate(container_cpu_usage_seconds_total{container!=""}[5m]))

# Alerte si un pod d√©passe 90% de sa limite m√©moire
# Aide √† pr√©venir les OOMKilled
(container_memory_working_set_bytes / container_spec_memory_limit_bytes) > 0.9
```

## D√©pannage

### Probl√®me : M√©triques Node Exporter manquantes

**V√©rifications** :

1. Le DaemonSet est-il running ?

```bash
microk8s kubectl get pods -n monitoring -l app.kubernetes.io/name=node-exporter
```

2. Le pod peut-il acc√©der √† /proc et /sys ?

Node Exporter a besoin de volumes hostPath pour acc√©der au syst√®me.

### Probl√®me : M√©triques kube-state-metrics manquantes

**V√©rifications** :

1. Le deployment est-il running ?

```bash
microk8s kubectl get deployment kube-state-metrics -n monitoring
```

2. A-t-il les permissions RBAC ?

kube-state-metrics a besoin de permissions pour lire l'API Kubernetes.

```bash
microk8s kubectl get clusterrole kube-state-metrics
```

### Probl√®me : M√©triques cAdvisor manquantes

**V√©rifications** :

1. Kubelet est-il accessible ?

```promql
up{job="kubelet"}
```

2. Les certificats sont-ils valides ?

Prometheus a besoin des bons certificats pour acc√©der √† Kubelet.

## Ressources suppl√©mentaires

### Documentation officielle

- **Node Exporter** : https://github.com/prometheus/node_exporter
- **kube-state-metrics** : https://github.com/kubernetes/kube-state-metrics
- **cAdvisor** : https://github.com/google/cadvisor

### Dashboards Grafana recommand√©s

- **Node Exporter Full** : ID 1860
- **Kubernetes / Compute Resources / Cluster** : ID 7249
- **Kubernetes / Compute Resources / Pod** : ID 6417

(Nous verrons comment importer ces dashboards dans le chapitre Grafana)

## R√©sum√©

Dans cette section, vous avez appris :

‚úÖ **Le concept d'exporters** et leur r√¥le dans Prometheus
‚úÖ **Node Exporter** pour les m√©triques syst√®me (CPU, RAM, disque, r√©seau)
‚úÖ **kube-state-metrics** pour l'√©tat des objets Kubernetes (pods, deployments, nodes)
‚úÖ **cAdvisor** pour les m√©triques de performance des conteneurs
‚úÖ **Les diff√©rences** entre les trois exporters et quand utiliser chacun
‚úÖ **Des requ√™tes PromQL pratiques** pour chaque exporter
‚úÖ **Comment v√©rifier** que les exporters fonctionnent correctement
‚úÖ **Les bonnes pratiques** pour interroger les m√©triques

**Points cl√©s √† retenir** :

1. Ces trois exporters forment la **base du monitoring Kubernetes**
2. **Node Exporter** = niveau infrastructure (OS/hardware)
3. **kube-state-metrics** = niveau orchestration (objets K8s)
4. **cAdvisor** = niveau application (conteneurs)
5. Combinez-les pour avoir une **vue compl√®te** de votre cluster

Dans la prochaine section (12.7), nous d√©couvrirons les **Recording Rules**, un m√©canisme pour optimiser Prometheus en pr√©-calculant des requ√™tes complexes.

---

**Conseil pratique** : Cr√©ez un dashboard Grafana simple avec quelques m√©triques de chaque exporter pour vous familiariser avec leurs diff√©rences. Cela vous aidera √† mieux comprendre quelle m√©trique utiliser dans chaque situation !

‚è≠Ô∏è [Recording rules et optimisation](/12-monitoring-avec-prometheus/07-recording-rules-et-optimisation.md)
