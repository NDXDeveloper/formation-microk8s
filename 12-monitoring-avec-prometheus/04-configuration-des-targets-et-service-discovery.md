üîù Retour au [Sommaire](/SOMMAIRE.md)

# 12.4 Configuration des targets et service discovery

## Introduction

Dans un environnement traditionnel, vous devez dire manuellement √† votre syst√®me de monitoring : "Surveille cette machine √† l'adresse 192.168.1.10, et celle-ci √† 192.168.1.11, etc." C'est fastidieux et source d'erreurs.

Dans Kubernetes, les choses changent constamment. Les pods sont cr√©√©s, d√©truits, d√©plac√©s. Leurs adresses IP changent. Comment Prometheus peut-il suivre tout cela automatiquement ?

C'est tout l'enjeu du **Service Discovery** (d√©couverte de services).

## Le probl√®me : Un environnement dynamique

Imaginez ce sc√©nario typique dans Kubernetes :

```
09:00 - Vous d√©ployez une application avec 3 r√©plicas
      ‚Üí 3 pods cr√©√©s avec des IPs : 10.1.1.5, 10.1.1.6, 10.1.1.7

10:30 - Un pod crash, Kubernetes le recr√©e
      ‚Üí Nouvelle IP : 10.1.1.12

14:00 - Vous scalez √† 5 r√©plicas
      ‚Üí 2 nouveaux pods : 10.1.1.18, 10.1.1.19

16:00 - Mise √† jour de l'application (rolling update)
      ‚Üí Tous les pods sont recr√©√©s avec de nouvelles IPs
```

**Question** : Comment Prometheus peut-il suivre toutes ces applications sans intervention manuelle ?

**R√©ponse** : Le Service Discovery automatique !

## Qu'est-ce que le Service Discovery ?

Le **Service Discovery** est le m√©canisme par lequel Prometheus d√©couvre automatiquement :
- **Quoi surveiller** : Quels pods, services, ou endpoints scraper
- **O√π les trouver** : Leurs adresses IP et ports
- **Comment les identifier** : Leurs labels et m√©tadonn√©es

### Analogie simple

Imaginez un facteur (Prometheus) qui doit distribuer du courrier (collecter des m√©triques). Dans un quartier traditionnel, il a une liste fixe d'adresses. Mais dans un quartier Kubernetes, les maisons apparaissent et disparaissent constamment, et changent d'adresse !

Le Service Discovery, c'est comme si le facteur avait acc√®s √† un registre en temps r√©el de toutes les maisons du quartier, avec leurs nouvelles adresses. Il n'a plus besoin d'une liste manuelle, il consulte simplement le registre.

## Comment fonctionne le Service Discovery dans Kubernetes ?

Prometheus utilise l'**API Kubernetes** comme source de v√©rit√©. Voici le processus :

```
1. Prometheus interroge l'API Kubernetes
   "Donne-moi la liste de tous les pods/services/endpoints"

2. L'API Kubernetes r√©pond avec tous les objets et leurs m√©tadonn√©es
   (noms, labels, IPs, ports, namespaces, etc.)

3. Prometheus filtre selon les r√®gles configur√©es
   "Je veux uniquement les pods avec le label 'monitoring=enabled'"

4. Prometheus extrait les informations n√©cessaires
   (IP, port, chemin /metrics)

5. Prometheus commence √† scraper ces targets

6. Ce processus se r√©p√®te r√©guli√®rement (toutes les 30 secondes par d√©faut)
```

### Le r√¥le de Prometheus Operator

MicroK8s utilise **Prometheus Operator**, qui simplifie √©norm√©ment la configuration. Au lieu de modifier directement la configuration Prometheus (fichier YAML complexe), vous cr√©ez simplement des objets Kubernetes sp√©ciaux :

- **ServiceMonitor** : Pour surveiller des Services Kubernetes
- **PodMonitor** : Pour surveiller des Pods directement
- **Probe** : Pour surveiller des endpoints externes

Ces objets sont automatiquement d√©tect√©s par Prometheus Operator qui met √† jour la configuration de Prometheus.

## ServiceMonitor : Surveiller via les Services

### Qu'est-ce qu'un ServiceMonitor ?

Un **ServiceMonitor** est un objet Kubernetes qui dit √† Prometheus :

> "Surveille tous les Pods derri√®re ce Service Kubernetes"

C'est la m√©thode recommand√©e car elle utilise les Services, qui sont l'abstraction standard de Kubernetes pour exposer des applications.

### Anatomie d'un ServiceMonitor

Voici un exemple simple :

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: mon-application
  namespace: default
  labels:
    app: mon-app
spec:
  # Quel Service surveiller ?
  selector:
    matchLabels:
      app: mon-app

  # Configuration du scraping
  endpoints:
    - port: metrics        # Nom du port (d√©fini dans le Service)
      path: /metrics       # Chemin de l'endpoint
      interval: 30s        # Fr√©quence de scraping
```

**Explication ligne par ligne** :

1. **apiVersion** : Version de l'API (fournie par Prometheus Operator)
2. **kind: ServiceMonitor** : Type d'objet
3. **metadata** : Informations sur le ServiceMonitor lui-m√™me
4. **selector.matchLabels** : "Trouve les Services avec ces labels"
5. **endpoints** : Configuration de comment scraper

### Comment √ßa marche ?

```
1. Vous cr√©ez un Service pour votre application :

   Service "mon-app" avec label app=mon-app
   ‚îú‚îÄ‚îÄ S√©lectionne les pods avec app=mon-app
   ‚îî‚îÄ‚îÄ Expose le port "metrics" (9090)

2. Vous cr√©ez un ServiceMonitor :

   ServiceMonitor cherche les Services avec label app=mon-app
   ‚Üí Trouve le Service "mon-app"
   ‚Üí D√©couvre les Pods derri√®re ce Service
   ‚Üí Configure Prometheus pour les scraper

3. Prometheus scrape automatiquement :

   http://pod-1:9090/metrics
   http://pod-2:9090/metrics
   http://pod-3:9090/metrics
```

### Exemple complet

Voici un exemple complet avec une application :

**1. D√©ploiement de l'application** :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mon-app
  namespace: default
spec:
  replicas: 3
  selector:
    matchLabels:
      app: mon-app
  template:
    metadata:
      labels:
        app: mon-app
    spec:
      containers:
      - name: app
        image: mon-app:v1.0
        ports:
        - name: metrics      # Important : nom du port
          containerPort: 9090
```

**2. Service associ√©** :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mon-app
  namespace: default
  labels:
    app: mon-app           # Label pour le ServiceMonitor
spec:
  selector:
    app: mon-app
  ports:
  - name: metrics          # Important : m√™me nom que dans le pod
    port: 9090
    targetPort: metrics
```

**3. ServiceMonitor** :

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: mon-app
  namespace: default
  labels:
    prometheus: kube-prometheus  # Important pour √™tre d√©tect√©
spec:
  selector:
    matchLabels:
      app: mon-app
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

**4. Prometheus scrape automatiquement** :

Apr√®s quelques secondes, Prometheus d√©tecte le ServiceMonitor et commence √† scraper les 3 pods de l'application.

### Label important : prometheus

Pour que Prometheus Operator d√©tecte votre ServiceMonitor, il doit avoir un label sp√©cifique. Par d√©faut dans MicroK8s :

```yaml
labels:
  prometheus: kube-prometheus
```

Ou pour surveiller dans tous les namespaces :

```yaml
labels:
  release: prometheus
```

**Comment savoir quel label utiliser ?**

V√©rifiez la configuration de votre Prometheus :

```bash
microk8s kubectl get prometheus -n monitoring prometheus-k8s -o yaml | grep serviceMonitorSelector -A5
```

## PodMonitor : Surveiller des Pods directement

### Quand utiliser un PodMonitor ?

Utilisez un **PodMonitor** quand :
- Vous voulez surveiller des pods qui n'ont pas de Service
- Vous voulez plus de contr√¥le granulaire
- Vous utilisez un StatefulSet avec des endpoints individuels

### Anatomie d'un PodMonitor

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: mon-app-pods
  namespace: default
  labels:
    prometheus: kube-prometheus
spec:
  # Quels Pods surveiller ?
  selector:
    matchLabels:
      app: mon-app

  # Configuration du scraping
  podMetricsEndpoints:
  - port: metrics
    path: /metrics
    interval: 30s
```

**Diff√©rence avec ServiceMonitor** :

- **ServiceMonitor** ‚Üí S√©lectionne des Services ‚Üí Surveille les Pods derri√®re
- **PodMonitor** ‚Üí S√©lectionne directement des Pods

### Exemple : Surveiller un StatefulSet

Pour un StatefulSet (comme une base de donn√©es), vous pourriez vouloir surveiller chaque instance individuellement :

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: postgres-monitoring
  namespace: default
  labels:
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: postgres
  podMetricsEndpoints:
  - port: metrics
    path: /metrics
    interval: 15s
  namespaceSelector:
    matchNames:
    - default
```

## Configuration avanc√©e des endpoints

### Plusieurs endpoints par service

Vous pouvez scraper plusieurs endpoints sur le m√™me pod :

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: multi-endpoint-app
spec:
  selector:
    matchLabels:
      app: mon-app
  endpoints:
  - port: metrics        # M√©triques de l'application
    path: /metrics
    interval: 30s
  - port: metrics        # M√©triques business
    path: /business-metrics
    interval: 60s
  - port: http           # M√©triques HTTP
    path: /actuator/prometheus
    interval: 30s
```

### Configuration du timeout

Par d√©faut, Prometheus attend 10 secondes pour chaque scrape. Vous pouvez ajuster :

```yaml
endpoints:
- port: metrics
  path: /metrics
  interval: 30s
  scrapeTimeout: 5s     # Timeout de 5 secondes
```

### Relabeling : Transformer les labels

Le relabeling permet de modifier, ajouter, ou supprimer des labels des m√©triques collect√©es.

**Exemple 1 : Ajouter un label personnalis√©**

```yaml
endpoints:
- port: metrics
  path: /metrics
  relabelings:
  - sourceLabels: [__meta_kubernetes_pod_name]
    targetLabel: pod_name
  - targetLabel: environment
    replacement: production
```

**Exemple 2 : Renommer un label**

```yaml
endpoints:
- port: metrics
  relabelings:
  - sourceLabels: [__meta_kubernetes_namespace]
    targetLabel: k8s_namespace
```

**Exemple 3 : Filtrer certaines m√©triques**

```yaml
endpoints:
- port: metrics
  metricRelabelings:
  - sourceLabels: [__name__]
    regex: 'go_.*'        # Supprime toutes les m√©triques go_*
    action: drop
```

### Authentication et TLS

Pour les endpoints s√©curis√©s :

```yaml
endpoints:
- port: metrics
  path: /metrics
  scheme: https           # Utilise HTTPS
  tlsConfig:
    insecureSkipVerify: true   # Pour les certificats auto-sign√©s
  bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
```

## Labels Kubernetes utilis√©s par le Service Discovery

Prometheus utilise des **meta labels** provenant de Kubernetes pour d√©couvrir et labelliser les targets. Voici les plus importants :

### Meta labels pour les Pods

```
__meta_kubernetes_pod_name                  # Nom du pod
__meta_kubernetes_pod_namespace             # Namespace du pod
__meta_kubernetes_pod_ip                    # IP du pod
__meta_kubernetes_pod_label_<labelname>     # Labels du pod
__meta_kubernetes_pod_annotation_<name>     # Annotations du pod
__meta_kubernetes_pod_node_name             # Node o√π s'ex√©cute le pod
__meta_kubernetes_pod_container_name        # Nom du conteneur
__meta_kubernetes_pod_container_port_name   # Nom du port
__meta_kubernetes_pod_container_port_number # Num√©ro du port
__meta_kubernetes_pod_ready                 # √âtat ready du pod
```

### Meta labels pour les Services

```
__meta_kubernetes_service_name              # Nom du service
__meta_kubernetes_service_namespace         # Namespace du service
__meta_kubernetes_service_label_<labelname> # Labels du service
__meta_kubernetes_service_annotation_<name> # Annotations du service
```

### Exemple d'utilisation

Ces meta labels sont automatiquement ajout√©s par Prometheus, mais vous pouvez les utiliser pour cr√©er vos propres labels :

```yaml
endpoints:
- port: metrics
  relabelings:
  # Cr√©er un label avec le nom du namespace
  - sourceLabels: [__meta_kubernetes_namespace]
    targetLabel: kubernetes_namespace

  # Cr√©er un label avec le nom du pod
  - sourceLabels: [__meta_kubernetes_pod_name]
    targetLabel: pod

  # Ajouter le nom du node
  - sourceLabels: [__meta_kubernetes_pod_node_name]
    targetLabel: node
```

## Configuration via annotations

Une m√©thode alternative (plus simple mais moins flexible) consiste √† utiliser des **annotations** directement sur vos Pods ou Services.

### Annotations Prometheus standard

Ajoutez ces annotations √† votre Deployment/Service :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mon-app
  annotations:
    prometheus.io/scrape: "true"      # Active le scraping
    prometheus.io/port: "9090"        # Port √† scraper
    prometheus.io/path: "/metrics"    # Chemin (d√©faut: /metrics)
    prometheus.io/scheme: "http"      # http ou https
spec:
  # ... reste de la configuration
```

**Note importante** : Cette m√©thode n√©cessite une configuration Prometheus qui recherche ces annotations. Avec Prometheus Operator (utilis√© par MicroK8s), **il est pr√©f√©rable d'utiliser des ServiceMonitors**.

## Namespace selection

Par d√©faut, un ServiceMonitor surveille uniquement les Services dans son propre namespace. Pour surveiller d'autres namespaces :

### Surveiller un namespace sp√©cifique

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: mon-app
  namespace: monitoring
spec:
  namespaceSelector:
    matchNames:
    - default
    - production
  selector:
    matchLabels:
      app: mon-app
  endpoints:
  - port: metrics
```

### Surveiller tous les namespaces

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: mon-app
  namespace: monitoring
spec:
  namespaceSelector:
    any: true              # Surveille tous les namespaces
  selector:
    matchLabels:
      app: mon-app
  endpoints:
  - port: metrics
```

**Attention** : Surveiller tous les namespaces peut cr√©er beaucoup de targets. Utilisez avec pr√©caution.

## V√©rifier le Service Discovery

### Via l'interface web Prometheus

La meilleure fa√ßon de v√©rifier que vos ServiceMonitors fonctionnent :

1. Acc√©dez √† Prometheus : `http://localhost:9090`
2. Allez dans **Status > Service Discovery**
3. Cherchez vos ServiceMonitors dans la liste

Vous verrez :
- Les ServiceMonitors d√©couverts
- Les Services/Pods qu'ils ciblent
- Les labels appliqu√©s
- Les endpoints g√©n√©r√©s

### Via l'interface Targets

1. Allez dans **Status > Targets**
2. Cherchez votre application
3. V√©rifiez que l'√©tat est **UP** (vert)

Si l'√©tat est **DOWN** (rouge), cliquez dessus pour voir l'erreur.

### Via kubectl

Lister tous les ServiceMonitors :

```bash
microk8s kubectl get servicemonitors -n monitoring
```

Voir les d√©tails d'un ServiceMonitor :

```bash
microk8s kubectl describe servicemonitor mon-app -n default
```

V√©rifier les labels d'un ServiceMonitor :

```bash
microk8s kubectl get servicemonitor mon-app -n default --show-labels
```

## Exemples de ServiceMonitors par d√©faut

MicroK8s installe plusieurs ServiceMonitors par d√©faut. Regardons-les :

### ServiceMonitor pour Prometheus lui-m√™me

```bash
microk8s kubectl get servicemonitor prometheus-k8s -n monitoring -o yaml
```

Ce ServiceMonitor indique √† Prometheus de se surveiller lui-m√™me !

### ServiceMonitor pour node-exporter

```bash
microk8s kubectl get servicemonitor node-exporter -n monitoring -o yaml
```

Surveille les m√©triques syst√®me de tous les nodes.

### ServiceMonitor pour kube-state-metrics

```bash
microk8s kubectl get servicemonitor kube-state-metrics -n monitoring -o yaml
```

Surveille l'√©tat des objets Kubernetes.

**Conseil** : √âtudiez ces ServiceMonitors existants pour comprendre comment les configurer.

## Bonnes pratiques

### 1. Utilisez des noms de ports explicites

```yaml
# ‚úÖ Bon
ports:
- name: metrics
  containerPort: 9090

# ‚ùå Moins bon
ports:
- containerPort: 9090
```

Avec un nom explicite, votre ServiceMonitor est plus clair :

```yaml
endpoints:
- port: metrics  # Clair et lisible
```

### 2. Organisez vos ServiceMonitors par namespace

Gardez vos ServiceMonitors dans le m√™me namespace que les applications qu'ils surveillent :

```
Namespace: default
‚îú‚îÄ‚îÄ Deployment: mon-app
‚îú‚îÄ‚îÄ Service: mon-app
‚îî‚îÄ‚îÄ ServiceMonitor: mon-app

Namespace: production
‚îú‚îÄ‚îÄ Deployment: api
‚îú‚îÄ‚îÄ Service: api
‚îî‚îÄ‚îÄ ServiceMonitor: api
```

### 3. Utilisez des labels coh√©rents

Adoptez une convention de nommage pour vos labels :

```yaml
labels:
  app: mon-app
  component: backend
  team: platform
  monitoring: enabled
```

### 4. Documentez vos ServiceMonitors

Ajoutez des annotations pour documenter :

```yaml
metadata:
  name: mon-app
  annotations:
    description: "Surveillance de l'API principale"
    contact: "team-platform@example.com"
    documentation: "https://wiki.example.com/monitoring/api"
```

### 5. Limitez le scope

Ne surveillez que ce qui est n√©cessaire :

```yaml
# ‚úÖ Bon : surveille uniquement le namespace production
namespaceSelector:
  matchNames:
  - production

# ‚ùå √âvitez : surveille tous les namespaces
namespaceSelector:
  any: true
```

### 6. Utilisez un intervalle de scraping adapt√©

```yaml
# M√©triques importantes (APM, erreurs)
endpoints:
- port: metrics
  interval: 15s     # Scrape fr√©quent

# M√©triques moins critiques (statistiques)
endpoints:
- port: stats
  interval: 60s     # Scrape moins fr√©quent
```

### 7. Ajoutez des labels d'environnement

```yaml
endpoints:
- port: metrics
  relabelings:
  - targetLabel: environment
    replacement: production
  - targetLabel: region
    replacement: eu-west-1
```

## D√©pannage du Service Discovery

### Probl√®me 1 : ServiceMonitor cr√©√© mais pas de target

**Sympt√¥mes** :
- ServiceMonitor existe
- Aucune target dans Prometheus

**Causes possibles** :

1. **Label prometheus manquant**

V√©rifiez que votre ServiceMonitor a le bon label :

```bash
microk8s kubectl get servicemonitor mon-app -o yaml | grep prometheus
```

Devrait contenir :

```yaml
labels:
  prometheus: kube-prometheus
```

2. **Selector ne trouve aucun Service**

V√©rifiez que les labels correspondent :

```bash
# Labels du ServiceMonitor
microk8s kubectl get servicemonitor mon-app -o yaml | grep -A3 selector

# Labels du Service
microk8s kubectl get service mon-app --show-labels
```

3. **Namespace incorrect**

Si le ServiceMonitor est dans un namespace diff√©rent, ajoutez :

```yaml
spec:
  namespaceSelector:
    matchNames:
    - default  # Namespace o√π se trouve votre Service
```

### Probl√®me 2 : Target DOWN

**Sympt√¥mes** :
- Target visible dans Prometheus
- √âtat : DOWN (rouge)

**V√©rifications** :

1. **Le pod est-il accessible ?**

```bash
# Test de connectivit√© depuis un pod test
microk8s kubectl run test --rm -it --image=busybox -- wget -O- http://mon-app:9090/metrics
```

2. **Le port est-il correct ?**

V√©rifiez que le port dans le ServiceMonitor correspond :

```bash
# Port dans le Service
microk8s kubectl get service mon-app -o yaml | grep -A5 ports

# Port dans le ServiceMonitor
microk8s kubectl get servicemonitor mon-app -o yaml | grep -A3 endpoints
```

3. **Le chemin /metrics existe-t-il ?**

```bash
# Acc√©dez au pod et testez
microk8s kubectl exec -it mon-app-xxxx -- curl localhost:9090/metrics
```

### Probl√®me 3 : Pas de m√©triques dans Prometheus

**Sympt√¥mes** :
- Target UP
- Mais requ√™tes PromQL ne retournent rien

**Causes possibles** :

1. **L'application n'expose pas de m√©triques**

V√©rifiez manuellement :

```bash
microk8s kubectl port-forward mon-app-xxxx 9090:9090
curl http://localhost:9090/metrics
```

Vous devriez voir des m√©triques au format Prometheus :

```
# HELP http_requests_total Total HTTP requests
# TYPE http_requests_total counter
http_requests_total{method="GET",status="200"} 1547
```

2. **Les m√©triques sont filtr√©es**

V√©rifiez s'il y a des r√®gles de metricRelabelings qui suppriment vos m√©triques.

### Probl√®me 4 : Trop de m√©triques (cardinality explosion)

**Sympt√¥mes** :
- Prometheus utilise beaucoup de RAM
- Ralentissements

**Causes** :
- Trop de labels uniques
- Labels avec des valeurs √† haute cardinalit√© (user_id, timestamp, etc.)

**Solutions** :

Filtrez les m√©triques probl√©matiques :

```yaml
endpoints:
- port: metrics
  metricRelabelings:
  # Supprimer les labels √† haute cardinalit√©
  - sourceLabels: [user_id]
    action: labeldrop
  # Garder seulement certaines m√©triques
  - sourceLabels: [__name__]
    regex: 'http_.*|app_.*'
    action: keep
```

## Monitoring de m√©triques personnalis√©es

### Exposer des m√©triques depuis votre application

Pour que Prometheus puisse surveiller votre application, elle doit exposer des m√©triques.

**Exemple conceptuel en Python** :

```python
from prometheus_client import Counter, Histogram, start_http_server

# Cr√©er des m√©triques
requests_total = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])
request_duration = Histogram('http_request_duration_seconds', 'HTTP request duration')

# Dans votre code
@app.route('/api/users')
def get_users():
    requests_total.labels(method='GET', endpoint='/api/users').inc()
    with request_duration.time():
        # Votre logique m√©tier
        return jsonify(users)

# Exposer les m√©triques sur le port 9090
start_http_server(9090)
```

**D√©ploiement dans Kubernetes** :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mon-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: mon-api
  template:
    metadata:
      labels:
        app: mon-api
    spec:
      containers:
      - name: api
        image: mon-api:v1.0
        ports:
        - name: http
          containerPort: 8080
        - name: metrics      # Port pour Prometheus
          containerPort: 9090
---
apiVersion: v1
kind: Service
metadata:
  name: mon-api
  labels:
    app: mon-api
spec:
  selector:
    app: mon-api
  ports:
  - name: http
    port: 8080
  - name: metrics          # Port pour Prometheus
    port: 9090
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: mon-api
  labels:
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: mon-api
  endpoints:
  - port: metrics
    interval: 30s
```

## R√©sum√©

Dans cette section, vous avez appris :

‚úÖ **Le concept de Service Discovery** et pourquoi il est essentiel dans Kubernetes
‚úÖ **Les ServiceMonitors** pour surveiller via les Services Kubernetes
‚úÖ **Les PodMonitors** pour surveiller directement les Pods
‚úÖ **La configuration avanc√©e** (relabeling, namespaces, authentication)
‚úÖ **Les meta labels Kubernetes** utilis√©s par Prometheus
‚úÖ **Les bonnes pratiques** pour organiser vos configurations
‚úÖ **Le d√©pannage** des probl√®mes de Service Discovery
‚úÖ **Comment exposer** des m√©triques personnalis√©es

**Points cl√©s √† retenir** :

1. Le Service Discovery automatise la d√©couverte des targets
2. ServiceMonitors sont la m√©thode recommand√©e avec Prometheus Operator
3. Les labels sont cruciaux pour le matching
4. V√©rifiez toujours dans l'UI Prometheus que vos targets sont UP
5. Commencez simple, ajoutez de la complexit√© progressivement

Dans la prochaine section (12.5), nous plongerons dans **PromQL**, le langage de requ√™te de Prometheus, pour apprendre √† interroger et analyser toutes ces m√©triques que nous collectons.

---

**Conseil pratique** : Cr√©ez un ServiceMonitor simple pour une application de test, v√©rifiez qu'il fonctionne dans l'UI Prometheus, puis ajoutez progressivement des fonctionnalit√©s avanc√©es. L'apprentissage it√©ratif est la meilleure approche !

‚è≠Ô∏è [PromQL : langage de requ√™te Prometheus](/12-monitoring-avec-prometheus/05-promql-langage-de-requete-prometheus.md)
