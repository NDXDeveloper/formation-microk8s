ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 12.8 Haute disponibilitÃ© Prometheus

## Introduction

Imaginez que vous ayez passÃ© des semaines Ã  configurer Prometheus, crÃ©Ã© des dizaines de dashboards Grafana, et configurÃ© des alertes critiques pour votre infrastructure. Un jour, le serveur qui hÃ©berge Prometheus tombe en panne. RÃ©sultat :
- âŒ Plus de dashboards
- âŒ Plus d'alertes
- âŒ Plus de monitoring
- âŒ Vous Ãªtes aveugle sur votre infrastructure

C'est exactement le problÃ¨me que rÃ©sout la **Haute DisponibilitÃ©** (High Availability ou HA).

### Qu'est-ce que la Haute DisponibilitÃ© ?

La **haute disponibilitÃ©** est la capacitÃ© d'un systÃ¨me Ã  rester opÃ©rationnel mÃªme en cas de panne d'un ou plusieurs composants. C'est l'Ã©limination des **points uniques de dÃ©faillance** (Single Point of Failure ou SPOF).

**Analogie** :

Imaginez un hÃ´pital avec un seul mÃ©decin. Si ce mÃ©decin tombe malade, plus personne ne peut Ãªtre soignÃ© (SPOF). Un hÃ´pital avec 5 mÃ©decins a une haute disponibilitÃ© : si un mÃ©decin est absent, les autres continuent Ã  travailler.

### Pourquoi s'en prÃ©occuper dans un lab ?

**Bonne question !** Pour un lab personnel sur MicroK8s, la haute disponibilitÃ© n'est gÃ©nÃ©ralement **pas nÃ©cessaire**. Si Prometheus tombe, vous pouvez simplement le redÃ©marrer.

**Cependant**, comprendre la HA est important car :
1. C'est essentiel en **production** (entreprise)
2. Cela vous prÃ©pare pour des **certifications** Kubernetes (CKA, CKAD)
3. C'est une **compÃ©tence recherchÃ©e** par les employeurs
4. Vous pourriez vouloir **expÃ©rimenter** dans votre lab
5. Comprendre l'architecture HA approfondit votre connaissance de Prometheus

**Dans cette section**, nous couvrirons :
- Les concepts gÃ©nÃ©raux de HA
- Comment implÃ©menter HA avec Prometheus
- Comment l'activer dans MicroK8s (si vous le souhaitez)
- Les solutions de stockage long-terme

## Les dÃ©fis de la Haute DisponibilitÃ© avec Prometheus

### Le problÃ¨me fondamental

Prometheus a Ã©tÃ© conÃ§u comme un systÃ¨me **simple et autonome** :
- Il stocke ses donnÃ©es **localement** (sur son propre disque)
- Il **ne partage pas** ses donnÃ©es entre instances
- Il n'y a **pas de rÃ©plication native**

**ConsÃ©quence** : Si vous avez 2 instances Prometheus qui scrapent les mÃªmes targets, vous obtenez :
- 2 bases de donnÃ©es **indÃ©pendantes**
- 2 copies **lÃ©gÃ¨rement diffÃ©rentes** des mÃªmes mÃ©triques
- Pas de synchronisation entre elles

### DiffÃ©rences entre les instances

MÃªme si deux instances Prometheus scrapent exactement les mÃªmes targets, leurs donnÃ©es diffÃ¨rent lÃ©gÃ¨rement :

```
Instance 1 scrape Ã  10:00:00 â†’ valeur: 100
Instance 2 scrape Ã  10:00:01 â†’ valeur: 101

Instance 1 scrape Ã  10:00:30 â†’ valeur: 150
Instance 2 scrape Ã  10:00:31 â†’ valeur: 151
```

Les timestamps et les valeurs ne sont jamais parfaitement identiques.

### Implications pour les requÃªtes

Quand vous interrogez un Prometheus HA, vous devez :
- Interroger **toutes les instances**
- **DÃ©dupliquer** les rÃ©sultats
- GÃ©rer les **sÃ©ries temporelles manquantes** (si une instance Ã©tait down)

## Architecture Haute DisponibilitÃ© : Concepts

### StratÃ©gie 1 : Prometheus en paires (RÃ©plication simple)

C'est l'approche la plus simple pour la HA.

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    CLUSTER KUBERNETES          â”‚
        â”‚                                â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”         â”‚
        â”‚   â”‚ App1 â”‚    â”‚ App2 â”‚         â”‚
        â”‚   â””â”€â”€â”€â”¬â”€â”€â”˜    â””â”€â”€â”€â”¬â”€â”€â”˜         â”‚
        â”‚       â”‚           â”‚            â”‚
        â”‚       â†“           â†“            â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
        â”‚   â”‚                   â”‚        â”‚
        â”‚   â†“                   â†“        â”‚
        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚ â”‚Prometheus 1â”‚  â”‚Prometheus 2â”‚ â”‚
        â”‚ â”‚            â”‚  â”‚            â”‚ â”‚
        â”‚ â”‚ Data Store â”‚  â”‚ Data Store â”‚ â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                â”‚
              â†“                â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚Grafana   â”‚    â”‚AlertMgr  â”‚
        â”‚(query    â”‚    â”‚(cluster) â”‚
        â”‚both)     â”‚    â”‚          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fonctionnement** :

1. **Deux instances Prometheus** scrapent exactement les mÃªmes targets
2. Chaque instance a sa **propre base de donnÃ©es**
3. **Grafana** interroge les deux instances
4. **Alertmanager** reÃ§oit les alertes des deux instances (et dÃ©duplique)

**Avantages** :
- âœ… Simple Ã  mettre en place
- âœ… Si une instance tombe, l'autre continue
- âœ… Pas de dÃ©pendance externe

**InconvÃ©nients** :
- âŒ Consomme 2x les ressources (2x CPU, 2x RAM, 2x disque)
- âŒ Les donnÃ©es ne sont pas identiques (lÃ©gÃ¨res variations)
- âŒ Grafana doit gÃ©rer la dÃ©duplication
- âŒ Pas de stockage long-terme

### StratÃ©gie 2 : Prometheus avec stockage externe (Remote Storage)

Au lieu de stocker localement, Prometheus envoie ses mÃ©triques vers un **stockage externe** centralisÃ©.

```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚      CLUSTER KUBERNETES              â”‚
     â”‚                                      â”‚
     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
     â”‚  â”‚Prometheus 1â”‚      â”‚Prometheus 2â”‚  â”‚
     â”‚  â”‚            â”‚      â”‚            â”‚  â”‚
     â”‚  â”‚(15 jours)  â”‚      â”‚(15 jours)  â”‚  â”‚
     â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
     â”‚        â”‚                   â”‚         â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                   â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ REMOTE STORAGE   â”‚
            â”‚                  â”‚
            â”‚ (Thanos, Cortex, â”‚
            â”‚  VictoriaMetrics)â”‚
            â”‚                  â”‚
            â”‚  (plusieurs      â”‚
            â”‚   annÃ©es)        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†‘
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
              â”‚   Grafana   â”‚
              â”‚   (query)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fonctionnement** :

1. Chaque Prometheus stocke **localement** les donnÃ©es rÃ©centes (ex: 15 jours)
2. Chaque Prometheus **envoie** aussi ses mÃ©triques au stockage externe
3. Le stockage externe **conserve** l'historique long-terme (plusieurs annÃ©es)
4. Grafana peut interroger soit Prometheus directement (donnÃ©es rÃ©centes) soit le stockage externe (historique)

**Avantages** :
- âœ… Stockage long-terme (annÃ©es)
- âœ… RequÃªtes sur l'historique complet
- âœ… Moins de stockage local nÃ©cessaire
- âœ… DÃ©duplication gÃ©rÃ©e par le stockage externe

**InconvÃ©nients** :
- âŒ Plus complexe Ã  configurer
- âŒ DÃ©pendance externe (besoin d'un systÃ¨me de stockage supplÃ©mentaire)
- âŒ CoÃ»t (infrastructure supplÃ©mentaire)

### StratÃ©gie 3 : Prometheus Operator avec StatefulSet

Avec Prometheus Operator (utilisÃ© dans MicroK8s), Prometheus est dÃ©ployÃ© comme un **StatefulSet** avec des volumes persistants.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    KUBERNETES CLUSTER           â”‚
â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Prometheus StatefulSet    â”‚ â”‚
â”‚  â”‚                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ prometheus-k8s-0     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â”‚  Prometheus      â”‚ â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â”‚                  â”‚ â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â”‚
â”‚  â”‚  â”‚          â”‚           â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ PersistentVolumeâ”‚ â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚   (15 jours)    â”‚ â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fonctionnement** :

1. Prometheus s'exÃ©cute dans un pod avec un **volume persistant**
2. Si le pod crash, Kubernetes le **redÃ©marre automatiquement**
3. Les donnÃ©es sont **prÃ©servÃ©es** sur le volume persistant
4. Le nouveau pod retrouve toutes les donnÃ©es

**Avantages** :
- âœ… RedÃ©marrage automatique
- âœ… DonnÃ©es prÃ©servÃ©es
- âœ… Simple (gÃ©rÃ© par Kubernetes)

**InconvÃ©nients** :
- âŒ Si le **node** entier tombe, Prometheus est down jusqu'Ã  ce que Kubernetes le reschedule
- âŒ Pas de vraie HA (un seul pod actif Ã  la fois)

**Note** : C'est la configuration par dÃ©faut dans MicroK8s.

## Alertmanager en Haute DisponibilitÃ©

### Le problÃ¨me des alertes dupliquÃ©es

Si vous avez 2 instances Prometheus qui envoient des alertes, vous recevrez **2 fois chaque alerte** :

```
Prometheus 1 â†’ Alerte: "CPU High" â†’ Slack: "CPU High"
Prometheus 2 â†’ Alerte: "CPU High" â†’ Slack: "CPU High"
```

Vous recevez 2 notifications identiques ! ğŸ˜«

### La solution : Alertmanager en cluster

Alertmanager peut fonctionner en **mode cluster** pour dÃ©dupliquer automatiquement les alertes.

```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚Prometheus 1 â”‚    â”‚Prometheus 2 â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
            â”‚                  â”‚
            â”‚ Alerte: CPU High â”‚
            â”‚                  â”‚
            â†“                  â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚AlertManager1â”‚â—„â”€â”€â–ºâ”‚AlertManager2â”‚
     â”‚             â”‚    â”‚             â”‚
     â”‚  (cluster)  â”‚    â”‚  (cluster)  â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
            â”‚                  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Slack    â”‚
              â”‚            â”‚
              â”‚ "CPU High" â”‚ â† Une seule notification
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fonctionnement** :

1. Les instances Alertmanager communiquent entre elles (gossip protocol)
2. Elles partagent les alertes qu'elles ont reÃ§ues
3. Elles **dÃ©duplicent** automatiquement
4. Une **seule** notification est envoyÃ©e

**Configuration** :

```yaml
apiVersion: monitoring.coreos.com/v1
kind: Alertmanager
metadata:
  name: main
  namespace: monitoring
spec:
  replicas: 3  # 3 instances en cluster
  # Les instances se dÃ©couvrent automatiquement
```

## Configuration HA dans MicroK8s

### Configuration par dÃ©faut

Par dÃ©faut, MicroK8s dÃ©ploie :
- **1 instance Prometheus** (prometheus-k8s-0)
- **1 instance Alertmanager** (alertmanager-main-0)

C'est suffisant pour un lab, mais pas HA.

### Activer la Haute DisponibilitÃ©

Pour activer la HA dans MicroK8s :

#### Ã‰tape 1 : Augmenter le nombre de replicas Prometheus

```bash
# Ã‰diter la ressource Prometheus
microk8s kubectl edit prometheus prometheus-k8s -n monitoring
```

Modifiez la ligne `replicas` :

```yaml
spec:
  replicas: 2  # Changez de 1 Ã  2 (ou plus)
```

Sauvegardez et quittez. Kubernetes crÃ©era automatiquement un deuxiÃ¨me pod Prometheus.

VÃ©rifiez :

```bash
microk8s kubectl get pods -n monitoring -l app.kubernetes.io/name=prometheus
```

Vous devriez voir :

```
NAME                READY   STATUS    RESTARTS   AGE
prometheus-k8s-0    2/2     Running   0          5m
prometheus-k8s-1    2/2     Running   0          1m  â† Nouveau pod
```

#### Ã‰tape 2 : Augmenter le nombre de replicas Alertmanager

```bash
# Ã‰diter la ressource Alertmanager
microk8s kubectl edit alertmanager alertmanager-main -n monitoring
```

Modifiez :

```yaml
spec:
  replicas: 3  # 3 pour former un cluster (nombre impair recommandÃ©)
```

VÃ©rifiez :

```bash
microk8s kubectl get pods -n monitoring -l app.kubernetes.io/name=alertmanager
```

```
NAME                    READY   STATUS    RESTARTS   AGE
alertmanager-main-0     2/2     Running   0          5m
alertmanager-main-1     2/2     Running   0          2m
alertmanager-main-2     2/2     Running   0          2m
```

#### Ã‰tape 3 : Configurer Grafana pour interroger les deux Prometheus

Grafana doit Ãªtre configurÃ© pour interroger les deux instances Prometheus.

**Option 1 : Data Source avec load balancing** (Simple)

Utilisez le Service Kubernetes qui fait dÃ©jÃ  du load balancing :

```yaml
# Le service prometheus-k8s fait automatiquement du load balancing
# entre les pods
http://prometheus-k8s.monitoring.svc:9090
```

**Option 2 : Deux Data Sources sÃ©parÃ©es** (Plus de contrÃ´le)

Dans Grafana, ajoutez deux data sources :

```
Data Source 1:
  Name: Prometheus-1
  URL: http://prometheus-k8s-0.prometheus-operated.monitoring.svc:9090

Data Source 2:
  Name: Prometheus-2
  URL: http://prometheus-k8s-1.prometheus-operated.monitoring.svc:9090
```

Puis dans vos dashboards, interrogez les deux sources et dÃ©duplicez les rÃ©sultats.

### VÃ©rifier la configuration HA

#### Test 1 : Simuler une panne

```bash
# Supprimer un pod Prometheus
microk8s kubectl delete pod prometheus-k8s-0 -n monitoring

# VÃ©rifier que l'autre prend le relais
microk8s kubectl get pods -n monitoring -l app.kubernetes.io/name=prometheus
```

Vous devriez voir :
- `prometheus-k8s-1` toujours Running
- `prometheus-k8s-0` en cours de redÃ©marrage (ContainerCreating)

**Pendant ce temps**, Grafana devrait continuer Ã  fonctionner (en interrogeant prometheus-k8s-1).

#### Test 2 : VÃ©rifier la dÃ©duplication Alertmanager

```bash
# Voir les logs d'un Alertmanager
microk8s kubectl logs alertmanager-main-0 -n monitoring -c alertmanager | grep -i cluster
```

Vous devriez voir des messages indiquant que les instances communiquent :

```
level=info msg="Listening on :9094 (cluster)"
level=info msg="Cluster joined" peers=3
```

### ConsidÃ©rations de ressources

**Important** : La HA consomme plus de ressources.

**Avant HA** :
- 1 Prometheus : ~500MB RAM, 0.5 CPU
- 1 Alertmanager : ~100MB RAM, 0.1 CPU
- **Total** : ~600MB RAM, 0.6 CPU

**AprÃ¨s HA (2 Prometheus, 3 Alertmanager)** :
- 2 Prometheus : ~1GB RAM, 1 CPU
- 3 Alertmanager : ~300MB RAM, 0.3 CPU
- **Total** : ~1.3GB RAM, 1.3 CPU

**Assurez-vous** d'avoir suffisamment de ressources sur votre machine avant d'activer la HA !

## Stockage Long-Terme : Thanos

### Qu'est-ce que Thanos ?

**Thanos** est une solution open-source qui Ã©tend Prometheus pour offrir :
- **Stockage long-terme** (annÃ©es) dans un stockage objet (S3, GCS, etc.)
- **RequÃªtes globales** sur plusieurs Prometheus
- **DÃ©duplication** automatique
- **Downsampling** (rÃ©duction de la rÃ©solution des anciennes donnÃ©es)

### Architecture Thanos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            KUBERNETES CLUSTER                      â”‚
â”‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Prometheus 1 â”‚           â”‚ Prometheus 2 â”‚       â”‚
â”‚  â”‚              â”‚           â”‚              â”‚       â”‚
â”‚  â”‚ + Sidecar    â”‚           â”‚ + Sidecar    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                          â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                  â”‚                                 â”‚
â”‚                  â†“                                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚         â”‚  Thanos Store   â”‚                        â”‚
â”‚         â”‚   Gateway       â”‚                        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Object Storageâ”‚
          â”‚   (S3, GCS)    â”‚
          â”‚                â”‚
          â”‚  (plusieurs    â”‚
          â”‚   annÃ©es)      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚Thanos Query  â”‚
            â”‚              â”‚
            â”‚ (API unifiÃ©e)â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Grafana    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Composants Thanos** :

1. **Thanos Sidecar** : S'exÃ©cute Ã  cÃ´tÃ© de Prometheus, envoie les donnÃ©es vers le stockage objet
2. **Thanos Store Gateway** : Permet de requÃªter les donnÃ©es historiques dans le stockage objet
3. **Thanos Query** : Interface unifiÃ©e qui interroge Ã  la fois Prometheus (donnÃ©es rÃ©centes) et Store Gateway (historique)
4. **Thanos Compactor** : Compacte et downsampling les anciennes donnÃ©es
5. **Thanos Ruler** : Ã‰value les recording et alerting rules sur les donnÃ©es long-terme

### Avantages de Thanos

âœ… **Stockage illimitÃ©** : Gardez des annÃ©es de mÃ©triques dans S3/GCS (peu coÃ»teux)
âœ… **Vue globale** : Interrogez plusieurs Prometheus depuis une seule interface
âœ… **DÃ©duplication** : GÃ¨re automatiquement les mÃ©triques dupliquÃ©es
âœ… **Performance** : Downsampling rÃ©duit la quantitÃ© de donnÃ©es pour les requÃªtes longues
âœ… **Haute disponibilitÃ©** : Si un Prometheus tombe, les autres continuent

### Installation de Thanos (Concepts)

**Note** : L'installation complÃ¨te de Thanos est avancÃ©e et sort du cadre d'un lab dÃ©butant. Voici les concepts.

#### Option 1 : Helm Chart

```bash
# Ajouter le repo Thanos
helm repo add bitnami https://charts.bitnami.com/bitnami

# Installer Thanos
helm install thanos bitnami/thanos \
  --namespace monitoring \
  --set objstoreConfig="..." \
  --set query.enabled=true \
  --set storegateway.enabled=true
```

#### Option 2 : kube-thanos

Le projet kube-thanos fournit des manifests Kubernetes prÃªts Ã  l'emploi.

### Configuration minimale

Pour utiliser Thanos, vous avez besoin :

1. **Stockage objet** : Compte AWS S3, Google Cloud Storage, ou MinIO local
2. **Configuration Prometheus** avec sidecar Thanos
3. **DÃ©ploiement** des composants Thanos

**Exemple de configuration stockage (S3)** :

```yaml
type: S3
config:
  bucket: "my-thanos-bucket"
  endpoint: "s3.amazonaws.com"
  access_key: "ACCESS_KEY"
  secret_key: "SECRET_KEY"
```

## Alternatives Ã  Thanos

### Cortex

**Cortex** est une alternative Ã  Thanos dÃ©veloppÃ©e par Grafana Labs (maintenant intÃ©grÃ© dans Grafana Mimir).

**DiffÃ©rences** :
- Cortex est un service complet (pas de sidecar)
- Prometheus envoie directement les mÃ©triques via remote write
- Architecture diffÃ©rente mais objectifs similaires

### VictoriaMetrics

**VictoriaMetrics** est une base de donnÃ©es de sÃ©ries temporelles compatible avec Prometheus.

**Avantages** :
- TrÃ¨s performant
- Utilise moins de ressources que Prometheus
- Stockage long-terme intÃ©grÃ©
- Compatible avec l'API Prometheus

**Utilisation** :

Prometheus envoie ses mÃ©triques vers VictoriaMetrics via remote write, et Grafana interroge VictoriaMetrics.

### M3DB

**M3DB** est la solution de stockage de sÃ©ries temporelles d'Uber.

Compatible avec Prometheus via remote write/read.

### Comparaison rapide

| Solution | ComplexitÃ© | Stockage LT | Performance | CommunautÃ© |
|----------|-----------|-------------|-------------|-----------|
| Thanos | Moyenne | âœ… Excellent | âœ… Bon | âœ… Large |
| Cortex/Mimir | Ã‰levÃ©e | âœ… Excellent | âœ… TrÃ¨s bon | âœ… Moyenne |
| VictoriaMetrics | Faible | âœ… Excellent | âœ… Excellent | âœ… Croissante |
| M3DB | Ã‰levÃ©e | âœ… Excellent | âœ… Bon | âš ï¸ Petite |

**Pour un lab MicroK8s** : VictoriaMetrics est probablement le plus simple Ã  expÃ©rimenter.

## Bonnes pratiques pour la Haute DisponibilitÃ©

### 1. Utilisez un nombre impair de replicas Alertmanager

```yaml
# âœ… Bon : nombre impair (consensus plus facile)
replicas: 3  # ou 5, 7

# âŒ Ã‰vitez : nombre pair
replicas: 2  # ou 4, 6
```

### 2. Distribuez sur plusieurs nodes (si multi-node)

Si vous avez un cluster multi-node, utilisez les **anti-affinity rules** pour que les pods Prometheus ne s'exÃ©cutent pas sur le mÃªme node.

```yaml
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values:
            - prometheus
        topologyKey: kubernetes.io/hostname
```

### 3. Configurez des requests et limits appropriÃ©s

```yaml
resources:
  requests:
    memory: 2Gi
    cpu: 1000m
  limits:
    memory: 4Gi
    cpu: 2000m
```

Cela Ã©vite qu'un Prometheus ne consomme toutes les ressources du node.

### 4. Surveillez Prometheus lui-mÃªme

CrÃ©ez des alertes sur Prometheus :

```yaml
- alert: PrometheusDown
  expr: up{job="prometheus"} == 0
  for: 5m
  annotations:
    summary: "Prometheus instance {{ $labels.instance }} is down"
```

### 5. Testez rÃ©guliÃ¨rement votre HA

```bash
# Test mensuel : simulez des pannes
microk8s kubectl delete pod prometheus-k8s-0 -n monitoring

# VÃ©rifiez que :
# - L'autre instance continue
# - Les alertes fonctionnent
# - Grafana affiche toujours les donnÃ©es
```

### 6. Documentez votre architecture

Gardez un schÃ©ma d'architecture Ã  jour montrant :
- Combien d'instances Prometheus
- OÃ¹ sont les donnÃ©es stockÃ©es
- Quelle est la rÃ©tention
- Comment les donnÃ©es sont sauvegardÃ©es

### 7. Planifiez la capacitÃ©

```promql
# Espace disque restant
predict_linear(node_filesystem_avail_bytes[1h], 7*24*3600) < 0

# Croissance des mÃ©triques
rate(prometheus_tsdb_head_series[1d])
```

Surveillez la croissance et ajustez les ressources avant d'avoir des problÃ¨mes.

## Quand implÃ©menter la HA ?

### Vous N'AVEZ PAS besoin de HA si :

- ğŸ  Lab personnel / apprentissage
- ğŸ‘¥ Ã‰quipe de dÃ©veloppement (environnement dev/test)
- ğŸ“Š Monitoring non critique
- ğŸ’» Ressources limitÃ©es
- ğŸ¯ Focus sur l'apprentissage de Prometheus de base

**Dans ces cas**, une seule instance avec un volume persistant suffit.

### Vous AVEZ besoin de HA si :

- ğŸ¢ Environnement de production
- ğŸ’° Monitoring critique pour le business
- ğŸ“ˆ SLA stricts (99.9%+ de disponibilitÃ©)
- ğŸ‘¥ Grande Ã©quipe qui dÃ©pend du monitoring
- ğŸ”” Alertes critiques (on-call, PagerDuty)
- ğŸŒ Monitoring multi-rÃ©gion/multi-cluster

## Backup et Disaster Recovery

MÃªme avec HA, vous devriez avoir une stratÃ©gie de backup.

### Option 1 : Snapshot des volumes persistants

Si vous utilisez un StorageClass qui supporte les snapshots :

```bash
# CrÃ©er un VolumeSnapshot
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: prometheus-snapshot
spec:
  volumeSnapshotClassName: csi-snapclass
  source:
    persistentVolumeClaimName: prometheus-k8s-db-prometheus-k8s-0
```

### Option 2 : Export avec Prometheus-backup-tool

Utilisez des outils comme `prometheus-backup-tool` pour exporter les donnÃ©es :

```bash
# Exemple conceptuel
prometheus-backup-tool \
  --prometheus-url=http://prometheus-k8s:9090 \
  --output=/backups/prometheus-$(date +%Y%m%d).tar.gz
```

### Option 3 : RÃ©plication vers stockage externe

Avec Thanos ou VictoriaMetrics, vos donnÃ©es sont automatiquement rÃ©pliquÃ©es vers un stockage objet durable (S3, GCS).

### FrÃ©quence de backup recommandÃ©e

- **Production critique** : Quotidien
- **Production standard** : Hebdomadaire
- **Dev/Test** : Optionnel

## Monitoring de la HA

Pour vÃ©rifier que votre configuration HA fonctionne :

```promql
# Nombre d'instances Prometheus UP
count(up{job="prometheus"} == 1)
# Devrait Ãªtre Ã©gal au nombre de replicas

# Nombre d'instances Alertmanager en cluster
sum(alertmanager_cluster_members)
# Devrait Ãªtre Ã©gal au nombre de replicas Alertmanager

# Alertes non dÃ©duplicÃ©es (problÃ¨me si > 0 pour la mÃªme alerte)
# VÃ©rifiez dans l'UI Alertmanager
```

## RÃ©sumÃ©

Dans cette section, vous avez appris :

âœ… **Pourquoi la HA est importante** (Ã©limination des SPOF)
âœ… **Les dÃ©fis spÃ©cifiques** de la HA avec Prometheus
âœ… **Les diffÃ©rentes stratÃ©gies HA** : rÃ©plication, remote storage, StatefulSet
âœ… **Alertmanager en cluster** pour dÃ©dupliquer les alertes
âœ… **Comment activer la HA** dans MicroK8s
âœ… **Thanos** et les solutions de stockage long-terme
âœ… **Les alternatives** : Cortex, VictoriaMetrics, M3DB
âœ… **Les bonnes pratiques** pour implÃ©menter et maintenir la HA
âœ… **Quand la HA est nÃ©cessaire** (et quand elle ne l'est pas)
âœ… **Backup et disaster recovery** pour protÃ©ger vos donnÃ©es

**Points clÃ©s Ã  retenir** :

1. La HA **n'est pas toujours nÃ©cessaire**, surtout dans un lab
2. Prometheus HA = **plusieurs instances indÃ©pendantes** qui scrapent les mÃªmes targets
3. **Alertmanager en cluster** dÃ©duplique automatiquement les alertes
4. **Thanos/VictoriaMetrics** pour le stockage long-terme et la vue globale
5. La HA a un **coÃ»t** : ressources, complexitÃ©, maintenance
6. **Testez** rÃ©guliÃ¨rement votre configuration HA
7. **Documentez** votre architecture et vos procÃ©dures

**Pour votre lab MicroK8s** : La configuration par dÃ©faut (1 Prometheus + 1 Alertmanager) est suffisante. Mais maintenant vous comprenez comment Ã©voluer vers une architecture HA si nÃ©cessaire !

Dans le prochain chapitre (13), nous dÃ©couvrirons **Grafana**, l'outil de visualisation qui transformera vos mÃ©triques Prometheus en magnifiques dashboards interactifs.

---

**Conseil** : Si vous voulez expÃ©rimenter la HA dans votre lab, commencez simplement avec 2 instances Prometheus et observez comment elles fonctionnent ensemble. Vous pouvez toujours revenir Ã  1 instance si les ressources sont limitÃ©es. L'important est de comprendre les concepts !

â­ï¸ [Visualisation avec Grafana](/13-visualisation-avec-grafana/README.md)
