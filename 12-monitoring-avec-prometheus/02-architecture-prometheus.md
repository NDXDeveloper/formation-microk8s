ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 12.2 Architecture Prometheus

## Introduction

Dans la section prÃ©cÃ©dente, nous avons dÃ©couvert l'Ã©cosystÃ¨me Prometheus dans son ensemble. Maintenant, plongeons dans l'architecture technique pour comprendre comment tout s'articule. Ne vous inquiÃ©tez pas si cela semble complexe au premier abord : nous allons dÃ©composer chaque Ã©lÃ©ment de maniÃ¨re progressive.

## Vue d'ensemble de l'architecture

Voici une reprÃ©sentation simplifiÃ©e de l'architecture Prometheus dans un cluster Kubernetes :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CLUSTER KUBERNETES                            â”‚
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Pod App 1  â”‚      â”‚   Pod App 2    â”‚      â”‚   Pod App 3    â”‚  â”‚
â”‚  â”‚  :8080/metricsâ”‚     â”‚  :8080/metrics â”‚      â”‚  :8080/metrics â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†‘                      â†‘                      â†‘            â”‚
â”‚         â”‚                      â”‚                      â”‚            â”‚
â”‚         â”‚      Scrape (pull)   â”‚                      â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                â”‚                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                    â”‚  PROMETHEUS SERVER   â”‚                        â”‚
â”‚                    â”‚                      â”‚                        â”‚
â”‚                    â”‚  â€¢ Service Discovery â”‚                        â”‚
â”‚                    â”‚  â€¢ Time Series DB    â”‚                        â”‚
â”‚                    â”‚  â€¢ PromQL Engine     â”‚                        â”‚
â”‚                    â”‚  â€¢ Alert Rules       â”‚                        â”‚
â”‚                    â”‚  â€¢ Web UI            â”‚                        â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                â”‚                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                    â”‚   ALERTMANAGER       â”‚                        â”‚
â”‚                    â”‚                      â”‚                        â”‚
â”‚                    â”‚  â€¢ Alert Routing     â”‚                        â”‚
â”‚                    â”‚  â€¢ Grouping          â”‚                        â”‚
â”‚                    â”‚  â€¢ Deduplication     â”‚                        â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                â”‚                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    NOTIFICATIONS        â”‚
                    â”‚                         â”‚
                    â”‚  â€¢ Email                â”‚
                    â”‚  â€¢ Slack                â”‚
                    â”‚  â€¢ PagerDuty            â”‚
                    â”‚  â€¢ Webhook              â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      GRAFANA         â”‚ â—„â”€â”€â”€ RequÃªtes PromQL
         â”‚                      â”‚
         â”‚  â€¢ Dashboards        â”‚
         â”‚  â€¢ Visualisations    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Les composants principaux en dÃ©tail

### 1. Prometheus Server : Le cerveau du systÃ¨me

Le serveur Prometheus est le composant central qui orchestre tout. Il est composÃ© de plusieurs modules internes :

#### A. Service Discovery (DÃ©couverte de services)

**Qu'est-ce que c'est ?**

Dans un environnement Kubernetes, les pods naissent et meurent constamment. Leurs adresses IP changent. Comment Prometheus peut-il savoir quoi surveiller ?

C'est lÃ  qu'intervient le **Service Discovery** (dÃ©couverte de services). Au lieu de configurer manuellement chaque cible Ã  surveiller, Prometheus interroge l'API Kubernetes pour dÃ©couvrir automatiquement :
- Les pods
- Les services
- Les endpoints
- Les nodes

**Comment Ã§a fonctionne ?**

```
1. Prometheus interroge l'API Kubernetes
2. Kubernetes rÃ©pond : "Voici tous les pods avec le label 'monitoring=enabled'"
3. Prometheus extrait les adresses IP et ports
4. Prometheus commence Ã  scraper ces endpoints
```

**Exemple concret** :

Si vous dÃ©ployez une nouvelle application avec un label `prometheus.io/scrape: "true"`, Prometheus la dÃ©tectera automatiquement et commencera Ã  collecter ses mÃ©triques. Pas besoin de redÃ©marrer Prometheus ou de modifier sa configuration !

#### B. Time Series Database (Base de donnÃ©es temporelle)

**Qu'est-ce que c'est ?**

Une base de donnÃ©es optimisÃ©e pour stocker des sÃ©ries de valeurs dans le temps. Contrairement Ã  une base de donnÃ©es classique (MySQL, PostgreSQL), elle est conÃ§ue spÃ©cifiquement pour les mÃ©triques.

**Structure des donnÃ©es** :

Chaque mÃ©trique est stockÃ©e comme une sÃ©rie temporelle :

```
mÃ©trique{labels} valeur timestamp

Exemple :
http_requests_total{method="GET", status="200", instance="app-1"} 1547 1698765432
http_requests_total{method="GET", status="200", instance="app-1"} 1552 1698765447
http_requests_total{method="GET", status="200", instance="app-1"} 1560 1698765462
```

**Pourquoi une base de donnÃ©es spÃ©cialisÃ©e ?**

- **Compression efficace** : Les mÃ©triques ont souvent des patterns rÃ©pÃ©titifs
- **RequÃªtes rapides** : OptimisÃ©e pour les agrÃ©gations temporelles
- **Retention automatique** : Suppression des anciennes donnÃ©es selon la configuration
- **Stockage en blocks** : Les donnÃ©es sont organisÃ©es en blocs de 2h (par dÃ©faut) pour une meilleure performance

**CaractÃ©ristiques importantes** :

- **Stockage local** : Par dÃ©faut, Prometheus stocke sur le disque local (pas de base externe)
- **RÃ©tention configurable** : Par dÃ©faut 15 jours, mais vous pouvez ajuster selon votre espace disque
- **Pas de haute disponibilitÃ© native** : Un serveur Prometheus = un stockage isolÃ©

#### C. PromQL Engine (Moteur de requÃªtes)

**Qu'est-ce que c'est ?**

C'est le moteur qui exÃ©cute vos requÃªtes PromQL pour extraire et transformer les donnÃ©es. Il peut :
- Filtrer les sÃ©ries temporelles
- Effectuer des agrÃ©gations (somme, moyenne, max, min)
- Calculer des taux de changement
- Combiner plusieurs mÃ©triques
- Appliquer des fonctions mathÃ©matiques

**Exemple simple** :

```promql
# Taux de requÃªtes HTTP par seconde
rate(http_requests_total[5m])

# Utilisation CPU moyenne par pod
avg(container_cpu_usage_seconds_total) by (pod)

# Pods utilisant plus de 80% de mÃ©moire
container_memory_usage_bytes / container_memory_limit_bytes > 0.8
```

#### D. Alert Rules Engine (Moteur de rÃ¨gles d'alerte)

**Qu'est-ce que c'est ?**

Ce module Ã©value pÃ©riodiquement (par dÃ©faut toutes les minutes) les rÃ¨gles d'alerte que vous avez dÃ©finies.

**Cycle de vie d'une alerte** :

```
1. RÃ¨gle dÃ©finie : "CPU > 80% pendant 5 minutes"
2. Ã‰valuation : Le moteur exÃ©cute la requÃªte PromQL
3. Condition vraie : L'alerte passe en Ã©tat "Pending"
4. DurÃ©e atteinte : L'alerte passe en Ã©tat "Firing"
5. Envoi : Alertmanager reÃ§oit l'alerte
6. RÃ©solution : Quand la condition n'est plus vraie, alerte rÃ©solue
```

**Ã‰tats d'une alerte** :

- **Inactive** : La condition n'est pas remplie
- **Pending** : La condition est remplie, mais pas encore assez longtemps
- **Firing** : La condition est remplie depuis la durÃ©e dÃ©finie, alerte active

#### E. HTTP Server et Web UI

**Qu'est-ce que c'est ?**

Prometheus expose une interface web simple sur le port 9090 qui permet de :
- ExÃ©cuter des requÃªtes PromQL manuellement
- Visualiser les graphiques basiques
- Voir l'Ã©tat des targets (cibles surveillÃ©es)
- Consulter les rÃ¨gles d'alerte et leur Ã©tat
- VÃ©rifier la configuration

**UtilitÃ©** :

C'est principalement un outil de dÃ©bogage et d'exploration. Pour de vraies visualisations, on utilise Grafana, mais l'UI Prometheus est pratique pour tester rapidement des requÃªtes.

### 2. Retrieval (Module de collecte)

**Qu'est-ce que c'est ?**

C'est le composant qui effectue le travail de scraping, c'est-Ã -dire qui va chercher les mÃ©triques auprÃ¨s des targets.

**Processus de scraping** :

```
1. Service Discovery fournit la liste des targets
2. Retrieval lit la configuration (intervalle, timeout, labels)
3. Pour chaque target, Retrieval envoie une requÃªte HTTP GET vers /metrics
4. La target rÃ©pond avec ses mÃ©triques au format Prometheus
5. Retrieval parse les mÃ©triques et ajoute les labels configurÃ©s
6. Les mÃ©triques sont envoyÃ©es au stockage
```

**Configuration du scraping** :

```yaml
scrape_configs:
  - job_name: 'my-app'
    scrape_interval: 15s      # FrÃ©quence de scraping
    scrape_timeout: 10s       # Timeout pour chaque requÃªte
    metrics_path: '/metrics'  # Chemin de l'endpoint
    static_configs:
      - targets: ['app:8080']
```

**Gestion des erreurs** :

Si un scrape Ã©choue :
- Prometheus enregistre l'erreur
- La mÃ©trique `up{job="my-app", instance="app:8080"}` passe Ã  0
- Prometheus rÃ©essaiera au prochain intervalle
- Vous pouvez voir les erreurs dans l'UI Prometheus

### 3. Exporters : Les traducteurs de mÃ©triques

Les exporters ne font pas techniquement partie de Prometheus, mais ils sont essentiels Ã  l'architecture.

#### Node Exporter

**RÃ´le** : Expose les mÃ©triques du systÃ¨me d'exploitation et du matÃ©riel

**MÃ©triques fournies** :
- Utilisation CPU par core
- MÃ©moire (totale, disponible, utilisÃ©e, swap)
- Disque (espace, I/O, latence)
- RÃ©seau (octets transmis/reÃ§us, erreurs, paquets droppÃ©s)
- Filesystem (points de montage, espace libre)
- Statistiques systÃ¨me (load average, uptime)

**DÃ©ploiement** : GÃ©nÃ©ralement un DaemonSet (un pod par node)

#### kube-state-metrics

**RÃ´le** : Expose l'Ã©tat des objets Kubernetes (API Kubernetes â†’ MÃ©triques Prometheus)

**MÃ©triques fournies** :
- Ã‰tat des pods (running, pending, failed)
- Ã‰tat des deployments (replicas desired vs available)
- Ã‰tat des nodes (ready, not ready)
- Ressources requests et limits
- Labels et annotations
- Ã‰tat des PersistentVolumeClaims

**DiffÃ©rence avec les mÃ©triques Kubelet** :
- kube-state-metrics = Ã©tat des objets Kubernetes
- Kubelet/cAdvisor = mÃ©triques de performance des conteneurs

#### cAdvisor

**RÃ´le** : Collecte les mÃ©triques au niveau conteneur (intÃ©grÃ© dans Kubelet)

**MÃ©triques fournies** :
- Utilisation CPU par conteneur
- Utilisation mÃ©moire par conteneur
- I/O disque par conteneur
- Statistiques rÃ©seau par conteneur
- Performance du filesystem

**Point important** : cAdvisor est dÃ©jÃ  prÃ©sent dans chaque node Kubernetes, pas besoin de l'installer.

### 4. Alertmanager : Le gestionnaire d'alertes

Alertmanager reÃ§oit les alertes de Prometheus et les gÃ¨re intelligemment.

#### Architecture interne d'Alertmanager

```
Alertes Prometheus
       â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   ALERTMANAGER     â”‚
   â”‚                    â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
   â”‚  â”‚  Dispatcher  â”‚  â”‚  â† RÃ©ception des alertes
   â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
   â”‚         â†“          â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
   â”‚  â”‚   Grouping   â”‚  â”‚  â† Regroupe les alertes similaires
   â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
   â”‚         â†“          â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
   â”‚  â”‚ Deduplicationâ”‚  â”‚  â† Ã‰limine les doublons
   â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
   â”‚         â†“          â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
   â”‚  â”‚   Silences   â”‚  â”‚  â† VÃ©rifie si l'alerte est silencÃ©e
   â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
   â”‚         â†“          â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
   â”‚  â”‚   Inhibition â”‚  â”‚  â† Supprime les alertes dÃ©pendantes
   â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
   â”‚         â†“          â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
   â”‚  â”‚   Routing    â”‚  â”‚  â† DÃ©termine oÃ¹ envoyer l'alerte
   â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
   â”‚         â†“          â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
   â”‚  â”‚  Notifiers   â”‚  â”‚  â† Envoie aux destinations
   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### FonctionnalitÃ©s clÃ©s

**Grouping (Regroupement)** :

Au lieu de recevoir 50 alertes "Pod down" sÃ©parÃ©ment, vous recevez un seul message :
```
[FIRING:50] Pods are down in namespace production
- pod-1 is down
- pod-2 is down
- pod-3 is down
...
```

**Deduplication (DÃ©duplication)** :

Si Prometheus redÃ©marre ou si vous avez plusieurs serveurs Prometheus, Alertmanager Ã©limine les alertes identiques.

**Silences** :

Vous pouvez temporairement dÃ©sactiver des alertes :
```
"Je fais une maintenance sur le serveur DB,
ignore toutes les alertes 'Database down' pendant 2 heures"
```

**Inhibition** :

Supprime les alertes dÃ©pendantes. Exemple :
```
Si "Node down" est actif,
alors supprime toutes les alertes "Pod down" sur ce node
(car elles sont une consÃ©quence Ã©vidente)
```

**Routing** :

Dirige les alertes vers les bonnes personnes :
```yaml
routes:
  - match:
      severity: critical
      team: backend
    receiver: backend-oncall-pagerduty

  - match:
      severity: warning
      team: frontend
    receiver: frontend-slack
```

### 5. Exporters d'application

#### Exporters officiels

Prometheus fournit des exporters officiels pour de nombreuses technologies :

- **PostgreSQL Exporter** : MÃ©triques de la base de donnÃ©es
- **MySQL Exporter** : MÃ©triques MySQL/MariaDB
- **Redis Exporter** : MÃ©triques Redis
- **NGINX Exporter** : MÃ©triques du serveur web
- **HAProxy Exporter** : MÃ©triques du load balancer
- **Elasticsearch Exporter** : MÃ©triques Elasticsearch

#### BibliothÃ¨ques client (Instrumentation)

Pour vos propres applications, Prometheus fournit des bibliothÃ¨ques dans plusieurs langages :

- **Go** : github.com/prometheus/client_golang
- **Python** : prometheus_client
- **Java** : io.prometheus:simpleclient
- **Node.js** : prom-client
- **.NET** : prometheus-net
- **Ruby** : prometheus-client

**Exemple conceptuel** :

```python
# Dans votre application Python
from prometheus_client import Counter, Histogram

# Compteur de requÃªtes
http_requests = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])

# Histogramme de latence
request_latency = Histogram('http_request_duration_seconds', 'HTTP request latency')

# Dans votre code
http_requests.labels(method='GET', endpoint='/api/users').inc()
with request_latency.time():
    # Votre logique mÃ©tier
    process_request()
```

## Flux de donnÃ©es complet

Voici le parcours d'une mÃ©trique de sa crÃ©ation Ã  sa visualisation :

```
1. APPLICATION
   â†“
   GÃ©nÃ¨re une mÃ©trique : http_requests_total{method="GET"} = 1547
   â†“

2. EXPOSITION
   â†“
   Expose sur HTTP : GET http://app:8080/metrics
   â†“

3. DÃ‰COUVERTE
   â†“
   Service Discovery dÃ©tecte l'application
   â†“

4. COLLECTE
   â†“
   Retrieval scrape l'endpoint toutes les 15s
   â†“

5. STOCKAGE
   â†“
   Time Series DB enregistre :
   http_requests_total{method="GET", instance="app-1"} 1547 @1698765432
   http_requests_total{method="GET", instance="app-1"} 1552 @1698765447
   â†“

6. Ã‰VALUATION
   â†“
   Alert Rules Engine vÃ©rifie les conditions
   rate(http_requests_total[5m]) < 10 â†’ Alerte !
   â†“

7. ALERTE
   â†“
   Alertmanager reÃ§oit, groupe, route
   â†“

8. NOTIFICATION
   â†“
   Email/Slack : "Low traffic detected on app-1"


En parallÃ¨le :

6bis. REQUÃŠTE
   â†“
   Grafana envoie une requÃªte PromQL
   â†“

7bis. TRAITEMENT
   â†“
   PromQL Engine exÃ©cute la requÃªte
   â†“

8bis. VISUALISATION
   â†“
   Grafana affiche le graphique
```

## ConsidÃ©rations d'architecture

### ScalabilitÃ©

**Limites d'un seul serveur Prometheus** :
- Peut gÃ©rer des milliers de targets
- Millions de sÃ©ries temporelles
- DÃ©pend du CPU, RAM, et I/O disque

**Quand scaler ?**
- Trop de mÃ©triques pour un seul serveur
- NÃ©cessitÃ© de haute disponibilitÃ©
- SÃ©paration par environnement ou Ã©quipe

**StratÃ©gies de scaling** :
- **FÃ©dÃ©ration** : Prometheus hiÃ©rarchiques (un central agrÃ¨ge plusieurs locaux)
- **Sharding** : DÃ©couper par namespace/application
- **Remote Storage** : Utiliser un stockage long-terme (Thanos, Cortex)

### Stockage et rÃ©tention

**Combien d'espace disque ?**

Estimation simplifiÃ©e :
```
Espace = nb_de_sÃ©ries Ã— Ã©chantillons_par_jour Ã— taille_Ã©chantillon Ã— rÃ©tention_jours

Exemple :
100 000 sÃ©ries Ã— 5 760 Ã©chantillons/jour Ã— 2 octets Ã— 15 jours
= 17 Go environ
```

**Ajuster la rÃ©tention** :
```yaml
# Dans la configuration Prometheus
storage:
  tsdb:
    retention.time: 15d    # Garder 15 jours
    retention.size: 50GB   # Ou 50 Go maximum
```

### Haute disponibilitÃ©

**ProblÃ¨me** : Un seul Prometheus = point unique de dÃ©faillance

**Solutions** :
1. **Plusieurs Prometheus identiques** : Ils scrapent tous les mÃªmes targets
2. **Alertmanager en cluster** : Ils se synchronisent pour dÃ©dupliquer
3. **Stockage externe** : Pour ne pas perdre l'historique

**Note importante pour MicroK8s** :

Pour un lab, la haute disponibilitÃ© n'est gÃ©nÃ©ralement pas nÃ©cessaire. Une instance Prometheus suffit. Nous couvrirons ce sujet dans la section 12.8 pour ceux qui veulent aller plus loin.

## Architecture dans MicroK8s

Lorsque vous exÃ©cutez `microk8s enable prometheus`, voici ce qui est dÃ©ployÃ© :

```
Namespace: monitoring

Deployments:
â”œâ”€â”€ prometheus-k8s (Prometheus Server)
â”œâ”€â”€ alertmanager-main (Alertmanager)
â”œâ”€â”€ kube-state-metrics (Ã‰tat Kubernetes)
â””â”€â”€ prometheus-operator (Gestion des CRDs Prometheus)

DaemonSets:
â””â”€â”€ node-exporter (Un par node)

Services:
â”œâ”€â”€ prometheus-k8s (Port 9090)
â”œâ”€â”€ alertmanager-main (Port 9093)
â””â”€â”€ kube-state-metrics (Port 8080)

ConfigMaps:
â”œâ”€â”€ prometheus-k8s-rulefiles (RÃ¨gles d'alerte)
â””â”€â”€ alertmanager-main (Configuration Alertmanager)

Secrets:
â””â”€â”€ prometheus-k8s (Tokens, certificats)
```

**Prometheus Operator** :

MicroK8s utilise le Prometheus Operator, qui est une extension Kubernetes qui facilite la gestion de Prometheus via des Custom Resources :

- **ServiceMonitor** : DÃ©finit quels services scraper
- **PodMonitor** : DÃ©finit quels pods scraper
- **PrometheusRule** : DÃ©finit les rÃ¨gles d'alerte
- **Alertmanager** : Configuration d'Alertmanager

Pas d'inquiÃ©tude si ces concepts sont nouveaux, nous les explorerons en pratique dans les prochaines sections.

## Points clÃ©s Ã  retenir

1. **Prometheus Server** est le cÅ“ur qui collecte, stocke, et Ã©value les mÃ©triques
2. **Service Discovery** permet la dÃ©couverte automatique des targets dans Kubernetes
3. **Time Series Database** stocke efficacement les mÃ©triques avec leur historique
4. **Exporters** traduisent les mÃ©triques de diffÃ©rents systÃ¨mes au format Prometheus
5. **Alertmanager** gÃ¨re intelligemment les alertes (grouping, routing, silences)
6. **PromQL** est le langage pour interroger les donnÃ©es
7. L'architecture est modulaire et chaque composant a un rÃ´le prÃ©cis

## Prochaines Ã©tapes

Maintenant que vous comprenez l'architecture, dans la prochaine section (12.3), nous allons **installer et configurer Prometheus** dans votre cluster MicroK8s et explorer l'interface web.

---

**Conseil** : Ne vous sentez pas obligÃ© de mÃ©moriser tous ces dÃ©tails immÃ©diatement. Revenez Ã  cette section lorsque vous aurez des questions sur "comment fonctionne telle ou telle partie". L'architecture prendra tout son sens au fur et Ã  mesure de votre pratique.

â­ï¸ [Installation de Prometheus (microk8s enable prometheus)](/12-monitoring-avec-prometheus/03-installation-de-prometheus-sur-microk8s.md)
