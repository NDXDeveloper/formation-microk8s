üîù Retour au [Sommaire](/SOMMAIRE.md)

# 12.2 Architecture Prometheus

## Introduction

Dans la section pr√©c√©dente, nous avons d√©couvert l'√©cosyst√®me Prometheus dans son ensemble. Maintenant, plongeons dans l'architecture technique pour comprendre comment tout s'articule. Ne vous inqui√©tez pas si cela semble complexe au premier abord : nous allons d√©composer chaque √©l√©ment de mani√®re progressive.

## Vue d'ensemble de l'architecture

Voici une repr√©sentation simplifi√©e de l'architecture Prometheus dans un cluster Kubernetes :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      CLUSTER KUBERNETES                            ‚îÇ
‚îÇ                                                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Pod App 1  ‚îÇ      ‚îÇ   Pod App 2    ‚îÇ      ‚îÇ   Pod App 3    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  :8080/metrics‚îÇ     ‚îÇ  :8080/metrics ‚îÇ      ‚îÇ  :8080/metrics ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚Üë                      ‚Üë                      ‚Üë            ‚îÇ
‚îÇ         ‚îÇ                      ‚îÇ                      ‚îÇ            ‚îÇ
‚îÇ         ‚îÇ      Scrape (pull)   ‚îÇ                      ‚îÇ            ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ                                ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ                    ‚îÇ  PROMETHEUS SERVER   ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ                      ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ Service Discovery ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ Time Series DB    ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ PromQL Engine     ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ Alert Rules       ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ Web UI            ‚îÇ                        ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                                ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ                    ‚îÇ   ALERTMANAGER       ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ                      ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ Alert Routing     ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ Grouping          ‚îÇ                        ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ Deduplication     ‚îÇ                        ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                                ‚îÇ                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    NOTIFICATIONS        ‚îÇ
                    ‚îÇ                         ‚îÇ
                    ‚îÇ  ‚Ä¢ Email                ‚îÇ
                    ‚îÇ  ‚Ä¢ Slack                ‚îÇ
                    ‚îÇ  ‚Ä¢ PagerDuty            ‚îÇ
                    ‚îÇ  ‚Ä¢ Webhook              ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ      GRAFANA         ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Requ√™tes PromQL
         ‚îÇ                      ‚îÇ
         ‚îÇ  ‚Ä¢ Dashboards        ‚îÇ
         ‚îÇ  ‚Ä¢ Visualisations    ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Les composants principaux en d√©tail

### 1. Prometheus Server : Le cerveau du syst√®me

Le serveur Prometheus est le composant central qui orchestre tout. Il est compos√© de plusieurs modules internes :

#### A. Service Discovery (D√©couverte de services)

**Qu'est-ce que c'est ?**

Dans un environnement Kubernetes, les pods naissent et meurent constamment. Leurs adresses IP changent. Comment Prometheus peut-il savoir quoi surveiller ?

C'est l√† qu'intervient le **Service Discovery** (d√©couverte de services). Au lieu de configurer manuellement chaque cible √† surveiller, Prometheus interroge l'API Kubernetes pour d√©couvrir automatiquement :
- Les pods
- Les services
- Les endpoints
- Les nodes

**Comment √ßa fonctionne ?**

```
1. Prometheus interroge l'API Kubernetes
2. Kubernetes r√©pond : "Voici tous les pods avec le label 'monitoring=enabled'"
3. Prometheus extrait les adresses IP et ports
4. Prometheus commence √† scraper ces endpoints
```

**Exemple concret** :

Si vous d√©ployez une nouvelle application avec un label `prometheus.io/scrape: "true"`, Prometheus la d√©tectera automatiquement et commencera √† collecter ses m√©triques. Pas besoin de red√©marrer Prometheus ou de modifier sa configuration !

#### B. Time Series Database (Base de donn√©es temporelle)

**Qu'est-ce que c'est ?**

Une base de donn√©es optimis√©e pour stocker des s√©ries de valeurs dans le temps. Contrairement √† une base de donn√©es classique (MySQL, PostgreSQL), elle est con√ßue sp√©cifiquement pour les m√©triques.

**Structure des donn√©es** :

Chaque m√©trique est stock√©e comme une s√©rie temporelle :

```
m√©trique{labels} valeur timestamp

Exemple :
http_requests_total{method="GET", status="200", instance="app-1"} 1547 1698765432
http_requests_total{method="GET", status="200", instance="app-1"} 1552 1698765447
http_requests_total{method="GET", status="200", instance="app-1"} 1560 1698765462
```

**Pourquoi une base de donn√©es sp√©cialis√©e ?**

- **Compression efficace** : Les m√©triques ont souvent des patterns r√©p√©titifs
- **Requ√™tes rapides** : Optimis√©e pour les agr√©gations temporelles
- **Retention automatique** : Suppression des anciennes donn√©es selon la configuration
- **Stockage en blocks** : Les donn√©es sont organis√©es en blocs de 2h (par d√©faut) pour une meilleure performance

**Caract√©ristiques importantes** :

- **Stockage local** : Par d√©faut, Prometheus stocke sur le disque local (pas de base externe)
- **R√©tention configurable** : Par d√©faut 15 jours, mais vous pouvez ajuster selon votre espace disque
- **Pas de haute disponibilit√© native** : Un serveur Prometheus = un stockage isol√©

#### C. PromQL Engine (Moteur de requ√™tes)

**Qu'est-ce que c'est ?**

C'est le moteur qui ex√©cute vos requ√™tes PromQL pour extraire et transformer les donn√©es. Il peut :
- Filtrer les s√©ries temporelles
- Effectuer des agr√©gations (somme, moyenne, max, min)
- Calculer des taux de changement
- Combiner plusieurs m√©triques
- Appliquer des fonctions math√©matiques

**Exemple simple** :

```promql
# Taux de requ√™tes HTTP par seconde
rate(http_requests_total[5m])

# Utilisation CPU moyenne par pod
avg(container_cpu_usage_seconds_total) by (pod)

# Pods utilisant plus de 80% de m√©moire
container_memory_usage_bytes / container_memory_limit_bytes > 0.8
```

#### D. Alert Rules Engine (Moteur de r√®gles d'alerte)

**Qu'est-ce que c'est ?**

Ce module √©value p√©riodiquement (par d√©faut toutes les minutes) les r√®gles d'alerte que vous avez d√©finies.

**Cycle de vie d'une alerte** :

```
1. R√®gle d√©finie : "CPU > 80% pendant 5 minutes"
2. √âvaluation : Le moteur ex√©cute la requ√™te PromQL
3. Condition vraie : L'alerte passe en √©tat "Pending"
4. Dur√©e atteinte : L'alerte passe en √©tat "Firing"
5. Envoi : Alertmanager re√ßoit l'alerte
6. R√©solution : Quand la condition n'est plus vraie, alerte r√©solue
```

**√âtats d'une alerte** :

- **Inactive** : La condition n'est pas remplie
- **Pending** : La condition est remplie, mais pas encore assez longtemps
- **Firing** : La condition est remplie depuis la dur√©e d√©finie, alerte active

#### E. HTTP Server et Web UI

**Qu'est-ce que c'est ?**

Prometheus expose une interface web simple sur le port 9090 qui permet de :
- Ex√©cuter des requ√™tes PromQL manuellement
- Visualiser les graphiques basiques
- Voir l'√©tat des targets (cibles surveill√©es)
- Consulter les r√®gles d'alerte et leur √©tat
- V√©rifier la configuration

**Utilit√©** :

C'est principalement un outil de d√©bogage et d'exploration. Pour de vraies visualisations, on utilise Grafana, mais l'UI Prometheus est pratique pour tester rapidement des requ√™tes.

### 2. Retrieval (Module de collecte)

**Qu'est-ce que c'est ?**

C'est le composant qui effectue le travail de scraping, c'est-√†-dire qui va chercher les m√©triques aupr√®s des targets.

**Processus de scraping** :

```
1. Service Discovery fournit la liste des targets
2. Retrieval lit la configuration (intervalle, timeout, labels)
3. Pour chaque target, Retrieval envoie une requ√™te HTTP GET vers /metrics
4. La target r√©pond avec ses m√©triques au format Prometheus
5. Retrieval parse les m√©triques et ajoute les labels configur√©s
6. Les m√©triques sont envoy√©es au stockage
```

**Configuration du scraping** :

```yaml
scrape_configs:
  - job_name: 'my-app'
    scrape_interval: 15s      # Fr√©quence de scraping
    scrape_timeout: 10s       # Timeout pour chaque requ√™te
    metrics_path: '/metrics'  # Chemin de l'endpoint
    static_configs:
      - targets: ['app:8080']
```

**Gestion des erreurs** :

Si un scrape √©choue :
- Prometheus enregistre l'erreur
- La m√©trique `up{job="my-app", instance="app:8080"}` passe √† 0
- Prometheus r√©essaiera au prochain intervalle
- Vous pouvez voir les erreurs dans l'UI Prometheus

### 3. Exporters : Les traducteurs de m√©triques

Les exporters ne font pas techniquement partie de Prometheus, mais ils sont essentiels √† l'architecture.

#### Node Exporter

**R√¥le** : Expose les m√©triques du syst√®me d'exploitation et du mat√©riel

**M√©triques fournies** :
- Utilisation CPU par core
- M√©moire (totale, disponible, utilis√©e, swap)
- Disque (espace, I/O, latence)
- R√©seau (octets transmis/re√ßus, erreurs, paquets dropp√©s)
- Filesystem (points de montage, espace libre)
- Statistiques syst√®me (load average, uptime)

**D√©ploiement** : G√©n√©ralement un DaemonSet (un pod par node)

#### kube-state-metrics

**R√¥le** : Expose l'√©tat des objets Kubernetes (API Kubernetes ‚Üí M√©triques Prometheus)

**M√©triques fournies** :
- √âtat des pods (running, pending, failed)
- √âtat des deployments (replicas desired vs available)
- √âtat des nodes (ready, not ready)
- Ressources requests et limits
- Labels et annotations
- √âtat des PersistentVolumeClaims

**Diff√©rence avec les m√©triques Kubelet** :
- kube-state-metrics = √©tat des objets Kubernetes
- Kubelet/cAdvisor = m√©triques de performance des conteneurs

#### cAdvisor

**R√¥le** : Collecte les m√©triques au niveau conteneur (int√©gr√© dans Kubelet)

**M√©triques fournies** :
- Utilisation CPU par conteneur
- Utilisation m√©moire par conteneur
- I/O disque par conteneur
- Statistiques r√©seau par conteneur
- Performance du filesystem

**Point important** : cAdvisor est d√©j√† pr√©sent dans chaque node Kubernetes, pas besoin de l'installer.

### 4. Alertmanager : Le gestionnaire d'alertes

Alertmanager re√ßoit les alertes de Prometheus et les g√®re intelligemment.

#### Architecture interne d'Alertmanager

```
Alertes Prometheus
       ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ   ALERTMANAGER     ‚îÇ
   ‚îÇ                    ‚îÇ
   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
   ‚îÇ  ‚îÇ  Dispatcher  ‚îÇ  ‚îÇ  ‚Üê R√©ception des alertes
   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
   ‚îÇ         ‚Üì          ‚îÇ
   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
   ‚îÇ  ‚îÇ   Grouping   ‚îÇ  ‚îÇ  ‚Üê Regroupe les alertes similaires
   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
   ‚îÇ         ‚Üì          ‚îÇ
   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
   ‚îÇ  ‚îÇ Deduplication‚îÇ  ‚îÇ  ‚Üê √âlimine les doublons
   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
   ‚îÇ         ‚Üì          ‚îÇ
   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
   ‚îÇ  ‚îÇ   Silences   ‚îÇ  ‚îÇ  ‚Üê V√©rifie si l'alerte est silenc√©e
   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
   ‚îÇ         ‚Üì          ‚îÇ
   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
   ‚îÇ  ‚îÇ   Inhibition ‚îÇ  ‚îÇ  ‚Üê Supprime les alertes d√©pendantes
   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
   ‚îÇ         ‚Üì          ‚îÇ
   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
   ‚îÇ  ‚îÇ   Routing    ‚îÇ  ‚îÇ  ‚Üê D√©termine o√π envoyer l'alerte
   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
   ‚îÇ         ‚Üì          ‚îÇ
   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
   ‚îÇ  ‚îÇ  Notifiers   ‚îÇ  ‚îÇ  ‚Üê Envoie aux destinations
   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Fonctionnalit√©s cl√©s

**Grouping (Regroupement)** :

Au lieu de recevoir 50 alertes "Pod down" s√©par√©ment, vous recevez un seul message :
```
[FIRING:50] Pods are down in namespace production
- pod-1 is down
- pod-2 is down
- pod-3 is down
...
```

**Deduplication (D√©duplication)** :

Si Prometheus red√©marre ou si vous avez plusieurs serveurs Prometheus, Alertmanager √©limine les alertes identiques.

**Silences** :

Vous pouvez temporairement d√©sactiver des alertes :
```
"Je fais une maintenance sur le serveur DB,
ignore toutes les alertes 'Database down' pendant 2 heures"
```

**Inhibition** :

Supprime les alertes d√©pendantes. Exemple :
```
Si "Node down" est actif,
alors supprime toutes les alertes "Pod down" sur ce node
(car elles sont une cons√©quence √©vidente)
```

**Routing** :

Dirige les alertes vers les bonnes personnes :
```yaml
routes:
  - match:
      severity: critical
      team: backend
    receiver: backend-oncall-pagerduty

  - match:
      severity: warning
      team: frontend
    receiver: frontend-slack
```

### 5. Exporters d'application

#### Exporters officiels

Prometheus fournit des exporters officiels pour de nombreuses technologies :

- **PostgreSQL Exporter** : M√©triques de la base de donn√©es
- **MySQL Exporter** : M√©triques MySQL/MariaDB
- **Redis Exporter** : M√©triques Redis
- **NGINX Exporter** : M√©triques du serveur web
- **HAProxy Exporter** : M√©triques du load balancer
- **Elasticsearch Exporter** : M√©triques Elasticsearch

#### Biblioth√®ques client (Instrumentation)

Pour vos propres applications, Prometheus fournit des biblioth√®ques dans plusieurs langages :

- **Go** : github.com/prometheus/client_golang
- **Python** : prometheus_client
- **Java** : io.prometheus:simpleclient
- **Node.js** : prom-client
- **.NET** : prometheus-net
- **Ruby** : prometheus-client

**Exemple conceptuel** :

```python
# Dans votre application Python
from prometheus_client import Counter, Histogram

# Compteur de requ√™tes
http_requests = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])

# Histogramme de latence
request_latency = Histogram('http_request_duration_seconds', 'HTTP request latency')

# Dans votre code
http_requests.labels(method='GET', endpoint='/api/users').inc()
with request_latency.time():
    # Votre logique m√©tier
    process_request()
```

## Flux de donn√©es complet

Voici le parcours d'une m√©trique de sa cr√©ation √† sa visualisation :

```
1. APPLICATION
   ‚Üì
   G√©n√®re une m√©trique : http_requests_total{method="GET"} = 1547
   ‚Üì

2. EXPOSITION
   ‚Üì
   Expose sur HTTP : GET http://app:8080/metrics
   ‚Üì

3. D√âCOUVERTE
   ‚Üì
   Service Discovery d√©tecte l'application
   ‚Üì

4. COLLECTE
   ‚Üì
   Retrieval scrape l'endpoint toutes les 15s
   ‚Üì

5. STOCKAGE
   ‚Üì
   Time Series DB enregistre :
   http_requests_total{method="GET", instance="app-1"} 1547 @1698765432
   http_requests_total{method="GET", instance="app-1"} 1552 @1698765447
   ‚Üì

6. √âVALUATION
   ‚Üì
   Alert Rules Engine v√©rifie les conditions
   rate(http_requests_total[5m]) < 10 ‚Üí Alerte !
   ‚Üì

7. ALERTE
   ‚Üì
   Alertmanager re√ßoit, groupe, route
   ‚Üì

8. NOTIFICATION
   ‚Üì
   Email/Slack : "Low traffic detected on app-1"


En parall√®le :

6bis. REQU√äTE
   ‚Üì
   Grafana envoie une requ√™te PromQL
   ‚Üì

7bis. TRAITEMENT
   ‚Üì
   PromQL Engine ex√©cute la requ√™te
   ‚Üì

8bis. VISUALISATION
   ‚Üì
   Grafana affiche le graphique
```

## Consid√©rations d'architecture

### Scalabilit√©

**Limites d'un seul serveur Prometheus** :
- Peut g√©rer des milliers de targets
- Millions de s√©ries temporelles
- D√©pend du CPU, RAM, et I/O disque

**Quand scaler ?**
- Trop de m√©triques pour un seul serveur
- N√©cessit√© de haute disponibilit√©
- S√©paration par environnement ou √©quipe

**Strat√©gies de scaling** :
- **F√©d√©ration** : Prometheus hi√©rarchiques (un central agr√®ge plusieurs locaux)
- **Sharding** : D√©couper par namespace/application
- **Remote Storage** : Utiliser un stockage long-terme (Thanos, Cortex)

### Stockage et r√©tention

**Combien d'espace disque ?**

Estimation simplifi√©e :
```
Espace = nb_de_s√©ries √ó √©chantillons_par_jour √ó taille_√©chantillon √ó r√©tention_jours

Exemple :
100 000 s√©ries √ó 5 760 √©chantillons/jour √ó 2 octets √ó 15 jours
= 17 Go environ
```

**Ajuster la r√©tention** :
```yaml
# Dans la configuration Prometheus
storage:
  tsdb:
    retention.time: 15d    # Garder 15 jours
    retention.size: 50GB   # Ou 50 Go maximum
```

### Haute disponibilit√©

**Probl√®me** : Un seul Prometheus = point unique de d√©faillance

**Solutions** :
1. **Plusieurs Prometheus identiques** : Ils scrapent tous les m√™mes targets
2. **Alertmanager en cluster** : Ils se synchronisent pour d√©dupliquer
3. **Stockage externe** : Pour ne pas perdre l'historique

**Note importante pour MicroK8s** :

Pour un lab, la haute disponibilit√© n'est g√©n√©ralement pas n√©cessaire. Une instance Prometheus suffit. Nous couvrirons ce sujet dans la section 12.8 pour ceux qui veulent aller plus loin.

## Architecture dans MicroK8s

Lorsque vous ex√©cutez `microk8s enable prometheus`, voici ce qui est d√©ploy√© :

```
Namespace: monitoring

Deployments:
‚îú‚îÄ‚îÄ prometheus-k8s (Prometheus Server)
‚îú‚îÄ‚îÄ alertmanager-main (Alertmanager)
‚îú‚îÄ‚îÄ kube-state-metrics (√âtat Kubernetes)
‚îî‚îÄ‚îÄ prometheus-operator (Gestion des CRDs Prometheus)

DaemonSets:
‚îî‚îÄ‚îÄ node-exporter (Un par node)

Services:
‚îú‚îÄ‚îÄ prometheus-k8s (Port 9090)
‚îú‚îÄ‚îÄ alertmanager-main (Port 9093)
‚îî‚îÄ‚îÄ kube-state-metrics (Port 8080)

ConfigMaps:
‚îú‚îÄ‚îÄ prometheus-k8s-rulefiles (R√®gles d'alerte)
‚îî‚îÄ‚îÄ alertmanager-main (Configuration Alertmanager)

Secrets:
‚îî‚îÄ‚îÄ prometheus-k8s (Tokens, certificats)
```

**Prometheus Operator** :

MicroK8s utilise le Prometheus Operator, qui est une extension Kubernetes qui facilite la gestion de Prometheus via des Custom Resources :

- **ServiceMonitor** : D√©finit quels services scraper
- **PodMonitor** : D√©finit quels pods scraper
- **PrometheusRule** : D√©finit les r√®gles d'alerte
- **Alertmanager** : Configuration d'Alertmanager

Pas d'inqui√©tude si ces concepts sont nouveaux, nous les explorerons en pratique dans les prochaines sections.

## Points cl√©s √† retenir

1. **Prometheus Server** est le c≈ìur qui collecte, stocke, et √©value les m√©triques
2. **Service Discovery** permet la d√©couverte automatique des targets dans Kubernetes
3. **Time Series Database** stocke efficacement les m√©triques avec leur historique
4. **Exporters** traduisent les m√©triques de diff√©rents syst√®mes au format Prometheus
5. **Alertmanager** g√®re intelligemment les alertes (grouping, routing, silences)
6. **PromQL** est le langage pour interroger les donn√©es
7. L'architecture est modulaire et chaque composant a un r√¥le pr√©cis

## Prochaines √©tapes

Maintenant que vous comprenez l'architecture, dans la prochaine section (12.3), nous allons **installer et configurer Prometheus** dans votre cluster MicroK8s et explorer l'interface web.

---

**Conseil** : Ne vous sentez pas oblig√© de m√©moriser tous ces d√©tails imm√©diatement. Revenez √† cette section lorsque vous aurez des questions sur "comment fonctionne telle ou telle partie". L'architecture prendra tout son sens au fur et √† mesure de votre pratique.

‚è≠Ô∏è [Installation de Prometheus (microk8s enable prometheus)](/12-monitoring-avec-prometheus/03-installation-de-prometheus-sur-microk8s.md)
