üîù Retour au [Sommaire](/SOMMAIRE.md)

# 20.5 Taints et Tolerations

## Introduction

Nous avons explor√© comment **attirer** les Pods vers certains n≈ìuds avec Node Selectors, Node Affinity et Pod Affinity. Mais que faire si vous voulez **repousser** les Pods de certains n≈ìuds ?

C'est exactement le r√¥le des **Taints** (souillures) et **Tolerations** (tol√©rances). Les Taints marquent un n≈ìud comme "sp√©cial" ou "restreint", et seuls les Pods ayant la Toleration appropri√©e peuvent y √™tre ordonnanc√©s.

### Analogie Simple

Imaginez un restaurant avec diff√©rentes sections :
- **Taints** = Panneaux "R√©serv√© VIP", "Zone fumeurs", "Acc√®s restreint"
- **Tolerations** = Badges ou autorisations sp√©ciales qui permettent d'entrer dans ces zones

Si vous n'avez pas le bon badge, vous ne pouvez pas entrer dans la zone r√©serv√©e.

---

## Concept de Base

### Taints (sur les N≈ìuds)

Un **Taint** est une propri√©t√© appliqu√©e √† un **n≈ìud** qui repousse les Pods. Un taint est compos√© de trois parties :

```
<key>=<value>:<effect>
```

- **key** : L'identifiant du taint (ex: `gpu`, `maintenance`, `dedicated`)
- **value** : Une valeur optionnelle (ex: `true`, `team-a`, `high-priority`)
- **effect** : Ce qui se passe pour les Pods non tol√©rants

### Tolerations (sur les Pods)

Une **Toleration** est une propri√©t√© ajout√©e √† un **Pod** qui lui permet de "tol√©rer" un taint et donc d'√™tre ordonnanc√© sur un n≈ìud avec ce taint.

### Relation Taint-Toleration

```
N≈ìud avec Taint: "special=true:NoSchedule"
                    ‚Üì
        Bloque tous les Pods
                    ‚Üì
        SAUF ceux qui ont une Toleration correspondante
                    ‚Üì
Pod avec Toleration: "special=true"
```

---

## Les Trois Effets des Taints

Kubernetes propose trois effets diff√©rents pour les taints, qui d√©finissent le comportement vis-√†-vis des Pods.

### 1. NoSchedule (Ne Pas Ordonnancer)

**Comportement** :
- Les nouveaux Pods **sans** toleration correspondante ne seront **jamais** ordonnanc√©s sur ce n≈ìud
- Les Pods **d√©j√† pr√©sents** sur le n≈ìud avant l'ajout du taint continuent de fonctionner normalement

**Usage** : Le plus courant, pour r√©server des n≈ìuds √† des workloads sp√©cifiques.

**Exemple** :
```bash
kubectl taint nodes node1 gpu=true:NoSchedule
```

### 2. PreferNoSchedule (Pr√©f√©rer Ne Pas Ordonnancer)

**Comportement** :
- Le scheduler **√©vite** de placer des Pods sans toleration sur ce n≈ìud
- Mais si **aucun autre n≈ìud** n'est disponible, le Pod sera quand m√™me plac√© ici
- C'est une **pr√©f√©rence douce**, pas une interdiction stricte

**Usage** : Pour d√©courager l'utilisation d'un n≈ìud sans la bloquer compl√®tement.

**Exemple** :
```bash
kubectl taint nodes node1 low-priority=true:PreferNoSchedule
```

### 3. NoExecute (Ne Pas Ex√©cuter)

**Comportement** :
- Les nouveaux Pods sans toleration ne seront **pas** ordonnanc√©s
- Les Pods **d√©j√† pr√©sents** sans toleration seront **expuls√©s** (√©victed)
- C'est l'effet le plus strict

**Usage** : Pour √©vacuer un n≈ìud ou le mettre en maintenance.

**Exemple** :
```bash
kubectl taint nodes node1 maintenance=true:NoExecute
```

**‚ö†Ô∏è Attention** : `NoExecute` peut interrompre des Pods en cours d'ex√©cution !

---

## Ajouter un Taint √† un N≈ìud

### Syntaxe G√©n√©rale

```bash
kubectl taint nodes <nom-noeud> <key>=<value>:<effect>
```

### Exemples Pratiques

#### Exemple 1 : R√©server un N≈ìud avec GPU

```bash
kubectl taint nodes node-gpu gpu=true:NoSchedule
```

**R√©sultat** : Seuls les Pods tol√©rant `gpu=true` pourront √™tre ordonnanc√©s sur `node-gpu`.

#### Exemple 2 : D√©dier un N≈ìud √† une √âquipe

```bash
kubectl taint nodes node-team-a team=team-a:NoSchedule
```

**R√©sultat** : Seuls les Pods de l'√©quipe A (avec toleration) iront sur ce n≈ìud.

#### Exemple 3 : D√©courager l'Utilisation d'un N≈ìud

```bash
kubectl taint nodes node-old deprecated=true:PreferNoSchedule
```

**R√©sultat** : Le scheduler √©vite ce n≈ìud, mais l'utilise si n√©cessaire.

#### Exemple 4 : Mettre un N≈ìud en Maintenance

```bash
kubectl taint nodes node1 maintenance=scheduled:NoExecute
```

**R√©sultat** : Tous les Pods sans toleration seront expuls√©s imm√©diatement.

### V√©rifier les Taints d'un N≈ìud

```bash
kubectl describe node <nom-noeud>
```

Dans la sortie, recherchez la section **Taints** :
```
Taints:    gpu=true:NoSchedule
```

Ou pour voir tous les n≈ìuds avec leurs taints :
```bash
kubectl get nodes -o custom-columns=NAME:.metadata.name,TAINTS:.spec.taints
```

---

## Ajouter une Toleration √† un Pod

### Syntaxe de Base

Dans le manifeste YAML du Pod, ajoutez la section `tolerations` :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mon-pod
spec:
  tolerations:
  - key: "<key>"
    operator: "Equal"
    value: "<value>"
    effect: "<effect>"
  containers:
  - name: mon-conteneur
    image: nginx
```

### Op√©rateurs de Toleration

Il existe deux op√©rateurs principaux :

#### 1. Equal (√âgal)

Le Pod tol√®re un taint si la cl√©, la valeur ET l'effet correspondent exactement.

```yaml
tolerations:
- key: "gpu"
  operator: "Equal"
  value: "true"
  effect: "NoSchedule"
```

**Signification** : Ce Pod tol√®re le taint `gpu=true:NoSchedule`.

#### 2. Exists (Existe)

Le Pod tol√®re un taint si la cl√© (et optionnellement l'effet) correspondent, **quelle que soit la valeur**.

```yaml
tolerations:
- key: "gpu"
  operator: "Exists"
  effect: "NoSchedule"
```

**Signification** : Ce Pod tol√®re **n'importe quel** taint avec la cl√© `gpu` et l'effet `NoSchedule`, peu importe la valeur.

### Toleration Universelle

Pour tol√©rer **tous** les taints d'un n≈ìud :

```yaml
tolerations:
- operator: "Exists"
```

**‚ö†Ô∏è Attention** : √Ä utiliser avec pr√©caution, cela ignore tous les taints !

---

## Exemples Pratiques Complets

### Exemple 1 : N≈ìud GPU R√©serv√©

**√âtape 1** : Ajouter un taint au n≈ìud GPU

```bash
kubectl taint nodes node-gpu hardware=gpu:NoSchedule
```

**√âtape 2** : D√©ployer une application de machine learning

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tensorflow-training
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ml-training
  template:
    metadata:
      labels:
        app: ml-training
    spec:
      tolerations:
      - key: "hardware"
        operator: "Equal"
        value: "gpu"
        effect: "NoSchedule"
      containers:
      - name: tensorflow
        image: tensorflow/tensorflow:latest-gpu
        resources:
          limits:
            nvidia.com/gpu: 1
```

**R√©sultat** :
- Les Pods de TensorFlow peuvent √™tre ordonnanc√©s sur `node-gpu`
- Tous les autres Pods (sans cette toleration) seront bloqu√©s

### Exemple 2 : N≈ìuds D√©di√©s par Environnement

**Configuration** :

```bash
# N≈ìuds de production
kubectl taint nodes node-prod-1 environment=production:NoSchedule
kubectl taint nodes node-prod-2 environment=production:NoSchedule

# N≈ìuds de staging
kubectl taint nodes node-staging-1 environment=staging:NoSchedule
```

**D√©ploiement Production** :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-production
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: mon-app
      env: production
  template:
    metadata:
      labels:
        app: mon-app
        env: production
    spec:
      tolerations:
      - key: "environment"
        operator: "Equal"
        value: "production"
        effect: "NoSchedule"
      containers:
      - name: app
        image: mon-app:v1.2.3
        resources:
          requests:
            cpu: "1000m"
            memory: "2Gi"
```

**D√©ploiement Staging** :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-staging
  namespace: staging
spec:
  replicas: 2
  selector:
    matchLabels:
      app: mon-app
      env: staging
  template:
    metadata:
      labels:
        app: mon-app
        env: staging
    spec:
      tolerations:
      - key: "environment"
        operator: "Equal"
        value: "staging"
        effect: "NoSchedule"
      containers:
      - name: app
        image: mon-app:latest
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
```

**R√©sultat** :
- Les apps de production ne vont que sur les n≈ìuds de production
- Les apps de staging ne vont que sur les n≈ìuds de staging
- Isolation compl√®te des environnements

### Exemple 3 : Maintenance d'un N≈ìud

Vous devez effectuer une maintenance sur un n≈ìud.

**√âtape 1** : Marquer le n≈ìud en maintenance (expulse les Pods existants)

```bash
kubectl taint nodes node1 maintenance=true:NoExecute
```

**√âtape 2** : Les Pods sans toleration sont expuls√©s automatiquement et re-cr√©√©s ailleurs

**√âtape 3** : Effectuer la maintenance

**√âtape 4** : Retirer le taint quand c'est termin√©

```bash
kubectl taint nodes node1 maintenance:NoExecute-
```

### Exemple 4 : Pods Syst√®me avec Toleration Universelle

Certains Pods syst√®me doivent pouvoir tourner partout, m√™me sur des n≈ìuds avec des taints.

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: monitoring-agent
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: monitoring
  template:
    metadata:
      labels:
        app: monitoring
    spec:
      tolerations:
      # Tol√®re tous les taints
      - operator: "Exists"
      containers:
      - name: agent
        image: monitoring-agent:latest
```

**R√©sultat** : L'agent de monitoring tourne sur **tous** les n≈ìuds, quels que soient leurs taints.

---

## Taints par D√©faut de Kubernetes

Kubernetes ajoute automatiquement certains taints dans des situations sp√©cifiques.

### 1. node.kubernetes.io/not-ready

**Quand** : N≈ìud pas encore pr√™t (au d√©marrage)

**Effet** : `NoExecute`

**Signification** : Les Pods ne peuvent pas √™tre ordonnanc√©s tant que le n≈ìud n'est pas pr√™t.

### 2. node.kubernetes.io/unreachable

**Quand** : N≈ìud injoignable par le control plane

**Effet** : `NoExecute`

**Signification** : Les Pods sont √©vacu√©s si le n≈ìud devient injoignable.

### 3. node.kubernetes.io/memory-pressure

**Quand** : N≈ìud sous pression m√©moire

**Effet** : `NoSchedule`

**Signification** : Nouveaux Pods non critiques ne seront pas ordonnanc√©s.

### 4. node.kubernetes.io/disk-pressure

**Quand** : N≈ìud sous pression disque

**Effet** : `NoSchedule`

**Signification** : Nouveaux Pods ne seront pas ordonnanc√©s.

### 5. node.kubernetes.io/unschedulable

**Quand** : N≈ìud marqu√© comme non-ordonnan√ßable (avec `kubectl cordon`)

**Effet** : `NoSchedule`

**Signification** : Aucun nouveau Pod ne sera ordonnanc√©.

### Voir les Taints Automatiques

```bash
kubectl describe node <nom-noeud> | grep Taints
```

---

## Toleration avec Dur√©e (tolerationSeconds)

Pour l'effet `NoExecute`, vous pouvez sp√©cifier combien de temps un Pod peut rester sur un n≈ìud apr√®s qu'un taint `NoExecute` a √©t√© ajout√©.

### Syntaxe

```yaml
tolerations:
- key: "node.kubernetes.io/not-ready"
  operator: "Exists"
  effect: "NoExecute"
  tolerationSeconds: 300
```

**Signification** :
- Si le n≈ìud devient "not-ready", le Pod peut rester pendant 300 secondes (5 minutes)
- Apr√®s ce d√©lai, le Pod sera expuls√©

### Cas d'Usage

Utile pour les Pods qui peuvent tol√©rer des pannes temporaires sans √™tre imm√©diatement expuls√©s.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-resiliente
spec:
  replicas: 3
  selector:
    matchLabels:
      app: resilient
  template:
    metadata:
      labels:
        app: resilient
    spec:
      tolerations:
      # Tol√®re un n≈ìud qui ne r√©pond plus pendant 10 minutes
      - key: "node.kubernetes.io/unreachable"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 600
      # Tol√®re un n≈ìud not-ready pendant 5 minutes
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 300
      containers:
      - name: app
        image: mon-app:latest
```

**R√©sultat** :
- Si un n≈ìud devient injoignable, les Pods attendent 10 minutes avant d'√™tre relocalis√©s
- √âvite des migrations inutiles pour des pannes courtes

---

## Retirer un Taint

Pour retirer un taint d'un n≈ìud, ajoutez un `-` √† la fin de la commande.

### Syntaxe

```bash
kubectl taint nodes <nom-noeud> <key>:<effect>-
```

### Exemples

```bash
# Retirer un taint sp√©cifique
kubectl taint nodes node1 gpu=true:NoSchedule-

# Si vous ne connaissez pas la valeur, utilisez juste la cl√©
kubectl taint nodes node1 gpu:NoSchedule-

# Retirer un taint NoExecute
kubectl taint nodes node1 maintenance:NoExecute-
```

### Retirer Tous les Taints d'un N≈ìud

```bash
# Voir les taints actuels
kubectl describe node node1 | grep Taints

# Retirer chaque taint individuellement
kubectl taint nodes node1 <key1>:<effect1>-
kubectl taint nodes node1 <key2>:<effect2>-
```

---

## Combinaison avec d'Autres M√©canismes

Les taints et tolerations se combinent avec les autres m√©canismes d'ordonnancement.

### Taint + Node Selector

```yaml
spec:
  nodeSelector:
    disktype: ssd
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "database"
    effect: "NoSchedule"
  containers:
  - name: postgres
    image: postgres:14
```

**Comportement** :
- Le Pod doit √™tre sur un n≈ìud avec `disktype=ssd` (Node Selector)
- Le Pod peut tol√©rer le taint `dedicated=database:NoSchedule`
- Si un n≈ìud a un SSD ET le taint, le Pod peut y aller

### Taint + Node Affinity

```yaml
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: performance
            operator: In
            values:
            - high
  tolerations:
  - key: "expensive"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
  containers:
  - name: app
    image: app-intensive:latest
```

### Taint + Pod Anti-Affinity

```yaml
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: mon-app
        topologyKey: kubernetes.io/hostname
  tolerations:
  - key: "special"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
  containers:
  - name: app
    image: mon-app:latest
```

---

## Cas d'Usage Pratiques avec MicroK8s

### Cas 1 : Cluster Hybride (Compute vs Storage)

Vous avez des n≈ìuds pour le calcul et d'autres pour le stockage.

**Configuration** :

```bash
# N≈ìuds de calcul
kubectl label nodes node1 role=compute
kubectl label nodes node2 role=compute

# N≈ìuds de stockage (avec taint pour les r√©server)
kubectl label nodes node3 role=storage
kubectl taint nodes node3 workload=storage:NoSchedule
kubectl label nodes node4 role=storage
kubectl taint nodes node4 workload=storage:NoSchedule
```

**Application Standard (va sur les n≈ìuds de calcul)** :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 4
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      # Pas de toleration = ne va pas sur les n≈ìuds storage
      containers:
      - name: nginx
        image: nginx:latest
```

**Base de Donn√©es (va sur les n≈ìuds de stockage)** :

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: database
spec:
  serviceName: db
  replicas: 2
  selector:
    matchLabels:
      app: database
  template:
    metadata:
      labels:
        app: database
    spec:
      tolerations:
      - key: "workload"
        operator: "Equal"
        value: "storage"
        effect: "NoSchedule"
      nodeSelector:
        role: storage
      containers:
      - name: postgres
        image: postgres:14
```

**R√©sultat** :
- Applications normales sur n≈ìuds compute (node1, node2)
- Bases de donn√©es sur n≈ìuds storage (node3, node4)
- Isolation claire des workloads

### Cas 2 : N≈ìuds √† Co√ªt √âlev√© (Spot Instances)

Vous avez des n≈ìuds spot (moins chers mais peuvent √™tre interrompus).

**Configuration** :

```bash
kubectl label nodes node-spot-1 instance-type=spot
kubectl taint nodes node-spot-1 spot=true:PreferNoSchedule
kubectl label nodes node-spot-2 instance-type=spot
kubectl taint nodes node-spot-2 spot=true:PreferNoSchedule
```

**Application Batch (tol√®re les spots)** :

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: data-processing
spec:
  template:
    metadata:
      labels:
        app: batch-job
    spec:
      tolerations:
      - key: "spot"
        operator: "Equal"
        value: "true"
        effect: "PreferNoSchedule"
      restartPolicy: OnFailure
      containers:
      - name: processor
        image: data-processor:latest
```

**Application Critique (√©vite les spots)** :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api
  template:
    metadata:
      labels:
        app: api
    spec:
      # Pas de toleration = √©vite les n≈ìuds spot (gr√¢ce √† PreferNoSchedule)
      containers:
      - name: api
        image: api:v1
```

**R√©sultat** :
- Jobs batch utilisent de pr√©f√©rence les instances spot (moins chers)
- Applications critiques √©vitent les spots mais peuvent les utiliser en dernier recours

### Cas 3 : Rotation et Mise √† Jour des N≈ìuds

Vous voulez vider un n≈ìud pour le mettre √† jour.

**√âtape 1** : Cordon (emp√™che les nouveaux Pods)

```bash
kubectl cordon node1
```

Cela ajoute automatiquement le taint : `node.kubernetes.io/unschedulable:NoSchedule`

**√âtape 2** : Drain (√©vacue les Pods existants)

```bash
kubectl drain node1 --ignore-daemonsets --delete-emptydir-data
```

Cela ajoute un taint `NoExecute` qui expulse tous les Pods.

**√âtape 3** : Effectuer la mise √† jour du n≈ìud

**√âtape 4** : Uncordon (r√©active le n≈ìud)

```bash
kubectl uncordon node1
```

Retire tous les taints ajout√©s.

---

## D√©bogage et Diagnostics

### Pod en Pending √† Cause d'un Taint

```bash
kubectl describe pod <pod-name>
```

√âv√©nements typiques :
```
Events:
  Type     Reason            Message
  ----     ------            -------
  Warning  FailedScheduling  0/3 nodes are available:
                             1 node(s) had taint {gpu: true}, that the pod didn't tolerate.
                             2 node(s) had taint {environment: production}, that the pod didn't tolerate.
```

**Solution** : Ajouter la toleration appropri√©e au Pod.

### Lister les N≈ìuds avec leurs Taints

```bash
kubectl get nodes -o json | jq '.items[] | {name: .metadata.name, taints: .spec.taints}'
```

Ou plus simple :

```bash
kubectl describe nodes | grep -A 5 "Taints:"
```

### Voir Quels Pods Tournent sur un N≈ìud avec Taints

```bash
kubectl get pods --all-namespaces -o wide --field-selector spec.nodeName=node1
```

---

## Bonnes Pratiques

### 1. Utilisez des Cl√©s Descriptives

```yaml
# ‚úÖ Bon : Cl√© claire
tolerations:
- key: "dedicated-gpu"
  operator: "Equal"
  value: "ml-training"
  effect: "NoSchedule"
```

```yaml
# ‚ùå Mauvais : Cl√© vague
tolerations:
- key: "special"
  operator: "Equal"
  value: "yes"
  effect: "NoSchedule"
```

### 2. Documentez vos Taints

Maintenez une documentation des taints utilis√©s dans votre cluster :

```markdown
# Taints Standard du Cluster

## N≈ìuds GPU
- Key: `hardware`
- Value: `gpu`
- Effect: `NoSchedule`
- Usage: R√©serv√© pour workloads ML/AI

## N≈ìuds Production
- Key: `environment`
- Value: `production`
- Effect: `NoSchedule`
- Usage: Applications de production uniquement

## Maintenance
- Key: `maintenance`
- Value: `true`
- Effect: `NoExecute`
- Usage: N≈ìud en maintenance, √©vacuation des Pods
```

### 3. NoExecute avec Pr√©caution

L'effet `NoExecute` peut interrompre des services. Utilisez-le avec pr√©caution :

```bash
# ‚úÖ Bon : Drain pour √©vacuer progressivement
kubectl drain node1 --ignore-daemonsets

# ‚ö†Ô∏è Attention : NoExecute √©vacue brutalement
kubectl taint nodes node1 maintenance=true:NoExecute
```

### 4. Combinez avec Labels

Les taints vont bien avec les labels pour une organisation claire :

```bash
# Label pour identifier le n≈ìud
kubectl label nodes node1 hardware=gpu

# Taint pour restreindre l'acc√®s
kubectl taint nodes node1 hardware=gpu:NoSchedule
```

### 5. Pr√©f√©rez PreferNoSchedule pour Commencer

Si vous n'√™tes pas s√ªr, utilisez `PreferNoSchedule` plut√¥t que `NoSchedule` :

```bash
# ‚úÖ Plus flexible
kubectl taint nodes node1 deprecated=true:PreferNoSchedule

# ‚ö†Ô∏è Plus strict
kubectl taint nodes node1 deprecated=true:NoSchedule
```

### 6. Taints Temporaires

Pour des taints temporaires, utilisez des noms explicites :

```bash
kubectl taint nodes node1 temporary-maintenance=$(date +%Y%m%d):NoExecute
```

Facilite l'identification des taints anciens √† nettoyer.

### 7. DaemonSets et Tolerations

Les DaemonSets ont souvent besoin de tolerations pour tourner partout :

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: log-collector
spec:
  selector:
    matchLabels:
      app: logs
  template:
    metadata:
      labels:
        app: logs
    spec:
      tolerations:
      # Tol√®re tous les taints pour tourner sur tous les n≈ìuds
      - operator: "Exists"
      containers:
      - name: fluentd
        image: fluentd:latest
```

---

## Comparaison : Taints vs Node Affinity

| Aspect | Taints + Tolerations | Node Affinity |
|--------|---------------------|---------------|
| **Direction** | N≈ìud ‚Üí Pod (repousse) | Pod ‚Üí N≈ìud (attire) |
| **Philosophie** | "Qui ne peut PAS venir ici ?" | "O√π ce Pod DOIT-il aller ?" |
| **Par d√©faut** | Bloque tout le monde | Autorise tout le monde |
| **Flexibilit√©** | 3 effets (NoSchedule, Prefer, NoExecute) | Required vs Preferred |
| **√âviction** | Oui (NoExecute) | Non |
| **Cas d'usage** | R√©server, isoler, maintenir | Optimiser, pr√©f√©rer, exiger |

### Quand Utiliser Quoi ?

**Utilisez Taints** quand :
- Vous voulez **r√©server** un n≈ìud pour un usage sp√©cial
- Vous voulez **prot√©ger** un n≈ìud contre les Pods normaux
- Vous voulez **√©vacuer** un n≈ìud

**Utilisez Node Affinity** quand :
- Vous voulez **diriger** des Pods vers certains n≈ìuds
- Vous voulez **exprimer des pr√©f√©rences** de placement
- Vous avez des **crit√®res complexes** de s√©lection

**Souvent, utilisez les deux ensemble** pour un contr√¥le complet !

---

## Exemple Complet : Architecture Enterprise

Voici une architecture compl√®te utilisant taints, tolerations et autres m√©canismes.

### Architecture

```
Cluster de 6 n≈ìuds :
- 2 n≈ìuds GPU (taints: gpu=true)
- 2 n≈ìuds Production (taints: env=prod)
- 2 n≈ìuds D√©veloppement (pas de taints)
```

### Configuration des N≈ìuds

```bash
# N≈ìuds GPU
kubectl label nodes node-gpu-1 hardware=gpu zone=a
kubectl taint nodes node-gpu-1 hardware=gpu:NoSchedule
kubectl label nodes node-gpu-2 hardware=gpu zone=b
kubectl taint nodes node-gpu-2 hardware=gpu:NoSchedule

# N≈ìuds Production
kubectl label nodes node-prod-1 environment=production zone=a disktype=ssd
kubectl taint nodes node-prod-1 environment=production:NoSchedule
kubectl label nodes node-prod-2 environment=production zone=b disktype=ssd
kubectl taint nodes node-prod-2 environment=production:NoSchedule

# N≈ìuds Dev (pas de taints)
kubectl label nodes node-dev-1 environment=development zone=a
kubectl label nodes node-dev-2 environment=development zone=b
```

### 1. Application de Machine Learning

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-training
  namespace: ml
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ml-training
  template:
    metadata:
      labels:
        app: ml-training
    spec:
      # Toleration pour acc√©der aux n≈ìuds GPU
      tolerations:
      - key: "hardware"
        operator: "Equal"
        value: "gpu"
        effect: "NoSchedule"
      # Node Affinity pour exiger un GPU
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: hardware
                operator: In
                values:
                - gpu
        # Pod Anti-Affinity pour distribuer
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: ml-training
              topologyKey: kubernetes.io/hostname
      containers:
      - name: tensorflow
        image: tensorflow/tensorflow:latest-gpu
        resources:
          limits:
            nvidia.com/gpu: 1
```

### 2. API de Production

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-production
  namespace: production
spec:
  replicas: 4
  selector:
    matchLabels:
      app: api
      env: production
  template:
    metadata:
      labels:
        app: api
        env: production
    spec:
      # Toleration pour acc√©der aux n≈ìuds production
      tolerations:
      - key: "environment"
        operator: "Equal"
        value: "production"
        effect: "NoSchedule"
      # Node Affinity pour exiger production + SSD
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: environment
                operator: In
                values:
                - production
              - key: disktype
                operator: In
                values:
                - ssd
        # Pod Anti-Affinity pour haute disponibilit√©
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: api
            topologyKey: zone
      containers:
      - name: api
        image: api:v2.1.0
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
```

### 3. Application de D√©veloppement

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-dev
  namespace: development
spec:
  replicas: 2
  selector:
    matchLabels:
      app: test-app
      env: dev
  template:
    metadata:
      labels:
        app: test-app
        env: dev
    spec:
      # Pas de tolerations = va uniquement sur les n≈ìuds dev (sans taints)
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: environment
                operator: In
                values:
                - development
      containers:
      - name: app
        image: test-app:latest
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
```

### 4. Monitoring (DaemonSet sur tous les n≈ìuds)

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      # Tol√®re tous les taints pour tourner partout
      tolerations:
      - operator: "Exists"
      containers:
      - name: node-exporter
        image: prom/node-exporter:latest
        ports:
        - containerPort: 9100
```

**R√©sultat de cette architecture** :
- ML training : Uniquement sur les n≈ìuds GPU
- API Production : Uniquement sur les n≈ìuds production avec SSD, distribu√©e par zone
- App Dev : Uniquement sur les n≈ìuds dev
- Monitoring : Sur tous les n≈ìuds
- Isolation compl√®te et optimisation des ressources

---

## Points Cl√©s √† Retenir

1. **Taints** = Marquent les n≈ìuds comme "sp√©ciaux" et repoussent les Pods
2. **Tolerations** = Permettent aux Pods de "tol√©rer" les taints
3. **Trois effets** :
   - `NoSchedule` : Bloque les nouveaux Pods
   - `PreferNoSchedule` : D√©courage mais n'emp√™che pas
   - `NoExecute` : √âvacue les Pods existants
4. **Direction** : N≈ìud ‚Üí Pod (contrairement √† l'affinity qui va Pod ‚Üí N≈ìud)
5. **Compl√©mentaire** : Combinez avec Node/Pod Affinity pour un contr√¥le total
6. **Maintenance** : Tr√®s utile pour cordon/drain des n≈ìuds
7. **DaemonSets** : N√©cessitent souvent `tolerations: operator: Exists`

---

## Conclusion

Les Taints et Tolerations sont un m√©canisme puissant et compl√©mentaire aux autres outils d'ordonnancement. Ils fonctionnent dans la direction inverse des affinities : au lieu de dire o√π les Pods **doivent** aller, vous dites o√π ils **ne peuvent pas** aller (sauf exception).

**Cas d'usage principaux** :
- **R√©server** des n≈ìuds pour des workloads sp√©ciaux (GPU, production, etc.)
- **Isoler** les environnements
- **Maintenir** les n≈ìuds en les vidant de leurs Pods
- **Prot√©ger** les n≈ìuds critiques

En combinant intelligemment Taints, Tolerations, Node Affinity et Pod Affinity, vous disposez d'un arsenal complet pour orchestrer pr√©cis√©ment le placement de vos Pods dans votre cluster Kubernetes.

Dans la prochaine section, nous d√©couvrirons les **Topology Spread Constraints**, un m√©canisme plus r√©cent et souvent plus simple pour distribuer uniform√©ment vos Pods √† travers votre infrastructure.

---

## Pour Aller Plus Loin

- **Documentation officielle** : [Taints and Tolerations](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
- **Node Maintenance** : [Safely Drain a Node](https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/)
- **Eviction** : [Pod Eviction](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-eviction/)

---

**Prochain chapitre** : 20.6 Topology Spread Constraints - Distribuer uniform√©ment vos Pods avec simplicit√©

‚è≠Ô∏è [Topology Spread Constraints](/20-ordonnancement-avance/06-topology-spread-constraints.md)
