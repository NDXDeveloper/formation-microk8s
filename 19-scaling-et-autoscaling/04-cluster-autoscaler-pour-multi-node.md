üîù Retour au [Sommaire](/SOMMAIRE.md)

# 19.4 Cluster Autoscaler (pour multi-node)

## Introduction au Cluster Autoscaler

Le **Cluster Autoscaler (CA)** est un composant Kubernetes qui ajuste automatiquement la taille de votre cluster en ajoutant ou retirant des **n≈ìuds** (nodes) en fonction des besoins. C'est le troisi√®me type d'autoscaling que nous d√©couvrons, et il compl√®te le HPA et le VPA.

### Les trois types d'autoscaling : R√©capitulatif

Avant d'entrer dans les d√©tails, r√©capitulons les trois niveaux d'autoscaling :

**1. Horizontal Pod Autoscaler (HPA) :**
- **Niveau :** Pods
- **Action :** Ajoute ou retire des pods
- **Exemple :** 3 pods ‚Üí 10 pods (sur les m√™mes n≈ìuds)

**2. Vertical Pod Autoscaler (VPA) :**
- **Niveau :** Ressources des pods
- **Action :** Augmente ou diminue CPU/m√©moire par pod
- **Exemple :** Pod avec 100m CPU ‚Üí Pod avec 500m CPU

**3. Cluster Autoscaler (CA) :**
- **Niveau :** N≈ìuds du cluster
- **Action :** Ajoute ou retire des machines (n≈ìuds)
- **Exemple :** Cluster de 3 n≈ìuds ‚Üí Cluster de 6 n≈ìuds

### Analogie de l'immeuble

Imaginez un immeuble de bureaux :

**HPA (Horizontal Pod Autoscaler) :**
- Ajouter plus d'employ√©s dans les bureaux existants
- "On embauche 5 personnes de plus"

**VPA (Vertical Pod Autoscaler) :**
- Donner un plus grand bureau √† chaque employ√©
- "Chaque employ√© passe d'un bureau de 10m¬≤ √† 20m¬≤"

**CA (Cluster Autoscaler) :**
- Louer un √©tage suppl√©mentaire dans l'immeuble
- "On ajoute tout un nouvel √©tage avec plus de bureaux"

Le Cluster Autoscaler agit au niveau le plus haut : l'infrastructure elle-m√™me !

## Pourquoi utiliser le Cluster Autoscaler ?

### Le probl√®me : Capacit√© limit√©e du cluster

Imaginez cette situation :

```
√âtat initial :
- Cluster avec 3 n≈ìuds
- Chaque n≈ìud : 4 CPU, 8 Gi RAM
- Capacit√© totale : 12 CPU, 24 Gi RAM

Une application n√©cessite :
- 20 r√©pliques
- Chaque pod : 1 CPU, 2 Gi RAM
- Besoin total : 20 CPU, 40 Gi RAM

Probl√®me : Pas assez de ressources !
```

Le HPA voudrait cr√©er 20 pods, mais le cluster n'a que 12 CPU disponibles. Les pods restent en √©tat `Pending` (en attente).

### La solution : Cluster Autoscaler

Le Cluster Autoscaler d√©tecte que des pods sont en attente faute de ressources, et :
1. Ajoute automatiquement de nouveaux n≈ìuds au cluster
2. Les pods en attente sont alors programm√©s sur ces nouveaux n≈ìuds
3. Quand la charge diminue, retire les n≈ìuds inutilis√©s

**Avantages :**

- ‚úÖ Capacit√© illimit√©e (dans les limites de votre infrastructure)
- ‚úÖ Optimisation automatique des co√ªts (retire les n≈ìuds inutiles)
- ‚úÖ Pas de limite artificielle de ressources
- ‚úÖ Fonctionne en synergie avec le HPA
- ‚úÖ Transparence pour les applications

## Comment fonctionne le Cluster Autoscaler ?

Le Cluster Autoscaler suit un cycle de d√©cision en deux phases :

### Phase 1 : Scale Up (Ajout de n≈ìuds)

Le CA surveille en permanence l'√©tat du cluster :

```
1. D√©tection de pods en Pending
   ‚Üì
2. Analyse : Pourquoi sont-ils en Pending ?
   - Pas assez de CPU ?
   - Pas assez de m√©moire ?
   - Probl√®me de scheduling ?
   ‚Üì
3. Simulation : Si on ajoute un n≈ìud, est-ce que √ßa aide ?
   ‚Üì
4. Si oui : Demander un nouveau n≈ìud au cloud provider
   ‚Üì
5. Attendre que le n≈ìud soit pr√™t (3-5 minutes)
   ‚Üì
6. Scheduler place les pods sur le nouveau n≈ìud
```

**D√©clencheurs de scale up :**
- Pods en √©tat `Pending` depuis plus de 30 secondes (configurable)
- Raison : Ressources insuffisantes (CPU, m√©moire)
- Le n≈ìud √† ajouter pourrait r√©soudre le probl√®me

**Le CA ne scale PAS up si :**
- Les pods sont Pending pour d'autres raisons (image non disponible, secrets manquants, etc.)
- Le nombre maximum de n≈ìuds est atteint
- Le budget est √©puis√©

### Phase 2 : Scale Down (Retrait de n≈ìuds)

Le CA analyse r√©guli√®rement si des n≈ìuds sont sous-utilis√©s :

```
1. Identifier les n≈ìuds sous-utilis√©s
   - Utilisation < 50% (par d√©faut)
   - Pendant 10 minutes (par d√©faut)
   ‚Üì
2. Simulation : Peut-on d√©placer tous les pods ailleurs ?
   ‚Üì
3. V√©rifier les contraintes :
   - PodDisruptionBudgets respect√©s ?
   - Pas de pods avec local storage ?
   - Pas de DaemonSets (sauf exceptions) ?
   ‚Üì
4. Si OK : Marquer le n≈ìud pour suppression
   ‚Üì
5. √âvacuer (drain) les pods vers d'autres n≈ìuds
   ‚Üì
6. Attendre que tous les pods soient relocalis√©s
   ‚Üì
7. Supprimer le n≈ìud
```

**Conditions pour scale down :**
- N≈ìud utilis√© √† moins de 50% de sa capacit√©
- Tous les pods peuvent √™tre d√©plac√©s ailleurs
- Pas de pods "non √©vacuables" (syst√®me, DaemonSets, local storage)
- PodDisruptionBudgets respect√©s
- Le n≈ìud est √©ligible depuis 10+ minutes

**Le CA ne scale PAS down si :**
- Cela violerait les PodDisruptionBudgets
- Des pods ne peuvent pas √™tre d√©plac√©s
- Le nombre minimum de n≈ìuds serait atteint
- Le n≈ìud a √©t√© ajout√© il y a moins de 10 minutes

## Pr√©requis pour utiliser le Cluster Autoscaler

### 1. Cluster multi-node

**Important :** Le Cluster Autoscaler n'a de sens que sur un cluster avec plusieurs n≈ìuds. Sur un cluster single-node, il ne peut rien faire !

**Pour MicroK8s :**
Vous devez avoir un cluster avec au moins 2-3 n≈ìuds. Voir la section 21 du tutoriel pour cr√©er un cluster multi-node.

```bash
# V√©rifier le nombre de n≈ìuds
kubectl get nodes
```

Sortie attendue (exemple) :
```
NAME          STATUS   ROLES    AGE   VERSION
node-master   Ready    <none>   5d    v1.28.3
node-worker1  Ready    <none>   5d    v1.28.3
node-worker2  Ready    <none>   5d    v1.28.3
```

### 2. Infrastructure compatible

Le Cluster Autoscaler fonctionne **seulement** avec des infrastructures qui supportent l'ajout/retrait automatique de machines :

**‚òÅÔ∏è Cloud providers support√©s :**
- AWS (Auto Scaling Groups)
- Google Cloud Platform (Managed Instance Groups)
- Azure (Virtual Machine Scale Sets)
- DigitalOcean
- Et autres...

**‚ö†Ô∏è Limitations pour MicroK8s on-premise :**

Si votre cluster MicroK8s tourne sur des machines physiques ou virtuelles que vous g√©rez vous-m√™me (homelab, datacenter local), le Cluster Autoscaler **ne peut pas** automatiquement cr√©er de nouvelles machines.

**Solutions pour on-premise :**
1. **Infrastructure as Code** : Utiliser Terraform, Ansible pour automatiser la cr√©ation de VMs
2. **Bare Metal Autoscaling** : Solutions comme Cluster API pour bare metal
3. **Hybrid approach** : Pool de machines "dormantes" que le CA peut activer
4. **Limitation accept√©e** : Pas de vrai autoscaling, gestion manuelle du nombre de n≈ìuds

Pour un **homelab typique**, le Cluster Autoscaler n'est g√©n√©ralement **pas pratique**. Cette section est surtout pertinente si vous d√©ployez MicroK8s dans le cloud ou avec une infrastructure automatisable.

### 3. Permissions n√©cessaires

Le Cluster Autoscaler doit pouvoir interagir avec votre infrastructure :

**Dans le cloud :**
- Permissions IAM pour cr√©er/d√©truire des instances
- Acc√®s √† l'API du cloud provider
- Credentials configur√©s

**Configuration typique (AWS exemple) :**
Le CA a besoin de :
- Lire les Auto Scaling Groups
- Modifier la taille des Auto Scaling Groups
- Lire les tags des instances

## Installation du Cluster Autoscaler

### M√©thode 1 : Installation via Helm (Recommand√©)

**√âtape 1 : Installer Helm si n√©cessaire**

```bash
# Sur MicroK8s
microk8s enable helm3

# Cr√©er un alias
alias helm='microk8s helm3'
```

**√âtape 2 : Ajouter le repository Helm**

```bash
helm repo add autoscaler https://kubernetes.github.io/autoscaler
helm repo update
```

**√âtape 3 : Cr√©er un fichier de configuration**

Cr√©ez `cluster-autoscaler-values.yaml` :

```yaml
cloudProvider: aws    # Ou gce, azure, etc.

awsRegion: eu-west-1  # Votre r√©gion AWS

autoDiscovery:
  clusterName: mon-cluster-microk8s
  enabled: true

rbac:
  create: true
  serviceAccount:
    name: cluster-autoscaler
    annotations:
      eks.amazonaws.com/role-arn: arn:aws:iam::123456789:role/cluster-autoscaler

extraArgs:
  scale-down-enabled: true
  scale-down-delay-after-add: 10m
  scale-down-unneeded-time: 10m
  skip-nodes-with-local-storage: false
  balance-similar-node-groups: true

resources:
  requests:
    cpu: 100m
    memory: 300Mi
  limits:
    cpu: 100m
    memory: 300Mi
```

**√âtape 4 : Installer le Cluster Autoscaler**

```bash
helm install cluster-autoscaler autoscaler/cluster-autoscaler \
  --namespace kube-system \
  --values cluster-autoscaler-values.yaml
```

**√âtape 5 : V√©rifier l'installation**

```bash
kubectl get pods -n kube-system | grep cluster-autoscaler
```

Sortie attendue :
```
cluster-autoscaler-xxxxxxxxx-xxxxx   1/1     Running   0          2m
```

### M√©thode 2 : Installation via manifeste YAML

Si vous ne pouvez pas utiliser Helm, vous pouvez d√©ployer via YAML :

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cluster-autoscaler
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cluster-autoscaler
rules:
- apiGroups: [""]
  resources: ["events", "endpoints"]
  verbs: ["create", "patch"]
- apiGroups: [""]
  resources: ["pods/eviction"]
  verbs: ["create"]
- apiGroups: [""]
  resources: ["pods/status"]
  verbs: ["update"]
- apiGroups: [""]
  resources: ["endpoints"]
  resourceNames: ["cluster-autoscaler"]
  verbs: ["get", "update"]
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["watch", "list", "get", "update"]
- apiGroups: [""]
  resources: ["namespaces", "pods", "services", "replicationcontrollers", "persistentvolumeclaims", "persistentvolumes"]
  verbs: ["watch", "list", "get"]
- apiGroups: ["extensions"]
  resources: ["replicasets", "daemonsets"]
  verbs: ["watch", "list", "get"]
- apiGroups: ["policy"]
  resources: ["poddisruptionbudgets"]
  verbs: ["watch", "list"]
- apiGroups: ["apps"]
  resources: ["statefulsets", "replicasets", "daemonsets"]
  verbs: ["watch", "list", "get"]
- apiGroups: ["storage.k8s.io"]
  resources: ["storageclasses", "csinodes", "csidrivers", "csistoragecapacities"]
  verbs: ["watch", "list", "get"]
- apiGroups: ["batch"]
  resources: ["jobs", "cronjobs"]
  verbs: ["watch", "list", "get"]
- apiGroups: ["coordination.k8s.io"]
  resources: ["leases"]
  verbs: ["create"]
- apiGroups: ["coordination.k8s.io"]
  resourceNames: ["cluster-autoscaler"]
  resources: ["leases"]
  verbs: ["get", "update"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cluster-autoscaler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-autoscaler
subjects:
- kind: ServiceAccount
  name: cluster-autoscaler
  namespace: kube-system
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
    spec:
      serviceAccountName: cluster-autoscaler
      containers:
      - name: cluster-autoscaler
        image: registry.k8s.io/autoscaling/cluster-autoscaler:v1.28.2
        command:
        - ./cluster-autoscaler
        - --v=4
        - --stderrthreshold=info
        - --cloud-provider=aws
        - --skip-nodes-with-local-storage=false
        - --expander=least-waste
        - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/mon-cluster
        - --balance-similar-node-groups
        - --skip-nodes-with-system-pods=false
        resources:
          requests:
            cpu: 100m
            memory: 300Mi
          limits:
            cpu: 100m
            memory: 300Mi
        volumeMounts:
        - name: ssl-certs
          mountPath: /etc/ssl/certs/ca-certificates.crt
          readOnly: true
      volumes:
      - name: ssl-certs
        hostPath:
          path: /etc/ssl/certs/ca-certificates.crt
```

**Note importante :** Cette configuration est pour AWS. Adaptez les param√®tres `--cloud-provider` et `--node-group-auto-discovery` selon votre infrastructure.

## Configuration du Cluster Autoscaler

### Param√®tres essentiels

**1. Cloud Provider**

```bash
--cloud-provider=aws    # ou gce, azure, etc.
```

Indique au CA comment interagir avec votre infrastructure.

**2. Node Groups Auto-Discovery**

**Pour AWS :**
```bash
--node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/mon-cluster
```

Le CA d√©couvre automatiquement les Auto Scaling Groups tagu√©s correctement.

**Pour GCP :**
```bash
--node-group-auto-discovery=mig:name=mig-prefix-[0-9]+
```

**3. Limites de scaling**

```bash
--nodes=1:10:node-group-name    # Min:Max:Name
```

D√©finit le nombre minimum et maximum de n≈ìuds par groupe.

**Exemple complet :**
```bash
--nodes=2:10:worker-nodes-a
--nodes=1:5:worker-nodes-b
```

Cela signifie :
- Groupe "worker-nodes-a" : Entre 2 et 10 n≈ìuds
- Groupe "worker-nodes-b" : Entre 1 et 5 n≈ìuds

### Param√®tres de comportement

**Scale Up :**

```bash
--max-node-provision-time=15m        # Temps max pour provisionner un n≈ìud
--max-total-unready-percentage=33    # Max de n≈ìuds non-ready tol√©r√©s
--ok-total-unready-count=3           # Nombre absolu de n≈ìuds non-ready OK
```

**Scale Down :**

```bash
--scale-down-enabled=true                     # Activer le scale down
--scale-down-delay-after-add=10m              # Attendre 10min apr√®s un scale up
--scale-down-delay-after-delete=10s           # Attendre 10s apr√®s un scale down
--scale-down-delay-after-failure=3m           # Attendre 3min apr√®s un √©chec
--scale-down-unneeded-time=10m                # N≈ìud sous-utilis√© pendant 10min
--scale-down-utilization-threshold=0.5        # Seuil d'utilisation (50%)
```

**Expander (Strat√©gie de choix de n≈ìud) :**

```bash
--expander=least-waste    # Strat√©gie de s√©lection
```

Strat√©gies disponibles :
- **random** : Choisir al√©atoirement
- **most-pods** : Groupe qui peut h√©berger le plus de pods
- **least-waste** : Groupe qui minimise le gaspillage de ressources (recommand√©)
- **price** : Le moins cher (n√©cessite configuration prix)
- **priority** : Bas√© sur des priorit√©s configur√©es

### Configuration via ConfigMap

Vous pouvez aussi utiliser un ConfigMap pour certains param√®tres :

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-status
  namespace: kube-system
data:
  status: |
    Cluster Autoscaler Status:
    - Nodes: 3
    - Min: 2
    - Max: 10
    - Last scale up: 2025-10-25 10:30:00
    - Last scale down: 2025-10-25 09:15:00
```

## Interaction avec le HPA

Le Cluster Autoscaler et le HPA fonctionnent **ensemble** de mani√®re compl√©mentaire :

### Sc√©nario typique : Pic de trafic

**√âtape 1 : Le trafic augmente**
```
√âtat initial :
- 3 n≈ìuds (chacun 4 CPU)
- Application : 2 pods (200m CPU chacun)
- HPA configur√© : min=2, max=20
```

**√âtape 2 : HPA d√©tecte la charge √©lev√©e**
```
- Utilisation CPU > 70%
- HPA d√©cide de scaler √† 15 pods
- HPA cr√©e des nouveaux pods
```

**√âtape 3 : Certains pods restent Pending**
```
- 10 pods Running (ressources suffisantes sur les 3 n≈ìuds)
- 5 pods Pending (pas assez de CPU disponible)
```

**√âtape 4 : Cluster Autoscaler intervient**
```
- CA d√©tecte les 5 pods Pending
- CA calcule qu'il faut 2 n≈ìuds suppl√©mentaires
- CA demande 2 nouveaux n≈ìuds √† AWS
```

**√âtape 5 : N≈ìuds provisionn√©s**
```
- Apr√®s 3-5 minutes, les 2 nouveaux n≈ìuds sont pr√™ts
- Total : 5 n≈ìuds maintenant
- Les 5 pods Pending sont programm√©s sur les nouveaux n≈ìuds
- Tous les pods sont Running !
```

**√âtape 6 : Le trafic diminue (plus tard)**
```
- HPA r√©duit √† 3 pods (charge faible)
- Les 5 n≈ìuds sont maintenant sous-utilis√©s
```

**√âtape 7 : Cluster Autoscaler nettoie**
```
- Apr√®s 10 minutes, CA d√©tecte 2 n≈ìuds quasi-vides
- CA √©vacue les quelques pods restants
- CA supprime les 2 n≈ìuds inutiles
- Retour √† 3 n≈ìuds
```

### Flux d√©cisionnel combin√©

```
Augmentation de charge
    ‚Üì
HPA ajoute des pods
    ‚Üì
Pods en Pending ?
    ‚Üì Oui
Cluster Autoscaler ajoute des n≈ìuds
    ‚Üì
Pods programm√©s sur nouveaux n≈ìuds
    ‚Üì
[Temps passe, charge diminue]
    ‚Üì
HPA retire des pods
    ‚Üì
N≈ìuds sous-utilis√©s ?
    ‚Üì Oui
Cluster Autoscaler retire des n≈ìuds
```

**C'est une danse coordonn√©e !**

## Annoter les pods pour contr√¥ler le comportement

Vous pouvez utiliser des annotations pour contr√¥ler le comportement du Cluster Autoscaler avec certains pods :

### Emp√™cher l'√©viction d'un pod

Pour les pods critiques que vous ne voulez **jamais** voir √©vacu√©s :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: critical-app
  annotations:
    cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
spec:
  containers:
  - name: app
    image: mon-app:latest
```

**Cas d'usage :**
- Pods avec state local important
- Applications avec startup tr√®s long
- Pods de monitoring critiques

### Autoriser l'√©viction malgr√© certaines conditions

Certains pods sont normalement "non-√©vacuables" mais vous pouvez forcer :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: tolerable-app
  annotations:
    cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
spec:
  containers:
  - name: app
    image: mon-app:latest
```

## Monitoring du Cluster Autoscaler

### Logs du Cluster Autoscaler

```bash
kubectl logs -n kube-system deployment/cluster-autoscaler -f
```

**Messages typiques :**

**Scale up :**
```
Scale-up: group worker-nodes-a size set to 5
Pod default/nginx-web-xxxxx is unschedulable
```

**Scale down :**
```
Scale-down: node node-worker-3 is unneeded
Scale-down: removing node node-worker-3
```

**√âchec :**
```
Failed to increase node group size: request failed
```

### M√©triques Prometheus

Le Cluster Autoscaler expose des m√©triques pour Prometheus :

```yaml
# M√©triques utiles
cluster_autoscaler_nodes_count              # Nombre de n≈ìuds
cluster_autoscaler_unschedulable_pods_count # Pods non schedulables
cluster_autoscaler_scaled_up_nodes_total    # Total de scale ups
cluster_autoscaler_scaled_down_nodes_total  # Total de scale downs
cluster_autoscaler_failed_scale_ups_total   # √âchecs de scale up
```

### Commandes utiles

```bash
# Voir l'√©tat des n≈ìuds
kubectl get nodes

# Voir les pods en Pending
kubectl get pods --all-namespaces --field-selector=status.phase=Pending

# Voir les √©v√©nements du cluster
kubectl get events --sort-by=.metadata.creationTimestamp

# D√©tails d'un n≈ìud
kubectl describe node <node-name>

# Voir l'utilisation des ressources
kubectl top nodes
```

### Dashboard Kubernetes

Le Dashboard Kubernetes (si activ√©) montre visuellement :
- Le nombre de n≈ìuds
- Les pods en Pending
- L'utilisation des ressources par n≈ìud

```bash
microk8s enable dashboard
```

## Cas d'usage du Cluster Autoscaler

### 1. Applications avec trafic variable dans le temps

**Exemple :** Site e-commerce avec pics pendant les soldes

```yaml
# HPA pour les pods
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: boutique-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: boutique
  minReplicas: 5
  maxReplicas: 100
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60

---
# Cluster Autoscaler configur√© pour 2-20 n≈ìuds
# Permet de g√©rer jusqu'√† 100 pods si n√©cessaire
```

### 2. Batch processing avec charges impr√©visibles

**Exemple :** Traitement d'images upload√©es par les utilisateurs

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: image-processor
spec:
  parallelism: 50    # Jusqu'√† 50 pods en parall√®le
  completions: 1000  # 1000 images √† traiter
  template:
    spec:
      containers:
      - name: processor
        image: image-processor:latest
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
```

Si le cluster n'a pas assez de ressources pour 50 pods, le CA ajoutera des n≈ìuds.

### 3. Environnements de dev/test co√ªteux

**Strat√©gie :** Scale down agressif la nuit et les week-ends

```bash
# Configuration CA pour dev
--scale-down-delay-after-add=5m         # Scale down rapide
--scale-down-unneeded-time=5m           # N≈ìud inutile apr√®s 5min
--scale-down-utilization-threshold=0.3  # Seuil bas (30%)
```

Combin√© avec un script pour scaler le HPA √† 0 la nuit :

```bash
# Cron job pour scaler down √† 22h
0 22 * * * kubectl scale deployment --all --replicas=0

# Cron job pour scaler up √† 8h
0 8 * * * kubectl scale deployment --all --replicas=3
```

### 4. Multi-tenant avec isolation

**Exemple :** Plateforme SaaS avec clients ayant des n≈ìuds d√©di√©s

```yaml
# Client A : N≈ìuds d√©di√©s
nodeSelector:
  customer: client-a

# Configuration CA
--nodes=1:5:client-a-nodes
--nodes=1:5:client-b-nodes
```

Chaque client a son propre pool de n≈ìuds qui scale ind√©pendamment.

## Limitations et pi√®ges √† √©viter

### 1. Temps de provisionnement

**Probl√®me :** Les n≈ìuds prennent du temps √† d√©marrer (3-5 minutes en cloud, plus en bare metal).

**Impact :** Pendant ce temps, les pods restent Pending.

**Mitigation :**
- Gardez toujours une marge de capacit√© (min replicas + buffer)
- Utilisez des readiness probes rapides
- Consid√©rez des strat√©gies de pre-scaling pour des √©v√©nements pr√©vus

### 2. Co√ªts impr√©vus

**Probl√®me :** Le CA peut ajouter beaucoup de n≈ìuds si mal configur√©, augmentant drastiquement les co√ªts.

**Mitigation :**
- D√©finissez toujours `maxReplicas` pour le HPA
- D√©finissez toujours `max nodes` pour chaque node group
- Configurez des alertes sur le nombre de n≈ìuds et les co√ªts
- Testez en environnement de dev d'abord !

### 3. Pods non √©vacuables

**Probl√®me :** Le CA ne peut pas scale down si des pods ne peuvent pas √™tre d√©plac√©s.

**Exemples de pods non √©vacuables :**
- Pods avec `local storage` (volumes hostPath, emptyDir)
- Pods sans controller (pods "nus" non g√©r√©s par Deployment/StatefulSet)
- Pods avec annotation `safe-to-evict: false`
- DaemonSets (par d√©faut)

**Mitigation :**
- Utilisez des PersistentVolumes au lieu de local storage
- Toujours cr√©er des pods via des Deployments
- Utilisez l'annotation `safe-to-evict` avec parcimonie

### 4. Scale down trop agressif

**Probl√®me :** Le CA retire des n≈ìuds trop vite, puis doit les recr√©er peu apr√®s (thrashing).

**Mitigation :**
```bash
--scale-down-delay-after-add=10m       # Attendre 10min apr√®s scale up
--scale-down-unneeded-time=10m         # Observer pendant 10min
--scale-down-utilization-threshold=0.5 # Pas trop bas
```

### 5. Conflits avec mises √† jour de cluster

**Probl√®me :** Pendant une mise √† jour de cluster (upgrade K8s), le CA peut interf√©rer.

**Solution :**
D√©sactivez temporairement le CA pendant les maintenances :

```bash
kubectl scale deployment cluster-autoscaler -n kube-system --replicas=0

# Faire la maintenance...

kubectl scale deployment cluster-autoscaler -n kube-system --replicas=1
```

### 6. Limitations avec MicroK8s on-premise

**Rappel important :**

Sur un homelab avec MicroK8s sur des machines physiques ou des VMs locales, le Cluster Autoscaler ne peut pas cr√©er automatiquement de nouvelles machines !

**Alternatives pour homelab :**
1. Utiliser le HPA uniquement (scaling horizontal des pods)
2. Dimensionner le cluster avec suffisamment de n≈ìuds fixes
3. Ajouter manuellement des n≈ìuds quand n√©cessaire
4. Utiliser le VPA pour optimiser les ressources par pod

## Bonnes pratiques

### 1. Commencez avec des limites conservatrices

```bash
--nodes=2:5:worker-nodes    # Commencez petit
```

Augmentez progressivement apr√®s observation.

### 2. Utilisez des PodDisruptionBudgets

Prot√©gez vos applications critiques :

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: mon-app-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: mon-app
```

### 3. Taggez correctement vos node groups

Pour AWS :

```
Tag: k8s.io/cluster-autoscaler/enabled = true
Tag: k8s.io/cluster-autoscaler/mon-cluster = owned
```

Sans ces tags, le CA ne peut pas d√©couvrir les groupes.

### 4. Surveillez les m√©triques

Configurez des alertes sur :
- Nombre de n≈ìuds
- Pods en Pending prolong√©
- √âchecs de scale up/down
- Co√ªts mensuels

### 5. Testez les sc√©narios de scale down

V√©rifiez r√©guli√®rement que le scale down fonctionne :

```bash
# Cr√©er une charge temporaire
kubectl run stress --image=stress -- stress --cpu 4 --timeout 60s

# Observer le scale up
kubectl get nodes -w

# Arr√™ter la charge
kubectl delete pod stress

# Observer le scale down (apr√®s 10min)
kubectl get nodes -w
```

### 6. Documentez votre configuration

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: ca-config-doc
  namespace: kube-system
data:
  notes: |
    Cluster Autoscaler Configuration
    ---------------------------------
    Provider: AWS
    Region: eu-west-1
    Min nodes: 2
    Max nodes: 10
    Scale down delay: 10m
    Last updated: 2025-10-25
    Contact: devops@example.com
```

### 7. Combinez avec le HPA intelligemment

```yaml
# HPA : R√©activit√© rapide (pods)
minReplicas: 3
maxReplicas: 50

# CA : Capacit√© √©lastique (n≈ìuds)
--nodes=2:10:worker-nodes
```

Assurez-vous que `maxReplicas * resources_per_pod ‚â§ max_nodes * resources_per_node`

## R√©sum√©

Le **Cluster Autoscaler** est un outil puissant pour g√©rer automatiquement la capacit√© de votre cluster Kubernetes.

**Points cl√©s :**

1. Le CA ajoute ou retire des **n≈ìuds** (machines) du cluster
2. Compl√©mentaire au HPA (qui g√®re les pods) et VPA (qui g√®re les ressources)
3. N√©cessite une infrastructure compatible (cloud ou automatisable)
4. **Pas pratique pour un homelab MicroK8s typique** (machines physiques)
5. Fonctionne en synergie avec le HPA pour un scaling complet
6. Les n≈ìuds prennent du temps √† provisionner (3-5 minutes minimum)
7. Le scale down est plus prudent que le scale up (par design)

**Les trois niveaux de scaling r√©capitul√©s :**

| Niveau | Outil | Ce qui change | Vitesse | Scope |
|--------|-------|---------------|---------|-------|
| **Pods** | HPA | Nombre de pods | Rapide (secondes) | Application |
| **Ressources** | VPA | CPU/RAM par pod | Lent (red√©marrage) | Pod |
| **N≈ìuds** | CA | Nombre de machines | Tr√®s lent (minutes) | Cluster |

**Quand utiliser le Cluster Autoscaler ?**

‚úÖ Cluster dans le cloud (AWS, GCP, Azure)
‚úÖ Charges tr√®s variables n√©cessitant capacit√© √©lastique
‚úÖ Applications avec HPA atteignant souvent les limites
‚úÖ Optimisation automatique des co√ªts
‚úÖ Infrastructure automatisable (Terraform, Cluster API)

‚ùå Homelab avec machines physiques fixes
‚ùå Cluster single-node
‚ùå Infrastructure non-automatisable
‚ùå Besoin de r√©activit√© instantan√©e (utilisez HPA seul)
‚ùå Contraintes de budget strictes sans surveillance

**Pour un lab MicroK8s typique :**

Si vous √™tes sur des machines physiques/VMs locales, concentrez-vous sur :
- **HPA** pour le scaling horizontal des pods
- **VPA** pour l'optimisation des ressources
- **Dimensionnement manuel** du cluster avec suffisamment de n≈ìuds

Le Cluster Autoscaler est fantastique dans le cloud, mais moins pertinent pour un environnement on-premise traditionnel !

---

**Prochaine section :** 19.5 Metrics Server - La fondation de tous les autoscalers !

‚è≠Ô∏è [Metrics Server](/19-scaling-et-autoscaling/05-metrics-server.md)
