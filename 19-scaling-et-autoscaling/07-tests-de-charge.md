üîù Retour au [Sommaire](/SOMMAIRE.md)

# 19.7 Tests de charge

## Introduction aux tests de charge

Les **tests de charge** (load testing) consistent √† simuler un grand nombre d'utilisateurs ou de requ√™tes pour v√©rifier comment votre application et votre autoscaling r√©agissent sous la pression. C'est une √©tape **essentielle** pour valider que vos configurations HPA, VPA, et m√©triques fonctionnent correctement.

### Pourquoi tester la charge ?

Imaginez que vous avez configur√© un HPA magnifique :

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: mon-api-hpa
spec:
  minReplicas: 2
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
```

**Questions importantes :**

- ‚úÖ Le HPA scale-t-il vraiment quand la charge augmente ?
- ‚úÖ Scale-t-il assez vite ?
- ‚úÖ Scale-t-il au bon moment (pas trop t√¥t, pas trop tard) ?
- ‚úÖ L'application reste-t-elle performante pendant le scaling ?
- ‚úÖ Le scale down fonctionne-t-il correctement apr√®s le pic ?
- ‚úÖ Les seuils sont-ils bien calibr√©s ?

**Sans tests de charge, vous ne le saurez jamais !**

### Analogie simple

**Sans tests de charge :**
- C'est comme installer un syst√®me anti-incendie dans une maison mais ne jamais v√©rifier qu'il fonctionne
- Vous pensez √™tre prot√©g√©, mais vous n'avez aucune garantie

**Avec tests de charge :**
- Vous simulez un incendie (de mani√®re contr√¥l√©e)
- Vous v√©rifiez que les d√©tecteurs se d√©clenchent
- Vous v√©rifiez que l'eau arrive bien
- Vous identifiez les probl√®mes avant qu'ils ne soient critiques

Les tests de charge sont votre "simulation d'incendie" pour l'autoscaling !

## Types de tests de charge

Il existe plusieurs types de tests selon vos objectifs :

### 1. Test de mont√©e en charge (Ramp-up test)

Augmentation progressive de la charge pour observer le comportement.

```
Charge
  ‚Üë
  |                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  |              ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  |        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  |  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  |‚ñà‚ñà
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> Temps
    0    2    4    6    8   10 min
```

**Objectif :** Voir comment le HPA r√©agit √† une augmentation progressive.

### 2. Test de pic brutal (Spike test)

Augmentation soudaine de la charge.

```
Charge
  ‚Üë
  |  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  |‚ñà‚ñà                    ‚ñà‚ñà‚ñà‚ñà
  |‚ñà                        ‚ñà‚ñà‚ñà‚ñà
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> Temps
    0    2    4    6    8   10 min
```

**Objectif :** Voir si le syst√®me peut g√©rer un pic soudain (flash sale, √©v√©nement viral).

### 3. Test de charge soutenue (Soak test)

Charge constante pendant une longue p√©riode.

```
Charge
  ‚Üë
  |  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  |‚ñà‚ñà                                ‚ñà‚ñà
  |‚ñà                                  ‚ñà
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> Temps
    0    1h   2h   3h   4h   5h
```

**Objectif :** D√©tecter les fuites m√©moire, les d√©gradations progressives.

### 4. Test de stress (Stress test)

Augmentation jusqu'√† la rupture pour trouver les limites.

```
Charge
  ‚Üë
  |                          ‚ñà‚ñà‚ñà‚ñà CRASH!
  |                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  |              ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  |        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  |  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  |‚ñà‚ñà
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> Temps
    0    2    4    6    8   10 min
```

**Objectif :** Trouver le point de rupture, valider que le syst√®me ne tombe pas brutalement.

## Outils de tests de charge

### 1. Apache Bench (ab) - Simple et rapide

**Installation :**

```bash
# Ubuntu/Debian
sudo apt install apache2-utils

# macOS
# D√©j√† install√© par d√©faut

# MicroK8s (dans un pod)
kubectl run ab --image=httpd:alpine --rm -it -- sh
apk add apache2-utils
```

**Utilisation basique :**

```bash
ab -n 10000 -c 100 http://mon-api.example.com/
```

**Param√®tres :**
- `-n 10000` : Nombre total de requ√™tes (10,000)
- `-c 100` : Nombre de requ√™tes concurrentes (100 en parall√®le)

**Sortie :**

```
Benchmarking mon-api.example.com (be patient)
Completed 1000 requests
Completed 2000 requests
...
Completed 10000 requests
Finished 10000 requests

Server Software:        nginx/1.21
Server Hostname:        mon-api.example.com
Server Port:            80

Concurrency Level:      100
Time taken for tests:   12.456 seconds
Complete requests:      10000
Failed requests:        0
Total transferred:      2450000 bytes
HTML transferred:       1250000 bytes
Requests per second:    802.84 [#/sec] (mean)
Time per request:       124.558 [ms] (mean)
Time per request:       1.246 [ms] (mean, across all concurrent requests)
Transfer rate:          192.05 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        1    5   2.1      4      15
Processing:    15  118  45.2    110     450
Waiting:       12  115  44.8    108     445
Total:         20  123  45.8    115     455

Percentage of the requests served within a certain time (ms)
  50%    115
  66%    130
  75%    145
  80%    155
  90%    180
  95%    220
  98%    280
  99%    350
 100%    455 (longest request)
```

**Avantages :**
- ‚úÖ Tr√®s simple √† utiliser
- ‚úÖ Install√© sur la plupart des syst√®mes
- ‚úÖ R√©sultats faciles √† lire

**Inconv√©nients :**
- ‚ùå Limit√© aux requ√™tes HTTP GET simples
- ‚ùå Pas de sc√©narios complexes
- ‚ùå Pas de graphiques

### 2. Hey - Ab moderne

**Installation :**

```bash
# Via Go
go install github.com/rakyll/hey@latest

# Ou t√©l√©charger le binaire
wget https://hey-release.s3.us-east-2.amazonaws.com/hey_linux_amd64
chmod +x hey_linux_amd64
sudo mv hey_linux_amd64 /usr/local/bin/hey
```

**Utilisation :**

```bash
# Test de 5 minutes avec 50 workers
hey -z 5m -c 50 http://mon-api.example.com/
```

**Param√®tres utiles :**
- `-z 5m` : Duration (5 minutes)
- `-c 50` : Concurrency (50 workers)
- `-q 100` : Rate limit (100 requ√™tes/sec max)
- `-m POST` : M√©thode HTTP
- `-H "Authorization: Bearer token"` : Header custom

**Exemple avec POST et body :**

```bash
hey -z 2m -c 30 -m POST \
  -H "Content-Type: application/json" \
  -d '{"name":"test","value":123}' \
  http://mon-api.example.com/api/data
```

**Sortie :**

```
Summary:
  Total:        300.0534 secs
  Slowest:      1.2456 secs
  Fastest:      0.0234 secs
  Average:      0.1567 secs
  Requests/sec: 159.97

  Total data:   2400000 bytes
  Size/request: 50 bytes

Response time histogram:
  0.023 [1]     |
  0.145 [12543] |‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†
  0.267 [23456] |‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†
  0.389 [8754]  |‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†
  0.511 [3214]  |‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†
  0.633 [876]   |‚ñ†‚ñ†‚ñ†
  0.755 [234]   |‚ñ†
  0.877 [87]    |
  0.999 [32]    |
  1.121 [12]    |
  1.246 [1]     |

Latency distribution:
  10% in 0.0856 secs
  25% in 0.1234 secs
  50% in 0.1567 secs
  75% in 0.2134 secs
  90% in 0.3456 secs
  95% in 0.4567 secs
  99% in 0.7890 secs

Status code distribution:
  [200] 48000 responses
```

**Avantages :**
- ‚úÖ Plus moderne et flexible que ab
- ‚úÖ Supporte POST, PUT, headers custom
- ‚úÖ Histogrammes et percentiles
- ‚úÖ Rate limiting int√©gr√©

**Inconv√©nients :**
- ‚ùå Pas de sc√©narios complexes
- ‚ùå Installation suppl√©mentaire n√©cessaire

### 3. K6 - Tests avanc√©s

**Installation :**

```bash
# Ubuntu/Debian
sudo gpg -k
sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
sudo apt-get update
sudo apt-get install k6

# macOS
brew install k6

# Docker
docker pull grafana/k6
```

**Script de test (script.js) :**

```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  stages: [
    { duration: '2m', target: 10 },   // Ramp up to 10 users
    { duration: '5m', target: 50 },   // Stay at 50 users
    { duration: '2m', target: 100 },  // Ramp up to 100 users
    { duration: '5m', target: 100 },  // Stay at 100 users
    { duration: '2m', target: 0 },    // Ramp down to 0 users
  ],
  thresholds: {
    'http_req_duration': ['p(95)<500'], // 95% des requ√™tes < 500ms
    'http_req_failed': ['rate<0.01'],   // Moins de 1% d'erreurs
  },
};

export default function () {
  let response = http.get('http://mon-api.example.com/');

  check(response, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });

  sleep(1); // Pause entre les requ√™tes
}
```

**Ex√©cution :**

```bash
k6 run script.js
```

**Sortie :**

```
          /\      |‚Äæ‚Äæ| /‚Äæ‚Äæ/   /‚Äæ‚Äæ/
     /\  /  \     |  |/  /   /  /
    /  \/    \    |     (   /   ‚Äæ‚Äæ\
   /          \   |  |\  \ |  (‚Äæ)  |
  / __________ \  |__| \__\ \_____/ .io

  execution: local
     script: script.js
     output: -

  scenarios: (100.00%) 1 scenario, 100 max VUs, 18m0s max duration
           * default: Up to 100 looping VUs for 16m0s over 5 stages

running (16m00.2s), 000/100 VUs, 45832 complete and 0 interrupted iterations
default ‚úì [======================================] 000/100 VUs  16m0s

     ‚úì status is 200
     ‚úì response time < 500ms

     checks.........................: 100.00% ‚úì 91664      ‚úó 0
     data_received..................: 229 MB  238 kB/s
     data_sent......................: 4.1 MB  4.3 kB/s
     http_req_blocked...............: avg=1.2ms    min=1¬µs     med=3¬µs      max=234ms   p(90)=5¬µs      p(95)=7¬µs
     http_req_connecting............: avg=567¬µs    min=0s      med=0s       max=123ms   p(90)=0s       p(95)=0s
     http_req_duration..............: avg=123.45ms min=23.12ms med=98.76ms  max=987ms   p(90)=234.56ms p(95)=345.67ms
     http_req_failed................: 0.00%   ‚úì 0          ‚úó 45832
     http_req_receiving.............: avg=234¬µs    min=12¬µs    med=156¬µs    max=23ms    p(90)=456¬µs    p(95)=678¬µs
     http_req_sending...............: avg=45¬µs     min=4¬µs     med=23¬µs     max=5ms     p(90)=67¬µs     p(95)=89¬µs
     http_req_tls_handshaking.......: avg=0s       min=0s      med=0s       max=0s      p(90)=0s       p(95)=0s
     http_req_waiting...............: avg=123.17ms min=23.08ms med=98.54ms  max=986ms   p(90)=234.12ms p(95)=345.23ms
     http_reqs......................: 45832   47.8/s
     iteration_duration.............: avg=1.12s    min=1.02s   med=1.09s    max=1.98s   p(90)=1.23s    p(95)=1.34s
     iterations.....................: 45832   47.8/s
     vus............................: 1       min=1        max=100
     vus_max........................: 100     min=100      max=100
```

**Avantages :**
- ‚úÖ Sc√©narios complexes (ramping, stages)
- ‚úÖ Scripting JavaScript complet
- ‚úÖ Thresholds et checks int√©gr√©s
- ‚úÖ M√©triques d√©taill√©es
- ‚úÖ Peut envoyer les r√©sultats √† Grafana Cloud

**Inconv√©nients :**
- ‚ùå Plus complexe √† apprendre
- ‚ùå N√©cessite l'√©criture de scripts

### 4. Locust - Tests avec interface web

**Installation :**

```bash
pip install locust
```

**Script de test (locustfile.py) :**

```python
from locust import HttpUser, task, between

class MyUser(HttpUser):
    wait_time = between(1, 3)  # Attente entre 1 et 3 secondes

    @task(3)  # Poids : 3x plus fr√©quent
    def get_homepage(self):
        self.client.get("/")

    @task(1)  # Poids : 1x
    def get_api_data(self):
        self.client.get("/api/data")

    @task(2)  # Poids : 2x
    def post_data(self):
        self.client.post("/api/submit", json={
            "name": "test",
            "value": 123
        })

    def on_start(self):
        # Ex√©cut√© au d√©marrage (login, etc.)
        self.client.post("/login", json={
            "username": "test",
            "password": "test123"
        })
```

**Lancer Locust :**

```bash
locust -f locustfile.py --host=http://mon-api.example.com
```

Puis ouvrez http://localhost:8089 dans votre navigateur.

**Interface web :**
- D√©finir le nombre d'utilisateurs (ex: 100)
- D√©finir le taux d'apparition (ex: 10 users/sec)
- D√©marrer le test
- Voir les graphiques en temps r√©el !

**Avantages :**
- ‚úÖ Interface web intuitive
- ‚úÖ Graphiques en temps r√©el
- ‚úÖ Sc√©narios Python flexibles
- ‚úÖ Distribution sur plusieurs machines possible

**Inconv√©nients :**
- ‚ùå N√©cessite Python
- ‚ùå Plus lourd que hey/ab

### 5. Tests depuis Kubernetes (Busybox/Curl)

Pour des tests rapides depuis le cluster :

```bash
# Pod busybox interactif
kubectl run -i --tty load-generator --rm --image=busybox --restart=Never -- /bin/sh

# Dans le pod
while true; do
  wget -q -O- http://mon-service.default.svc.cluster.local/
done
```

Ou un Job Kubernetes :

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: load-test
spec:
  parallelism: 10  # 10 pods en parall√®le
  completions: 100 # 100 ex√©cutions au total
  template:
    spec:
      containers:
      - name: curl
        image: curlimages/curl
        command:
        - sh
        - -c
        - |
          for i in $(seq 1 100); do
            curl -s http://mon-service.default.svc.cluster.local/ > /dev/null
            sleep 0.1
          done
      restartPolicy: Never
```

## M√©thodologie de test

### Phase 1 : Pr√©paration

**1. D√©finir les objectifs**

Qu'est-ce que vous voulez tester ?
- ‚úÖ Le HPA scale-t-il correctement ?
- ‚úÖ √Ä quel seuil de charge scale-t-il ?
- ‚úÖ La latence reste-t-elle acceptable ?
- ‚úÖ Quelle est la capacit√© maximale ?

**2. Identifier les endpoints √† tester**

```
Endpoints critiques :
- GET  /                      (homepage)
- GET  /api/products          (liste)
- GET  /api/products/:id      (d√©tail)
- POST /api/orders            (cr√©ation)
- GET  /api/orders/:id        (statut)
```

**3. Pr√©parer l'environnement**

```bash
# V√©rifier l'√©tat initial
kubectl get hpa
kubectl get pods
kubectl top nodes
kubectl top pods

# S'assurer que Metrics Server fonctionne
kubectl top nodes
```

**4. Pr√©parer les outils de monitoring**

Ouvrez plusieurs terminaux :

**Terminal 1 : Observer le HPA**
```bash
watch -n 2 kubectl get hpa
```

**Terminal 2 : Observer les pods**
```bash
watch -n 2 kubectl get pods
```

**Terminal 3 : Observer les m√©triques**
```bash
watch -n 5 kubectl top pods
```

**Terminal 4 : Lancer le test de charge**
```bash
hey -z 10m -c 50 http://mon-api.example.com/
```

### Phase 2 : Test de base (Baseline)

Commencez avec une charge faible pour √©tablir une r√©f√©rence.

```bash
# Charge faible : 10 requ√™tes/sec pendant 2 minutes
hey -z 2m -q 10 http://mon-api.example.com/
```

**Observer :**
- Latence moyenne
- Taux d'erreurs
- Utilisation CPU/m√©moire
- Nombre de pods (doit rester stable)

**R√©sultat attendu :** Tout est stable, pas de scaling.

### Phase 3 : Test de mont√©e en charge

Augmentez progressivement la charge.

```bash
# √âtape 1 : 50 requ√™tes/sec
hey -z 3m -q 50 http://mon-api.example.com/

# √âtape 2 : 100 requ√™tes/sec
hey -z 3m -q 100 http://mon-api.example.com/

# √âtape 3 : 200 requ√™tes/sec
hey -z 3m -q 200 http://mon-api.example.com/
```

**Observer :**

**Dans le terminal HPA :**
```
NAME      REFERENCE        TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
my-hpa    Deployment/app   25%/50%    2         10        2          5m

# 2 minutes plus tard...
NAME      REFERENCE        TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
my-hpa    Deployment/app   65%/50%    2         10        4          7m

# Encore 2 minutes...
NAME      REFERENCE        TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
my-hpa    Deployment/app   48%/50%    2         10        6          9m
```

**Questions √† se poser :**
- ‚úÖ √Ä quel moment le HPA a-t-il commenc√© √† scaler ?
- ‚úÖ Le scaling est-il suffisamment rapide ?
- ‚úÖ L'utilisation CPU est-elle revenue proche de la cible ?
- ‚úÖ La latence est-elle rest√©e acceptable ?

### Phase 4 : Test de pic

Simulez un pic soudain de trafic.

```bash
# Pic brutal : 500 requ√™tes/sec pendant 5 minutes
hey -z 5m -q 500 http://mon-api.example.com/
```

**Observer :**
- Le HPA r√©agit-il assez vite ?
- Y a-t-il des erreurs pendant le pic ?
- Combien de temps pour stabiliser ?

**√âv√©nements typiques :**

```
0:00 - D√©but du test, 2 pods, CPU 20%
0:30 - CPU monte √† 85%, HPA d√©tecte
1:00 - HPA cr√©e 2 nouveaux pods (total: 4)
1:30 - Pods d√©marrent, CPU √† 60%
2:00 - HPA cr√©e encore 2 pods (total: 6)
2:30 - CPU stable √† 45%
5:00 - Fin du test
7:00 - HPA commence √† scale down
12:00 - Retour √† 2 pods
```

### Phase 5 : Test de descente

Arr√™tez la charge et observez le scale down.

```bash
# Arr√™ter le test
# Attendre et observer
watch -n 10 kubectl get hpa
```

**Points d'attention :**
- Le scale down prend **plus de temps** que le scale up (par design)
- Par d√©faut : 5 minutes avant de scale down
- C'est normal et souhaitable (√©vite les oscillations)

### Phase 6 : Test de stress (optionnel)

Trouvez les limites du syst√®me.

```bash
# Augmentation progressive jusqu'√† la rupture
hey -z 1m -q 100 http://mon-api.example.com/   # 100 req/s
hey -z 1m -q 200 http://mon-api.example.com/   # 200 req/s
hey -z 1m -q 500 http://mon-api.example.com/   # 500 req/s
hey -z 1m -q 1000 http://mon-api.example.com/  # 1000 req/s
hey -z 1m -q 2000 http://mon-api.example.com/  # 2000 req/s
```

**Continuez jusqu'√† observer :**
- Taux d'erreurs qui augmente significativement (>1%)
- Latence qui explose (>5 secondes)
- HPA qui atteint maxReplicas mais ne peut plus suivre
- Cluster qui manque de ressources

**R√©sultat :** Vous connaissez maintenant la capacit√© maximale de votre syst√®me !

## Interpr√©ter les r√©sultats

### M√©triques cl√©s √† surveiller

**1. Latence (Response Time)**

```
p50 (m√©diane):  125ms   ‚Üê 50% des requ√™tes
p95:            340ms   ‚Üê 95% des requ√™tes
p99:            850ms   ‚Üê 99% des requ√™tes
```

**Bon :** p95 < 500ms, p99 < 1000ms
**Probl√®me :** p95 > 1000ms, p99 > 5000ms

**2. Taux d'erreurs (Error Rate)**

```
Total requests: 10000
Failed:         15
Error rate:     0.15%
```

**Bon :** < 0.1%
**Acceptable :** < 1%
**Probl√®me :** > 5%

**3. Throughput (D√©bit)**

```
Requests per second: 247.5
```

**Comparez avec vos objectifs :**
- Objectif : 500 req/s ‚Üí **Probl√®me** (seulement 247)
- Objectif : 200 req/s ‚Üí **Bon** (d√©passe l'objectif)

**4. Utilisation des ressources**

```bash
kubectl top pods
```

```
NAME                CPU      MEMORY
app-xxxxx-abcd      450m     256Mi    # 90% du request (500m)
app-xxxxx-efgh      480m     280Mi    # 96% du request
app-xxxxx-ijkl      420m     240Mi    # 84% du request
```

**Bon :** 50-70% d'utilisation (marge pour les pics)
**Probl√®me :** >90% (risque de throttling/OOM)

### Signes que tout fonctionne bien

‚úÖ **Le HPA scale up quand n√©cessaire**
```
Charge augmente ‚Üí CPU > 50% ‚Üí HPA ajoute des pods ‚Üí CPU redescend vers 50%
```

‚úÖ **La latence reste stable**
```
p95 avant scaling:  450ms
p95 apr√®s scaling:  480ms   (acceptable, <20% augmentation)
```

‚úÖ **Pas (ou tr√®s peu) d'erreurs**
```
Error rate: 0.05%   (excellent)
```

‚úÖ **Le scale down fonctionne**
```
Charge diminue ‚Üí Apr√®s 5-10min ‚Üí HPA retire des pods
```

### Signes de probl√®mes

‚ùå **HPA ne scale pas du tout**

```
TARGETS: 85%/50%   REPLICAS: 2/2   (reste √† 2 malgr√© 85% CPU)
```

**Causes possibles :**
- Metrics Server ne fonctionne pas
- Pas de requests d√©finis dans les pods
- HPA mal configur√©

‚ùå **HPA scale mais trop lentement**

```
0:00 - CPU 80%
3:00 - CPU 85%, toujours 2 pods
6:00 - Enfin, scaling √† 4 pods
```

**Solutions :**
- R√©duire le seuil (de 50% √† 40%)
- Augmenter minReplicas pour avoir plus de marge

‚ùå **Latence explose pendant le scaling**

```
p95: 450ms ‚Üí 3500ms pendant 2 minutes ‚Üí 500ms
```

**Causes :**
- Nouveaux pods trop lents √† d√©marrer
- Probes mal configur√©es
- Image trop lourde

**Solutions :**
- Optimiser le startup (readinessProbe)
- Utiliser des images plus l√©g√®res
- Pr√©-scaler avant les pics connus

‚ùå **Oscillations (flapping)**

```
10:00 - 2 pods
10:03 - 5 pods
10:08 - 2 pods
10:11 - 5 pods
```

**Causes :**
- Seuil trop proche de l'utilisation r√©elle
- Fen√™tre de stabilisation trop courte

**Solutions :**
- Augmenter la fen√™tre de stabilisation pour scale down
- Ajuster les seuils avec plus de marge

‚ùå **Cluster satur√©**

```
HPA recommande 20 pods mais reste √† 10
Events: FailedScheduling - Insufficient cpu
```

**Cause :** Pas assez de ressources dans le cluster

**Solutions :**
- Ajouter des n≈ìuds (scale up le cluster)
- Optimiser les requests des pods
- Utiliser Cluster Autoscaler (section 19.4)

## Sc√©narios de test r√©alistes

### Sc√©nario 1 : E-commerce - Vente flash

Simuler une vente flash avec pic soudain :

```bash
# Trafic normal (2 min)
hey -z 2m -q 50 https://boutique.example.com/

# Vente flash annonc√©e ! (pic brutal - 5 min)
hey -z 5m -q 500 https://boutique.example.com/products/promo

# Apr√®s la vente (retour √† la normale - 3 min)
hey -z 3m -q 80 https://boutique.example.com/
```

**Objectifs :**
- Latence < 1s m√™me pendant le pic
- 0 erreurs
- HPA scale rapidement (< 2 minutes)

### Sc√©nario 2 : API - Mont√©e progressive journ√©e type

Simuler une journ√©e typique :

```bash
# Nuit (charge faible - 5 min)
hey -z 5m -q 10 https://api.example.com/

# Matin (mont√©e - 5 min)
hey -z 5m -q 100 https://api.example.com/

# Midi (pic - 5 min)
hey -z 5m -q 300 https://api.example.com/

# Apr√®s-midi (charge moyenne - 5 min)
hey -z 5m -q 150 https://api.example.com/

# Soir (descente - 5 min)
hey -z 5m -q 50 https://api.example.com/
```

**Objectifs :**
- Utilisation CPU stable autour de 50-60%
- HPA adapte le nombre de pods progressivement
- Co√ªts optimis√©s (scale down le soir)

### Sc√©nario 3 : Webhook - Rafales irr√©guli√®res

Simuler des webhooks qui arrivent par rafales :

```bash
# Script K6 avec pattern irr√©gulier
cat <<EOF > webhook-test.js
import http from 'k6/http';
import { sleep } from 'k6';

export let options = {
  stages: [
    { duration: '1m', target: 10 },
    { duration: '30s', target: 100 },  // Rafale 1
    { duration: '2m', target: 10 },
    { duration: '30s', target: 150 },  // Rafale 2
    { duration: '2m', target: 10 },
    { duration: '30s', target: 200 },  // Rafale 3
    { duration: '1m', target: 0 },
  ],
};

export default function () {
  http.post('https://webhook.example.com/events', JSON.stringify({
    event: 'order.created',
    data: { order_id: Math.floor(Math.random() * 10000) }
  }), {
    headers: { 'Content-Type': 'application/json' },
  });
  sleep(Math.random() * 2);
}
EOF

k6 run webhook-test.js
```

**Objectifs :**
- HPA r√©agit aux rafales
- Aucun webhook perdu
- Scale down entre les rafales

## Bonnes pratiques

### 1. Tester en environnement de dev/staging d'abord

**Ne testez jamais directement en production !**

```bash
# Dev/Staging
hey -z 10m -c 100 https://staging.example.com/

# Analyser les r√©sultats
# Ajuster la configuration
# R√©p√©ter jusqu'√† satisfaction

# Seulement ensuite : Production
```

### 2. Commencer petit, augmenter progressivement

```bash
# Mauvais : 10 000 utilisateurs d'un coup
hey -z 1m -c 10000 https://api.example.com/

# Bon : Progression
hey -z 2m -c 10 https://api.example.com/     # 10 users
hey -z 2m -c 50 https://api.example.com/     # 50 users
hey -z 2m -c 100 https://api.example.com/    # 100 users
hey -z 2m -c 500 https://api.example.com/    # 500 users
```

### 3. Tester diff√©rents endpoints

Ne testez pas uniquement `/` :

```bash
# Test sur plusieurs endpoints
hey -z 5m -c 50 https://api.example.com/ &
hey -z 5m -c 30 https://api.example.com/api/products &
hey -z 5m -c 20 https://api.example.com/api/orders &
wait
```

### 4. Inclure des donn√©es r√©alistes

```bash
# Mauvais : toujours les m√™mes donn√©es
hey -z 5m -d '{"id":1}' https://api.example.com/

# Bon : donn√©es vari√©es (avec script K6/Locust)
for i in $(seq 1 100); do
  curl -X POST https://api.example.com/api/orders \
    -H "Content-Type: application/json" \
    -d "{\"product_id\": $((RANDOM % 1000)), \"quantity\": $((RANDOM % 10))}"
  sleep 0.1
done
```

### 5. Mesurer avant et apr√®s les changements

```bash
# Baseline
hey -z 5m -c 100 https://api.example.com/ > baseline.txt

# Faire des modifications (ajuster HPA, optimiser code, etc.)

# Re-test
hey -z 5m -c 100 https://api.example.com/ > after-changes.txt

# Comparer
diff baseline.txt after-changes.txt
```

### 6. Automatiser les tests

Int√©grez les tests de charge dans votre CI/CD :

```yaml
# .gitlab-ci.yml
load-test:
  stage: test
  script:
    - hey -z 2m -c 50 https://staging.example.com/ > results.txt
    - |
      if grep -q "Failed requests:.*[1-9]" results.txt; then
        echo "Load test failed: errors detected"
        exit 1
      fi
    - |
      AVG_LATENCY=$(grep "Average:" results.txt | awk '{print $2}')
      if (( $(echo "$AVG_LATENCY > 500" | bc -l) )); then
        echo "Load test failed: average latency > 500ms"
        exit 1
      fi
  artifacts:
    paths:
      - results.txt
```

### 7. Documenter les r√©sultats

Conservez un historique :

```bash
# Structure de dossiers
load-tests/
‚îú‚îÄ‚îÄ 2025-10-25-baseline/
‚îÇ   ‚îú‚îÄ‚îÄ results.txt
‚îÇ   ‚îú‚îÄ‚îÄ hpa-state.txt
‚îÇ   ‚îî‚îÄ‚îÄ notes.md
‚îú‚îÄ‚îÄ 2025-11-01-after-optimization/
‚îÇ   ‚îú‚îÄ‚îÄ results.txt
‚îÇ   ‚îú‚îÄ‚îÄ hpa-state.txt
‚îÇ   ‚îî‚îÄ‚îÄ notes.md
‚îî‚îÄ‚îÄ README.md
```

**notes.md exemple :**

```markdown
# Load Test - 2025-10-25

## Configuration
- HPA: min=2, max=10, target=50% CPU
- Instance: 2 CPU, 4GB RAM per pod
- Metrics Server: enabled

## R√©sultats
- Baseline: 150 req/s, p95=450ms
- With 100 concurrent users:
  - Throughput: 245 req/s
  - p95 latency: 680ms
  - Error rate: 0.02%
  - HPA scaled from 2 to 6 pods in 3 minutes

## Observations
- HPA r√©agit bien
- Latence acceptable
- Scale down apr√®s 8 minutes

## Actions
- ‚úÖ Pr√™t pour production
- Consid√©rer minReplicas=3 pour plus de marge
```

### 8. Surveiller le cluster pendant les tests

Pendant les tests, v√©rifiez aussi :

```bash
# Utilisation des n≈ìuds
kubectl top nodes

# √âv√©nements du cluster
kubectl get events --sort-by=.metadata.creationTimestamp | tail -20

# Logs des pods (erreurs ?)
kubectl logs -l app=mon-api --tail=50

# √âtat du r√©seau
kubectl get svc
kubectl describe svc mon-api
```

## Outils de monitoring pendant les tests

### Grafana dashboards

Si vous avez Prometheus + Grafana (section 12-13), cr√©ez un dashboard pour les tests de charge :

**M√©triques √† afficher :**
- Nombre de pods (gauge)
- Requ√™tes par seconde (graph)
- Latence p50, p95, p99 (graph)
- Taux d'erreurs (graph)
- Utilisation CPU par pod (heatmap)
- Utilisation m√©moire par pod (heatmap)

### Terminal multiplex√©

Utilisez `tmux` ou `screen` pour voir tout en m√™me temps :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ watch kubectl get   ‚îÇ watch kubectl top   ‚îÇ
‚îÇ hpa                 ‚îÇ pods                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ watch kubectl get   ‚îÇ hey -z 10m -c 100   ‚îÇ
‚îÇ pods                ‚îÇ https://api.com     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Configuration tmux :

```bash
tmux new-session \; \
  split-window -h \; \
  split-window -v \; \
  select-pane -t 0 \; \
  split-window -v \; \
  select-pane -t 0 \; \
  send-keys 'watch -n 2 kubectl get hpa' C-m \; \
  select-pane -t 1 \; \
  send-keys 'watch -n 2 kubectl get pods' C-m \; \
  select-pane -t 2 \; \
  send-keys 'watch -n 5 kubectl top pods' C-m \; \
  select-pane -t 3
```

## Checklist de test de charge

Avant de consid√©rer que votre autoscaling est pr√™t pour la production :

### Tests de base
- [ ] Test de charge faible (baseline √©tabli)
- [ ] Test de mont√©e progressive
- [ ] Test de pic soudain
- [ ] Test de descente (scale down)
- [ ] Test de dur√©e (soak test 1h+)

### Validations
- [ ] HPA scale up correctement
- [ ] HPA scale down correctement
- [ ] Latence reste acceptable (p95 < objectif)
- [ ] Taux d'erreurs < 0.1%
- [ ] Pas d'oscillations (flapping)
- [ ] Capacit√© maximale identifi√©e
- [ ] Temps de r√©ponse du scaling < 3 minutes

### M√©triques document√©es
- [ ] Throughput maximal connu
- [ ] Latence √† diff√©rentes charges mesur√©e
- [ ] Configuration HPA optimale document√©e
- [ ] Ressources par pod calibr√©es (requests/limits)

### Outils configur√©s
- [ ] Monitoring en place (Prometheus/Grafana)
- [ ] Alertes configur√©es
- [ ] Tests automatis√©s dans CI/CD
- [ ] Runbook de r√©ponse aux incidents

## R√©sum√©

Les **tests de charge** sont essentiels pour valider que votre autoscaling fonctionne comme pr√©vu.

**Points cl√©s :**

1. Testez **avant** la production, jamais directement en prod
2. Commencez avec des charges faibles, augmentez progressivement
3. Utilisez les bons outils : hey/ab pour le simple, K6/Locust pour l'avanc√©
4. Observez simultan√©ment : HPA, pods, m√©triques, latence, erreurs
5. Diff√©rents types de tests : baseline, ramp-up, spike, soak, stress
6. Interpr√©tez les r√©sultats : latence (p95, p99), erreurs, throughput, scaling
7. Documentez tout : configurations, r√©sultats, observations, actions
8. Automatisez les tests dans votre CI/CD

**Outils recommand√©s selon le contexte :**

| Besoin | Outil recommand√© |
|--------|------------------|
| Test rapide simple | Apache Bench (ab) |
| Tests HTTP modernes | Hey |
| Sc√©narios complexes | K6 |
| Interface web + Python | Locust |
| Tests internes au cluster | Busybox/curl |

**Progression recommand√©e :**

1. **D√©butant** : Utilisez `hey` avec des commandes simples
2. **Interm√©diaire** : Cr√©ez des scripts K6 avec stages
3. **Avanc√©** : Automatisez dans CI/CD, tests continus

**Citation importante :**

> "Le meilleur moment pour tester votre autoscaling est AVANT le Black Friday, pas PENDANT !"

Les tests de charge vous permettent de dormir tranquille en sachant que votre syst√®me peut g√©rer la charge. C'est un investissement de temps qui rapporte √©norm√©ment en fiabilit√© et confiance !

---

**F√©licitations !** Vous avez maintenant une compr√©hension compl√®te du scaling et autoscaling dans Kubernetes, du manuel (19.1) aux tests de validation (19.7). Vous √™tes pr√™t √† g√©rer des applications scalables en production !

‚è≠Ô∏è [Ordonnancement Avanc√©](/20-ordonnancement-avance/README.md)
