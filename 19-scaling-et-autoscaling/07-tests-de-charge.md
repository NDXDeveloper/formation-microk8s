ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 19.7 Tests de charge

## Introduction aux tests de charge

Les **tests de charge** (load testing) consistent Ã  simuler un grand nombre d'utilisateurs ou de requÃªtes pour vÃ©rifier comment votre application et votre autoscaling rÃ©agissent sous la pression. C'est une Ã©tape **essentielle** pour valider que vos configurations HPA, VPA, et mÃ©triques fonctionnent correctement.

### Pourquoi tester la charge ?

Imaginez que vous avez configurÃ© un HPA magnifique :

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: mon-api-hpa
spec:
  minReplicas: 2
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
```

**Questions importantes :**

- âœ… Le HPA scale-t-il vraiment quand la charge augmente ?
- âœ… Scale-t-il assez vite ?
- âœ… Scale-t-il au bon moment (pas trop tÃ´t, pas trop tard) ?
- âœ… L'application reste-t-elle performante pendant le scaling ?
- âœ… Le scale down fonctionne-t-il correctement aprÃ¨s le pic ?
- âœ… Les seuils sont-ils bien calibrÃ©s ?

**Sans tests de charge, vous ne le saurez jamais !**

### Analogie simple

**Sans tests de charge :**
- C'est comme installer un systÃ¨me anti-incendie dans une maison mais ne jamais vÃ©rifier qu'il fonctionne
- Vous pensez Ãªtre protÃ©gÃ©, mais vous n'avez aucune garantie

**Avec tests de charge :**
- Vous simulez un incendie (de maniÃ¨re contrÃ´lÃ©e)
- Vous vÃ©rifiez que les dÃ©tecteurs se dÃ©clenchent
- Vous vÃ©rifiez que l'eau arrive bien
- Vous identifiez les problÃ¨mes avant qu'ils ne soient critiques

Les tests de charge sont votre "simulation d'incendie" pour l'autoscaling !

## Types de tests de charge

Il existe plusieurs types de tests selon vos objectifs :

### 1. Test de montÃ©e en charge (Ramp-up test)

Augmentation progressive de la charge pour observer le comportement.

```
Charge
  â†‘
  |                    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  |              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  |        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  |  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  |â–ˆâ–ˆ
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Temps
    0    2    4    6    8   10 min
```

**Objectif :** Voir comment le HPA rÃ©agit Ã  une augmentation progressive.

### 2. Test de pic brutal (Spike test)

Augmentation soudaine de la charge.

```
Charge
  â†‘
  |  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  |â–ˆâ–ˆ                    â–ˆâ–ˆâ–ˆâ–ˆ
  |â–ˆ                        â–ˆâ–ˆâ–ˆâ–ˆ
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Temps
    0    2    4    6    8   10 min
```

**Objectif :** Voir si le systÃ¨me peut gÃ©rer un pic soudain (flash sale, Ã©vÃ©nement viral).

### 3. Test de charge soutenue (Soak test)

Charge constante pendant une longue pÃ©riode.

```
Charge
  â†‘
  |  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  |â–ˆâ–ˆ                                â–ˆâ–ˆ
  |â–ˆ                                  â–ˆ
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Temps
    0    1h   2h   3h   4h   5h
```

**Objectif :** DÃ©tecter les fuites mÃ©moire, les dÃ©gradations progressives.

### 4. Test de stress (Stress test)

Augmentation jusqu'Ã  la rupture pour trouver les limites.

```
Charge
  â†‘
  |                          â–ˆâ–ˆâ–ˆâ–ˆ CRASH!
  |                    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  |              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  |        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  |  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  |â–ˆâ–ˆ
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Temps
    0    2    4    6    8   10 min
```

**Objectif :** Trouver le point de rupture, valider que le systÃ¨me ne tombe pas brutalement.

## Outils de tests de charge

### 1. Apache Bench (ab) - Simple et rapide

**Installation :**

```bash
# Ubuntu/Debian
sudo apt install apache2-utils

# macOS
# DÃ©jÃ  installÃ© par dÃ©faut

# MicroK8s (dans un pod)
kubectl run ab --image=httpd:alpine --rm -it -- sh
apk add apache2-utils
```

**Utilisation basique :**

```bash
ab -n 10000 -c 100 http://mon-api.example.com/
```

**ParamÃ¨tres :**
- `-n 10000` : Nombre total de requÃªtes (10,000)
- `-c 100` : Nombre de requÃªtes concurrentes (100 en parallÃ¨le)

**Sortie :**

```
Benchmarking mon-api.example.com (be patient)
Completed 1000 requests
Completed 2000 requests
...
Completed 10000 requests
Finished 10000 requests

Server Software:        nginx/1.21
Server Hostname:        mon-api.example.com
Server Port:            80

Concurrency Level:      100
Time taken for tests:   12.456 seconds
Complete requests:      10000
Failed requests:        0
Total transferred:      2450000 bytes
HTML transferred:       1250000 bytes
Requests per second:    802.84 [#/sec] (mean)
Time per request:       124.558 [ms] (mean)
Time per request:       1.246 [ms] (mean, across all concurrent requests)
Transfer rate:          192.05 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        1    5   2.1      4      15
Processing:    15  118  45.2    110     450
Waiting:       12  115  44.8    108     445
Total:         20  123  45.8    115     455

Percentage of the requests served within a certain time (ms)
  50%    115
  66%    130
  75%    145
  80%    155
  90%    180
  95%    220
  98%    280
  99%    350
 100%    455 (longest request)
```

**Avantages :**
- âœ… TrÃ¨s simple Ã  utiliser
- âœ… InstallÃ© sur la plupart des systÃ¨mes
- âœ… RÃ©sultats faciles Ã  lire

**InconvÃ©nients :**
- âŒ LimitÃ© aux requÃªtes HTTP GET simples
- âŒ Pas de scÃ©narios complexes
- âŒ Pas de graphiques

### 2. Hey - Ab moderne

**Installation :**

```bash
# Via Go
go install github.com/rakyll/hey@latest

# Ou tÃ©lÃ©charger le binaire
wget https://hey-release.s3.us-east-2.amazonaws.com/hey_linux_amd64
chmod +x hey_linux_amd64
sudo mv hey_linux_amd64 /usr/local/bin/hey
```

**Utilisation :**

```bash
# Test de 5 minutes avec 50 workers
hey -z 5m -c 50 http://mon-api.example.com/
```

**ParamÃ¨tres utiles :**
- `-z 5m` : Duration (5 minutes)
- `-c 50` : Concurrency (50 workers)
- `-q 100` : Rate limit (100 requÃªtes/sec max)
- `-m POST` : MÃ©thode HTTP
- `-H "Authorization: Bearer token"` : Header custom

**Exemple avec POST et body :**

```bash
hey -z 2m -c 30 -m POST \
  -H "Content-Type: application/json" \
  -d '{"name":"test","value":123}' \
  http://mon-api.example.com/api/data
```

**Sortie :**

```
Summary:
  Total:        300.0534 secs
  Slowest:      1.2456 secs
  Fastest:      0.0234 secs
  Average:      0.1567 secs
  Requests/sec: 159.97

  Total data:   2400000 bytes
  Size/request: 50 bytes

Response time histogram:
  0.023 [1]     |
  0.145 [12543] |â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
  0.267 [23456] |â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
  0.389 [8754]  |â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– 
  0.511 [3214]  |â– â– â– â– â– â– â– â– â– â– 
  0.633 [876]   |â– â– â– 
  0.755 [234]   |â– 
  0.877 [87]    |
  0.999 [32]    |
  1.121 [12]    |
  1.246 [1]     |

Latency distribution:
  10% in 0.0856 secs
  25% in 0.1234 secs
  50% in 0.1567 secs
  75% in 0.2134 secs
  90% in 0.3456 secs
  95% in 0.4567 secs
  99% in 0.7890 secs

Status code distribution:
  [200] 48000 responses
```

**Avantages :**
- âœ… Plus moderne et flexible que ab
- âœ… Supporte POST, PUT, headers custom
- âœ… Histogrammes et percentiles
- âœ… Rate limiting intÃ©grÃ©

**InconvÃ©nients :**
- âŒ Pas de scÃ©narios complexes
- âŒ Installation supplÃ©mentaire nÃ©cessaire

### 3. K6 - Tests avancÃ©s

**Installation :**

```bash
# Ubuntu/Debian
sudo gpg -k
sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
sudo apt-get update
sudo apt-get install k6

# macOS
brew install k6

# Docker
docker pull grafana/k6
```

**Script de test (script.js) :**

```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  stages: [
    { duration: '2m', target: 10 },   // Ramp up to 10 users
    { duration: '5m', target: 50 },   // Stay at 50 users
    { duration: '2m', target: 100 },  // Ramp up to 100 users
    { duration: '5m', target: 100 },  // Stay at 100 users
    { duration: '2m', target: 0 },    // Ramp down to 0 users
  ],
  thresholds: {
    'http_req_duration': ['p(95)<500'], // 95% des requÃªtes < 500ms
    'http_req_failed': ['rate<0.01'],   // Moins de 1% d'erreurs
  },
};

export default function () {
  let response = http.get('http://mon-api.example.com/');

  check(response, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });

  sleep(1); // Pause entre les requÃªtes
}
```

**ExÃ©cution :**

```bash
k6 run script.js
```

**Sortie :**

```
          /\      |â€¾â€¾| /â€¾â€¾/   /â€¾â€¾/
     /\  /  \     |  |/  /   /  /
    /  \/    \    |     (   /   â€¾â€¾\
   /          \   |  |\  \ |  (â€¾)  |
  / __________ \  |__| \__\ \_____/ .io

  execution: local
     script: script.js
     output: -

  scenarios: (100.00%) 1 scenario, 100 max VUs, 18m0s max duration
           * default: Up to 100 looping VUs for 16m0s over 5 stages

running (16m00.2s), 000/100 VUs, 45832 complete and 0 interrupted iterations
default âœ“ [======================================] 000/100 VUs  16m0s

     âœ“ status is 200
     âœ“ response time < 500ms

     checks.........................: 100.00% âœ“ 91664      âœ— 0
     data_received..................: 229 MB  238 kB/s
     data_sent......................: 4.1 MB  4.3 kB/s
     http_req_blocked...............: avg=1.2ms    min=1Âµs     med=3Âµs      max=234ms   p(90)=5Âµs      p(95)=7Âµs
     http_req_connecting............: avg=567Âµs    min=0s      med=0s       max=123ms   p(90)=0s       p(95)=0s
     http_req_duration..............: avg=123.45ms min=23.12ms med=98.76ms  max=987ms   p(90)=234.56ms p(95)=345.67ms
     http_req_failed................: 0.00%   âœ“ 0          âœ— 45832
     http_req_receiving.............: avg=234Âµs    min=12Âµs    med=156Âµs    max=23ms    p(90)=456Âµs    p(95)=678Âµs
     http_req_sending...............: avg=45Âµs     min=4Âµs     med=23Âµs     max=5ms     p(90)=67Âµs     p(95)=89Âµs
     http_req_tls_handshaking.......: avg=0s       min=0s      med=0s       max=0s      p(90)=0s       p(95)=0s
     http_req_waiting...............: avg=123.17ms min=23.08ms med=98.54ms  max=986ms   p(90)=234.12ms p(95)=345.23ms
     http_reqs......................: 45832   47.8/s
     iteration_duration.............: avg=1.12s    min=1.02s   med=1.09s    max=1.98s   p(90)=1.23s    p(95)=1.34s
     iterations.....................: 45832   47.8/s
     vus............................: 1       min=1        max=100
     vus_max........................: 100     min=100      max=100
```

**Avantages :**
- âœ… ScÃ©narios complexes (ramping, stages)
- âœ… Scripting JavaScript complet
- âœ… Thresholds et checks intÃ©grÃ©s
- âœ… MÃ©triques dÃ©taillÃ©es
- âœ… Peut envoyer les rÃ©sultats Ã  Grafana Cloud

**InconvÃ©nients :**
- âŒ Plus complexe Ã  apprendre
- âŒ NÃ©cessite l'Ã©criture de scripts

### 4. Locust - Tests avec interface web

**Installation :**

```bash
pip install locust
```

**Script de test (locustfile.py) :**

```python
from locust import HttpUser, task, between

class MyUser(HttpUser):
    wait_time = between(1, 3)  # Attente entre 1 et 3 secondes

    @task(3)  # Poids : 3x plus frÃ©quent
    def get_homepage(self):
        self.client.get("/")

    @task(1)  # Poids : 1x
    def get_api_data(self):
        self.client.get("/api/data")

    @task(2)  # Poids : 2x
    def post_data(self):
        self.client.post("/api/submit", json={
            "name": "test",
            "value": 123
        })

    def on_start(self):
        # ExÃ©cutÃ© au dÃ©marrage (login, etc.)
        self.client.post("/login", json={
            "username": "test",
            "password": "test123"
        })
```

**Lancer Locust :**

```bash
locust -f locustfile.py --host=http://mon-api.example.com
```

Puis ouvrez http://localhost:8089 dans votre navigateur.

**Interface web :**
- DÃ©finir le nombre d'utilisateurs (ex: 100)
- DÃ©finir le taux d'apparition (ex: 10 users/sec)
- DÃ©marrer le test
- Voir les graphiques en temps rÃ©el !

**Avantages :**
- âœ… Interface web intuitive
- âœ… Graphiques en temps rÃ©el
- âœ… ScÃ©narios Python flexibles
- âœ… Distribution sur plusieurs machines possible

**InconvÃ©nients :**
- âŒ NÃ©cessite Python
- âŒ Plus lourd que hey/ab

### 5. Tests depuis Kubernetes (Busybox/Curl)

Pour des tests rapides depuis le cluster :

```bash
# Pod busybox interactif
kubectl run -i --tty load-generator --rm --image=busybox --restart=Never -- /bin/sh

# Dans le pod
while true; do
  wget -q -O- http://mon-service.default.svc.cluster.local/
done
```

Ou un Job Kubernetes :

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: load-test
spec:
  parallelism: 10  # 10 pods en parallÃ¨le
  completions: 100 # 100 exÃ©cutions au total
  template:
    spec:
      containers:
      - name: curl
        image: curlimages/curl
        command:
        - sh
        - -c
        - |
          for i in $(seq 1 100); do
            curl -s http://mon-service.default.svc.cluster.local/ > /dev/null
            sleep 0.1
          done
      restartPolicy: Never
```

## MÃ©thodologie de test

### Phase 1 : PrÃ©paration

**1. DÃ©finir les objectifs**

Qu'est-ce que vous voulez tester ?
- âœ… Le HPA scale-t-il correctement ?
- âœ… Ã€ quel seuil de charge scale-t-il ?
- âœ… La latence reste-t-elle acceptable ?
- âœ… Quelle est la capacitÃ© maximale ?

**2. Identifier les endpoints Ã  tester**

```
Endpoints critiques :
- GET  /                      (homepage)
- GET  /api/products          (liste)
- GET  /api/products/:id      (dÃ©tail)
- POST /api/orders            (crÃ©ation)
- GET  /api/orders/:id        (statut)
```

**3. PrÃ©parer l'environnement**

```bash
# VÃ©rifier l'Ã©tat initial
kubectl get hpa
kubectl get pods
kubectl top nodes
kubectl top pods

# S'assurer que Metrics Server fonctionne
kubectl top nodes
```

**4. PrÃ©parer les outils de monitoring**

Ouvrez plusieurs terminaux :

**Terminal 1 : Observer le HPA**
```bash
watch -n 2 kubectl get hpa
```

**Terminal 2 : Observer les pods**
```bash
watch -n 2 kubectl get pods
```

**Terminal 3 : Observer les mÃ©triques**
```bash
watch -n 5 kubectl top pods
```

**Terminal 4 : Lancer le test de charge**
```bash
hey -z 10m -c 50 http://mon-api.example.com/
```

### Phase 2 : Test de base (Baseline)

Commencez avec une charge faible pour Ã©tablir une rÃ©fÃ©rence.

```bash
# Charge faible : 10 requÃªtes/sec pendant 2 minutes
hey -z 2m -q 10 http://mon-api.example.com/
```

**Observer :**
- Latence moyenne
- Taux d'erreurs
- Utilisation CPU/mÃ©moire
- Nombre de pods (doit rester stable)

**RÃ©sultat attendu :** Tout est stable, pas de scaling.

### Phase 3 : Test de montÃ©e en charge

Augmentez progressivement la charge.

```bash
# Ã‰tape 1 : 50 requÃªtes/sec
hey -z 3m -q 50 http://mon-api.example.com/

# Ã‰tape 2 : 100 requÃªtes/sec
hey -z 3m -q 100 http://mon-api.example.com/

# Ã‰tape 3 : 200 requÃªtes/sec
hey -z 3m -q 200 http://mon-api.example.com/
```

**Observer :**

**Dans le terminal HPA :**
```
NAME      REFERENCE        TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
my-hpa    Deployment/app   25%/50%    2         10        2          5m

# 2 minutes plus tard...
NAME      REFERENCE        TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
my-hpa    Deployment/app   65%/50%    2         10        4          7m

# Encore 2 minutes...
NAME      REFERENCE        TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
my-hpa    Deployment/app   48%/50%    2         10        6          9m
```

**Questions Ã  se poser :**
- âœ… Ã€ quel moment le HPA a-t-il commencÃ© Ã  scaler ?
- âœ… Le scaling est-il suffisamment rapide ?
- âœ… L'utilisation CPU est-elle revenue proche de la cible ?
- âœ… La latence est-elle restÃ©e acceptable ?

### Phase 4 : Test de pic

Simulez un pic soudain de trafic.

```bash
# Pic brutal : 500 requÃªtes/sec pendant 5 minutes
hey -z 5m -q 500 http://mon-api.example.com/
```

**Observer :**
- Le HPA rÃ©agit-il assez vite ?
- Y a-t-il des erreurs pendant le pic ?
- Combien de temps pour stabiliser ?

**Ã‰vÃ©nements typiques :**

```
0:00 - DÃ©but du test, 2 pods, CPU 20%
0:30 - CPU monte Ã  85%, HPA dÃ©tecte
1:00 - HPA crÃ©e 2 nouveaux pods (total: 4)
1:30 - Pods dÃ©marrent, CPU Ã  60%
2:00 - HPA crÃ©e encore 2 pods (total: 6)
2:30 - CPU stable Ã  45%
5:00 - Fin du test
7:00 - HPA commence Ã  scale down
12:00 - Retour Ã  2 pods
```

### Phase 5 : Test de descente

ArrÃªtez la charge et observez le scale down.

```bash
# ArrÃªter le test
# Attendre et observer
watch -n 10 kubectl get hpa
```

**Points d'attention :**
- Le scale down prend **plus de temps** que le scale up (par design)
- Par dÃ©faut : 5 minutes avant de scale down
- C'est normal et souhaitable (Ã©vite les oscillations)

### Phase 6 : Test de stress (optionnel)

Trouvez les limites du systÃ¨me.

```bash
# Augmentation progressive jusqu'Ã  la rupture
hey -z 1m -q 100 http://mon-api.example.com/   # 100 req/s
hey -z 1m -q 200 http://mon-api.example.com/   # 200 req/s
hey -z 1m -q 500 http://mon-api.example.com/   # 500 req/s
hey -z 1m -q 1000 http://mon-api.example.com/  # 1000 req/s
hey -z 1m -q 2000 http://mon-api.example.com/  # 2000 req/s
```

**Continuez jusqu'Ã  observer :**
- Taux d'erreurs qui augmente significativement (>1%)
- Latence qui explose (>5 secondes)
- HPA qui atteint maxReplicas mais ne peut plus suivre
- Cluster qui manque de ressources

**RÃ©sultat :** Vous connaissez maintenant la capacitÃ© maximale de votre systÃ¨me !

## InterprÃ©ter les rÃ©sultats

### MÃ©triques clÃ©s Ã  surveiller

**1. Latence (Response Time)**

```
p50 (mÃ©diane):  125ms   â† 50% des requÃªtes
p95:            340ms   â† 95% des requÃªtes
p99:            850ms   â† 99% des requÃªtes
```

**Bon :** p95 < 500ms, p99 < 1000ms
**ProblÃ¨me :** p95 > 1000ms, p99 > 5000ms

**2. Taux d'erreurs (Error Rate)**

```
Total requests: 10000
Failed:         15
Error rate:     0.15%
```

**Bon :** < 0.1%
**Acceptable :** < 1%
**ProblÃ¨me :** > 5%

**3. Throughput (DÃ©bit)**

```
Requests per second: 247.5
```

**Comparez avec vos objectifs :**
- Objectif : 500 req/s â†’ **ProblÃ¨me** (seulement 247)
- Objectif : 200 req/s â†’ **Bon** (dÃ©passe l'objectif)

**4. Utilisation des ressources**

```bash
kubectl top pods
```

```
NAME                CPU      MEMORY
app-xxxxx-abcd      450m     256Mi    # 90% du request (500m)
app-xxxxx-efgh      480m     280Mi    # 96% du request
app-xxxxx-ijkl      420m     240Mi    # 84% du request
```

**Bon :** 50-70% d'utilisation (marge pour les pics)
**ProblÃ¨me :** >90% (risque de throttling/OOM)

### Signes que tout fonctionne bien

âœ… **Le HPA scale up quand nÃ©cessaire**
```
Charge augmente â†’ CPU > 50% â†’ HPA ajoute des pods â†’ CPU redescend vers 50%
```

âœ… **La latence reste stable**
```
p95 avant scaling:  450ms
p95 aprÃ¨s scaling:  480ms   (acceptable, <20% augmentation)
```

âœ… **Pas (ou trÃ¨s peu) d'erreurs**
```
Error rate: 0.05%   (excellent)
```

âœ… **Le scale down fonctionne**
```
Charge diminue â†’ AprÃ¨s 5-10min â†’ HPA retire des pods
```

### Signes de problÃ¨mes

âŒ **HPA ne scale pas du tout**

```
TARGETS: 85%/50%   REPLICAS: 2/2   (reste Ã  2 malgrÃ© 85% CPU)
```

**Causes possibles :**
- Metrics Server ne fonctionne pas
- Pas de requests dÃ©finis dans les pods
- HPA mal configurÃ©

âŒ **HPA scale mais trop lentement**

```
0:00 - CPU 80%
3:00 - CPU 85%, toujours 2 pods
6:00 - Enfin, scaling Ã  4 pods
```

**Solutions :**
- RÃ©duire le seuil (de 50% Ã  40%)
- Augmenter minReplicas pour avoir plus de marge

âŒ **Latence explose pendant le scaling**

```
p95: 450ms â†’ 3500ms pendant 2 minutes â†’ 500ms
```

**Causes :**
- Nouveaux pods trop lents Ã  dÃ©marrer
- Probes mal configurÃ©es
- Image trop lourde

**Solutions :**
- Optimiser le startup (readinessProbe)
- Utiliser des images plus lÃ©gÃ¨res
- PrÃ©-scaler avant les pics connus

âŒ **Oscillations (flapping)**

```
10:00 - 2 pods
10:03 - 5 pods
10:08 - 2 pods
10:11 - 5 pods
```

**Causes :**
- Seuil trop proche de l'utilisation rÃ©elle
- FenÃªtre de stabilisation trop courte

**Solutions :**
- Augmenter la fenÃªtre de stabilisation pour scale down
- Ajuster les seuils avec plus de marge

âŒ **Cluster saturÃ©**

```
HPA recommande 20 pods mais reste Ã  10
Events: FailedScheduling - Insufficient cpu
```

**Cause :** Pas assez de ressources dans le cluster

**Solutions :**
- Ajouter des nÅ“uds (scale up le cluster)
- Optimiser les requests des pods
- Utiliser Cluster Autoscaler (section 19.4)

## ScÃ©narios de test rÃ©alistes

### ScÃ©nario 1 : E-commerce - Vente flash

Simuler une vente flash avec pic soudain :

```bash
# Trafic normal (2 min)
hey -z 2m -q 50 https://boutique.example.com/

# Vente flash annoncÃ©e ! (pic brutal - 5 min)
hey -z 5m -q 500 https://boutique.example.com/products/promo

# AprÃ¨s la vente (retour Ã  la normale - 3 min)
hey -z 3m -q 80 https://boutique.example.com/
```

**Objectifs :**
- Latence < 1s mÃªme pendant le pic
- 0 erreurs
- HPA scale rapidement (< 2 minutes)

### ScÃ©nario 2 : API - MontÃ©e progressive journÃ©e type

Simuler une journÃ©e typique :

```bash
# Nuit (charge faible - 5 min)
hey -z 5m -q 10 https://api.example.com/

# Matin (montÃ©e - 5 min)
hey -z 5m -q 100 https://api.example.com/

# Midi (pic - 5 min)
hey -z 5m -q 300 https://api.example.com/

# AprÃ¨s-midi (charge moyenne - 5 min)
hey -z 5m -q 150 https://api.example.com/

# Soir (descente - 5 min)
hey -z 5m -q 50 https://api.example.com/
```

**Objectifs :**
- Utilisation CPU stable autour de 50-60%
- HPA adapte le nombre de pods progressivement
- CoÃ»ts optimisÃ©s (scale down le soir)

### ScÃ©nario 3 : Webhook - Rafales irrÃ©guliÃ¨res

Simuler des webhooks qui arrivent par rafales :

```bash
# Script K6 avec pattern irrÃ©gulier
cat <<EOF > webhook-test.js
import http from 'k6/http';
import { sleep } from 'k6';

export let options = {
  stages: [
    { duration: '1m', target: 10 },
    { duration: '30s', target: 100 },  // Rafale 1
    { duration: '2m', target: 10 },
    { duration: '30s', target: 150 },  // Rafale 2
    { duration: '2m', target: 10 },
    { duration: '30s', target: 200 },  // Rafale 3
    { duration: '1m', target: 0 },
  ],
};

export default function () {
  http.post('https://webhook.example.com/events', JSON.stringify({
    event: 'order.created',
    data: { order_id: Math.floor(Math.random() * 10000) }
  }), {
    headers: { 'Content-Type': 'application/json' },
  });
  sleep(Math.random() * 2);
}
EOF

k6 run webhook-test.js
```

**Objectifs :**
- HPA rÃ©agit aux rafales
- Aucun webhook perdu
- Scale down entre les rafales

## Bonnes pratiques

### 1. Tester en environnement de dev/staging d'abord

**Ne testez jamais directement en production !**

```bash
# Dev/Staging
hey -z 10m -c 100 https://staging.example.com/

# Analyser les rÃ©sultats
# Ajuster la configuration
# RÃ©pÃ©ter jusqu'Ã  satisfaction

# Seulement ensuite : Production
```

### 2. Commencer petit, augmenter progressivement

```bash
# Mauvais : 10 000 utilisateurs d'un coup
hey -z 1m -c 10000 https://api.example.com/

# Bon : Progression
hey -z 2m -c 10 https://api.example.com/     # 10 users
hey -z 2m -c 50 https://api.example.com/     # 50 users
hey -z 2m -c 100 https://api.example.com/    # 100 users
hey -z 2m -c 500 https://api.example.com/    # 500 users
```

### 3. Tester diffÃ©rents endpoints

Ne testez pas uniquement `/` :

```bash
# Test sur plusieurs endpoints
hey -z 5m -c 50 https://api.example.com/ &
hey -z 5m -c 30 https://api.example.com/api/products &
hey -z 5m -c 20 https://api.example.com/api/orders &
wait
```

### 4. Inclure des donnÃ©es rÃ©alistes

```bash
# Mauvais : toujours les mÃªmes donnÃ©es
hey -z 5m -d '{"id":1}' https://api.example.com/

# Bon : donnÃ©es variÃ©es (avec script K6/Locust)
for i in $(seq 1 100); do
  curl -X POST https://api.example.com/api/orders \
    -H "Content-Type: application/json" \
    -d "{\"product_id\": $((RANDOM % 1000)), \"quantity\": $((RANDOM % 10))}"
  sleep 0.1
done
```

### 5. Mesurer avant et aprÃ¨s les changements

```bash
# Baseline
hey -z 5m -c 100 https://api.example.com/ > baseline.txt

# Faire des modifications (ajuster HPA, optimiser code, etc.)

# Re-test
hey -z 5m -c 100 https://api.example.com/ > after-changes.txt

# Comparer
diff baseline.txt after-changes.txt
```

### 6. Automatiser les tests

IntÃ©grez les tests de charge dans votre CI/CD :

```yaml
# .gitlab-ci.yml
load-test:
  stage: test
  script:
    - hey -z 2m -c 50 https://staging.example.com/ > results.txt
    - |
      if grep -q "Failed requests:.*[1-9]" results.txt; then
        echo "Load test failed: errors detected"
        exit 1
      fi
    - |
      AVG_LATENCY=$(grep "Average:" results.txt | awk '{print $2}')
      if (( $(echo "$AVG_LATENCY > 500" | bc -l) )); then
        echo "Load test failed: average latency > 500ms"
        exit 1
      fi
  artifacts:
    paths:
      - results.txt
```

### 7. Documenter les rÃ©sultats

Conservez un historique :

```bash
# Structure de dossiers
load-tests/
â”œâ”€â”€ 2025-10-25-baseline/
â”‚   â”œâ”€â”€ results.txt
â”‚   â”œâ”€â”€ hpa-state.txt
â”‚   â””â”€â”€ notes.md
â”œâ”€â”€ 2025-11-01-after-optimization/
â”‚   â”œâ”€â”€ results.txt
â”‚   â”œâ”€â”€ hpa-state.txt
â”‚   â””â”€â”€ notes.md
â””â”€â”€ README.md
```

**notes.md exemple :**

```markdown
# Load Test - 2025-10-25

## Configuration
- HPA: min=2, max=10, target=50% CPU
- Instance: 2 CPU, 4GB RAM per pod
- Metrics Server: enabled

## RÃ©sultats
- Baseline: 150 req/s, p95=450ms
- With 100 concurrent users:
  - Throughput: 245 req/s
  - p95 latency: 680ms
  - Error rate: 0.02%
  - HPA scaled from 2 to 6 pods in 3 minutes

## Observations
- HPA rÃ©agit bien
- Latence acceptable
- Scale down aprÃ¨s 8 minutes

## Actions
- âœ… PrÃªt pour production
- ConsidÃ©rer minReplicas=3 pour plus de marge
```

### 8. Surveiller le cluster pendant les tests

Pendant les tests, vÃ©rifiez aussi :

```bash
# Utilisation des nÅ“uds
kubectl top nodes

# Ã‰vÃ©nements du cluster
kubectl get events --sort-by=.metadata.creationTimestamp | tail -20

# Logs des pods (erreurs ?)
kubectl logs -l app=mon-api --tail=50

# Ã‰tat du rÃ©seau
kubectl get svc
kubectl describe svc mon-api
```

## Outils de monitoring pendant les tests

### Grafana dashboards

Si vous avez Prometheus + Grafana (section 12-13), crÃ©ez un dashboard pour les tests de charge :

**MÃ©triques Ã  afficher :**
- Nombre de pods (gauge)
- RequÃªtes par seconde (graph)
- Latence p50, p95, p99 (graph)
- Taux d'erreurs (graph)
- Utilisation CPU par pod (heatmap)
- Utilisation mÃ©moire par pod (heatmap)

### Terminal multiplexÃ©

Utilisez `tmux` ou `screen` pour voir tout en mÃªme temps :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ watch kubectl get   â”‚ watch kubectl top   â”‚
â”‚ hpa                 â”‚ pods                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ watch kubectl get   â”‚ hey -z 10m -c 100   â”‚
â”‚ pods                â”‚ https://api.com     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Configuration tmux :

```bash
tmux new-session \; \
  split-window -h \; \
  split-window -v \; \
  select-pane -t 0 \; \
  split-window -v \; \
  select-pane -t 0 \; \
  send-keys 'watch -n 2 kubectl get hpa' C-m \; \
  select-pane -t 1 \; \
  send-keys 'watch -n 2 kubectl get pods' C-m \; \
  select-pane -t 2 \; \
  send-keys 'watch -n 5 kubectl top pods' C-m \; \
  select-pane -t 3
```

## Checklist de test de charge

Avant de considÃ©rer que votre autoscaling est prÃªt pour la production :

### Tests de base
- [ ] Test de charge faible (baseline Ã©tabli)
- [ ] Test de montÃ©e progressive
- [ ] Test de pic soudain
- [ ] Test de descente (scale down)
- [ ] Test de durÃ©e (soak test 1h+)

### Validations
- [ ] HPA scale up correctement
- [ ] HPA scale down correctement
- [ ] Latence reste acceptable (p95 < objectif)
- [ ] Taux d'erreurs < 0.1%
- [ ] Pas d'oscillations (flapping)
- [ ] CapacitÃ© maximale identifiÃ©e
- [ ] Temps de rÃ©ponse du scaling < 3 minutes

### MÃ©triques documentÃ©es
- [ ] Throughput maximal connu
- [ ] Latence Ã  diffÃ©rentes charges mesurÃ©e
- [ ] Configuration HPA optimale documentÃ©e
- [ ] Ressources par pod calibrÃ©es (requests/limits)

### Outils configurÃ©s
- [ ] Monitoring en place (Prometheus/Grafana)
- [ ] Alertes configurÃ©es
- [ ] Tests automatisÃ©s dans CI/CD
- [ ] Runbook de rÃ©ponse aux incidents

## RÃ©sumÃ©

Les **tests de charge** sont essentiels pour valider que votre autoscaling fonctionne comme prÃ©vu.

**Points clÃ©s :**

1. Testez **avant** la production, jamais directement en prod
2. Commencez avec des charges faibles, augmentez progressivement
3. Utilisez les bons outils : hey/ab pour le simple, K6/Locust pour l'avancÃ©
4. Observez simultanÃ©ment : HPA, pods, mÃ©triques, latence, erreurs
5. DiffÃ©rents types de tests : baseline, ramp-up, spike, soak, stress
6. InterprÃ©tez les rÃ©sultats : latence (p95, p99), erreurs, throughput, scaling
7. Documentez tout : configurations, rÃ©sultats, observations, actions
8. Automatisez les tests dans votre CI/CD

**Outils recommandÃ©s selon le contexte :**

| Besoin | Outil recommandÃ© |
|--------|------------------|
| Test rapide simple | Apache Bench (ab) |
| Tests HTTP modernes | Hey |
| ScÃ©narios complexes | K6 |
| Interface web + Python | Locust |
| Tests internes au cluster | Busybox/curl |

**Progression recommandÃ©e :**

1. **DÃ©butant** : Utilisez `hey` avec des commandes simples
2. **IntermÃ©diaire** : CrÃ©ez des scripts K6 avec stages
3. **AvancÃ©** : Automatisez dans CI/CD, tests continus

**Citation importante :**

> "Le meilleur moment pour tester votre autoscaling est AVANT le Black Friday, pas PENDANT !"

Les tests de charge vous permettent de dormir tranquille en sachant que votre systÃ¨me peut gÃ©rer la charge. C'est un investissement de temps qui rapporte Ã©normÃ©ment en fiabilitÃ© et confiance !

---

**FÃ©licitations !** Vous avez maintenant une comprÃ©hension complÃ¨te du scaling et autoscaling dans Kubernetes, du manuel (19.1) aux tests de validation (19.7). Vous Ãªtes prÃªt Ã  gÃ©rer des applications scalables en production !

â­ï¸ [Ordonnancement AvancÃ©](/20-ordonnancement-avance/README.md)
