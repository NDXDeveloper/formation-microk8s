üîù Retour au [Sommaire](/SOMMAIRE.md)

# 19.1 Scaling Manuel

## Introduction au Scaling

Le **scaling** (mise √† l'√©chelle en fran√ßais) consiste √† augmenter ou diminuer le nombre de r√©pliques de votre application qui s'ex√©cutent simultan√©ment dans votre cluster Kubernetes. C'est l'une des fonctionnalit√©s les plus puissantes de Kubernetes.

### Pourquoi scaler une application ?

Imaginez que vous avez une boutique en ligne. En temps normal, un seul serveur suffit. Mais pendant les soldes ou le Black Friday, le trafic explose et un seul serveur ne peut plus g√©rer toutes les demandes. C'est l√† qu'intervient le scaling :

- **Augmenter la capacit√©** : Plus de pods = plus de capacit√© √† traiter les requ√™tes
- **Am√©liorer la disponibilit√©** : Si un pod tombe en panne, les autres continuent de fonctionner
- **G√©rer les pics de charge** : Adapter les ressources en fonction du besoin
- **Optimiser les co√ªts** : R√©duire le nombre de pods quand la charge diminue

## Concepts de Base

### Qu'est-ce qu'un pod ?

Un **pod** est la plus petite unit√© d√©ployable dans Kubernetes. C'est un conteneur (ou groupe de conteneurs) qui ex√©cute votre application.

### Qu'est-ce qu'un Deployment ?

Un **Deployment** g√®re plusieurs r√©pliques identiques de votre application. C'est lui que nous allons scaler. Quand vous demandez 5 r√©pliques, Kubernetes cr√©e et maintient 5 pods identiques.

### R√©pliques vs Pods

- Une **r√©plique** est une copie de votre application
- Un **pod** est l'instance concr√®te qui ex√©cute cette r√©plique
- Le **Deployment** g√®re automatiquement les pods pour maintenir le nombre de r√©pliques souhait√©

## Le Scaling Manuel avec kubectl

Le scaling manuel signifie que **vous** d√©cidez du nombre de r√©pliques, manuellement, via une commande. C'est vous qui contr√¥lez quand augmenter ou diminuer ce nombre.

### Commande de base

La commande principale pour scaler manuellement est :

```bash
kubectl scale deployment <nom-du-deployment> --replicas=<nombre>
```

**Exemple concret :**

```bash
kubectl scale deployment nginx-web --replicas=5
```

Cette commande demande √† Kubernetes de maintenir exactement 5 r√©pliques du d√©ploiement `nginx-web`.

### V√©rifier l'√©tat actuel

Avant de scaler, il est utile de voir combien de r√©pliques vous avez actuellement :

```bash
kubectl get deployment nginx-web
```

Sortie typique :

```
NAME        READY   UP-TO-DATE   AVAILABLE   AGE
nginx-web   1/1     1            1           10m
```

Ici, `1/1` signifie : 1 r√©plique disponible sur 1 demand√©e.

### Scaler vers le haut (Scale Up)

Pour augmenter le nombre de r√©pliques (par exemple, passer de 1 √† 5) :

```bash
kubectl scale deployment nginx-web --replicas=5
```

Kubernetes va alors :
1. Cr√©er 4 nouveaux pods
2. Les d√©marrer progressivement
3. V√©rifier qu'ils sont en bonne sant√©
4. Les ajouter au service de load balancing

V√©rification apr√®s scaling :

```bash
kubectl get deployment nginx-web
```

Sortie :

```
NAME        READY   UP-TO-DATE   AVAILABLE   AGE
nginx-web   5/5     5            5           12m
```

Vous pouvez aussi voir les pods individuels :

```bash
kubectl get pods -l app=nginx-web
```

Sortie :

```
NAME                         READY   STATUS    RESTARTS   AGE
nginx-web-7d8c9f5b6d-abcde   1/1     Running   0          2m
nginx-web-7d8c9f5b6d-fghij   1/1     Running   0          2m
nginx-web-7d8c9f5b6d-klmno   1/1     Running   0          2m
nginx-web-7d8c9f5b6d-pqrst   1/1     Running   0          12m
nginx-web-7d8c9f5b6d-uvwxy   1/1     Running   0          2m
```

### Scaler vers le bas (Scale Down)

Pour r√©duire le nombre de r√©pliques (par exemple, revenir √† 2) :

```bash
kubectl scale deployment nginx-web --replicas=2
```

Kubernetes va alors :
1. S√©lectionner 3 pods √† terminer
2. Arr√™ter progressivement ces pods
3. Ne conserver que 2 pods actifs

**Important :** Kubernetes choisit intelligemment quels pods arr√™ter (g√©n√©ralement les plus r√©cents ou ceux sur des n≈ìuds moins charg√©s).

### Scaler √† z√©ro

Vous pouvez m√™me scaler √† z√©ro pour arr√™ter compl√®tement une application sans la supprimer :

```bash
kubectl scale deployment nginx-web --replicas=0
```

Cela arr√™te tous les pods mais conserve la configuration du Deployment. Pour red√©marrer, il suffit de scaler √† nouveau :

```bash
kubectl scale deployment nginx-web --replicas=3
```

## Scaler avec des fichiers YAML

Au lieu d'utiliser la commande `kubectl scale`, vous pouvez modifier directement le fichier YAML de votre Deployment.

**Fichier original :**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-web
spec:
  replicas: 1    # Nombre initial de r√©pliques
  selector:
    matchLabels:
      app: nginx-web
  template:
    metadata:
      labels:
        app: nginx-web
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

**Pour scaler √† 5 r√©pliques, modifiez la ligne :**

```yaml
spec:
  replicas: 5    # Chang√© de 1 √† 5
```

Puis appliquez la modification :

```bash
kubectl apply -f nginx-deployment.yaml
```

Cette m√©thode est pr√©f√©rable pour :
- Garder une trace des modifications dans Git
- Reproduire la m√™me configuration ailleurs
- Documenter votre infrastructure

## Surveillance du Scaling

### Observer le scaling en temps r√©el

Pour voir le scaling se produire en direct :

```bash
kubectl get pods -l app=nginx-web --watch
```

L'option `--watch` actualise l'affichage en temps r√©el. Vous verrez les nouveaux pods appara√Ætre avec le statut `ContainerCreating`, puis `Running`.

### V√©rifier les √©v√©nements

Pour voir l'historique des √©v√©nements li√©s au scaling :

```bash
kubectl describe deployment nginx-web
```

Dans la section "Events", vous verrez des lignes comme :

```
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  2m    deployment-controller  Scaled up replica set nginx-web-7d8c9f5b6d to 5
```

### V√©rifier la distribution des pods

Si vous avez un cluster multi-n≈ìuds, v√©rifiez sur quels n≈ìuds les pods sont distribu√©s :

```bash
kubectl get pods -l app=nginx-web -o wide
```

La colonne `NODE` vous montre la distribution.

## Cas d'Usage du Scaling Manuel

### 1. Pic de trafic pr√©vu

Vous savez que votre application va recevoir beaucoup de trafic (promotion, lancement de produit) :

```bash
# Avant l'√©v√©nement
kubectl scale deployment boutique-en-ligne --replicas=20

# Apr√®s l'√©v√©nement
kubectl scale deployment boutique-en-ligne --replicas=3
```

### 2. Maintenance ou debugging

Pour isoler un probl√®me, r√©duisez √† 1 r√©plique :

```bash
kubectl scale deployment app-problematique --replicas=1
```

Cela facilite le d√©bogage en √©vitant d'avoir plusieurs pods qui g√©n√®rent des logs en m√™me temps.

### 3. Tests de charge

Pour tester comment votre application se comporte avec plusieurs instances :

```bash
kubectl scale deployment mon-api --replicas=10
```

### 4. √âconomie de ressources

La nuit ou le week-end, si votre application interne n'est pas utilis√©e :

```bash
kubectl scale deployment app-interne --replicas=0
```

Le lundi matin :

```bash
kubectl scale deployment app-interne --replicas=5
```

## Limitations du Scaling Manuel

Bien que le scaling manuel soit simple et efficace, il pr√©sente des limitations :

### 1. Intervention humaine requise

Vous devez √™tre l√† pour ex√©cuter la commande. Si un pic de trafic arrive √† 3h du matin, votre application peut tomber en panne avant que vous ne r√©agissiez.

### 2. Pas de r√©activit√© automatique

Le scaling manuel ne s'adapte pas automatiquement √† la charge. Vous devez surveiller constamment et ajuster manuellement.

### 3. Risque de sur-provisionnement ou sous-provisionnement

- **Sur-provisionnement** : Trop de r√©pliques = gaspillage de ressources
- **Sous-provisionnement** : Pas assez de r√©pliques = performances d√©grad√©es

### 4. Difficult√© de pr√©diction

Il est difficile de pr√©dire avec pr√©cision le nombre de r√©pliques n√©cessaires pour une charge donn√©e.

## Bonnes Pratiques

### 1. Commencez petit

Ne scalez pas imm√©diatement √† 100 r√©pliques. Augmentez progressivement :
- 1 ‚Üí 3 r√©pliques
- Observez
- 3 ‚Üí 5 r√©pliques
- Observez
- Etc.

### 2. Surveillez les ressources

Avant de scaler, v√©rifiez que votre cluster a suffisamment de ressources :

```bash
kubectl top nodes    # CPU et m√©moire par n≈ìud
kubectl top pods     # CPU et m√©moire par pod
```

**Note :** Cette commande n√©cessite le Metrics Server (nous le verrons dans la section 19.5).

### 3. D√©finissez des requests et limits

Assurez-vous que vos pods ont des `requests` et `limits` de ressources d√©finis :

```yaml
resources:
  requests:
    memory: "128Mi"
    cpu: "100m"
  limits:
    memory: "256Mi"
    cpu: "500m"
```

Cela permet √† Kubernetes de mieux g√©rer le placement des pods.

### 4. Utilisez des nombres impairs pour la haute disponibilit√©

Pour des applications critiques, utilisez 3, 5, 7 r√©pliques plut√¥t que 2, 4, 6. Cela aide √† pr√©venir les situations de "split-brain" et am√©liore la r√©silience.

### 5. Documentez vos d√©cisions

Notez pourquoi vous avez choisi un certain nombre de r√©pliques :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  annotations:
    scaling-notes: "3 r√©pliques suffisent pour la charge normale. Scaler √† 10 pendant les promotions."
spec:
  replicas: 3
  # ...
```

### 6. Testez le scaling en environnement de d√©veloppement

Avant de scaler en production, testez dans votre lab MicroK8s :
- V√©rifiez que l'application fonctionne avec plusieurs r√©pliques
- Observez la consommation de ressources
- Testez le scale up et scale down

### 7. Pr√©parez-vous pour l'autoscaling

Le scaling manuel est un bon point de d√©part, mais envisagez l'autoscaling (HPA) pour automatiser ce processus. Nous verrons cela dans les sections suivantes.

## Diff√©rence entre Scaling et Mise √† Jour

Il est important de ne pas confondre :

- **Scaling** : Changer le nombre de r√©pliques (m√™me version de l'application)
- **Mise √† jour (Rolling Update)** : D√©ployer une nouvelle version de l'application

Exemples :

```bash
# Scaling : changer le nombre de r√©pliques
kubectl scale deployment nginx-web --replicas=5

# Mise √† jour : changer l'image (nouvelle version)
kubectl set image deployment/nginx-web nginx=nginx:1.21
```

## Commandes R√©capitulatives

Voici un r√©sum√© des commandes les plus utiles :

```bash
# Scaler un deployment
kubectl scale deployment <nom> --replicas=<nombre>

# Voir l'√©tat des deployments
kubectl get deployments

# Voir l'√©tat d√©taill√© d'un deployment
kubectl describe deployment <nom>

# Voir les pods d'un deployment
kubectl get pods -l app=<nom-app>

# Observer le scaling en temps r√©el
kubectl get pods --watch

# Voir les √©v√©nements r√©cents
kubectl get events --sort-by=.metadata.creationTimestamp

# Scaler plusieurs deployments
kubectl scale deployment app1 app2 app3 --replicas=3
```

## R√©sum√©

Le **scaling manuel** est la m√©thode la plus simple pour ajuster le nombre de r√©pliques de votre application dans Kubernetes. C'est un excellent point de d√©part pour comprendre comment Kubernetes g√®re la scalabilit√©.

**Points cl√©s √† retenir :**

1. Le scaling change le nombre de pods d'un Deployment
2. La commande de base est `kubectl scale deployment <nom> --replicas=<nombre>`
3. Kubernetes g√®re automatiquement la cr√©ation et la suppression des pods
4. Le scaling manuel n√©cessite une intervention humaine
5. C'est utile pour les pics de charge pr√©visibles et les tests
6. Pour une r√©activit√© automatique, l'autoscaling (HPA) est pr√©f√©rable

Dans les prochaines sections, nous d√©couvrirons comment automatiser ce processus avec le Horizontal Pod Autoscaler (HPA) et le Vertical Pod Autoscaler (VPA), qui ajusteront automatiquement vos r√©pliques en fonction de la charge r√©elle de votre application.

---

**Prochaine section :** 19.2 Horizontal Pod Autoscaler (HPA) - Automatisez le scaling en fonction des m√©triques !

‚è≠Ô∏è [Horizontal Pod Autoscaler (HPA)](/19-scaling-et-autoscaling/02-horizontal-pod-autoscaler-hpa.md)
