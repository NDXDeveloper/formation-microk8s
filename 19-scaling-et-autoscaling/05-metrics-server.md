ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 19.5 Metrics Server

## Introduction au Metrics Server

Le **Metrics Server** est un composant essentiel de Kubernetes qui collecte les mÃ©triques de consommation de ressources (CPU et mÃ©moire) de tous les nÅ“uds et pods de votre cluster. C'est la **fondation** sur laquelle reposent le HPA, le VPA, et la commande `kubectl top`.

### Analogie simple

Imaginez un immeuble de bureaux :

**Sans Metrics Server :**
- Vous savez combien de bureaux vous avez (nÅ“uds)
- Vous savez combien d'employÃ©s travaillent (pods)
- Mais vous ne savez **pas** combien chaque employÃ© consomme d'Ã©lectricitÃ© ou d'espace

**Avec Metrics Server :**
- Un compteur intelligent mesure en temps rÃ©el la consommation de chaque bureau
- Vous pouvez voir qui consomme beaucoup ou peu
- Vous pouvez prendre des dÃ©cisions intelligentes (ajouter/retirer des bureaux)

Le Metrics Server est ce "compteur intelligent" pour votre cluster Kubernetes !

## Pourquoi le Metrics Server est essentiel ?

### Sans Metrics Server

Voici ce qui **ne fonctionne pas** sans Metrics Server :

```bash
# Cette commande Ã©choue
kubectl top nodes
Error from server (ServiceUnavailable): the server is currently unable to handle the request

# Cette commande Ã©choue aussi
kubectl top pods
Error from server (ServiceUnavailable): the server is currently unable to handle the request

# Le HPA ne peut pas fonctionner
kubectl get hpa
NAME        REFERENCE          TARGETS         MINPODS   MAXPODS   REPLICAS
my-app-hpa  Deployment/my-app  <unknown>/50%   1         10        1

# Le VPA n'a pas de donnÃ©es
kubectl describe vpa my-app-vpa
Status:
  Conditions:
    Message: Waiting for metrics...
```

**RÃ©sultat :** Vous ne pouvez pas utiliser l'autoscaling automatique !

### Avec Metrics Server

Une fois le Metrics Server activÃ© :

âœ… `kubectl top nodes` fonctionne (voir l'utilisation CPU/mÃ©moire par nÅ“ud)
âœ… `kubectl top pods` fonctionne (voir l'utilisation CPU/mÃ©moire par pod)
âœ… HPA peut prendre des dÃ©cisions basÃ©es sur les mÃ©triques rÃ©elles
âœ… VPA peut calculer des recommandations prÃ©cises
âœ… Dashboard Kubernetes affiche les graphiques de ressources
âœ… Vous pouvez surveiller votre cluster efficacement

## Architecture du Metrics Server

Le Metrics Server suit une architecture simple :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API Server                       â”‚
â”‚  (kubectl top, HPA, VPA consultent les mÃ©triques)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†‘
                         â”‚ Expose les mÃ©triques via
                         â”‚ l'API Metrics (metrics.k8s.io)
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Metrics Server                     â”‚
â”‚  (Collecte et agrÃ¨ge les mÃ©triques)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†‘
                         â”‚ Interroge toutes les 60s
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Kubelet                         â”‚
â”‚  (Agent sur chaque nÅ“ud, expose les mÃ©triques       â”‚
â”‚   via cAdvisor - Container Advisor)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†‘
                         â”‚ Lit les statistiques
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Conteneurs (Pods)                      â”‚
â”‚  (Runtime collecte CPU/RAM utilisÃ©s)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants expliquÃ©s

**1. Conteneurs et Runtime**
- Chaque conteneur consomme du CPU et de la mÃ©moire
- Le runtime (containerd, CRI-O) collecte ces statistiques via cgroups

**2. Kubelet et cAdvisor**
- Le Kubelet (agent K8s sur chaque nÅ“ud) intÃ¨gre cAdvisor
- cAdvisor collecte les mÃ©triques des conteneurs
- Expose ces mÃ©triques via une API HTTP sur le Kubelet

**3. Metrics Server**
- Interroge tous les Kubelets toutes les **60 secondes** (par dÃ©faut)
- Collecte les mÃ©triques de tous les nÅ“uds et pods
- AgrÃ¨ge et stocke temporairement ces donnÃ©es (en mÃ©moire uniquement)
- Calcule des moyennes mobiles

**4. Metrics API**
- Le Metrics Server expose une API standard (`metrics.k8s.io`)
- Accessible via l'API Server de Kubernetes
- Permet Ã  `kubectl top`, HPA, VPA de consulter les mÃ©triques

### CaractÃ©ristiques importantes

**Stockage en mÃ©moire uniquement :**
- Les mÃ©triques ne sont **pas** persistÃ©es sur disque
- ConservÃ©es pour une courte durÃ©e (~5-15 minutes)
- Suffisant pour l'autoscaling, mais pas pour l'historique long terme

**FrÃ©quence de collecte :**
- Collecte toutes les 60 secondes par dÃ©faut
- Les mÃ©triques ont donc un lÃ©ger retard (~1 minute)
- Suffisant pour l'autoscaling (pas besoin de temps rÃ©el strict)

**MÃ©triques limitÃ©es :**
- Uniquement CPU et mÃ©moire
- Pas de mÃ©triques rÃ©seau, disque, ou custom
- Pour des mÃ©triques avancÃ©es, utilisez Prometheus (section 12)

## Installation sur MicroK8s

Bonne nouvelle ! Sur MicroK8s, l'installation du Metrics Server est **extrÃªmement simple** grÃ¢ce Ã  l'addon intÃ©grÃ©.

### MÃ©thode simple : Addon MicroK8s

**Ã‰tape 1 : Activer l'addon**

```bash
microk8s enable metrics-server
```

Sortie :
```
Infer repository core for addon metrics-server
Enabling Metrics-Server
serviceaccount/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
service/metrics-server created
deployment.apps/metrics-server created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
Metrics-Server is enabled
```

**C'est tout !** Le Metrics Server est installÃ© et fonctionnel.

**Ã‰tape 2 : VÃ©rifier l'installation**

```bash
kubectl get pods -n kube-system | grep metrics-server
```

Sortie attendue :
```
metrics-server-xxxxxxxxx-xxxxx   1/1     Running   0          1m
```

Le pod doit Ãªtre en statut `Running`.

**Ã‰tape 3 : VÃ©rifier l'API Metrics**

```bash
kubectl get apiservices | grep metrics
```

Sortie :
```
v1beta1.metrics.k8s.io   kube-system/metrics-server   True   2m
```

Le statut doit Ãªtre `True`.

### Attendre la collecte des premiÃ¨res mÃ©triques

Le Metrics Server a besoin de quelques minutes pour collecter les premiÃ¨res donnÃ©es.

**Attendez 2-3 minutes**, puis testez :

```bash
kubectl top nodes
```

Si vous obtenez une erreur, attendez encore 1-2 minutes. Si l'erreur persiste aprÃ¨s 5 minutes, voir la section "DÃ©pannage".

## Utilisation du Metrics Server

### Commande kubectl top nodes

Affiche l'utilisation des ressources **par nÅ“ud** :

```bash
kubectl top nodes
```

Sortie exemple :
```
NAME          CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
microk8s-vm   450m         22%    2048Mi          51%
```

**InterprÃ©tation :**

- **CPU(cores)** : 450m = 450 millicores = 0.45 CPU
- **CPU%** : 22% de la capacitÃ© totale du nÅ“ud
- **MEMORY(bytes)** : 2048Mi = ~2 GB de RAM utilisÃ©e
- **MEMORY%** : 51% de la mÃ©moire totale du nÅ“ud

### Commande kubectl top pods

Affiche l'utilisation des ressources **par pod** :

```bash
kubectl top pods
```

Sortie exemple :
```
NAME                        CPU(cores)   MEMORY(bytes)
nginx-web-7d8c9f5b6d-abcd   5m           10Mi
nginx-web-7d8c9f5b6d-efgh   3m           8Mi
postgres-0                  25m          150Mi
```

**InterprÃ©tation :**

- **nginx-web-abcd** : Utilise 5 millicores CPU et 10 Mi de RAM
- **postgres-0** : Utilise 25 millicores CPU et 150 Mi de RAM

### Options utiles de kubectl top

**Voir tous les namespaces :**
```bash
kubectl top pods --all-namespaces
```

**Trier par CPU :**
```bash
kubectl top pods --sort-by=cpu
```

Sortie (pods triÃ©s du plus consommateur au moins) :
```
NAME                        CPU(cores)   MEMORY(bytes)
postgres-0                  25m          150Mi
nginx-web-7d8c9f5b6d-abcd   5m           10Mi
nginx-web-7d8c9f5b6d-efgh   3m           8Mi
```

**Trier par mÃ©moire :**
```bash
kubectl top pods --sort-by=memory
```

**Filtrer par label :**
```bash
kubectl top pods -l app=nginx
```

**Voir les conteneurs individuellement :**
```bash
kubectl top pods --containers
```

Sortie :
```
POD                         NAME       CPU(cores)   MEMORY(bytes)
nginx-web-7d8c9f5b6d-abcd   nginx      5m           10Mi
nginx-web-7d8c9f5b6d-abcd   sidecar    2m           5Mi
```

Utile quand un pod a plusieurs conteneurs.

### Surveiller en temps rÃ©el

**Commande avec rafraÃ®chissement automatique :**

```bash
watch -n 2 kubectl top pods
```

Cela rafraÃ®chit l'affichage toutes les 2 secondes.

**Alternative avec kubectl :**

```bash
kubectl top pods --watch
```

Malheureusement, `--watch` n'existe pas pour `kubectl top`, utilisez donc `watch`.

## Utilisation par le HPA

Le HPA interroge le Metrics Server pour obtenir les mÃ©triques de CPU et mÃ©moire.

### Exemple : HPA basÃ© sur CPU

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-web
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
```

**Flux de dÃ©cision du HPA :**

1. HPA interroge le Metrics Server : "Quelle est l'utilisation CPU moyenne des pods nginx-web ?"
2. Metrics Server rÃ©pond : "Utilisation moyenne : 75%"
3. HPA calcule : "Cible = 50%, Actuel = 75%, donc scale up nÃ©cessaire"
4. HPA augmente le nombre de rÃ©pliques

**Visualiser ce qui se passe :**

```bash
kubectl get hpa nginx-hpa
```

Sortie :
```
NAME        REFERENCE              TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
nginx-hpa   Deployment/nginx-web   75%/50%   1         10        3          5m
```

**TARGETS** montre `75%/50%` :
- **75%** : Utilisation actuelle (donnÃ©es du Metrics Server)
- **50%** : Cible configurÃ©e

### Exemple : HPA basÃ© sur mÃ©moire

```yaml
metrics:
- type: Resource
  resource:
    name: memory
    target:
      type: Utilization
      averageUtilization: 70
```

Le HPA interroge le Metrics Server pour l'utilisation mÃ©moire.

### Si Metrics Server est absent

Si vous crÃ©ez un HPA sans Metrics Server :

```bash
kubectl get hpa
```

Sortie :
```
NAME        REFERENCE              TARGETS         MINPODS   MAXPODS   REPLICAS
nginx-hpa   Deployment/nginx-web   <unknown>/50%   1         10        1
```

**TARGETS** affiche `<unknown>/50%` car le HPA ne peut pas obtenir les mÃ©triques.

Le HPA ne peut pas fonctionner et ne scale pas !

## Utilisation par le VPA

Le VPA utilise aussi le Metrics Server, mais de maniÃ¨re diffÃ©rente.

### Collecte d'historique

Le VPA Recommender collecte les mÃ©triques en continu pour construire un historique :

```
Jour 1 : Pod utilise 100m CPU, 200Mi RAM
Jour 2 : Pod utilise 150m CPU, 250Mi RAM
Jour 3 : Pod utilise 120m CPU, 220Mi RAM
...
Jour 8 : Moyenne calculÃ©e : ~130m CPU, ~230Mi RAM
```

Le VPA recommande alors des `requests` basÃ©s sur ces patterns.

### Recommandations basÃ©es sur les percentiles

Le VPA ne prend pas simplement la moyenne, mais utilise des **percentiles** :

- **Lower Bound** : BasÃ© sur le minimum observÃ© (percentile 5-10%)
- **Target** : BasÃ© sur un percentile Ã©levÃ© (90-95%)
- **Upper Bound** : BasÃ© sur le maximum observÃ© (percentile 99%)

**Pourquoi les percentiles ?**

Imaginez ces mesures :
```
Utilisation CPU : 100m, 120m, 110m, 800m, 115m, 105m, 125m
```

- **Moyenne** : ~200m (faussÃ©e par le pic de 800m)
- **Percentile 95%** : ~125m (ignore les valeurs extrÃªmes)

Le percentile 95% donne une meilleure recommandation !

## MÃ©triques disponibles

Le Metrics Server fournit **uniquement** deux types de mÃ©triques :

### 1. MÃ©triques CPU

**UnitÃ©s :**
- **Millicores (m)** : 1000m = 1 CPU core
- Exemples : 100m, 500m, 1500m

**Ce qui est mesurÃ© :**
- Temps CPU rÃ©el consommÃ© par les conteneurs
- AgrÃ©gÃ© sur la fenÃªtre de collecte (derniÃ¨re minute)

**Calcul du pourcentage :**
```
% CPU = (CPU utilisÃ© / CPU request) Ã— 100
```

Exemple :
- Request : 200m
- Utilisation : 150m
- Pourcentage : (150/200) Ã— 100 = 75%

### 2. MÃ©triques MÃ©moire

**UnitÃ©s :**
- **Bytes** : octets
- **Ki, Mi, Gi** : Kibibytes, Mebibytes, Gibibytes
- Exemples : 128Mi, 1Gi, 500Mi

**Ce qui est mesurÃ© :**
- MÃ©moire rÃ©sidente (RSS - Resident Set Size)
- MÃ©moire rÃ©ellement utilisÃ©e par le processus
- **Ne compte pas** le cache du systÃ¨me d'exploitation

**Calcul du pourcentage :**
```
% MÃ©moire = (MÃ©moire utilisÃ©e / MÃ©moire request) Ã— 100
```

Exemple :
- Request : 256Mi
- Utilisation : 200Mi
- Pourcentage : (200/256) Ã— 100 = 78%

### Ce que le Metrics Server ne fournit PAS

âŒ MÃ©triques rÃ©seau (bande passante, paquets)
âŒ MÃ©triques disque (IOPS, latence, espace)
âŒ MÃ©triques custom (requÃªtes/sec, latence HTTP, etc.)
âŒ Historique long terme (pas de persistence)
âŒ MÃ©triques applicatives (threads, connexions DB, etc.)

**Pour ces mÃ©triques, utilisez :**
- **Prometheus** (voir section 12) : MÃ©triques avancÃ©es et historique
- **Custom Metrics API** : Pour le HPA avec mÃ©triques custom (voir section 19.6)

## Comprendre les requests et limits

Le Metrics Server mesure l'utilisation rÃ©elle, mais le HPA calcule les pourcentages basÃ©s sur les **requests**.

### Importance des requests

**Sans requests dÃ©finis :**

```yaml
containers:
- name: nginx
  image: nginx:latest
  # Pas de resources !
```

Le HPA ne peut pas calculer de pourcentage :
```
Utilisation actuelle : 100m
Request : non dÃ©fini
Pourcentage : impossible Ã  calculer !
```

**Avec requests dÃ©finis :**

```yaml
containers:
- name: nginx
  image: nginx:latest
  resources:
    requests:
      cpu: "200m"
      memory: "128Mi"
```

Le HPA peut calculer :
```
Utilisation actuelle : 100m
Request : 200m
Pourcentage : 50%
```

### Recommandation importante

**Toujours dÃ©finir les requests** pour tous les conteneurs si vous utilisez :
- HPA
- VPA
- Scheduling basÃ© sur les ressources

```yaml
resources:
  requests:
    cpu: "100m"      # Minimum garanti
    memory: "128Mi"
  limits:
    cpu: "500m"      # Maximum autorisÃ©
    memory: "512Mi"
```

## Configuration avancÃ©e du Metrics Server

### ParamÃ¨tres de configuration

Sur MicroK8s, le Metrics Server est dÃ©jÃ  bien configurÃ©, mais vous pouvez modifier certains paramÃ¨tres si nÃ©cessaire.

**Voir la configuration actuelle :**

```bash
kubectl get deployment metrics-server -n kube-system -o yaml
```

**ParamÃ¨tres intÃ©ressants :**

```yaml
spec:
  containers:
  - name: metrics-server
    args:
    - --cert-dir=/tmp
    - --secure-port=4443
    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
    - --kubelet-use-node-status-port
    - --metric-resolution=60s        # FrÃ©quence de collecte
    - --kubelet-insecure-tls         # Pour environnements de dev
```

### FrÃ©quence de collecte

**Par dÃ©faut :** 60 secondes

Pour collecter plus frÃ©quemment (utilise plus de ressources) :

```yaml
args:
- --metric-resolution=15s    # Collecte toutes les 15 secondes
```

**Note :** Rarement nÃ©cessaire. 60 secondes est suffisant pour l'autoscaling.

### Ressources du Metrics Server

Le Metrics Server lui-mÃªme consomme des ressources :

```yaml
resources:
  requests:
    cpu: 100m
    memory: 200Mi
  limits:
    cpu: 100m
    memory: 200Mi
```

**Impact typique :**
- CPU : ~50-100m pour un cluster de 10-20 nÅ“uds
- MÃ©moire : ~100-300Mi selon le nombre de pods

Sur un petit cluster MicroK8s (1-3 nÅ“uds, <50 pods), l'impact est nÃ©gligeable.

## Comparaison : Metrics Server vs Prometheus

Beaucoup de dÃ©butants confondent Metrics Server et Prometheus. Voici les diffÃ©rences :

| Aspect | Metrics Server | Prometheus |
|--------|---------------|------------|
| **Objectif** | Autoscaling et `kubectl top` | Monitoring complet et alerting |
| **MÃ©triques** | CPU et mÃ©moire uniquement | Toutes mÃ©triques possibles |
| **Stockage** | En mÃ©moire (~15 min) | Persistant (jours/mois/annÃ©es) |
| **Historique** | Non | Oui |
| **FrÃ©quence** | 60 secondes | Configurable (15s typique) |
| **Overhead** | TrÃ¨s faible | Moyen |
| **Custom metrics** | Non | Oui |
| **Visualisation** | `kubectl top` uniquement | Grafana dashboards |
| **Alerting** | Non | Oui (Alertmanager) |
| **Requis pour HPA** | Oui (pour CPU/mÃ©moire) | Non (sauf mÃ©triques custom) |
| **ComplexitÃ©** | Simple | Moyenne-Ã©levÃ©e |

**RÃ¨gle simple :**

- **Metrics Server** : NÃ©cessaire pour l'autoscaling basique
- **Prometheus** : Optionnel mais fortement recommandÃ© pour le monitoring complet

**Ils sont complÃ©mentaires, pas exclusifs !**

Dans un cluster de production, vous aurez typiquement **les deux** :
- Metrics Server pour HPA/VPA
- Prometheus pour monitoring, dashboards, et alertes

## DÃ©pannage

### ProblÃ¨me 1 : Metrics Server ne dÃ©marre pas

**SymptÃ´me :**

```bash
kubectl get pods -n kube-system | grep metrics-server
metrics-server-xxx   0/1   CrashLoopBackOff   5   5m
```

**Cause possible :** ProblÃ¨me de certificats TLS

**Solution :**

VÃ©rifier les logs :
```bash
kubectl logs -n kube-system deployment/metrics-server
```

Si vous voyez des erreurs de certificat, le Metrics Server sur MicroK8s inclut dÃ©jÃ  `--kubelet-insecure-tls` donc cela devrait fonctionner. Si problÃ¨me persiste :

```bash
microk8s disable metrics-server
microk8s enable metrics-server
```

### ProblÃ¨me 2 : kubectl top retourne "unavailable"

**SymptÃ´me :**

```bash
kubectl top nodes
Error from server (ServiceUnavailable): the server is currently unable to handle the request
```

**Solutions :**

**1. VÃ©rifier que le Metrics Server tourne :**
```bash
kubectl get pods -n kube-system | grep metrics-server
```

Le pod doit Ãªtre `Running`.

**2. VÃ©rifier l'API Service :**
```bash
kubectl get apiservices | grep metrics
```

Doit afficher `True`.

**3. Attendre 2-3 minutes :**
Le Metrics Server a besoin de collecter les premiÃ¨res mÃ©triques.

**4. VÃ©rifier la connectivitÃ© au Kubelet :**
```bash
kubectl logs -n kube-system deployment/metrics-server
```

Cherchez des erreurs de connexion au Kubelet.

### ProblÃ¨me 3 : MÃ©triques toujours Ã  0

**SymptÃ´me :**

```bash
kubectl top pods
NAME        CPU(cores)   MEMORY(bytes)
my-pod      0m           0Mi
```

**Cause :** Les conteneurs ne consomment vraiment rien, ou le pod vient juste de dÃ©marrer.

**Solutions :**

- Attendre 1-2 minutes pour que les mÃ©triques s'accumulent
- VÃ©rifier que le pod fait effectivement quelque chose
- Relancer la collecte : `kubectl delete pod -n kube-system -l k8s-app=metrics-server`

### ProblÃ¨me 4 : HPA affiche "unknown"

**SymptÃ´me :**

```bash
kubectl get hpa
NAME     REFERENCE        TARGETS         MINPODS   MAXPODS   REPLICAS
my-hpa   Deployment/app   <unknown>/50%   1         10        1
```

**Causes possibles :**

**1. Pas de requests dÃ©finis dans les pods :**

VÃ©rifiez :
```bash
kubectl get deployment app -o yaml | grep -A 5 resources
```

Si absent, ajoutez :
```yaml
resources:
  requests:
    cpu: "100m"
    memory: "128Mi"
```

**2. Pods pas encore prÃªts :**

```bash
kubectl get pods -l app=app
```

Tous les pods doivent Ãªtre `Running` et `Ready`.

**3. Metrics Server pas encore prÃªt :**

Attendez 2-3 minutes aprÃ¨s avoir activÃ© le Metrics Server.

### ProblÃ¨me 5 : MÃ©triques incohÃ©rentes

**SymptÃ´me :**

Les mÃ©triques fluctuent Ã©normÃ©ment ou semblent incorrectes.

**Explications :**

**1. Les mÃ©triques sont des moyennes mobiles :**
L'utilisation peut varier beaucoup d'une seconde Ã  l'autre. Le Metrics Server lisse ces variations.

**2. DÃ©lai de collecte :**
Les mÃ©triques ont un retard de ~60 secondes. Ce que vous voyez n'est pas instantanÃ©.

**3. Bursts temporaires :**
Un pic de 2 secondes toutes les minutes ne sera pas trÃ¨s visible dans les moyennes.

**Solution :**

Pour des mÃ©triques plus dÃ©taillÃ©es, utilisez Prometheus qui collecte toutes les 15 secondes et conserve l'historique.

## Monitoring du Metrics Server

### SantÃ© du Metrics Server

```bash
# VÃ©rifier le statut
kubectl get pods -n kube-system -l k8s-app=metrics-server

# Voir les logs
kubectl logs -n kube-system -l k8s-app=metrics-server -f

# VÃ©rifier l'API
kubectl get apiservices v1beta1.metrics.k8s.io
```

### MÃ©triques du Metrics Server lui-mÃªme

Le Metrics Server expose ses propres mÃ©triques (pour Prometheus) :

```bash
kubectl port-forward -n kube-system service/metrics-server 4443:443
```

Puis :
```bash
curl -k https://localhost:4443/metrics
```

MÃ©triques intÃ©ressantes :
- `metrics_server_manager_tick_duration_seconds` : DurÃ©e de collecte
- `metrics_server_scraper_duration_seconds` : DurÃ©e d'interrogation des Kubelets
- `metrics_server_storage_points` : Nombre de points de donnÃ©es stockÃ©s

### Alertes recommandÃ©es

Si vous utilisez Prometheus, configurez des alertes pour :

```yaml
- alert: MetricsServerDown
  expr: up{job="metrics-server"} == 0
  for: 5m
  annotations:
    summary: "Metrics Server is down"

- alert: MetricsServerHighLatency
  expr: metrics_server_manager_tick_duration_seconds > 10
  for: 10m
  annotations:
    summary: "Metrics Server taking too long to collect metrics"
```

## Bonnes pratiques

### 1. Activer immÃ©diatement le Metrics Server

DÃ¨s que vous crÃ©ez un cluster MicroK8s :

```bash
microk8s enable metrics-server
```

C'est un prÃ©requis pour presque tout ce qui concerne l'autoscaling.

### 2. Toujours dÃ©finir les requests

Pour **tous** vos Deployments :

```yaml
resources:
  requests:
    cpu: "100m"
    memory: "128Mi"
  limits:
    cpu: "500m"
    memory: "512Mi"
```

Sans cela, le HPA ne peut pas fonctionner correctement.

### 3. Ne pas confondre Metrics Server et Prometheus

- **Metrics Server** : Pour l'autoscaling (requis)
- **Prometheus** : Pour le monitoring complet (fortement recommandÃ©)

Activez les deux dans un cluster de production.

### 4. Comprendre les limites

Le Metrics Server fournit :
- âœ… MÃ©triques actuelles (derniÃ¨re minute)
- âœ… CPU et mÃ©moire uniquement
- âŒ Pas d'historique
- âŒ Pas de mÃ©triques custom

Pour plus, ajoutez Prometheus.

### 5. VÃ©rifier rÃ©guliÃ¨rement

Incluez dans vos checks de santÃ© rÃ©guliers :

```bash
#!/bin/bash
# healthcheck.sh

echo "Checking Metrics Server..."
kubectl get pods -n kube-system -l k8s-app=metrics-server | grep Running
if [ $? -eq 0 ]; then
  echo "âœ“ Metrics Server is running"
else
  echo "âœ— Metrics Server is not running!"
  exit 1
fi

echo "Checking metrics API..."
kubectl top nodes > /dev/null 2>&1
if [ $? -eq 0 ]; then
  echo "âœ“ Metrics API is working"
else
  echo "âœ— Metrics API is not working!"
  exit 1
fi
```

### 6. Ne pas surcharger avec des top frÃ©quents

La commande `kubectl top` interroge le Metrics Server. Si vous l'appelez trop souvent (ex: toutes les secondes dans un script), vous pouvez surcharger le Metrics Server.

**Bon :**
```bash
watch -n 5 kubectl top pods    # Toutes les 5 secondes
```

**Mauvais :**
```bash
while true; do kubectl top pods; done    # Trop frÃ©quent !
```

### 7. Surveiller l'utilisation du Metrics Server

Sur de gros clusters (100+ nÅ“uds, 1000+ pods), le Metrics Server peut consommer plus de ressources.

Surveillez :
```bash
kubectl top pods -n kube-system -l k8s-app=metrics-server
```

Si nÃ©cessaire, augmentez les ressources :

```bash
kubectl edit deployment metrics-server -n kube-system
```

Modifiez :
```yaml
resources:
  requests:
    cpu: 200m        # AugmentÃ© de 100m
    memory: 400Mi    # AugmentÃ© de 200Mi
```

## RÃ©sumÃ©

Le **Metrics Server** est un composant fondamental pour l'autoscaling dans Kubernetes.

**Points clÃ©s :**

1. Collecte les mÃ©triques CPU et mÃ©moire de tous les nÅ“uds et pods
2. NÃ©cessaire pour que le HPA et le VPA fonctionnent
3. Permet d'utiliser `kubectl top nodes` et `kubectl top pods`
4. TrÃ¨s simple Ã  activer sur MicroK8s : `microk8s enable metrics-server`
5. Collecte les mÃ©triques toutes les 60 secondes par dÃ©faut
6. Stocke les donnÃ©es en mÃ©moire uniquement (pas d'historique long terme)
7. Fournit uniquement CPU et mÃ©moire (pas de mÃ©triques custom ou rÃ©seau)

**Relation avec les autres outils :**

```
Metrics Server â†’ Fournit les mÃ©triques de base
      â†“
HPA â†’ Utilise ces mÃ©triques pour scaler horizontalement
VPA â†’ Utilise ces mÃ©triques pour recommander des ressources
kubectl top â†’ Affiche ces mÃ©triques pour l'utilisateur
```

**Ã€ retenir :**

âœ… Activez toujours le Metrics Server (c'est gratuit et sans impact)
âœ… DÃ©finissez toujours des `requests` pour vos conteneurs
âœ… Utilisez `kubectl top` pour surveiller votre cluster
âœ… Combinez avec Prometheus pour un monitoring complet
âœ… C'est la fondation de tout autoscaling efficace

Sans Metrics Server, vous Ãªtes "aveugle" sur les ressources rÃ©elles consommÃ©es par votre cluster. C'est comme conduire une voiture sans tableau de bord : vous savez que le moteur tourne, mais vous ne savez ni la vitesse, ni le niveau d'essence, ni la tempÃ©rature !

---

**Prochaine section :** 19.6 Custom Metrics - Utiliser des mÃ©triques personnalisÃ©es pour un autoscaling encore plus intelligent !

â­ï¸ [Custom metrics](/19-scaling-et-autoscaling/06-custom-metrics.md)
