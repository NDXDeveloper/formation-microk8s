üîù Retour au [Sommaire](/SOMMAIRE.md)

# 9.1 Concepts de Load Balancing

## Introduction

Le **load balancing** (ou r√©partition de charge en fran√ßais) est un concept fondamental dans le monde des infrastructures informatiques modernes. Dans le contexte de Kubernetes et MicroK8s, comprendre ce concept est essentiel pour exposer vos applications de mani√®re fiable et performante.

## Qu'est-ce que le Load Balancing ?

Imaginez un restaurant tr√®s populaire. Si tous les clients devaient √™tre servis par un seul serveur, le service serait lent et chaotique. La solution ? Avoir plusieurs serveurs et un ma√Ætre d'h√¥tel qui r√©partit √©quitablement les clients entre eux. Le load balancing fonctionne exactement sur ce principe pour vos applications.

Un **load balancer** est un composant qui :
- Re√ßoit les requ√™tes entrantes (trafic r√©seau)
- Les distribue intelligemment entre plusieurs instances de votre application (les Pods dans Kubernetes)
- S'assure que chaque instance re√ßoit une charge de travail √©quilibr√©e
- Redirige automatiquement le trafic en cas de d√©faillance d'une instance

## Pourquoi le Load Balancing est-il N√©cessaire ?

### 1. **Haute Disponibilit√©**

Si vous n'avez qu'une seule instance de votre application et qu'elle tombe en panne, votre service devient indisponible. Avec le load balancing et plusieurs instances :
- Si une instance √©choue, les autres continuent de fonctionner
- Le load balancer d√©tecte l'instance d√©faillante et cesse de lui envoyer du trafic
- Vos utilisateurs ne remarquent m√™me pas le probl√®me

### 2. **Performance et Scalabilit√©**

Une seule instance d'application a des limites (CPU, m√©moire, capacit√© de traitement). Le load balancing permet de :
- R√©partir les requ√™tes entre plusieurs instances
- Augmenter la capacit√© globale en ajoutant simplement plus d'instances
- √âviter la surcharge d'une seule instance
- Am√©liorer les temps de r√©ponse pour vos utilisateurs

### 3. **Maintenance sans Interruption**

Avec le load balancing, vous pouvez :
- Mettre √† jour vos applications progressivement (rolling updates)
- Retirer temporairement des instances pour maintenance
- Maintenir le service actif pendant les op√©rations de maintenance

## Types de Load Balancing

### Load Balancing au Niveau 4 (Transport)

Le load balancer travaille au niveau TCP/UDP (couche transport du mod√®le OSI) :
- **Avantages** : Tr√®s rapide, faible latence, simple
- **Limitations** : Ne peut pas prendre de d√©cisions bas√©es sur le contenu HTTP
- **Cas d'usage** : Applications non-HTTP, bases de donn√©es, trafic g√©n√©rique

### Load Balancing au Niveau 7 (Application)

Le load balancer comprend le protocole HTTP/HTTPS :
- **Avantages** : Routage intelligent bas√© sur l'URL, les headers, les cookies
- **Capacit√©s** : Terminaison SSL/TLS, r√©√©criture d'URL, routage par chemin
- **Cas d'usage** : Applications web, APIs REST, microservices

## Algorithmes de R√©partition de Charge

Un load balancer utilise diff√©rents algorithmes pour d√©cider quelle instance doit recevoir la prochaine requ√™te :

### 1. **Round Robin (Tour √† tour)**
Les requ√™tes sont distribu√©es s√©quentiellement √† chaque instance, l'une apr√®s l'autre.

```
Requ√™te 1 ‚Üí Instance A
Requ√™te 2 ‚Üí Instance B
Requ√™te 3 ‚Üí Instance C
Requ√™te 4 ‚Üí Instance A (on recommence)
```

**Avantage** : Simple et √©quitable
**Inconv√©nient** : Ne prend pas en compte la charge actuelle de chaque instance

### 2. **Least Connections (Moins de connexions)**
Les requ√™tes sont envoy√©es √† l'instance ayant le moins de connexions actives.

**Avantage** : Meilleure r√©partition si les requ√™tes ont des dur√©es variables
**Cas d'usage** : Applications avec des sessions longues

### 3. **IP Hash**
La d√©cision est bas√©e sur l'adresse IP du client (via une fonction de hachage).

**Avantage** : Un m√™me client arrive toujours sur la m√™me instance (affinit√© de session)
**Cas d'usage** : Applications avec √©tat (stateful) n√©cessitant la persistence de session

### 4. **Weighted (Pond√©r√©)**
Chaque instance re√ßoit un poids, et les requ√™tes sont distribu√©es proportionnellement.

**Cas d'usage** : Quand certaines instances sont plus puissantes que d'autres

## Load Balancing dans Kubernetes

Dans Kubernetes, le load balancing est int√©gr√© de plusieurs fa√ßons :

### Services de Type ClusterIP (Par d√©faut)

- Load balancing **interne** uniquement
- Accessible uniquement depuis l'int√©rieur du cluster
- Kubernetes distribue automatiquement le trafic entre les Pods correspondants
- Utilise kube-proxy pour la r√©partition

### Services de Type NodePort

- Expose un port sur chaque n≈ìud du cluster
- Kubernetes fait du load balancing entre les Pods
- Accessible de l'ext√©rieur via `<NodeIP>:<NodePort>`
- Limitation : N√©cessite de conna√Ætre l'IP des n≈ìuds et utilise des ports hauts (30000-32767)

### Services de Type LoadBalancer

- **C'est ici que MetalLB entre en jeu !**
- Fournit une IP externe unique pour acc√©der au service
- Le load balancer externe distribue le trafic vers les n≈ìuds
- Kubernetes distribue ensuite le trafic vers les Pods

## Le Probl√®me que MetalLB R√©sout

Kubernetes a √©t√© con√ßu principalement pour les environnements cloud (AWS, GCP, Azure). Dans ces environnements, quand vous cr√©ez un Service de type `LoadBalancer`, le cloud provider provisionne automatiquement un load balancer (payant) avec une IP publique.

**Probl√®me** : Dans un environnement bare-metal (serveurs physiques) ou dans un lab personnel, vous n'avez pas ce fournisseur cloud automatique.

**Solution** : MetalLB est une impl√©mentation de load balancer pour Kubernetes en bare-metal. Il permet d'assigner des IP externes √† vos Services de type LoadBalancer, m√™me sans cloud provider.

## Flux de Trafic avec Load Balancing

Voici comment le trafic circule avec un load balancer :

```
1. Client (Utilisateur)
   ‚Üì
2. Load Balancer (IP externe unique)
   ‚Üì
3. Distribution vers les N≈ìuds du cluster
   ‚Üì
4. Service Kubernetes (r√©partition vers les Pods)
   ‚Üì
5. Pods de l'application (instances multiples)
```

### Exemple Concret

Imaginez une application web d√©ploy√©e avec 3 replicas :

```
Utilisateur ‚Üí http://mon-app.com (IP: 192.168.1.100)
                ‚Üì
         Load Balancer (MetalLB)
        /        |        \
       /         |         \
   Pod 1      Pod 2      Pod 3
```

Le load balancer :
1. Re√ßoit toutes les requ√™tes sur l'IP 192.168.1.100
2. V√©rifie quels Pods sont en bonne sant√© (health checks)
3. Distribue les requ√™tes entre les Pods disponibles
4. Si Pod 2 tombe, il redirige tout le trafic vers Pod 1 et Pod 3

## Health Checks (V√©rifications de Sant√©)

Un load balancer intelligent ne se contente pas de distribuer le trafic, il v√©rifie aussi que les instances sont en bonne sant√© :

### Liveness Probes (Sondes de Vivacit√©)
- "L'application est-elle vivante ?"
- Si la sonde √©choue, Kubernetes red√©marre le Pod
- D√©tecte les applications bloqu√©es ou crash√©es

### Readiness Probes (Sondes de Disponibilit√©)
- "L'application est-elle pr√™te √† recevoir du trafic ?"
- Si la sonde √©choue, le load balancer arr√™te d'envoyer du trafic √† ce Pod
- Ne red√©marre pas le Pod, attend juste qu'il soit pr√™t

**Exemple** : Une application qui d√©marre peut prendre 30 secondes pour se connecter √† une base de donn√©es. Pendant ce temps, elle est "alive" mais pas "ready".

## B√©n√©fices du Load Balancing dans MicroK8s

Pour votre lab personnel ou environnement de d√©veloppement, le load balancing avec MetalLB vous apporte :

1. **Une exp√©rience similaire au cloud** : Vous pouvez cr√©er des Services LoadBalancer comme sur AWS/GCP
2. **Des IP stables et accessibles** : Acc√©dez √† vos applications via des IP d√©di√©es
3. **Une pr√©paration pour la production** : Les comp√©tences apprises sont directement transf√©rables
4. **Gestion simplifi√©e** : Plus besoin de jongler avec des NodePorts ou des configurations complexes
5. **Haute disponibilit√© locale** : Testez et apprenez les concepts de HA sur votre propre infrastructure

## Limitations et Consid√©rations

### Limitations du Load Balancing L4

- Pas de routage bas√© sur l'URL (pas de `/api` vs `/web`)
- Pas de terminaison SSL/TLS au niveau du load balancer
- Pour ces fonctionnalit√©s avanc√©es, vous utiliserez un **Ingress Controller** (voir chapitre 10)

### Diff√©rence Load Balancer vs Ingress

Il est important de comprendre la diff√©rence :

**Load Balancer (MetalLB)** :
- Une IP par Service
- Load balancing niveau 4 (TCP/UDP)
- Simple mais peut devenir co√ªteux (une IP par service)

**Ingress** :
- Une seule IP pour plusieurs services
- Routage niveau 7 (HTTP/HTTPS)
- Routage intelligent bas√© sur les noms de domaine et chemins
- Terminaison SSL/TLS centralis√©e

**En pratique** : On utilise souvent les deux ensemble :
- MetalLB fournit l'IP externe √† l'Ingress Controller
- L'Ingress Controller fait ensuite le routage intelligent vers les diff√©rents Services

## R√©sum√©

Le load balancing est un m√©canisme essentiel pour :
- Distribuer le trafic entre plusieurs instances d'une application
- Assurer la haute disponibilit√© et la performance
- Permettre la scalabilit√© horizontale (ajouter plus d'instances)
- G√©rer automatiquement les pannes

Dans MicroK8s, MetalLB permet de b√©n√©ficier de Services de type LoadBalancer m√™me sans cloud provider, en assignant des IP du r√©seau local √† vos Services. C'est une brique fondamentale pour exposer vos applications de mani√®re professionnelle.

Dans les sections suivantes, nous verrons comment installer et configurer MetalLB concr√®tement dans votre cluster MicroK8s.

---

**Prochaine √©tape** : Installation de MetalLB (Section 9.2)

‚è≠Ô∏è [Installation de MetalLB (microk8s enable metallb)](/09-load-balancing-avec-metallb/02-installation-de-metallb.md)
