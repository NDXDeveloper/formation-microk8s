üîù Retour au [Sommaire](/SOMMAIRE.md)

# 4.2 D√©ploiement d'une Application Web Simple

## Introduction

Maintenant que vous comprenez l'anatomie d'un manifeste YAML, il est temps de passer √† la pratique ! Dans cette section, nous allons d√©ployer notre premi√®re application web sur MicroK8s. Nous utiliserons **Nginx**, un serveur web l√©ger et populaire, comme exemple.

Nous allons d√©couvrir deux approches :
1. **Le d√©ploiement d'un Pod simple** (pour comprendre les bases)
2. **Le d√©ploiement avec un Deployment** (la m√©thode recommand√©e en production)

## Pourquoi Nginx ?

Nginx est un excellent choix pour d√©buter car :
- ‚úÖ Image Docker l√©g√®re et fiable
- ‚úÖ D√©marrage rapide
- ‚úÖ Page web par d√©faut visible imm√©diatement
- ‚úÖ Largement utilis√© en production
- ‚úÖ Parfait pour comprendre les concepts

## M√©thode 1 : D√©ployer un Pod Simple

### Comprendre le Pod

Un **Pod** est l'unit√© de d√©ploiement la plus petite dans Kubernetes. Il contient un ou plusieurs conteneurs qui partagent :
- La m√™me adresse IP
- Le m√™me espace de stockage
- Le m√™me namespace r√©seau

**Analogie :** Pensez √† un Pod comme une "enveloppe" qui contient vos conteneurs.

### Cr√©er le manifeste du Pod

Cr√©ez un fichier nomm√© `nginx-pod.yaml` :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx
    type: webserver
spec:
  containers:
  - name: nginx
    image: nginx:1.21-alpine
    ports:
    - containerPort: 80
      name: http
```

**D√©cortiquons ce manifeste :**

| Champ | Valeur | Explication |
|-------|--------|-------------|
| `apiVersion: v1` | Version de l'API | Pods sont dans l'API v1 stable |
| `kind: Pod` | Type d'objet | Nous cr√©ons un Pod |
| `name: nginx-pod` | Nom unique | Identifiant de notre Pod |
| `labels.app` | nginx | Label pour identifier l'application |
| `containers[0].name` | nginx | Nom du conteneur dans le Pod |
| `containers[0].image` | nginx:1.21-alpine | Image Docker √† t√©l√©charger |
| `containerPort` | 80 | Port sur lequel Nginx √©coute |

**üí° Note sur l'image :**
- `nginx:1.21-alpine` utilise Alpine Linux (version tr√®s l√©g√®re)
- La taille est d'environ 23 MB au lieu de 133 MB pour la version standard
- Parfait pour un lab ou un environnement de d√©veloppement

### D√©ployer le Pod

```bash
# Appliquer le manifeste
microk8s kubectl apply -f nginx-pod.yaml

# Vous devriez voir :
# pod/nginx-pod created
```

**Que se passe-t-il en arri√®re-plan ?**

1. kubectl envoie le manifeste au serveur API Kubernetes
2. Le serveur API valide le manifeste
3. L'objet Pod est stock√© dans etcd (base de donn√©es Kubernetes)
4. Le scheduler assigne le Pod √† un n≈ìud
5. Le kubelet sur ce n≈ìud t√©l√©charge l'image Docker
6. Le conteneur d√©marre

### V√©rifier le d√©ploiement

```bash
# Lister les Pods
microk8s kubectl get pods

# Sortie attendue :
# NAME        READY   STATUS    RESTARTS   AGE
# nginx-pod   1/1     Running   0          30s
```

**Comprendre la sortie :**

- `NAME` : Nom du Pod
- `READY` : 1/1 signifie 1 conteneur pr√™t sur 1 total
- `STATUS` : √âtat actuel (Running, Pending, Error, etc.)
- `RESTARTS` : Nombre de red√©marrages
- `AGE` : Temps depuis la cr√©ation

### Obtenir plus de d√©tails

```bash
# Informations d√©taill√©es du Pod
microk8s kubectl describe pod nginx-pod
```

Cette commande affiche :
- **Events** : Historique des √©v√©nements (cr√©ation, t√©l√©chargement image, d√©marrage)
- **Conditions** : √âtat de sant√© du Pod
- **IP** : Adresse IP interne du Pod
- **Conteneurs** : D√©tails de chaque conteneur
- **Volumes** : Volumes mont√©s (s'il y en a)

### Acc√©der aux logs

```bash
# Voir les logs du conteneur
microk8s kubectl logs nginx-pod

# Suivre les logs en temps r√©el
microk8s kubectl logs -f nginx-pod
```

Les logs montrent les requ√™tes HTTP re√ßues par Nginx et d'√©ventuelles erreurs.

### Tester l'application

Pour l'instant, le Pod n'est accessible qu'√† l'int√©rieur du cluster. Nous allons utiliser le **port-forwarding** pour y acc√©der depuis notre machine locale :

```bash
# Cr√©er un tunnel entre votre machine et le Pod
microk8s kubectl port-forward nginx-pod 8080:80
```

**Que fait cette commande ?**
- Transf√®re le port **8080 de votre machine** vers le **port 80 du Pod**
- Le processus reste actif (Ctrl+C pour arr√™ter)

Ouvrez votre navigateur et acc√©dez √† : **http://localhost:8080**

Vous devriez voir la page d'accueil par d√©faut de Nginx : "Welcome to nginx!"

### Limitations d'un Pod simple

D√©ployer un Pod directement pr√©sente plusieurs inconv√©nients :

‚ùå **Pas de r√©silience** : Si le Pod crash, il ne red√©marre pas automatiquement
‚ùå **Pas de mise √† l'√©chelle** : Impossible d'avoir plusieurs r√©pliques facilement
‚ùå **Pas de rolling updates** : Pas de mise √† jour progressive sans interruption
‚ùå **Gestion manuelle** : Vous devez recr√©er le Pod manuellement en cas de probl√®me

**C'est pourquoi nous utilisons des Deployments en production !**

### Supprimer le Pod

```bash
# Supprimer le Pod
microk8s kubectl delete pod nginx-pod

# Ou via le fichier
microk8s kubectl delete -f nginx-pod.yaml
```

## M√©thode 2 : D√©ployer avec un Deployment (Recommand√©)

### Pourquoi utiliser un Deployment ?

Un **Deployment** est un contr√¥leur qui g√®re des Pods pour vous. Il offre :

‚úÖ **Auto-r√©paration** : Red√©marre automatiquement les Pods d√©faillants
‚úÖ **R√©plication** : Maintient le nombre de r√©pliques souhait√©
‚úÖ **Mises √† jour progressives** : Rolling updates sans interruption de service
‚úÖ **Rollback** : Retour √† une version pr√©c√©dente en cas de probl√®me
‚úÖ **D√©claratif** : Vous d√©clarez l'√©tat souhait√©, Kubernetes s'en charge

**Analogie :** Si un Pod est un employ√©, un Deployment est le manager qui s'assure qu'il y a toujours le bon nombre d'employ√©s op√©rationnels.

### Cr√©er le manifeste du Deployment

Cr√©ez un fichier nomm√© `nginx-deployment.yaml` :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21-alpine
        ports:
        - containerPort: 80
          name: http
        resources:
          requests:
            memory: "64Mi"
            cpu: "100m"
          limits:
            memory: "128Mi"
            cpu: "200m"
```

**D√©cortiquons les nouveaux √©l√©ments :**

#### replicas: 3
```yaml
replicas: 3
```
Le Deployment maintiendra **3 r√©pliques** (copies) du Pod en permanence. Si un Pod meurt, un nouveau sera cr√©√© automatiquement.

#### selector
```yaml
selector:
  matchLabels:
    app: nginx
```
Le s√©lecteur indique au Deployment **quels Pods il doit g√©rer**. Il cherche les Pods avec le label `app: nginx`.

**‚ö†Ô∏è Important :** Les labels du `selector` doivent correspondre aux labels dans `template.metadata.labels`.

#### template
```yaml
template:
  metadata:
    labels:
      app: nginx
  spec:
    # ... sp√©cifications du Pod
```
Le `template` est le **mod√®le de Pod** que le Deployment utilisera pour cr√©er les r√©pliques. C'est exactement la m√™me structure que notre Pod simple, mais imbriqu√©e dans le Deployment.

#### resources
```yaml
resources:
  requests:
    memory: "64Mi"
    cpu: "100m"
  limits:
    memory: "128Mi"
    cpu: "200m"
```

Les ressources d√©finissent les besoins CPU/RAM :

- **requests** : Ressources garanties au conteneur
  - `100m` = 0,1 CPU (10% d'un c≈ìur)
  - `64Mi` = 64 m√©gaoctets de RAM

- **limits** : Ressources maximales que le conteneur peut utiliser
  - `200m` = 0,2 CPU (20% d'un c≈ìur)
  - `128Mi` = 128 m√©gaoctets de RAM

**Pourquoi d√©finir des ressources ?**
- √âvite qu'un conteneur monopolise toutes les ressources
- Aide le scheduler √† placer les Pods efficacement
- Am√©liore la stabilit√© du cluster

### D√©ployer le Deployment

```bash
# Appliquer le manifeste
microk8s kubectl apply -f nginx-deployment.yaml

# Sortie :
# deployment.apps/nginx-deployment created
```

### V√©rifier le Deployment

```bash
# Voir les Deployments
microk8s kubectl get deployments

# Sortie attendue :
# NAME               READY   UP-TO-DATE   AVAILABLE   AGE
# nginx-deployment   3/3     3            3           1m
```

**Comprendre la sortie :**

- `READY` : 3/3 = 3 Pods pr√™ts sur 3 souhait√©s
- `UP-TO-DATE` : Nombre de Pods √† jour avec la derni√®re configuration
- `AVAILABLE` : Nombre de Pods disponibles pour servir du trafic
- `AGE` : Temps depuis la cr√©ation

```bash
# Voir les Pods cr√©√©s par le Deployment
microk8s kubectl get pods

# Sortie attendue :
# NAME                                READY   STATUS    RESTARTS   AGE
# nginx-deployment-5d59d67564-7k9xm   1/1     Running   0          1m
# nginx-deployment-5d59d67564-h2p4l   1/1     Running   0          1m
# nginx-deployment-5d59d67564-tz8wq   1/1     Running   0          1m
```

**Remarquez :**
- Les Pods ont des noms g√©n√©r√©s automatiquement
- Format : `<deployment-name>-<replicaset-id>-<random-id>`
- Il y a bien 3 Pods comme demand√©

### Tester la r√©silience

L'un des grands avantages d'un Deployment est la **r√©silience automatique**. Testons-la :

```bash
# Supprimer un Pod manuellement
microk8s kubectl delete pod nginx-deployment-5d59d67564-7k9xm

# Imm√©diatement apr√®s, lister les Pods
microk8s kubectl get pods
```

**Observation :** Un nouveau Pod est cr√©√© automatiquement pour remplacer celui supprim√© ! Le Deployment maintient toujours 3 r√©pliques.

```
NAME                                READY   STATUS              RESTARTS   AGE
nginx-deployment-5d59d67564-h2p4l   1/1     Running             0          5m
nginx-deployment-5d59d67564-tz8wq   1/1     Running             0          5m
nginx-deployment-5d59d67564-x9n4k   0/1     ContainerCreating   0          2s
```

Le nouveau Pod `x9n4k` remplace automatiquement celui que nous avons supprim√©.

### Mise √† l'√©chelle (Scaling)

Changer le nombre de r√©pliques est tr√®s simple :

#### M√©thode 1 : Via kubectl

```bash
# Passer √† 5 r√©pliques
microk8s kubectl scale deployment nginx-deployment --replicas=5

# V√©rifier
microk8s kubectl get pods
```

Vous verrez maintenant 5 Pods au lieu de 3.

#### M√©thode 2 : Modifier le manifeste

Modifiez `nginx-deployment.yaml` :

```yaml
spec:
  replicas: 2  # Chang√© de 3 √† 2
```

Puis appliquez :

```bash
microk8s kubectl apply -f nginx-deployment.yaml
```

Kubernetes ajustera automatiquement pour avoir exactement 2 r√©pliques (suppression d'un Pod).

**üí° Bonne pratique :** Pr√©f√©rez modifier le fichier YAML et appliquer les changements. Cela maintient vos fichiers comme source de v√©rit√© et facilite le versioning avec Git.

### Mettre √† jour l'application

Imaginons que nous voulons passer √† Nginx 1.22. C'est tr√®s simple avec un Deployment.

#### Mise √† jour de l'image

Modifiez `nginx-deployment.yaml` :

```yaml
containers:
- name: nginx
  image: nginx:1.22-alpine  # Chang√© de 1.21 √† 1.22
```

Appliquez la modification :

```bash
microk8s kubectl apply -f nginx-deployment.yaml
```

#### Observer le rolling update

```bash
# Voir le statut de la mise √† jour
microk8s kubectl rollout status deployment/nginx-deployment

# Sortie :
# Waiting for deployment "nginx-deployment" rollout to finish: 1 out of 3 new replicas have been updated...
# Waiting for deployment "nginx-deployment" rollout to finish: 2 out of 3 new replicas have been updated...
# deployment "nginx-deployment" successfully rolled out
```

**Que se passe-t-il ?**

1. Kubernetes cr√©e un nouveau Pod avec la nouvelle image
2. Attend qu'il soit pr√™t
3. Supprime un ancien Pod
4. R√©p√®te jusqu'√† ce que tous les Pods soient √† jour

**Avantage :** Aucune interruption de service ! Des Pods sont toujours disponibles pendant la mise √† jour.

#### V√©rifier l'historique

```bash
# Voir l'historique des d√©ploiements
microk8s kubectl rollout history deployment/nginx-deployment

# Sortie :
# REVISION  CHANGE-CAUSE
# 1         <none>
# 2         <none>
```

### Rollback : Revenir en arri√®re

Si la nouvelle version pose probl√®me, vous pouvez revenir √† la version pr√©c√©dente instantan√©ment :

```bash
# Revenir √† la r√©vision pr√©c√©dente
microk8s kubectl rollout undo deployment/nginx-deployment

# Revenir √† une r√©vision sp√©cifique
microk8s kubectl rollout undo deployment/nginx-deployment --to-revision=1
```

Kubernetes effectuera un rolling update inverse, restaurant progressivement l'ancienne version.

### Obtenir des informations d√©taill√©es

```bash
# Description compl√®te du Deployment
microk8s kubectl describe deployment nginx-deployment
```

Cette commande affiche :
- Informations de configuration
- Strat√©gie de d√©ploiement
- √âtat des r√©pliques
- √âv√©nements r√©cents
- Conditions

```bash
# Voir les logs d'un Pod sp√©cifique
microk8s kubectl logs nginx-deployment-5d59d67564-h2p4l

# Voir les logs de tous les Pods du Deployment
microk8s kubectl logs -l app=nginx

# Suivre les logs en temps r√©el
microk8s kubectl logs -l app=nginx -f
```

### Strat√©gies de d√©ploiement

Kubernetes supporte plusieurs strat√©gies pour mettre √† jour un Deployment :

#### RollingUpdate (par d√©faut)

```yaml
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
```

- `maxUnavailable` : Nombre maximum de Pods indisponibles pendant la mise √† jour
- `maxSurge` : Nombre maximum de Pods suppl√©mentaires cr√©√©s temporairement

**Comportement :** Mise √† jour progressive, z√©ro downtime.

#### Recreate

```yaml
spec:
  strategy:
    type: Recreate
```

**Comportement :** Supprime tous les Pods existants avant de cr√©er les nouveaux. Provoque un downtime mais utile pour les applications qui ne supportent pas plusieurs versions simultan√©es.

## Commandes Essentielles - R√©capitulatif

### Gestion des Deployments

```bash
# Cr√©er/mettre √† jour depuis un fichier
microk8s kubectl apply -f deployment.yaml

# Lister les Deployments
microk8s kubectl get deployments

# D√©tails d'un Deployment
microk8s kubectl describe deployment nginx-deployment

# Supprimer un Deployment
microk8s kubectl delete deployment nginx-deployment
```

### Gestion des Pods

```bash
# Lister les Pods
microk8s kubectl get pods

# Lister avec plus d'informations (IP, Node)
microk8s kubectl get pods -o wide

# D√©tails d'un Pod
microk8s kubectl describe pod <pod-name>

# Logs d'un Pod
microk8s kubectl logs <pod-name>

# Logs en temps r√©el
microk8s kubectl logs -f <pod-name>

# Acc√©der au shell d'un conteneur
microk8s kubectl exec -it <pod-name> -- /bin/sh
```

### Scaling et Mises √† jour

```bash
# Changer le nombre de r√©pliques
microk8s kubectl scale deployment nginx-deployment --replicas=5

# Mettre √† jour l'image
microk8s kubectl set image deployment/nginx-deployment nginx=nginx:1.22-alpine

# Statut du rollout
microk8s kubectl rollout status deployment/nginx-deployment

# Historique
microk8s kubectl rollout history deployment/nginx-deployment

# Rollback
microk8s kubectl rollout undo deployment/nginx-deployment
```

### D√©bogage

```bash
# √âv√©nements du cluster
microk8s kubectl get events

# √âv√©nements tri√©s par date
microk8s kubectl get events --sort-by='.lastTimestamp'

# Utiliser port-forward pour tester
microk8s kubectl port-forward deployment/nginx-deployment 8080:80
```

## Comparaison Pod vs Deployment

| Aspect | Pod Simple | Deployment |
|--------|------------|------------|
| **R√©silience** | ‚ùå Aucune | ‚úÖ Auto-r√©paration |
| **R√©plication** | ‚ùå Manuelle | ‚úÖ Automatique |
| **Mises √† jour** | ‚ùå Manuelles avec downtime | ‚úÖ Rolling updates |
| **Rollback** | ‚ùå Impossible | ‚úÖ Facile |
| **Use case** | Tests rapides, jobs ponctuels | Production, applications |

**Recommandation :** Utilisez toujours des Deployments pour vos applications, sauf cas tr√®s sp√©cifiques.

## Bonnes Pratiques

### 1. Toujours utiliser des labels

```yaml
metadata:
  labels:
    app: nginx
    version: "1.21"
    environment: production
```

Les labels facilitent la gestion et le filtrage des ressources.

### 2. D√©finir les ressources

```yaml
resources:
  requests:
    memory: "64Mi"
    cpu: "100m"
  limits:
    memory: "128Mi"
    cpu: "200m"
```

Aide Kubernetes √† mieux g√©rer les ressources du cluster.

### 3. Utiliser des versions d'images sp√©cifiques

‚ùå **√âviter :**
```yaml
image: nginx:latest
```

‚úÖ **Pr√©f√©rer :**
```yaml
image: nginx:1.21-alpine
```

Les tags `latest` peuvent changer et causer des comportements impr√©visibles.

### 4. Configurer les health checks

```yaml
livenessProbe:
  httpGet:
    path: /
    port: 80
  initialDelaySeconds: 30
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /
    port: 80
  initialDelaySeconds: 5
  periodSeconds: 5
```

Les probes permettent √† Kubernetes de d√©tecter si votre application fonctionne correctement.

### 5. Organiser vos fichiers

Cr√©ez une structure de dossiers claire :

```
mon-projet/
‚îú‚îÄ‚îÄ deployments/
‚îÇ   ‚îî‚îÄ‚îÄ nginx-deployment.yaml
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ nginx-service.yaml
‚îî‚îÄ‚îÄ configmaps/
    ‚îî‚îÄ‚îÄ nginx-config.yaml
```

### 6. Versionner avec Git

Stockez tous vos manifestes YAML dans Git pour :
- Historique des changements
- Collaboration en √©quipe
- Faciliter les rollbacks
- Documentation automatique

### 7. Utiliser des namespaces

```yaml
metadata:
  name: nginx-deployment
  namespace: production
```

Les namespaces permettent d'isoler les environnements (dev, staging, production).

## R√©solution de Probl√®mes Courants

### Le Pod reste en "Pending"

**Causes possibles :**
- Ressources insuffisantes sur le cluster
- Probl√®mes de volumes
- Image registry inaccessible

**Diagnostic :**
```bash
microk8s kubectl describe pod <pod-name>
```

Regardez la section **Events** en bas pour identifier le probl√®me.

### Le Pod est en "CrashLoopBackOff"

Le conteneur d√©marre puis crash en boucle.

**Diagnostic :**
```bash
# Voir les logs
microk8s kubectl logs <pod-name>

# Logs du conteneur pr√©c√©dent (avant crash)
microk8s kubectl logs <pod-name> --previous
```

**Causes courantes :**
- Erreur dans l'application
- Configuration incorrecte
- D√©pendances manquantes

### Le Pod est en "ImagePullBackOff"

Kubernetes ne peut pas t√©l√©charger l'image Docker.

**Causes :**
- Image n'existe pas
- Nom d'image incorrect
- Registry priv√© n√©cessite une authentification

**V√©rification :**
```bash
microk8s kubectl describe pod <pod-name>
```

Recherchez les messages d'erreur dans les Events.

### Le conteneur d√©marre mais l'application ne r√©pond pas

**Diagnostic :**
```bash
# Acc√©der au shell du conteneur
microk8s kubectl exec -it <pod-name> -- /bin/sh

# Tester depuis l'int√©rieur
curl localhost:80
```

## Prochaines √âtapes

Maintenant que votre application est d√©ploy√©e, les prochaines √©tapes logiques sont :

1. **Exposer l'application** : Cr√©er un Service pour rendre l'application accessible (section 4.3)
2. **Configurer l'application** : Utiliser ConfigMaps et Secrets (sections suivantes)
3. **Persister les donn√©es** : Ajouter des volumes pour les donn√©es permanentes
4. **Monitorer** : Mettre en place des health checks et du monitoring

## R√©capitulatif

Dans cette section, vous avez appris √† :

‚úÖ D√©ployer un Pod simple avec Nginx
‚úÖ Cr√©er un Deployment pour g√©rer des r√©pliques
‚úÖ Utiliser les commandes kubectl essentielles
‚úÖ Mettre √† l'√©chelle une application
‚úÖ Effectuer des mises √† jour progressives (rolling updates)
‚úÖ Revenir √† une version pr√©c√©dente (rollback)
‚úÖ D√©boguer des probl√®mes courants

**Points cl√©s :**

- Les **Deployments** sont pr√©f√©rables aux Pods simples en production
- Kubernetes g√®re automatiquement la **r√©silience** et la **r√©plication**
- Les **rolling updates** permettent des mises √† jour sans interruption
- Toujours d√©finir des **ressources** et utiliser des **labels**
- Les **manifestes YAML** doivent √™tre versionn√©s dans Git

Vous avez maintenant une application web fonctionnelle sur votre cluster MicroK8s ! La prochaine √©tape sera de l'exposer pour y acc√©der plus facilement.

---

**Prochaine section :** 4.3 Exposition d'une application

‚è≠Ô∏è [Exposition d'une application](/04-premiers-deploiements/03-exposition-dune-application.md)
