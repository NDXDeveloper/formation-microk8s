üîù Retour au [Sommaire](/SOMMAIRE.md)

# 4.3 Exposition d'une Application

## Introduction

Dans la section pr√©c√©dente, nous avons d√©ploy√© une application Nginx avec succ√®s. Cependant, cette application n'est accessible qu'√† l'int√©rieur du cluster Kubernetes. Pour qu'elle soit utilisable, nous devons l'**exposer** au monde ext√©rieur (ou au moins √† notre r√©seau local).

Dans cette section, nous allons d√©couvrir le concept de **Service** dans Kubernetes, l'objet qui permet d'exposer vos applications de mani√®re stable et fiable.

## Le Probl√®me : Les Pods sont √âph√©m√®res

Avant de comprendre les Services, il faut comprendre le probl√®me qu'ils r√©solvent.

### Pods et adresses IP volatiles

Chaque Pod dans Kubernetes re√ßoit sa propre adresse IP. Cependant :

‚ùå **Les IPs des Pods changent** : Quand un Pod est recr√©√© (crash, mise √† jour, scaling), il obtient une nouvelle IP
‚ùå **Impossible √† m√©moriser** : Avec plusieurs r√©pliques, il faudrait conna√Ætre toutes les IPs
‚ùå **Pas de load balancing** : Comment r√©partir le trafic entre plusieurs r√©pliques ?

**Exemple concret :**

```bash
# Voir les IPs des Pods
microk8s kubectl get pods -o wide

# Sortie :
# NAME                                READY   STATUS    RESTARTS   AGE   IP
# nginx-deployment-5d59d67564-7k9xm   1/1     Running   0          5m    10.1.1.5
# nginx-deployment-5d59d67564-h2p4l   1/1     Running   0          5m    10.1.1.6
# nginx-deployment-5d59d67564-tz8wq   1/1     Running   0          5m    10.1.1.7
```

Si vous supprimez un de ces Pods, le nouveau aura une IP diff√©rente !

### La Solution : Les Services Kubernetes

Un **Service** est un objet Kubernetes qui :

‚úÖ Fournit une **adresse IP stable** (qui ne change jamais)
‚úÖ Expose un **nom DNS** facile √† retenir
‚úÖ Fait du **load balancing** automatique entre les Pods
‚úÖ Surveille la sant√© des Pods et route uniquement vers les Pods sains

**Analogie :** Un Service est comme un standard t√©l√©phonique d'entreprise. Vous appelez toujours le m√™me num√©ro (IP stable), et le standard vous connecte √† un employ√© disponible (Pod), peu importe qui c'est ou s'il y a eu des changements dans le personnel.

## Types de Services

Kubernetes propose quatre types de Services, chacun adapt√© √† un cas d'usage sp√©cifique :

| Type | Utilisation | Accessibilit√© |
|------|-------------|---------------|
| **ClusterIP** | Communication interne | Uniquement dans le cluster |
| **NodePort** | Acc√®s simple depuis l'ext√©rieur | Via IP du n≈ìud + port sp√©cifique |
| **LoadBalancer** | Production avec load balancer externe | Via une IP publique d√©di√©e |
| **ExternalName** | Alias vers un service externe | Redirection DNS |

Nous allons explorer les trois premiers types en d√©tail.

## Type 1 : ClusterIP (Par D√©faut)

### Qu'est-ce que ClusterIP ?

**ClusterIP** est le type de Service par d√©faut. Il expose votre application uniquement **√† l'int√©rieur du cluster** Kubernetes.

**Cas d'usage :**
- Communication entre microservices
- Backend non accessible depuis l'ext√©rieur
- Base de donn√©es interne
- API interne

### Cr√©er un Service ClusterIP

Cr√©ez un fichier `nginx-service-clusterip.yaml` :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
  labels:
    app: nginx
spec:
  type: ClusterIP
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
```

**D√©cortiquons ce manifeste :**

#### selector
```yaml
selector:
  app: nginx
```

Le **selector** est crucial ! Il indique au Service quels Pods cibler. Le Service routera le trafic vers tous les Pods ayant le label `app: nginx`.

**‚ö†Ô∏è Important :** Ce label doit correspondre aux labels de votre Deployment !

#### ports
```yaml
ports:
- protocol: TCP
  port: 80          # Port du Service
  targetPort: 80    # Port du conteneur dans le Pod
```

- **port** : Le port sur lequel le Service √©coute (ce que les clients utilisent)
- **targetPort** : Le port sur lequel votre application √©coute dans le Pod
- **protocol** : TCP ou UDP

**Sch√©ma conceptuel :**

```
Client ‚Üí Service (port 80) ‚Üí Pod (targetPort 80)
```

### D√©ployer le Service

```bash
# Cr√©er le Service
microk8s kubectl apply -f nginx-service-clusterip.yaml

# Sortie :
# service/nginx-service created
```

### V√©rifier le Service

```bash
# Lister les Services
microk8s kubectl get services
# ou la forme courte :
microk8s kubectl get svc

# Sortie :
# NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
# kubernetes      ClusterIP   10.152.183.1    <none>        443/TCP   5d
# nginx-service   ClusterIP   10.152.183.45   <none>        80/TCP    30s
```

**Comprendre la sortie :**
- `CLUSTER-IP` : L'IP interne stable du Service (10.152.183.45)
- `EXTERNAL-IP` : `<none>` car ClusterIP est interne uniquement
- `PORT(S)` : 80/TCP - le port expos√©

### Tester le Service

Depuis un Pod dans le cluster, vous pouvez acc√©der au Service :

```bash
# Cr√©er un Pod temporaire pour tester
microk8s kubectl run test-pod --image=busybox --rm -it --restart=Never -- sh

# Dans le Pod, tester avec wget
wget -qO- nginx-service
# ou avec curl si disponible
wget -qO- http://nginx-service:80
```

Vous devriez voir le HTML de la page d'accueil Nginx !

**Magie du DNS :** Le nom `nginx-service` est automatiquement r√©solu par le DNS interne de Kubernetes vers l'IP du Service.

### Acc√©der depuis votre machine (port-forward)

Pour tester depuis votre machine locale :

```bash
# Cr√©er un tunnel
microk8s kubectl port-forward service/nginx-service 8080:80

# Acc√©der dans le navigateur : http://localhost:8080
```

**Note :** Le port-forward est pratique pour le d√©veloppement mais pas pour la production.

## Type 2 : NodePort

### Qu'est-ce que NodePort ?

**NodePort** expose votre Service sur un port sp√©cifique de **chaque n≈ìud** du cluster. C'est le moyen le plus simple d'acc√©der √† votre application depuis l'ext√©rieur.

**Comment √ßa marche :**
1. Kubernetes ouvre un port (entre 30000-32767) sur tous les n≈ìuds
2. Le trafic vers `<IP-du-n≈ìud>:<NodePort>` est rout√© vers votre Service
3. Le Service fait du load balancing vers les Pods

**Cas d'usage :**
- Labs et environnements de d√©veloppement
- Acc√®s rapide depuis l'ext√©rieur
- Clusters sans load balancer externe

### Cr√©er un Service NodePort

Cr√©ez un fichier `nginx-service-nodeport.yaml` :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-nodeport
  labels:
    app: nginx
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30080
```

**Nouveaux √©l√©ments :**

```yaml
type: NodePort
nodePort: 30080
```

- `type: NodePort` : Change le type de Service
- `nodePort: 30080` : Port sp√©cifique √† utiliser (optionnel, sinon Kubernetes en assigne un automatiquement)

**‚ö†Ô∏è Plage valide :** Les NodePorts doivent √™tre entre 30000 et 32767.

### D√©ployer le Service NodePort

```bash
# Cr√©er le Service
microk8s kubectl apply -f nginx-service-nodeport.yaml

# V√©rifier
microk8s kubectl get svc nginx-nodeport

# Sortie :
# NAME             TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
# nginx-nodeport   NodePort   10.152.183.100   <none>        80:30080/TCP   10s
```

**Comprendre `PORT(S)` :**
- `80:30080/TCP` signifie :
  - Port du Service : 80
  - NodePort (port externe) : 30080

### Acc√©der au Service

Vous pouvez maintenant acc√©der √† votre application via l'IP de votre machine !

```bash
# Obtenir l'IP de votre n≈ìud
hostname -I
# ou
ip addr show

# Supposons que votre IP est 192.168.1.100
# Acc√©dez via : http://192.168.1.100:30080
```

**Depuis un autre ordinateur sur le m√™me r√©seau :**
- Ouvrez un navigateur
- Allez √† `http://192.168.1.100:30080`
- Vous verrez la page Nginx !

### Laisser Kubernetes choisir le port

Si vous ne sp√©cifiez pas `nodePort`, Kubernetes en assigne un automatiquement :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-nodeport-auto
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    # Pas de nodePort sp√©cifi√©
```

Kubernetes choisira un port disponible dans la plage 30000-32767.

```bash
# Voir le port assign√©
microk8s kubectl get svc nginx-nodeport-auto

# Sortie exemple :
# NAME                  TYPE       CLUSTER-IP       PORT(S)        AGE
# nginx-nodeport-auto   NodePort   10.152.183.101   80:31245/TCP   5s
```

Le port assign√© ici est 31245.

### Avantages et Inconv√©nients

**‚úÖ Avantages :**
- Simple √† configurer
- Pas besoin d'infrastructure suppl√©mentaire
- Id√©al pour les labs et le d√©veloppement

**‚ùå Inconv√©nients :**
- N√©cessite de conna√Ætre l'IP du n≈ìud
- Ports peu conviviaux (30000-32767)
- Un seul Service par port
- Pas id√©al pour la production

## Type 3 : LoadBalancer

### Qu'est-ce qu'un LoadBalancer ?

**LoadBalancer** est le type de Service le plus "professionnel". Il provisionne automatiquement un **load balancer externe** qui distribue le trafic vers vos Pods.

**Comment √ßa marche :**
1. Vous cr√©ez un Service de type LoadBalancer
2. Kubernetes demande √† votre plateforme cloud (ou MetalLB pour MicroK8s) de cr√©er un load balancer
3. Une IP externe est assign√©e
4. Le trafic vers cette IP est distribu√© entre vos Pods

**Cas d'usage :**
- Applications de production
- Besoin d'une IP publique propre
- Load balancing professionnel

### Pr√©requis pour MicroK8s : MetalLB

Sur les clouds publics (AWS, GCP, Azure), le LoadBalancer est fourni automatiquement. Pour MicroK8s, nous devons activer **MetalLB**, un addon qui √©mule un load balancer.

```bash
# Activer MetalLB
microk8s enable metallb

# MicroK8s vous demandera une plage d'IPs
# Exemple pour un r√©seau local 192.168.1.0/24 :
# Entrez : 192.168.1.200-192.168.1.250
```

**‚ö†Ô∏è Important :** Choisissez des IPs libres sur votre r√©seau local, pas d√©j√† utilis√©es par d'autres machines.

**Qu'est-ce que MetalLB ?**
- Fournit des IPs externes pour les Services LoadBalancer
- Annonce ces IPs sur le r√©seau local via ARP
- Distribue le trafic vers les Pods

Nous approfondirons MetalLB dans le chapitre 9.

### Cr√©er un Service LoadBalancer

Cr√©ez un fichier `nginx-service-loadbalancer.yaml` :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-loadbalancer
  labels:
    app: nginx
spec:
  type: LoadBalancer
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
```

**Changement cl√© :**
```yaml
type: LoadBalancer
```

C'est tout ! Pas besoin de sp√©cifier de NodePort.

### D√©ployer le Service LoadBalancer

```bash
# Cr√©er le Service
microk8s kubectl apply -f nginx-service-loadbalancer.yaml

# V√©rifier (peut prendre quelques secondes)
microk8s kubectl get svc nginx-loadbalancer

# Sortie :
# NAME                 TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)        AGE
# nginx-loadbalancer   LoadBalancer   10.152.183.102   192.168.1.200   80:31678/TCP   1m
```

**Comprendre la sortie :**
- `EXTERNAL-IP` : L'IP externe assign√©e par MetalLB (192.168.1.200)
- Si vous voyez `<pending>`, attendez quelques secondes
- Si cela reste `<pending>`, v√©rifiez que MetalLB est bien activ√©

### Acc√©der au Service

C'est tr√®s simple maintenant :

```bash
# Depuis n'importe o√π sur votre r√©seau local
curl http://192.168.1.200
# ou ouvrez http://192.168.1.200 dans un navigateur
```

**Avantage :** Pas besoin de sp√©cifier un port ! Le Service est accessible sur le port standard 80.

### Multiples ports

Un Service peut exposer plusieurs ports :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  type: LoadBalancer
  selector:
    app: webapp
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 8080
  - name: https
    protocol: TCP
    port: 443
    targetPort: 8443
  - name: metrics
    protocol: TCP
    port: 9090
    targetPort: 9090
```

**Note :** Quand vous avez plusieurs ports, il est recommand√© de leur donner des noms (`http`, `https`, `metrics`).

## Comparaison des Types de Services

| Crit√®re | ClusterIP | NodePort | LoadBalancer |
|---------|-----------|----------|--------------|
| **Accessibilit√©** | Interne uniquement | Externe via NodePort | Externe via IP d√©di√©e |
| **IP externe** | ‚ùå Non | ‚ùå Non | ‚úÖ Oui |
| **Port** | Port standard | 30000-32767 | Port standard |
| **Load balancing** | ‚úÖ Oui | ‚úÖ Oui | ‚úÖ Oui |
| **Use case** | Microservices internes | Dev/Test | Production |
| **Complexit√©** | Simple | Simple | N√©cessite MetalLB/Cloud |
| **Co√ªt** | Gratuit | Gratuit | Gratuit avec MetalLB |

**Recommandations :**
- **Dev/Test local** : NodePort ou port-forward
- **Production** : LoadBalancer (avec MetalLB ou cloud provider)
- **Communication interne** : ClusterIP

## DNS Interne et Discovery

### R√©solution DNS automatique

Kubernetes fournit un **DNS interne** (CoreDNS) qui permet aux Pods de se trouver facilement.

**Format du nom DNS :**
```
<service-name>.<namespace>.svc.cluster.local
```

**Exemples :**

```bash
# Depuis un Pod dans le m√™me namespace
curl http://nginx-service

# Depuis un Pod dans un autre namespace
curl http://nginx-service.default.svc.cluster.local

# Format court
curl http://nginx-service.default
```

### Variables d'environnement

Kubernetes injecte automatiquement des variables d'environnement pour chaque Service :

```bash
# Lister les variables dans un Pod
microk8s kubectl exec <pod-name> -- env | grep NGINX_SERVICE

# Sortie exemple :
# NGINX_SERVICE_SERVICE_HOST=10.152.183.45
# NGINX_SERVICE_SERVICE_PORT=80
```

**Format :**
- `<SERVICE_NAME>_SERVICE_HOST` : IP du Service
- `<SERVICE_NAME>_SERVICE_PORT` : Port du Service

**Note :** Le nom est en majuscules avec underscores au lieu de tirets.

## Load Balancing et Session Affinity

### Load Balancing par d√©faut

Par d√©faut, Kubernetes distribue le trafic de mani√®re **round-robin** entre tous les Pods sains.

**Exemple avec 3 r√©pliques :**
1. Requ√™te 1 ‚Üí Pod A
2. Requ√™te 2 ‚Üí Pod B
3. Requ√™te 3 ‚Üí Pod C
4. Requ√™te 4 ‚Üí Pod A (on recommence)

### Session Affinity (Sticky Sessions)

Parfois, vous voulez que les requ√™tes d'un m√™me client soient toujours rout√©es vers le m√™me Pod :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-sticky
spec:
  type: LoadBalancer
  selector:
    app: nginx
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 3600
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
```

**Nouveaux champs :**
- `sessionAffinity: ClientIP` : Route les requ√™tes de la m√™me IP client vers le m√™me Pod
- `timeoutSeconds: 3600` : Dur√©e de validit√© (1 heure ici)

**Use cases :**
- Applications avec sessions utilisateur
- Caching local dans les Pods
- WebSockets

## Health Checks et Endpoints

### Comment le Service sait quels Pods sont pr√™ts ?

Le Service ne route le trafic que vers les Pods **"Ready"**. Kubernetes utilise les **readiness probes** pour d√©terminer si un Pod est pr√™t.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21-alpine
        ports:
        - containerPort: 80
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
```

**Avec cette configuration :**
- Kubernetes teste `GET http://pod-ip/` toutes les 5 secondes
- Si le code HTTP est 200-399, le Pod est "Ready"
- Sinon, le Pod est retir√© temporairement du Service

### Voir les Endpoints

Les **Endpoints** repr√©sentent les IPs des Pods s√©lectionn√©s par le Service :

```bash
# Voir les Endpoints
microk8s kubectl get endpoints nginx-service

# Sortie :
# NAME            ENDPOINTS                                      AGE
# nginx-service   10.1.1.5:80,10.1.1.6:80,10.1.1.7:80           5m
```

Chaque IP correspond √† un Pod "Ready".

**V√©rifier en d√©tail :**
```bash
microk8s kubectl describe endpoints nginx-service
```

## Exposer via kubectl expose

Au lieu de cr√©er un fichier YAML, vous pouvez utiliser `kubectl expose` :

```bash
# Exposer un Deployment
microk8s kubectl expose deployment nginx-deployment \
  --type=LoadBalancer \
  --port=80 \
  --target-port=80 \
  --name=nginx-exposed

# Exposer un Pod
microk8s kubectl expose pod nginx-pod \
  --type=NodePort \
  --port=80 \
  --name=nginx-pod-service
```

**Avantages :**
- Rapide pour tester
- Moins de fichiers √† g√©rer

**Inconv√©nients :**
- Pas de versioning (pas dans Git)
- Moins de contr√¥le
- Difficile √† reproduire

**üí° Recommandation :** Utilisez des fichiers YAML pour la production, `kubectl expose` pour les tests rapides.

## Commandes Essentielles

### Gestion des Services

```bash
# Lister les Services
microk8s kubectl get services
microk8s kubectl get svc

# D√©tails d'un Service
microk8s kubectl describe service nginx-service

# Voir les Endpoints
microk8s kubectl get endpoints

# Supprimer un Service
microk8s kubectl delete service nginx-service

# Cr√©er depuis un fichier
microk8s kubectl apply -f service.yaml
```

### Debugging

```bash
# Tester avec port-forward
microk8s kubectl port-forward service/nginx-service 8080:80

# Voir les √©v√©nements
microk8s kubectl get events --sort-by='.lastTimestamp'

# V√©rifier les labels des Pods
microk8s kubectl get pods --show-labels

# Tester depuis un Pod temporaire
microk8s kubectl run test --image=busybox --rm -it -- wget -qO- http://nginx-service
```

## Manifeste Complet : Deployment + Service

Voici un exemple complet combinant Deployment et Service dans un seul fichier :

```yaml
---
# Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-app
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21-alpine
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: "64Mi"
            cpu: "100m"
          limits:
            memory: "128Mi"
            cpu: "200m"
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10

---
# Service
apiVersion: v1
kind: Service
metadata:
  name: nginx-app-service
  labels:
    app: nginx
spec:
  type: LoadBalancer
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    name: http
```

**D√©ployer le tout :**
```bash
microk8s kubectl apply -f nginx-complete.yaml

# V√©rifier
microk8s kubectl get deployments,services,pods
```

## Bonnes Pratiques

### 1. Toujours nommer vos ports

```yaml
ports:
- name: http
  protocol: TCP
  port: 80
  targetPort: 80
- name: https
  protocol: TCP
  port: 443
  targetPort: 443
```

Les noms facilitent la compr√©hension et la documentation.

### 2. Utiliser des labels coh√©rents

```yaml
# Dans le Deployment
metadata:
  labels:
    app: nginx
    version: "1.21"
    environment: production

# Dans le Service
selector:
  app: nginx
  environment: production
```

### 3. D√©finir des readiness probes

```yaml
readinessProbe:
  httpGet:
    path: /health
    port: 80
  initialDelaySeconds: 5
  periodSeconds: 5
```

Assurez-vous que le Service ne route que vers des Pods sains.

### 4. Choisir le bon type de Service

- **D√©veloppement local** : ClusterIP + port-forward ou NodePort
- **Production** : LoadBalancer avec MetalLB
- **Communication interne** : ClusterIP

### 5. Documenter avec des annotations

```yaml
metadata:
  name: nginx-service
  annotations:
    description: "Service principal pour l'application web Nginx"
    contact: "devops-team@example.com"
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
```

### 6. Limiter l'exposition

N'exposez que ce qui doit l'√™tre :
- Bases de donn√©es ‚Üí ClusterIP uniquement
- APIs internes ‚Üí ClusterIP
- Frontends web ‚Üí LoadBalancer

## R√©solution de Probl√®mes

### Le Service n'a pas d'Endpoints

**Sympt√¥me :**
```bash
microk8s kubectl get endpoints nginx-service
# NAME            ENDPOINTS   AGE
# nginx-service   <none>      2m
```

**Causes possibles :**
1. Les labels du selector ne correspondent pas
2. Aucun Pod n'est "Ready"
3. Les Pods n'existent pas

**Solution :**
```bash
# V√©rifier les labels des Pods
microk8s kubectl get pods --show-labels

# V√©rifier le selector du Service
microk8s kubectl describe service nginx-service

# V√©rifier si les Pods sont Ready
microk8s kubectl get pods
```

### LoadBalancer reste en "Pending"

**Sympt√¥me :**
```bash
# EXTERNAL-IP reste <pending>
microk8s kubectl get svc
```

**Causes :**
- MetalLB n'est pas activ√©
- Pas d'IPs disponibles dans le pool MetalLB

**Solution :**
```bash
# Activer MetalLB
microk8s enable metallb

# V√©rifier les logs
microk8s kubectl logs -n metallb-system -l app=metallb
```

### Impossible d'acc√©der au Service NodePort

**V√©rifications :**
1. Le firewall bloque-t-il le port ?
```bash
sudo ufw status
sudo ufw allow 30080/tcp
```

2. Utilisez-vous la bonne IP ?
```bash
hostname -I
```

3. Le Service est-il bien de type NodePort ?
```bash
microk8s kubectl get svc
```

### Connexion refus√©e

**V√©rifications :**
1. Le Pod est-il Ready ?
```bash
microk8s kubectl get pods
```

2. Le conteneur √©coute-t-il sur le bon port ?
```bash
microk8s kubectl exec <pod-name> -- netstat -tlnp
```

3. Le targetPort est-il correct ?
```bash
microk8s kubectl describe service nginx-service
```

## R√©capitulatif

Dans cette section, vous avez appris √† :

‚úÖ Comprendre le r√¥le des Services dans Kubernetes
‚úÖ Cr√©er des Services de type **ClusterIP**, **NodePort** et **LoadBalancer**
‚úÖ Choisir le bon type de Service selon le cas d'usage
‚úÖ Utiliser le DNS interne pour la d√©couverte de services
‚úÖ Configurer le load balancing et la session affinity
‚úÖ D√©boguer les probl√®mes d'exposition courants

**Points cl√©s :**

- Les **Services** fournissent une IP stable et du load balancing
- **ClusterIP** : Communication interne uniquement
- **NodePort** : Acc√®s simple depuis l'ext√©rieur (ports 30000-32767)
- **LoadBalancer** : Solution professionnelle avec IP externe d√©di√©e
- Les **selectors** et **labels** doivent correspondre entre Service et Pods
- **MetalLB** √©mule un load balancer pour MicroK8s

Votre application est maintenant d√©ploy√©e et accessible ! Les prochaines sections couvriront la configuration avec des variables d'environnement et des donn√©es sensibles.

---

**Prochaine section :** 4.4 Variables d'environnement

‚è≠Ô∏è [Variables d'environnement](/04-premiers-deploiements/04-variables-denvironnement.md)
