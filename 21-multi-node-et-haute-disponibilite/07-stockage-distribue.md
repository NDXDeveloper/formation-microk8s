ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 21.7 Stockage DistribuÃ©

## Introduction

Vous avez maintenant un cluster multi-node avec load balancing. Mais il reste un Ã©lÃ©ment crucial Ã  maÃ®triser : le **stockage distribuÃ©**. Sans lui, vos donnÃ©es sont liÃ©es Ã  un seul nÅ“ud, ce qui limite la rÃ©silience et la flexibilitÃ© de votre cluster.

Dans ce chapitre, nous allons dÃ©couvrir :
- Pourquoi le stockage distribuÃ© est essentiel dans un cluster multi-node
- Les diffÃ©rentes solutions de stockage disponibles
- Comment configurer du stockage distribuÃ© avec MicroK8s
- Les concepts de PersistentVolumes, PersistentVolumeClaims et StorageClasses
- Les bonnes pratiques pour gÃ©rer les donnÃ©es persistantes

Le stockage distribuÃ© permet Ã  vos applications de :
- **Survivre aux pannes** de nÅ“uds (les donnÃ©es sont rÃ©pliquÃ©es)
- **Se dÃ©placer librement** entre nÅ“uds (les pods peuvent accÃ©der aux donnÃ©es depuis n'importe quel nÅ“ud)
- **Scaler horizontalement** (ajouter de la capacitÃ© en ajoutant des nÅ“uds)
- **Garantir la durabilitÃ©** des donnÃ©es critiques

## Le ProblÃ¨me du Stockage Local

### Stockage Local : Comment Ã§a Fonctionne

Par dÃ©faut, avec l'addon `hostpath-storage` de MicroK8s, le stockage est **local** Ã  chaque nÅ“ud.

**SchÃ©ma du stockage local :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLUSTER                            â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Node 1    â”‚   â”‚   Node 2    â”‚   â”‚   Node 3    â”‚  â”‚
â”‚  â”‚             â”‚   â”‚             â”‚   â”‚             â”‚  â”‚
â”‚  â”‚  Pod A      â”‚   â”‚  Pod B      â”‚   â”‚  Pod C      â”‚  â”‚
â”‚  â”‚  â”‚          â”‚   â”‚  â”‚          â”‚   â”‚  â”‚          â”‚  â”‚
â”‚  â”‚  â–¼          â”‚   â”‚  â–¼          â”‚   â”‚  â–¼          â”‚  â”‚
â”‚  â”‚ /data       â”‚   â”‚ /data       â”‚   â”‚ /data       â”‚  â”‚
â”‚  â”‚ (local)     â”‚   â”‚ (local)     â”‚   â”‚ (local)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â–²                 â–²                 â–²           â”‚
â”‚       â”‚                 â”‚                 â”‚           â”‚
â”‚   DonnÃ©es sur       DonnÃ©es sur       DonnÃ©es sur     â”‚
â”‚   le disque         le disque         le disque       â”‚
â”‚   de Node 1         de Node 2         de Node 3       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Chaque pod stocke ses donnÃ©es sur le disque local du nÅ“ud oÃ¹ il s'exÃ©cute.**

### Les ProblÃ¨mes du Stockage Local

**ProblÃ¨me 1 : Perte de donnÃ©es en cas de panne**

Si Node 2 tombe en panne :
```
Node 1 : âœ… DonnÃ©es accessibles
Node 2 : âŒ PANNE â†’ DonnÃ©es inaccessibles
Node 3 : âœ… DonnÃ©es accessibles
```

Pod B sera redÃ©marrÃ© sur Node 1 ou Node 3, mais **ses donnÃ©es sont perdues** car elles Ã©taient sur Node 2.

**ProblÃ¨me 2 : Pod liÃ© Ã  un nÅ“ud spÃ©cifique**

Si un pod utilise du stockage local, Kubernetes **ne peut pas** le dÃ©placer sur un autre nÅ“ud (car ses donnÃ©es ne sont pas accessibles ailleurs).

**Exemple concret :**
```bash
# Pod avec base de donnÃ©es sur Node 2
microk8s kubectl get pod postgres-pod -o wide
```
```
NAME            READY   STATUS    NODE
postgres-pod    1/1     Running   node2
```

Si vous drainez Node 2 pour maintenance :
```bash
microk8s kubectl drain node2 --ignore-daemonsets
```

Le pod postgres-pod **ne peut pas** Ãªtre Ã©vacuÃ© car ses donnÃ©es sont liÃ©es Ã  Node 2. Il reste bloquÃ©.

**ProblÃ¨me 3 : Pas de rÃ©plication**

Les donnÃ©es existent en un seul exemplaire. Pas de backup automatique, pas de redondance.

**ProblÃ¨me 4 : CapacitÃ© limitÃ©e**

La capacitÃ© de stockage est limitÃ©e au disque du nÅ“ud. Vous ne pouvez pas facilement ajouter de la capacitÃ©.

### Quand le Stockage Local Suffit

**Le stockage local est acceptable pour :**
- DonnÃ©es temporaires (cache, logs)
- Applications stateless (sans Ã©tat)
- Environnements de dÃ©veloppement/test
- Clusters single-node

**Le stockage local N'EST PAS acceptable pour :**
- Bases de donnÃ©es en production
- Applications stateful critiques
- DonnÃ©es qui doivent survivre aux pannes
- Clusters multi-node en production

## Qu'est-ce que le Stockage DistribuÃ© ?

### DÃ©finition

Le **stockage distribuÃ©** est un systÃ¨me oÃ¹ les donnÃ©es sont rÃ©parties et rÃ©pliquÃ©es sur plusieurs nÅ“uds du cluster. Chaque nÅ“ud peut accÃ©der aux donnÃ©es, peu importe oÃ¹ elles sont physiquement stockÃ©es.

**Analogie du cloud personnel :**
C'est comme avoir Google Drive ou Dropbox dans votre cluster :
- Les fichiers sont rÃ©pliquÃ©s sur plusieurs serveurs
- Vous pouvez y accÃ©der depuis n'importe quelle machine
- Si un serveur tombe, les donnÃ©es restent accessibles via les autres

**SchÃ©ma du stockage distribuÃ© :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLUSTER                            â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Node 1    â”‚   â”‚   Node 2    â”‚   â”‚   Node 3    â”‚  â”‚
â”‚  â”‚             â”‚   â”‚             â”‚   â”‚             â”‚  â”‚
â”‚  â”‚  Pod A      â”‚   â”‚  Pod B      â”‚   â”‚  Pod C      â”‚  â”‚
â”‚  â”‚  â”‚          â”‚   â”‚  â”‚          â”‚   â”‚  â”‚          â”‚  â”‚
â”‚  â”‚  â–¼          â”‚   â”‚  â–¼          â”‚   â”‚  â–¼          â”‚  â”‚
â”‚  â””â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚     â”‚                 â”‚                 â”‚             â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                       â”‚                               â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚           â”‚  STOCKAGE DISTRIBUÃ‰                  â”‚    â”‚
â”‚           â”‚  (RÃ©pliquÃ© 3x)                       â”‚    â”‚
â”‚           â”‚                                      â”‚    â”‚
â”‚           â”‚  Replica 1  Replica 2   Replica 3    â”‚    â”‚
â”‚           â”‚  (Node 1)   (Node 2)   (Node 3)      â”‚    â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tous les pods peuvent accÃ©der aux mÃªmes donnÃ©es, peu importe leur nÅ“ud.**

### Avantages du Stockage DistribuÃ©

**1. RÃ©silience aux pannes**
- DonnÃ©es rÃ©pliquÃ©es sur plusieurs nÅ“uds (3 copies par dÃ©faut)
- Si un nÅ“ud tombe, les donnÃ©es restent accessibles

**2. MobilitÃ© des pods**
- Un pod peut Ãªtre dÃ©placÃ© d'un nÅ“ud Ã  un autre
- Il retrouve ses donnÃ©es automatiquement

**3. Haute disponibilitÃ©**
- Applications stateful peuvent avoir de la HA
- Pas de downtime lors des maintenances

**4. ScalabilitÃ©**
- Ajouter de la capacitÃ© en ajoutant des nÅ“uds
- Distribution automatique des donnÃ©es

**5. Performance**
- Lectures parallÃ¨les possibles
- Load balancing du stockage

### Concepts ClÃ©s

**RÃ©plication :**
Chaque donnÃ©e existe en plusieurs exemplaires (replicas). Par dÃ©faut : 3 copies.

**Consistency (CohÃ©rence) :**
Toutes les copies des donnÃ©es sont synchronisÃ©es. Si vous Ã©crivez sur un nÅ“ud, la modification est propagÃ©e aux autres.

**Fault Tolerance (TolÃ©rance aux pannes) :**
Le systÃ¨me continue de fonctionner mÃªme si un ou plusieurs nÅ“uds tombent.

**Self-Healing (Auto-rÃ©paration) :**
Si un nÅ“ud tombe, le systÃ¨me recrÃ©e automatiquement les replicas manquants sur d'autres nÅ“uds.

## Solutions de Stockage DistribuÃ© pour Kubernetes

Il existe plusieurs solutions de stockage distribuÃ©. Voici les principales :

### 1. Ceph (avec Rook)

**Description :**
- Solution de stockage distribuÃ© trÃ¨s mature
- UtilisÃ©e par les grandes entreprises
- GÃ©rÃ©e par Rook (orchestrateur Kubernetes pour Ceph)

**Avantages :**
- TrÃ¨s robuste et Ã©prouvÃ©e
- Supporte block, file et object storage
- Excellente performance
- TrÃ¨s scalable (jusqu'Ã  des milliers de nÅ“uds)

**InconvÃ©nients :**
- Complexe Ã  configurer
- Consomme beaucoup de ressources (RAM, CPU)
- Overkill pour un petit cluster

**RecommandÃ© pour :**
- Grandes entreprises
- Clusters de 10+ nÅ“uds
- Production Ã  grande Ã©chelle

### 2. Longhorn

**Description :**
- DÃ©veloppÃ© par Rancher (SUSE)
- ConÃ§u pour Ãªtre simple et lÃ©ger
- Interface web intÃ©grÃ©e

**Avantages :**
- **Simple Ã  installer et utiliser**
- Interface web intuitive
- LÃ©ger en ressources
- Backups intÃ©grÃ©s
- Parfait pour les petits/moyens clusters

**InconvÃ©nients :**
- Moins mature que Ceph
- Performance moyenne (suffisante pour la plupart des cas)

**RecommandÃ© pour :**
- **Homelabs et PME** â† NOTRE CAS
- Clusters de 3-20 nÅ“uds
- Applications standard

### 3. OpenEBS

**Description :**
- Stockage distribuÃ© cloud-native
- Plusieurs "storage engines" disponibles
- CNCF Sandbox project

**Avantages :**
- Flexible (plusieurs backends)
- IntÃ©gration Kubernetes native
- Bonnes performances

**InconvÃ©nients :**
- Configuration parfois complexe
- Documentation touffue

**RecommandÃ© pour :**
- Utilisateurs avancÃ©s
- Besoins spÃ©cifiques de performance

### 4. NFS (Network File System)

**Description :**
- Protocole de partage de fichiers rÃ©seau
- Ancien mais Ã©prouvÃ©
- NÃ©cessite un serveur NFS externe

**Avantages :**
- TrÃ¨s simple
- Compatible avec tout
- Pas besoin de ressources cluster

**InconvÃ©nients :**
- **Serveur NFS = Single Point of Failure**
- Pas de rÃ©plication intÃ©grÃ©e
- Performances variables
- Pas vraiment "distribuÃ©"

**RecommandÃ© pour :**
- Prototypes rapides
- Si vous avez dÃ©jÃ  un NAS/serveur NFS
- Environnements de test

### 5. GlusterFS

**Description :**
- SystÃ¨me de fichiers distribuÃ©
- Alternative Ã  Ceph

**Avantages :**
- Mature
- Pas d'architecture client-serveur (peer-to-peer)

**InconvÃ©nients :**
- Configuration complexe
- Moins activement dÃ©veloppÃ© qu'avant

**RecommandÃ© pour :**
- Cas spÃ©cifiques
- Utilisateurs expÃ©rimentÃ©s avec GlusterFS

## Choisir la Bonne Solution

### Tableau Comparatif

| Solution | ComplexitÃ© | Ressources | Performance | HA | RecommandÃ© pour |
|----------|-----------|------------|-------------|----|-----------------|
| **Longhorn** | â­ Faible | â­ Faible | â­â­â­ Bonne | âœ… Oui | **Homelabs, PME** |
| Ceph+Rook | â­â­â­ Ã‰levÃ©e | â­â­â­ Ã‰levÃ©e | â­â­â­â­ Excellente | âœ… Oui | Grandes entreprises |
| OpenEBS | â­â­ Moyenne | â­â­ Moyenne | â­â­â­ Bonne | âœ… Oui | Utilisateurs avancÃ©s |
| NFS | â­ Faible | â­ TrÃ¨s faible | â­â­ Moyenne | âŒ Non | Test/Dev |
| GlusterFS | â­â­â­ Ã‰levÃ©e | â­â­ Moyenne | â­â­â­ Bonne | âœ… Oui | Cas spÃ©cifiques |

### Recommandation pour Votre Cluster

**Pour un cluster MicroK8s 3-10 nÅ“uds (homelab, PME) :**

**â†’ Longhorn** est le choix idÃ©al :
- Installation simple
- Interface web claire
- Ressources raisonnables
- Parfait pour apprendre et produire

**Pour un cluster 10+ nÅ“uds (production enterprise) :**

**â†’ Ceph avec Rook** pour :
- Performance maximale
- ScalabilitÃ© illimitÃ©e
- Support enterprise

**Pour du prototypage rapide :**

**â†’ NFS** si vous avez dÃ©jÃ  un NAS

## Installer Longhorn sur MicroK8s

Nous allons installer **Longhorn** car c'est la solution la plus adaptÃ©e pour un cluster MicroK8s multi-node.

### PrÃ©requis

**Ressources minimales :**
- 3 nÅ“uds (pour la rÃ©plication)
- 2 GB RAM par nÅ“ud (en plus de ce qui tourne dÃ©jÃ )
- 10 GB d'espace disque libre par nÅ“ud

**Paquets systÃ¨me nÃ©cessaires :**

Sur **chaque nÅ“ud** du cluster :
```bash
# Installer les dÃ©pendances
sudo apt update
sudo apt install -y open-iscsi nfs-common

# DÃ©marrer et activer iSCSI (protocole utilisÃ© par Longhorn)
sudo systemctl enable --now iscsid
sudo systemctl status iscsid

# VÃ©rifier que le module kernel est chargÃ©
lsmod | grep iscsi
```

**VÃ©rifier l'espace disque disponible :**
```bash
df -h /var/lib/longhorn
```

### Installation de Longhorn

**MÃ©thode 1 : Via Helm (RecommandÃ©e)**

```bash
# 1. Activer Helm (si pas dÃ©jÃ  fait)
microk8s enable helm3

# 2. Ajouter le repo Longhorn
microk8s helm3 repo add longhorn https://charts.longhorn.io
microk8s helm3 repo update

# 3. Installer Longhorn
microk8s helm3 install longhorn longhorn/longhorn \
  --namespace longhorn-system \
  --create-namespace

# 4. Attendre que tous les pods soient prÃªts (peut prendre 2-5 minutes)
microk8s kubectl get pods -n longhorn-system -w
```

**MÃ©thode 2 : Via YAML**

```bash
# 1. TÃ©lÃ©charger le manifest
kubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/v1.5.3/deploy/longhorn.yaml

# 2. Attendre le dÃ©ploiement
microk8s kubectl get pods -n longhorn-system -w
```

### VÃ©rifier l'Installation

**Tous les pods doivent Ãªtre en Running :**
```bash
microk8s kubectl get pods -n longhorn-system
```

**Sortie attendue :**
```
NAME                                        READY   STATUS
csi-attacher-xxx                            1/1     Running
csi-provisioner-xxx                         1/1     Running
csi-resizer-xxx                             1/1     Running
csi-snapshotter-xxx                         1/1     Running
engine-image-ei-xxx                         1/1     Running
instance-manager-e-xxx                      1/1     Running
instance-manager-r-xxx                      1/1     Running
longhorn-csi-plugin-xxx                     2/2     Running
longhorn-driver-deployer-xxx                1/1     Running
longhorn-manager-xxx                        1/1     Running
longhorn-ui-xxx                             1/1     Running
```

**VÃ©rifier la StorageClass crÃ©Ã©e :**
```bash
microk8s kubectl get storageclass
```

```
NAME                 PROVISIONER          RECLAIMPOLICY
longhorn (default)   driver.longhorn.io   Delete
```

**ğŸ‰ Longhorn est installÃ© et prÃªt !**

### AccÃ©der Ã  l'Interface Web Longhorn

Longhorn fournit une interface web pour gÃ©rer le stockage.

**Option 1 : Port-forward (Simple)**
```bash
microk8s kubectl port-forward -n longhorn-system svc/longhorn-frontend 8080:80
```

Ouvrez votre navigateur : `http://localhost:8080`

**Option 2 : Service LoadBalancer (Avec MetalLB)**
```bash
# Ã‰diter le service
microk8s kubectl edit svc longhorn-frontend -n longhorn-system

# Changer "type: ClusterIP" en "type: LoadBalancer"
# Sauvegarder et quitter

# Obtenir l'IP
microk8s kubectl get svc -n longhorn-system longhorn-frontend
```

AccÃ©dez via l'IP externe attribuÃ©e par MetalLB.

**Option 3 : Ingress (RecommandÃ© pour production)**
```yaml
# longhorn-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: longhorn-ingress
  namespace: longhorn-system
  annotations:
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: basic-auth
spec:
  rules:
  - host: longhorn.yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: longhorn-frontend
            port:
              number: 80
```

**CrÃ©er un mot de passe :**
```bash
# CrÃ©er un fichier auth
sudo apt install -y apache2-utils
htpasswd -c auth admin

# CrÃ©er le secret
microk8s kubectl -n longhorn-system create secret generic basic-auth --from-file=auth

# Appliquer l'Ingress
microk8s kubectl apply -f longhorn-ingress.yaml
```

AccÃ©dez via `http://longhorn.yourdomain.com` (configurez le DNS).

## Utiliser le Stockage DistribuÃ©

### Concepts Kubernetes

Avant de crÃ©er des volumes, comprenons les concepts :

**PersistentVolume (PV) :**
- ReprÃ©sente un morceau de stockage dans le cluster
- CrÃ©Ã© par l'administrateur ou dynamiquement par une StorageClass
- IndÃ©pendant du cycle de vie d'un pod

**PersistentVolumeClaim (PVC) :**
- Demande de stockage par un utilisateur/application
- "Je veux 10 GB de stockage"
- LiÃ© automatiquement Ã  un PV disponible

**StorageClass :**
- DÃ©finit le "type" de stockage (performance, rÃ©plication, etc.)
- Permet le provisioning dynamique
- Longhorn crÃ©e automatiquement une StorageClass

**SchÃ©ma des relations :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Pod      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚     PVC      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚     PV       â”‚
â”‚              â”‚  utiliseâ”‚  (Demande)   â”‚   liÃ©   â”‚  (Stockage)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                                                          â”‚ crÃ©Ã© par
                                                          â–¼
                                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                   â”‚ StorageClass â”‚
                                                   â”‚  (Longhorn)  â”‚
                                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CrÃ©er un PVC et l'Utiliser

**Exemple : Base de donnÃ©es PostgreSQL avec stockage distribuÃ©**

**1. CrÃ©er un PVC :**
```yaml
# postgres-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
spec:
  accessModes:
    - ReadWriteOnce  # Un seul pod peut Ã©crire Ã  la fois
  storageClassName: longhorn  # Utiliser Longhorn
  resources:
    requests:
      storage: 10Gi  # Demander 10 GB
```

```bash
microk8s kubectl apply -f postgres-pvc.yaml
```

**VÃ©rifier le PVC :**
```bash
microk8s kubectl get pvc
```

```
NAME           STATUS   VOLUME                                     CAPACITY   STORAGECLASS
postgres-pvc   Bound    pvc-abc123-def456-ghi789                   10Gi       longhorn
```

**STATUS = Bound** â†’ Le PVC est liÃ© Ã  un PV crÃ©Ã© automatiquement par Longhorn ! âœ…

**2. CrÃ©er le Deployment PostgreSQL :**
```yaml
# postgres-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:15-alpine
        env:
        - name: POSTGRES_PASSWORD
          value: "monmotdepasse"
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        ports:
        - containerPort: 5432
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
      volumes:
      - name: postgres-storage
        persistentVolumeClaim:
          claimName: postgres-pvc  # â† Utiliser le PVC crÃ©Ã©
```

```bash
microk8s kubectl apply -f postgres-deployment.yaml
```

**VÃ©rifier le pod :**
```bash
microk8s kubectl get pods
```

```
NAME                        READY   STATUS    RESTARTS   AGE
postgres-xxxxxxxxxx-xxxxx   1/1     Running   0          30s
```

**3. Tester la rÃ©silience :**

**CrÃ©er une table dans la base :**
```bash
# Obtenir le nom du pod
POD_NAME=$(microk8s kubectl get pod -l app=postgres -o jsonpath="{.items[0].metadata.name}")

# Se connecter Ã  PostgreSQL
microk8s kubectl exec -it $POD_NAME -- psql -U postgres

# Dans psql:
CREATE TABLE test (id SERIAL PRIMARY KEY, data TEXT);
INSERT INTO test (data) VALUES ('Mon premier enregistrement');
SELECT * FROM test;
\q
```

**Simuler une panne : supprimer le pod**
```bash
microk8s kubectl delete pod $POD_NAME
```

Kubernetes recrÃ©e automatiquement le pod (Deployment avec replicas=1).

**VÃ©rifier que les donnÃ©es sont toujours lÃ  :**
```bash
# Attendre que le nouveau pod soit prÃªt
microk8s kubectl get pods -w

# Nouveau nom de pod
POD_NAME=$(microk8s kubectl get pod -l app=postgres -o jsonpath="{.items[0].metadata.name}")

# Se connecter
microk8s kubectl exec -it $POD_NAME -- psql -U postgres

# Dans psql:
SELECT * FROM test;
```

**Le rÃ©sultat est toujours lÃ  !** ğŸ‰

Les donnÃ©es ont survÃ©cu Ã  la suppression du pod grÃ¢ce au stockage distribuÃ©.

**4. Tester la mobilitÃ© :**

**Voir sur quel nÅ“ud le pod tourne :**
```bash
microk8s kubectl get pod $POD_NAME -o wide
```

```
NAME        NODE     STATUS
postgres-xxx node2   Running
```

**Drainer Node 2 (forcer le pod Ã  aller ailleurs) :**
```bash
microk8s kubectl drain node2 --ignore-daemonsets --delete-emptydir-data
```

Le pod est recrÃ©Ã© sur node1 ou node3.

**VÃ©rifier les donnÃ©es :**
```bash
# Nouveau pod sur un autre nÅ“ud
microk8s kubectl get pod -l app=postgres -o wide

# Se connecter et vÃ©rifier
microk8s kubectl exec -it <nouveau-pod> -- psql -U postgres -c "SELECT * FROM test;"
```

**Les donnÃ©es sont toujours accessibles !** Le pod a "suivi" ses donnÃ©es sur le nouveau nÅ“ud.

**5. LibÃ©rer les ressources :**
```bash
# Supprimer le deployment
microk8s kubectl delete deployment postgres

# Supprimer le PVC (et donc le PV)
microk8s kubectl delete pvc postgres-pvc
```

### Modes d'AccÃ¨s (Access Modes)

Quand vous crÃ©ez un PVC, vous devez spÃ©cifier le **mode d'accÃ¨s** :

**1. ReadWriteOnce (RWO) - Le plus courant**
- Volume montÃ© en lecture/Ã©criture par **un seul nÅ“ud** Ã  la fois
- Parfait pour : bases de donnÃ©es, applications stateful

**2. ReadOnlyMany (ROX)**
- Volume montÃ© en lecture seule par **plusieurs nÅ“uds** simultanÃ©ment
- Parfait pour : fichiers de configuration partagÃ©s, assets statiques

**3. ReadWriteMany (RWX)**
- Volume montÃ© en lecture/Ã©criture par **plusieurs nÅ“uds** simultanÃ©ment
- Parfait pour : applications qui partagent des fichiers (CMS, etc.)
- **Note :** Longhorn supporte RWX via NFS

**Tableau de support Longhorn :**
| Mode | SupportÃ© | Usage |
|------|----------|-------|
| RWO | âœ… Oui | Bases de donnÃ©es, apps standard |
| ROX | âœ… Oui | Config partagÃ©e en lecture |
| RWX | âœ… Oui (via NFS) | Partage de fichiers |

**Exemple RWX :**
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: shared-storage
spec:
  accessModes:
    - ReadWriteMany  # â† Plusieurs nÅ“uds peuvent Ã©crire
  storageClassName: longhorn
  resources:
    requests:
      storage: 20Gi
```

## Configuration AvancÃ©e de Longhorn

### RÃ©plication et Haute DisponibilitÃ©

Par dÃ©faut, Longhorn crÃ©e **3 replicas** de chaque volume (si vous avez 3+ nÅ“uds).

**VÃ©rifier dans l'interface web Longhorn :**
- Onglet "Volume" â†’ Cliquez sur un volume
- Section "Replicas" : vous verrez 3 replicas sur 3 nÅ“uds diffÃ©rents

**Modifier le nombre de replicas (via la StorageClass) :**
```yaml
# storageclass-longhorn-2replicas.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: longhorn-2replicas
provisioner: driver.longhorn.io
allowVolumeExpansion: true
parameters:
  numberOfReplicas: "2"  # â† 2 copies au lieu de 3
  staleReplicaTimeout: "2880"
```

```bash
microk8s kubectl apply -f storageclass-longhorn-2replicas.yaml
```

**Utiliser cette StorageClass :**
```yaml
spec:
  storageClassName: longhorn-2replicas
```

**Quand utiliser 2 replicas ?**
- Cluster de 2 nÅ“uds (pas le choix)
- Ã‰conomiser de l'espace disque
- DonnÃ©es moins critiques

**Quand utiliser 3+ replicas ?**
- Production (recommandÃ©)
- DonnÃ©es critiques
- Cluster de 3+ nÅ“uds

### Snapshots et Backups

**Longhorn supporte les snapshots (instantanÃ©s) et backups.**

**CrÃ©er un snapshot manuel :**
```bash
# Via l'interface web : Volume â†’ Actions â†’ Take Snapshot

# Ou via kubectl
microk8s kubectl apply -f - <<EOF
apiVersion: longhorn.io/v1beta2
kind: VolumeSnapshot
metadata:
  name: postgres-snapshot-1
  namespace: longhorn-system
spec:
  volumeName: pvc-abc123-def456-ghi789
EOF
```

**Restaurer depuis un snapshot :**
Dans l'interface web Longhorn :
1. Onglet "Volume"
2. SÃ©lectionner le volume
3. Onglet "Snapshot"
4. Cliquer sur "Revert" sur le snapshot souhaitÃ©

**Configurer des backups automatiques :**
Longhorn peut sauvegarder vers S3, NFS, etc.

```yaml
# Exemple : Backup vers NFS
apiVersion: v1
kind: Secret
metadata:
  name: backup-target
  namespace: longhorn-system
stringData:
  AWS_ACCESS_KEY_ID: ""
  AWS_SECRET_ACCESS_KEY: ""
  AWS_ENDPOINTS: ""
  BACKUP_TARGET: "nfs://192.168.1.100:/exports/backups"
```

Puis dans les settings Longhorn (interface web) :
- Backup Target : `nfs://192.168.1.100:/exports/backups`

**CrÃ©er un backup :**
Interface web â†’ Volume â†’ Actions â†’ Create Backup

### Performances et Tuning

**Optimisations possibles :**

**1. Utiliser des disques SSD**
Les performances de Longhorn dÃ©pendent des disques sous-jacents. Des SSD donnent de bien meilleures performances que des HDD.

**2. Ã‰viter l'overcommit**
Ne pas remplir les disques Ã  plus de 80%.

**3. Ajuster les ressources Longhorn**
```bash
# Ã‰diter les deployments Longhorn pour augmenter les ressources
microk8s kubectl edit deployment longhorn-manager -n longhorn-system

# Augmenter CPU/RAM si besoin
resources:
  limits:
    cpu: "1"
    memory: "1Gi"
  requests:
    cpu: "500m"
    memory: "512Mi"
```

**4. DÃ©sactiver la rÃ©plication pour les donnÃ©es temporaires**
Pour des caches ou logs, utilisez `numberOfReplicas: "1"`.

### Monitoring Longhorn

**MÃ©triques Prometheus :**
Longhorn expose des mÃ©triques Prometheus automatiquement.

**Si Prometheus est activÃ© :**
```bash
microk8s enable prometheus
```

Longhorn sera automatiquement scrappÃ©.

**MÃ©triques utiles :**
- `longhorn_volume_actual_size_bytes` : Taille rÃ©elle des volumes
- `longhorn_volume_usage_bytes` : Utilisation des volumes
- `longhorn_volume_robustness` : SantÃ© des volumes
- `longhorn_node_storage_capacity_bytes` : CapacitÃ© totale par nÅ“ud

**Dashboard Grafana pour Longhorn :**
ID: 13032 (sur grafana.com)

## Alternatives et Comparaisons

### Ceph avec Rook

**Si vous avez besoin de plus de puissance que Longhorn :**

```bash
# Installation Rook-Ceph (plus complexe)
microk8s kubectl apply -f https://raw.githubusercontent.com/rook/rook/release-1.12/deploy/examples/crds.yaml
microk8s kubectl apply -f https://raw.githubusercontent.com/rook/rook/release-1.12/deploy/examples/operator.yaml
microk8s kubectl apply -f https://raw.githubusercontent.com/rook/rook/release-1.12/deploy/examples/cluster.yaml
```

**Avantages sur Longhorn :**
- Meilleures performances
- Plus scalable
- Support object storage (S3-compatible)

**InconvÃ©nients :**
- Beaucoup plus complexe
- Consomme beaucoup plus de ressources
- Configuration longue

### NFS Simple

**Si vous voulez du prototypage rapide :**

**1. Configurer un serveur NFS (sur une machine sÃ©parÃ©e ou un NAS) :**
```bash
# Sur le serveur NFS
sudo apt install nfs-kernel-server
sudo mkdir -p /exports/k8s
sudo chown nobody:nogroup /exports/k8s
sudo chmod 777 /exports/k8s

# Ã‰diter /etc/exports
echo "/exports/k8s 192.168.1.0/24(rw,sync,no_subtree_check,no_root_squash)" | sudo tee -a /etc/exports

# Appliquer
sudo exportfs -ra
```

**2. Installer le provisioner NFS dans Kubernetes :**
```bash
microk8s enable community
microk8s enable nfs
```

**3. CrÃ©er une StorageClass NFS :**
```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs
provisioner: nfs.csi.k8s.io
parameters:
  server: 192.168.1.100  # IP du serveur NFS
  share: /exports/k8s
```

**Limitation :** Serveur NFS = SPOF (single point of failure). Pas de vraie HA.

## Bonnes Pratiques

### 1. Toujours Utiliser des PVC en Production

**âŒ Mauvais (stockage Ã©phÃ©mÃ¨re) :**
```yaml
volumes:
- name: data
  emptyDir: {}
```

DonnÃ©es perdues Ã  chaque redÃ©marrage du pod.

**âœ… Bon (stockage persistant) :**
```yaml
volumes:
- name: data
  persistentVolumeClaim:
    claimName: my-pvc
```

### 2. DÃ©finir des Resource Requests/Limits

**Sur le PVC :**
```yaml
resources:
  requests:
    storage: 10Gi  # QuantitÃ© demandÃ©e
```

**Sur les pods Longhorn :**
Assurez-vous que les pods Longhorn ont assez de ressources.

### 3. Surveiller l'Utilisation du Stockage

```bash
# Voir l'utilisation des PVC
microk8s kubectl get pvc

# DÃ©tails d'un PVC
microk8s kubectl describe pvc postgres-pvc
```

Dans l'interface Longhorn :
- Onglet "Node" â†’ Voir l'espace disque disponible sur chaque nÅ“ud
- Configurer des alertes quand < 20% d'espace libre

### 4. Faire des Backups RÃ©guliers

MÃªme avec la rÃ©plication, faire des backups hors cluster :
- Snapshots Longhorn rÃ©guliers
- Backups vers stockage externe (S3, NFS)
- Tests de restauration

**Automatiser avec CronJobs :**
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: longhorn-backup
spec:
  schedule: "0 2 * * *"  # Tous les jours Ã  2h du matin
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: longhornio/longhorn-manager
            command:
            - /bin/sh
            - -c
            - |
              # Script de backup
              kubectl -n longhorn-system exec deploy/longhorn-manager -- \
                longhorn-manager backup create --volume pvc-abc123
          restartPolicy: OnFailure
```

### 5. Nettoyer les PVC InutilisÃ©s

**Lister les PVC non utilisÃ©s :**
```bash
# PVC sans pod associÃ©
microk8s kubectl get pvc --all-namespaces
```

**Supprimer un PVC :**
```bash
microk8s kubectl delete pvc <nom-du-pvc>
```

**Attention :** La suppression d'un PVC supprime aussi le PV et donc **les donnÃ©es** (si `reclaimPolicy: Delete`).

### 6. Utiliser des Labels et Annotations

**Organiser vos PVC :**
```yaml
metadata:
  name: postgres-pvc
  labels:
    app: postgres
    environment: production
    backup: enabled
  annotations:
    description: "Stockage pour PostgreSQL production"
```

## DÃ©pannage

### ProblÃ¨me : PVC reste en "Pending"

**SymptÃ´me :**
```bash
microk8s kubectl get pvc
```
```
NAME           STATUS    VOLUME   CAPACITY
postgres-pvc   Pending
```

**Causes possibles :**

**1. Longhorn pas installÃ© ou pods pas prÃªts**
```bash
microk8s kubectl get pods -n longhorn-system
```

VÃ©rifier que tous les pods sont en `Running`.

**2. StorageClass incorrecte**
```bash
microk8s kubectl get storageclass
```

VÃ©rifier que la StorageClass existe.

**3. Pas assez d'espace disque**
```bash
df -h /var/lib/longhorn
```

LibÃ©rer de l'espace si nÃ©cessaire.

**4. Logs du provisioner**
```bash
microk8s kubectl logs -n longhorn-system -l app=longhorn-manager
```

### ProblÃ¨me : Volume en "Degraded"

**SymptÃ´me :**
Dans l'interface Longhorn, un volume apparaÃ®t en rouge/orange "Degraded".

**Cause :**
Un ou plusieurs replicas ne sont pas sains.

**Solution :**
1. Interface Longhorn â†’ Volume â†’ Voir les replicas
2. Identifier le replica dÃ©faillant
3. Supprimer le replica dÃ©faillant (il sera recrÃ©Ã© automatiquement)
4. Ou redÃ©marrer le nÅ“ud problÃ©matique

### ProblÃ¨me : Performances Lentes

**Diagnostic :**

**1. VÃ©rifier les disques sous-jacents**
```bash
# Test de performance I/O
sudo apt install fio
fio --name=randwrite --ioengine=libaio --iodepth=16 --rw=randwrite --bs=4k --direct=1 --size=1G --numjobs=4 --runtime=60 --group_reporting --filename=/var/lib/longhorn/test
```

**2. VÃ©rifier la latence rÃ©seau**
```bash
ping -c 100 <autre-noeud>
```

Si > 10ms de latence moyenne ou > 1% de paquets perdus â†’ problÃ¨me rÃ©seau.

**3. VÃ©rifier les ressources Longhorn**
```bash
microk8s kubectl top pods -n longhorn-system
```

Si CPU/RAM saturÃ©s, augmenter les ressources.

**Solutions :**
- Utiliser des SSD au lieu de HDD
- Optimiser le rÃ©seau (switch Gigabit, cables Cat6)
- RÃ©duire le nombre de replicas (de 3 Ã  2) pour les donnÃ©es moins critiques

### ProblÃ¨me : NÅ“ud Plein

**SymptÃ´me :**
```
Events:
  Warning  FailedScheduling  pod/xxx: 0/3 nodes available: insufficient storage
```

**Solution :**

**1. Voir l'espace par nÅ“ud (interface Longhorn)**
Onglet "Node"

**2. Nettoyer les anciens snapshots**
Interface Longhorn â†’ Volume â†’ Snapshots â†’ Supprimer les vieux

**3. Augmenter la capacitÃ©**
- Ajouter un disque supplÃ©mentaire sur un nÅ“ud
- Ajouter un nouveau nÅ“ud

**4. Configurer l'overprovisioning**
Par dÃ©faut, Longhorn rÃ©serve 25% d'espace libre. Vous pouvez le rÃ©duire (non recommandÃ© en production).

Settings â†’ `Storage Over Provisioning Percentage`

## Points ClÃ©s Ã  Retenir

1. **Stockage local** = liÃ© Ã  un nÅ“ud, pas de rÃ©silience
2. **Stockage distribuÃ©** = donnÃ©es rÃ©pliquÃ©es, accessibles depuis n'importe quel nÅ“ud
3. **Longhorn** = solution idÃ©ale pour homelabs et PME (simple, lÃ©ger, efficace)
4. **3 replicas** par dÃ©faut = haute disponibilitÃ©
5. **PVC** = demande de stockage, **PV** = stockage rÃ©el
6. **RWO** = un pod Ã  la fois (DB), **RWX** = plusieurs pods (partage de fichiers)
7. **Interface web** Longhorn = gestion facile, snapshots, backups
8. **Monitoring** = surveiller l'espace disque et les volumes degraded
9. **Backups** = mÃªme avec rÃ©plication, toujours faire des backups externes
10. **SSD recommandÃ©** pour de bonnes performances

## Prochaines Ã‰tapes

Vous maÃ®trisez maintenant le stockage distribuÃ© ! Les prochains chapitres couvriront :

- **21.8** : Backup du control plane et stratÃ©gies de sauvegarde complÃ¨tes
- **21.9** : StratÃ©gies de redondance avancÃ©es
- **21.10** : Tests de failover et validation de la rÃ©silience

Avec Longhorn, vos applications stateful peuvent maintenant profiter de la haute disponibilitÃ© et de la rÃ©silience du cluster multi-node ! ğŸš€

---

**FÃ©licitations !** Vous savez maintenant configurer et gÃ©rer du stockage distribuÃ© dans votre cluster Kubernetes. C'est la derniÃ¨re piÃ¨ce du puzzle pour avoir un cluster multi-node vÃ©ritablement rÃ©silient et prÃªt pour la production !

â­ï¸ [Backup du control plane](/21-multi-node-et-haute-disponibilite/08-backup-du-control-plane.md)
