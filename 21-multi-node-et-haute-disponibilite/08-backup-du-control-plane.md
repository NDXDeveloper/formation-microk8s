ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 21.8 Backup du Control Plane

## Introduction

Vous avez construit un cluster multi-node rÃ©silient avec haute disponibilitÃ©, load balancing et stockage distribuÃ©. Mais il reste une question cruciale : **que se passe-t-il si tout le cluster est perdu ?** Incendie, catastrophe naturelle, erreur humaine massive, corruption de donnÃ©es...

C'est lÃ  qu'intervient le **backup du control plane**. Dans ce chapitre, nous allons apprendre Ã  :
- Sauvegarder l'Ã©tat complet de votre cluster
- Comprendre ce qui doit Ãªtre sauvegardÃ© et pourquoi
- Mettre en place des backups automatiques
- Restaurer un cluster depuis un backup
- Tester rÃ©guliÃ¨rement vos sauvegardes
- Ã‰laborer un plan de reprise d'activitÃ© (DRP)

Le backup du control plane est votre **derniÃ¨re ligne de dÃ©fense**. MÃªme avec la haute disponibilitÃ©, vous devez pouvoir reconstruire votre cluster depuis zÃ©ro si nÃ©cessaire.

**RÃ¨gle d'or :** Les backups ne valent rien sans tests de restauration rÃ©guliers.

## Pourquoi Sauvegarder le Control Plane ?

### Les Risques Sans Backup

**ScÃ©nario 1 : Erreur Humaine**
```bash
# Oups... mauvaise commande
microk8s kubectl delete namespace production --force
```
Sans backup : Tous vos dÃ©ploiements, services, ConfigMaps, Secrets de production sont **dÃ©finitivement perdus**.

**ScÃ©nario 2 : Corruption de Dqlite**
Un bug, une panne Ã©lectrique au mauvais moment, un disque dÃ©faillant â†’ la base de donnÃ©es Dqlite est corrompue. Le cluster ne dÃ©marre plus.

**ScÃ©nario 3 : Catastrophe Physique**
Incendie, inondation, vol du matÃ©riel â†’ tous les nÅ“uds sont perdus.

**ScÃ©nario 4 : Ransomware**
Attaque qui chiffre les donnÃ©es du cluster. Sans backup externe, tout est perdu.

**ScÃ©nario 5 : Mise Ã  Jour RatÃ©e**
Une mise Ã  jour de Kubernetes casse le cluster. Impossible de revenir en arriÃ¨re sans backup.

### Ce Que Vous Perdez Sans Backup

**Ã‰tat du cluster :**
- Tous les Deployments, StatefulSets, DaemonSets
- Tous les Services (ClusterIP, NodePort, LoadBalancer)
- Tous les ConfigMaps et Secrets
- Tous les Ingress et rÃ¨gles rÃ©seau
- Tous les RBAC (rÃ´les, permissions)
- Tous les CRDs (Custom Resource Definitions)
- Configuration des addons

**DonnÃ©es applicatives :**
- Volumes persistants (si pas de backup sÃ©parÃ©)
- Bases de donnÃ©es
- Fichiers uploadÃ©s par les utilisateurs

**Configuration cluster :**
- Settings Kubernetes
- Configuration des nÅ“uds
- Historique des dÃ©ploiements

### La Haute DisponibilitÃ© N'est PAS un Backup

**HA protÃ¨ge contre :** Panne d'un nÅ“ud, crash d'un pod
**Backup protÃ¨ge contre :** Perte totale du cluster, erreurs humaines, corruption de donnÃ©es

**Analogie :**
- HA = avoir plusieurs voitures (si une tombe en panne, vous en avez une autre)
- Backup = avoir une assurance tous risques (si toutes vos voitures brÃ»lent, vous pouvez en racheter)

**Les deux sont complÃ©mentaires, pas alternatifs !**

## Qu'est-ce Qui Doit ÃŠtre SauvegardÃ© ?

### 1. Ã‰tat du Control Plane (Dqlite)

**Dqlite contient TOUT l'Ã©tat du cluster :**
- DÃ©finitions de tous les objets Kubernetes
- ConfigMaps et Secrets
- Ã‰tat actuel vs Ã©tat dÃ©sirÃ©
- Historique des changements

**Emplacement :** `/var/snap/microk8s/current/var/kubernetes/backend/`

**C'est la sauvegarde la plus critique !**

### 2. Configurations et Certificats

**Fichiers importants :**
- Certificats TLS du cluster
- Configuration kubeconfig
- Tokens d'authentification
- Configuration des addons

**Emplacements :**
- `/var/snap/microk8s/current/credentials/`
- `/var/snap/microk8s/current/certs/`
- `/var/snap/microk8s/current/args/`

### 3. DÃ©finitions YAML

**Best practice :** Stocker tous vos manifestes YAML dans Git (GitOps).

Si vous dÃ©ployez toujours avec `kubectl apply -f` sans conserver les YAML, vous ne pourrez pas recrÃ©er vos applications.

**Solution recommandÃ©e :**
```
ğŸ“ git-repo/
  ğŸ“ kubernetes/
    ğŸ“ apps/
      ğŸ“„ deployment-app1.yaml
      ğŸ“„ service-app1.yaml
    ğŸ“ configs/
      ğŸ“„ configmap-app1.yaml
      ğŸ“„ secret-app1.yaml
    ğŸ“ ingress/
      ğŸ“„ ingress-rules.yaml
```

Commitez chaque changement dans Git â†’ backup automatique.

### 4. Volumes Persistants

**Les PV contiennent les donnÃ©es applicatives :**
- Bases de donnÃ©es
- Uploads utilisateurs
- Logs applicatifs

**Avec Longhorn :** Utiliser les snapshots et backups intÃ©grÃ©s (vu au chapitre 21.7)

**Sans stockage distribuÃ© :** Backups manuels ou avec des outils comme Velero.

### 5. Configuration des NÅ“uds

**Moins critique mais utile :**
- Configuration rÃ©seau (`/etc/netplan/`)
- Configuration firewall
- Packages installÃ©s
- Configuration MicroK8s

**Architecture de Backup ComplÃ¨te :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            STRATÃ‰GIE DE BACKUP COMPLÃˆTE            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  1. Control Plane (Dqlite)                         â”‚
â”‚     â†’ Backup quotidien                             â”‚
â”‚     â†’ RÃ©tention: 7 jours                           â”‚
â”‚     â†’ Stockage externe                             â”‚
â”‚                                                    â”‚
â”‚  2. Manifestes YAML                                â”‚
â”‚     â†’ Git (push Ã  chaque changement)               â”‚
â”‚     â†’ GitHub/GitLab                                â”‚
â”‚                                                    â”‚
â”‚  3. Volumes Persistants                            â”‚
â”‚     â†’ Snapshots Longhorn (quotidien)               â”‚
â”‚     â†’ Backup vers S3/NFS (hebdomadaire)            â”‚
â”‚     â†’ RÃ©tention: 30 jours                          â”‚
â”‚                                                    â”‚
â”‚  4. Secrets et Certificats                         â”‚
â”‚     â†’ Backup chiffrÃ© mensuel                       â”‚
â”‚     â†’ Stockage offline (USB, coffre)               â”‚
â”‚                                                    â”‚
â”‚  5. Configuration des NÅ“uds                        â”‚
â”‚     â†’ Documentation + scripts                      â”‚
â”‚     â†’ Git repository                               â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## MÃ©thodes de Backup du Control Plane

### MÃ©thode 1 : Backup Manuel Complet

**Cette mÃ©thode sauvegarde tout l'Ã©tat du cluster en quelques commandes.**

**Sur un nÅ“ud du control plane (node1, node2 ou node3) :**

```bash
#!/bin/bash
# backup-cluster-manual.sh

# Variables
BACKUP_DIR="/backups/microk8s"
TIMESTAMP=$(date +%Y%m%d-%H%M%S)
BACKUP_PATH="$BACKUP_DIR/backup-$TIMESTAMP"

# CrÃ©er le rÃ©pertoire de backup
mkdir -p "$BACKUP_PATH"

echo "=== DÃ©but du backup MicroK8s ==="
echo "Date: $(date)"
echo "Backup dans: $BACKUP_PATH"

# 1. ArrÃªter MicroK8s (optionnel, mais garantit la cohÃ©rence)
echo "ArrÃªt de MicroK8s..."
microk8s stop

# 2. Backup de Dqlite (base de donnÃ©es du cluster)
echo "Backup de Dqlite..."
sudo cp -r /var/snap/microk8s/current/var/kubernetes/backend "$BACKUP_PATH/dqlite"

# 3. Backup des certificats et credentials
echo "Backup des certificats..."
sudo cp -r /var/snap/microk8s/current/credentials "$BACKUP_PATH/credentials"
sudo cp -r /var/snap/microk8s/current/certs "$BACKUP_PATH/certs"

# 4. Backup de la configuration
echo "Backup de la configuration..."
sudo cp -r /var/snap/microk8s/current/args "$BACKUP_PATH/args"

# 5. Backup de la version MicroK8s
echo "Backup de la version..."
snap list microk8s > "$BACKUP_PATH/microk8s-version.txt"

# 6. RedÃ©marrer MicroK8s
echo "RedÃ©marrage de MicroK8s..."
microk8s start
microk8s status --wait-ready

# 7. Export de tous les objets Kubernetes (backup logique)
echo "Export des objets Kubernetes..."
microk8s kubectl get all --all-namespaces -o yaml > "$BACKUP_PATH/all-resources.yaml"
microk8s kubectl get configmap --all-namespaces -o yaml > "$BACKUP_PATH/configmaps.yaml"
microk8s kubectl get secret --all-namespaces -o yaml > "$BACKUP_PATH/secrets.yaml"
microk8s kubectl get pvc --all-namespaces -o yaml > "$BACKUP_PATH/pvcs.yaml"
microk8s kubectl get ingress --all-namespaces -o yaml > "$BACKUP_PATH/ingress.yaml"

# 8. Compresser le backup
echo "Compression du backup..."
cd "$BACKUP_DIR"
tar -czf "backup-$TIMESTAMP.tar.gz" "backup-$TIMESTAMP"

# 9. Nettoyer le rÃ©pertoire non compressÃ©
rm -rf "backup-$TIMESTAMP"

# 10. Copier vers un stockage externe (optionnel)
# scp "backup-$TIMESTAMP.tar.gz" user@backup-server:/backups/
# ou
# rclone copy "backup-$TIMESTAMP.tar.gz" s3:mybucket/microk8s-backups/

echo "=== Backup terminÃ© ==="
echo "Fichier: $BACKUP_DIR/backup-$TIMESTAMP.tar.gz"
echo "Taille: $(du -h "$BACKUP_DIR/backup-$TIMESTAMP.tar.gz" | cut -f1)"
```

**Rendre le script exÃ©cutable et le lancer :**
```bash
chmod +x backup-cluster-manual.sh
sudo ./backup-cluster-manual.sh
```

**Avantages :**
- Simple et rapide
- Backup complet
- Pas de dÃ©pendances externes

**InconvÃ©nients :**
- NÃ©cessite l'arrÃªt de MicroK8s (quelques secondes)
- Manuel (sauf si automatisÃ© avec cron)
- Backup "froid" (point dans le temps)

### MÃ©thode 2 : Backup Ã  Chaud (Sans ArrÃªt)

**Pour Ã©viter l'arrÃªt du cluster :**

```bash
#!/bin/bash
# backup-cluster-hot.sh

BACKUP_DIR="/backups/microk8s"
TIMESTAMP=$(date +%Y%m%d-%H%M%S)
BACKUP_PATH="$BACKUP_DIR/backup-$TIMESTAMP"

mkdir -p "$BACKUP_PATH"

echo "=== Backup Ã  chaud MicroK8s ==="

# 1. Backup logique via kubectl (sans arrÃªt)
microk8s kubectl get all --all-namespaces -o yaml > "$BACKUP_PATH/all-resources.yaml"
microk8s kubectl get configmap --all-namespaces -o yaml > "$BACKUP_PATH/configmaps.yaml"
microk8s kubectl get secret --all-namespaces -o yaml > "$BACKUP_PATH/secrets.yaml"
microk8s kubectl get pvc --all-namespaces -o yaml > "$BACKUP_PATH/pvcs.yaml"
microk8s kubectl get pv -o yaml > "$BACKUP_PATH/pvs.yaml"
microk8s kubectl get storageclass -o yaml > "$BACKUP_PATH/storageclasses.yaml"
microk8s kubectl get ingress --all-namespaces -o yaml > "$BACKUP_PATH/ingress.yaml"
microk8s kubectl get networkpolicy --all-namespaces -o yaml > "$BACKUP_PATH/networkpolicies.yaml"

# 2. Backup des CRDs et namespaces
microk8s kubectl get crd -o yaml > "$BACKUP_PATH/crds.yaml"
microk8s kubectl get namespace -o yaml > "$BACKUP_PATH/namespaces.yaml"

# 3. Backup de la version
snap list microk8s > "$BACKUP_PATH/microk8s-version.txt"

# 4. Compression
cd "$BACKUP_DIR"
tar -czf "backup-hot-$TIMESTAMP.tar.gz" "backup-$TIMESTAMP"
rm -rf "backup-$TIMESTAMP"

echo "=== Backup Ã  chaud terminÃ© ==="
echo "Fichier: $BACKUP_DIR/backup-hot-$TIMESTAMP.tar.gz"
```

**Avantages :**
- Pas d'arrÃªt du cluster
- Peut tourner en production
- Automatisable facilement

**InconvÃ©nients :**
- Ne backup pas Dqlite directement (backup logique uniquement)
- LÃ©gÃ¨rement moins fiable qu'un backup Ã  froid

### MÃ©thode 3 : Velero (RecommandÃ© pour Production)

**Velero est l'outil de backup standard pour Kubernetes.**

**FonctionnalitÃ©s :**
- Backups automatiques programmÃ©s
- Restauration sÃ©lective
- Migration de clusters
- Backup des volumes persistants
- Interface CLI conviviale

#### Installation de Velero

**1. Installer le CLI Velero sur votre machine :**
```bash
# Linux
wget https://github.com/vmware-tanzu/velero/releases/download/v1.12.0/velero-v1.12.0-linux-amd64.tar.gz
tar -xvf velero-v1.12.0-linux-amd64.tar.gz
sudo mv velero-v1.12.0-linux-amd64/velero /usr/local/bin/
velero version --client-only

# macOS
brew install velero

# VÃ©rifier
velero version --client-only
```

**2. Configurer un backend de stockage (exemple avec MinIO local) :**

**Installer MinIO dans le cluster :**
```bash
# CrÃ©er un namespace
microk8s kubectl create namespace velero

# Installer MinIO
microk8s kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: minio
  namespace: velero
spec:
  replicas: 1
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      containers:
      - name: minio
        image: minio/minio:latest
        args:
        - server
        - /data
        env:
        - name: MINIO_ROOT_USER
          value: "minio"
        - name: MINIO_ROOT_PASSWORD
          value: "minio123"
        ports:
        - containerPort: 9000
        volumeMounts:
        - name: data
          mountPath: /data
      volumes:
      - name: data
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: minio
  namespace: velero
spec:
  type: ClusterIP
  ports:
  - port: 9000
    targetPort: 9000
  selector:
    app: minio
EOF
```

**3. CrÃ©er un bucket dans MinIO :**
```bash
# Port-forward vers MinIO
microk8s kubectl port-forward -n velero svc/minio 9000:9000 &

# Installer le client MinIO
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc
sudo mv mc /usr/local/bin/

# Configurer
mc alias set minio http://localhost:9000 minio minio123

# CrÃ©er le bucket
mc mb minio/velero
```

**4. CrÃ©er un fichier de credentials pour Velero :**
```bash
cat > credentials-velero <<EOF
[default]
aws_access_key_id = minio
aws_secret_access_key = minio123
EOF
```

**5. Installer Velero dans le cluster :**
```bash
velero install \
  --provider aws \
  --plugins velero/velero-plugin-for-aws:v1.8.0 \
  --bucket velero \
  --secret-file ./credentials-velero \
  --use-volume-snapshots=false \
  --backup-location-config region=minio,s3ForcePathStyle="true",s3Url=http://minio.velero.svc:9000
```

**VÃ©rifier l'installation :**
```bash
microk8s kubectl get pods -n velero
```

```
NAME                     READY   STATUS
velero-xxxxxxxxxx-xxxxx  1/1     Running
```

#### Utiliser Velero

**CrÃ©er un backup complet :**
```bash
velero backup create backup-complet-$(date +%Y%m%d)
```

**Voir les backups :**
```bash
velero backup get
```

**CrÃ©er un backup d'un namespace spÃ©cifique :**
```bash
velero backup create backup-production --include-namespaces production
```

**Programmer un backup quotidien :**
```bash
velero schedule create daily-backup --schedule="0 2 * * *"
```

Backup quotidien Ã  2h du matin.

**Restaurer depuis un backup :**
```bash
# Lister les backups
velero backup get

# Restaurer
velero restore create --from-backup backup-complet-20250101
```

**Voir le statut de la restauration :**
```bash
velero restore get
velero restore describe <nom-restore>
```

**Avantages de Velero :**
- Standard de l'industrie
- Backups automatiques programmÃ©s
- Restauration granulaire (namespace, labels, etc.)
- Support des volumes persistants
- Migration de clusters facilitÃ©e

**InconvÃ©nients :**
- Plus complexe Ã  configurer
- NÃ©cessite un backend S3-compatible
- Consomme des ressources

## Automatisation des Backups

### CronJob Kubernetes pour Backup Quotidien

**CrÃ©er un CronJob qui exÃ©cute un backup tous les jours :**

```yaml
# cronjob-backup.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cluster-backup
  namespace: kube-system
spec:
  schedule: "0 2 * * *"  # Tous les jours Ã  2h du matin
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: backup-sa
          containers:
          - name: backup
            image: bitnami/kubectl:latest
            command:
            - /bin/bash
            - -c
            - |
              set -e
              TIMESTAMP=$(date +%Y%m%d-%H%M%S)
              BACKUP_DIR="/backups/backup-$TIMESTAMP"

              mkdir -p $BACKUP_DIR

              # Export de tous les objets
              kubectl get all --all-namespaces -o yaml > $BACKUP_DIR/all-resources.yaml
              kubectl get configmap --all-namespaces -o yaml > $BACKUP_DIR/configmaps.yaml
              kubectl get secret --all-namespaces -o yaml > $BACKUP_DIR/secrets.yaml
              kubectl get pvc --all-namespaces -o yaml > $BACKUP_DIR/pvcs.yaml
              kubectl get ingress --all-namespaces -o yaml > $BACKUP_DIR/ingress.yaml
              kubectl get crd -o yaml > $BACKUP_DIR/crds.yaml

              # Compresser
              cd /backups
              tar -czf backup-$TIMESTAMP.tar.gz backup-$TIMESTAMP
              rm -rf backup-$TIMESTAMP

              echo "Backup crÃ©Ã©: backup-$TIMESTAMP.tar.gz"

              # Copier vers stockage externe (exemple NFS)
              # cp backup-$TIMESTAMP.tar.gz /mnt/nfs-backup/

              # Nettoyer les anciens backups (garder 7 jours)
              find /backups -name "backup-*.tar.gz" -mtime +7 -delete

            volumeMounts:
            - name: backup-storage
              mountPath: /backups
          restartPolicy: OnFailure
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: backup-pvc
  namespace: kube-system
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: longhorn
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: backup-sa
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: backup-role
rules:
- apiGroups: ["*"]
  resources: ["*"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: backup-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: backup-role
subjects:
- kind: ServiceAccount
  name: backup-sa
  namespace: kube-system
```

**Appliquer :**
```bash
microk8s kubectl apply -f cronjob-backup.yaml
```

**VÃ©rifier les CronJobs :**
```bash
microk8s kubectl get cronjob -n kube-system
```

**DÃ©clencher manuellement (pour tester) :**
```bash
microk8s kubectl create job --from=cronjob/cluster-backup manual-backup-1 -n kube-system
```

**Voir les logs :**
```bash
microk8s kubectl logs -n kube-system job/manual-backup-1
```

### Script Cron sur le Serveur

**Alternative : Cron classique sur un nÅ“ud du cluster :**

```bash
# Ã‰diter la crontab
sudo crontab -e

# Ajouter la ligne
0 2 * * * /usr/local/bin/backup-cluster-manual.sh >> /var/log/microk8s-backup.log 2>&1
```

Backup tous les jours Ã  2h du matin, logs dans `/var/log/microk8s-backup.log`.

## Restauration depuis un Backup

### ScÃ©nario 1 : Restauration ComplÃ¨te (Cluster Perdu)

**Situation :** Tous les nÅ“uds sont perdus, vous devez reconstruire le cluster depuis zÃ©ro.

**Ã‰tapes :**

**1. Reconstruire l'infrastructure :**
```bash
# Sur 3 nouvelles machines (node1, node2, node3)
# Installer MicroK8s (mÃªme version que le backup)

# Sur chaque nÅ“ud
sudo snap install microk8s --classic --channel=1.28/stable
```

**2. Former le cluster HA :**
```bash
# Sur node1
microk8s add-node

# Sur node2
microk8s join <token>

# Sur node1
microk8s add-node

# Sur node3
microk8s join <token>
```

**3. Restaurer les addons de base :**
```bash
microk8s enable dns
microk8s enable storage
```

**4. Restaurer depuis le backup YAML :**
```bash
# Copier le backup sur node1
scp backup-20250101.tar.gz node1:/tmp/

# Sur node1, extraire
cd /tmp
tar -xzf backup-20250101.tar.gz
cd backup-20250101

# Restaurer les namespaces d'abord
microk8s kubectl apply -f namespaces.yaml

# Restaurer les CRDs
microk8s kubectl apply -f crds.yaml

# Attendre que les CRDs soient prÃªts
sleep 10

# Restaurer les ConfigMaps et Secrets
microk8s kubectl apply -f configmaps.yaml
microk8s kubectl apply -f secrets.yaml

# Restaurer les StorageClasses
microk8s kubectl apply -f storageclasses.yaml

# Restaurer les PVCs
microk8s kubectl apply -f pvcs.yaml

# Restaurer les ressources applicatives
microk8s kubectl apply -f all-resources.yaml

# Restaurer les Ingress
microk8s kubectl apply -f ingress.yaml
```

**5. VÃ©rifier la restauration :**
```bash
microk8s kubectl get all --all-namespaces
microk8s kubectl get pvc --all-namespaces
```

**6. Restaurer les donnÃ©es des volumes (si sauvegardÃ©s sÃ©parÃ©ment) :**
Avec Longhorn : restaurer depuis les snapshots/backups Longhorn.

### ScÃ©nario 2 : Restauration Partielle (Namespace SupprimÃ©)

**Situation :** Vous avez accidentellement supprimÃ© le namespace `production`.

**Avec un backup YAML :**
```bash
# Extraire le backup
tar -xzf backup-20250101.tar.gz
cd backup-20250101

# Filtrer uniquement le namespace production
grep -A 10000 "namespace: production" all-resources.yaml > production-only.yaml

# Restaurer
microk8s kubectl apply -f production-only.yaml
```

**Avec Velero :**
```bash
# Restaurer uniquement le namespace production
velero restore create restore-production \
  --from-backup backup-complet-20250101 \
  --include-namespaces production
```

### ScÃ©nario 3 : Restauration de Dqlite (Backup Physique)

**Si vous avez un backup de Dqlite (mÃ©thode 1 - backup Ã  froid) :**

```bash
# 1. ArrÃªter MicroK8s sur TOUS les nÅ“uds
# Sur node1, node2, node3
microk8s stop

# 2. Sur un nÅ“ud, restaurer Dqlite
sudo rm -rf /var/snap/microk8s/current/var/kubernetes/backend
sudo cp -r /path/to/backup/dqlite /var/snap/microk8s/current/var/kubernetes/backend

# 3. Restaurer les certificats (si nÃ©cessaire)
sudo cp -r /path/to/backup/credentials/* /var/snap/microk8s/current/credentials/
sudo cp -r /path/to/backup/certs/* /var/snap/microk8s/current/certs/

# 4. RedÃ©marrer MicroK8s sur tous les nÅ“uds
microk8s start
microk8s status --wait-ready

# 5. VÃ©rifier
microk8s kubectl get nodes
microk8s kubectl get all --all-namespaces
```

**âš ï¸ Cette mÃ©thode est risquÃ©e et doit Ãªtre testÃ©e en environnement de dev d'abord !**

## Tests de Restauration

### Pourquoi Tester ?

**Statistique effrayante :** 34% des entreprises dÃ©couvrent que leurs backups sont corrompus ou incomplets... **lors d'une vraie catastrophe**.

**Un backup non testÃ© n'est pas un backup.**

### Processus de Test RecommandÃ©

**FrÃ©quence :** Tous les trimestres (4 fois par an minimum).

**Processus :**

**1. Environnement de test isolÃ©**
Utilisez un cluster sÃ©parÃ© ou des VMs temporaires.

**2. Simulation de panne**
```bash
# Sur le cluster de test
microk8s kubectl delete namespace production
# Ou pire : supprimer tous les nÅ“uds
```

**3. Restauration depuis le backup**
Suivez la procÃ©dure de restauration complÃ¨te.

**4. Validation**
```bash
# VÃ©rifier que tout fonctionne
microk8s kubectl get all --all-namespaces
microk8s kubectl get pvc --all-namespaces

# Tester l'accÃ¨s aux applications
curl http://<app-url>

# VÃ©rifier les donnÃ©es
# Se connecter Ã  la DB et vÃ©rifier les tables
```

**5. Mesurer le RTO et RPO**
- **RTO** (Recovery Time Objective) : Temps pour restaurer
- **RPO** (Recovery Point Objective) : Perte de donnÃ©es acceptable

Exemple :
- RTO = 2 heures (restauration complÃ¨te en 2h)
- RPO = 24 heures (backup quotidien, perte max = 1 jour de donnÃ©es)

**6. Documenter**
Notez :
- Temps de restauration rÃ©el
- ProblÃ¨mes rencontrÃ©s
- DonnÃ©es perdues/non restaurÃ©es
- AmÃ©liorations nÃ©cessaires

### Checklist de Test de Restauration

```markdown
# Test de Restauration - [DATE]

## PrÃ©paration
- [ ] Backup rÃ©cent disponible
- [ ] Environnement de test prÃªt
- [ ] Documentation Ã  jour

## Restauration
- [ ] Extraction du backup : OK
- [ ] Reconstruction du cluster : OK (temps: ___ min)
- [ ] Restauration des namespaces : OK
- [ ] Restauration des CRDs : OK
- [ ] Restauration des ConfigMaps/Secrets : OK
- [ ] Restauration des PVCs : OK
- [ ] Restauration des applications : OK

## Validation
- [ ] Tous les pods en Running
- [ ] Services accessibles
- [ ] DonnÃ©es intÃ¨gres
- [ ] Ingress fonctionnel
- [ ] Monitoring opÃ©rationnel

## MÃ©triques
- Temps total : ___ heures
- DonnÃ©es perdues : ___ (aucune/quelques/beaucoup)
- ProblÃ¨mes majeurs : ___

## Actions
- [ ] Documenter les problÃ¨mes
- [ ] Mettre Ã  jour la procÃ©dure
- [ ] AmÃ©liorer les backups si nÃ©cessaire

## RÃ©sultat
- [ ] âœ… SuccÃ¨s complet
- [ ] âš ï¸ SuccÃ¨s avec rÃ©serves
- [ ] âŒ Ã‰chec (raison: ___)
```

## Plan de Reprise d'ActivitÃ© (DRP)

### Qu'est-ce qu'un DRP ?

Un **Disaster Recovery Plan** (Plan de Reprise d'ActivitÃ©) est un document qui dÃ©crit :
- Quoi faire en cas de catastrophe
- Qui fait quoi
- Dans quel ordre
- En combien de temps

### Structure d'un DRP SimplifiÃ©

```markdown
# Plan de Reprise d'ActivitÃ© - Cluster Kubernetes

## 1. Contact d'Urgence
- Admin principal : Jean Dupont - 06 XX XX XX XX
- Admin secondaire : Marie Martin - 06 YY YY YY YY
- Support : support@example.com

## 2. Localisation des Backups
- Backups quotidiens : /backups/microk8s/ sur node1
- Backups hebdomadaires : NFS 192.168.1.100:/exports/backups
- Backups mensuels : S3 bucket s3://company-backups/kubernetes/
- Manifestes YAML : GitHub https://github.com/company/k8s-configs

## 3. Inventaire du Cluster
- 3 nÅ“uds : node1 (192.168.1.10), node2 (.11), node3 (.12)
- Version MicroK8s : 1.28/stable
- Addons critiques : dns, storage, ingress, cert-manager, metallb, longhorn
- Applications critiques : production (namespace), database (namespace)

## 4. ProcÃ©dure de Restauration ComplÃ¨te

### Ã‰tape 1 : Ã‰valuation (30 min)
- Identifier l'Ã©tendue du sinistre
- VÃ©rifier la disponibilitÃ© des backups
- Mobiliser l'Ã©quipe

### Ã‰tape 2 : Reconstruction Infrastructure (1h)
- Provisionner 3 nouvelles machines
- Installer Ubuntu 22.04
- Configurer rÃ©seau (IPs statiques)
- Installer MicroK8s (version : voir backup)

### Ã‰tape 3 : Formation du Cluster (30 min)
- Former le cluster HA (3 nÅ“uds)
- Activer les addons de base

### Ã‰tape 4 : Restauration des DonnÃ©es (2h)
- Restaurer depuis le dernier backup
- VÃ©rifier l'intÃ©gritÃ©
- Restaurer les volumes persistants

### Ã‰tape 5 : Validation (1h)
- Tests de connectivitÃ©
- Validation des applications
- Monitoring

### Ã‰tape 6 : Communication (15 min)
- Informer les utilisateurs
- Documenter l'incident
- Post-mortem

**Temps Total EstimÃ© : 5 heures**

## 5. Contacts Fournisseurs
- HÃ©bergeur : XXX
- Support Canonical : XXX
- DNS : XXX

## 6. DerniÃ¨re Mise Ã  Jour
- Date : 2025-01-01
- Par : Jean Dupont
- Prochain test : 2025-04-01
```

### RTO et RPO

**DÃ©finir vos objectifs :**

**Exemple pour une PME :**
- RTO : 4 heures (le cluster doit Ãªtre opÃ©rationnel en 4h max)
- RPO : 24 heures (perte maximale = 1 jour de donnÃ©es)

**Exemple pour une startup non-critique :**
- RTO : 24 heures
- RPO : 1 semaine

**Exemple pour une entreprise critique :**
- RTO : 1 heure
- RPO : 1 heure

**Adapter votre stratÃ©gie de backup en fonction :**
- RPO 1h â†’ Backups toutes les heures (Velero schedulÃ©)
- RPO 24h â†’ Backups quotidiens (CronJob)

## Bonnes Pratiques

### 1. RÃ¨gle du 3-2-1

**3 copies de vos donnÃ©es :**
- 1 copie en production (le cluster lui-mÃªme)
- 1 copie sur le cluster (snapshots Longhorn)
- 1 copie externe (NFS, S3, etc.)

**2 supports diffÃ©rents :**
- Disque dur local
- Stockage cloud/NFS

**1 copie hors-site :**
- Cloud (S3, Backblaze B2)
- Datacentre distant
- USB stockÃ© dans un coffre

### 2. Chiffrer les Backups

**Les backups contiennent des Secrets !**

```bash
# Chiffrer un backup
gpg --symmetric --cipher-algo AES256 backup-20250101.tar.gz

# DÃ©chiffrer
gpg --decrypt backup-20250101.tar.gz.gpg > backup-20250101.tar.gz
```

**Stocker la clÃ© de chiffrement de maniÃ¨re sÃ©curisÃ©e** (gestionnaire de mots de passe, coffre).

### 3. Rotation des Backups

**Politique recommandÃ©e :**
- **Quotidien** : Garder 7 jours
- **Hebdomadaire** : Garder 4 semaines
- **Mensuel** : Garder 12 mois
- **Annuel** : Garder 3 ans (conformitÃ© lÃ©gale)

**Script de rotation automatique :**
```bash
#!/bin/bash
# rotate-backups.sh

BACKUP_DIR="/backups/microk8s"

# Supprimer les backups quotidiens > 7 jours
find $BACKUP_DIR/daily -name "*.tar.gz" -mtime +7 -delete

# Supprimer les backups hebdomadaires > 28 jours
find $BACKUP_DIR/weekly -name "*.tar.gz" -mtime +28 -delete

# Supprimer les backups mensuels > 365 jours
find $BACKUP_DIR/monthly -name "*.tar.gz" -mtime +365 -delete
```

### 4. Monitoring des Backups

**Alertes essentielles :**
- Backup quotidien Ã©chouÃ©
- Espace disque < 20% sur le stockage de backup
- Backup pas testÃ© depuis > 90 jours

**Avec Prometheus :**
```yaml
# Exemple de rÃ¨gle d'alerte
groups:
- name: backup-alerts
  rules:
  - alert: BackupFailed
    expr: kube_job_status_failed{job_name=~"cluster-backup.*"} > 0
    for: 10m
    annotations:
      summary: "Backup du cluster a Ã©chouÃ©"
```

### 5. Documenter Tout

**Maintenir Ã  jour :**
- ProcÃ©dure de backup
- ProcÃ©dure de restauration
- Inventaire du cluster
- Derniers tests de restauration
- DRP complet

**Stocker la documentation :**
- Dans Git (avec les manifestes)
- Dans un wiki interne
- Copie papier dans un coffre

### 6. GitOps : Version Control pour Tout

**Stocker dans Git :**
```
ğŸ“ k8s-infrastructure/
  ğŸ“ manifests/
    ğŸ“ apps/
    ğŸ“ configs/
    ğŸ“ monitoring/
  ğŸ“ docs/
    ğŸ“„ DRP.md
    ğŸ“„ backup-procedure.md
    ğŸ“„ restore-procedure.md
  ğŸ“ scripts/
    ğŸ“„ backup-cluster.sh
    ğŸ“„ restore-cluster.sh
  ğŸ“„ README.md
```

**Avantages :**
- Historique des changements (git log)
- Backup automatique (GitHub, GitLab)
- Collaboration facilitÃ©e
- PossibilitÃ© de rollback (git revert)

### 7. Automatiser et Oublier

**Principe :** Les backups manuels finissent par Ãªtre oubliÃ©s.

**Solution :**
- CronJob Kubernetes
- Velero avec schedule
- CI/CD qui backup aprÃ¨s chaque dÃ©ploiement

**Une fois configurÃ©, Ã§a doit tourner sans intervention.**

## Outils ComplÃ©mentaires

### Restic

**Backup incrÃ©mental efficace :**
```bash
# Installer Restic
sudo apt install restic

# Initialiser un repo
restic init --repo /mnt/backup-repo

# Backup
restic backup /var/snap/microk8s/current --repo /mnt/backup-repo

# Restaurer
restic restore latest --repo /mnt/backup-repo --target /restore
```

### Kopia

**Alternative moderne Ã  Restic :**
- Chiffrement intÃ©grÃ©
- DÃ©duplication
- Snapshots incrÃ©mentiels

### Snapshot du Serveur Complet

**Si sur VMs (Proxmox, VMware) :**
Snapshot de la VM entiÃ¨re = backup ultra rapide.

**Attention :** Snapshot â‰  backup (ne protÃ¨ge pas contre corruption du stockage).

## Points ClÃ©s Ã  Retenir

1. **HA â‰  Backup** : Les deux sont complÃ©mentaires
2. **3-2-1** : 3 copies, 2 supports, 1 hors-site
3. **Tester rÃ©guliÃ¨rement** : Un backup non testÃ© est inutile
4. **Automatiser** : CronJob ou Velero
5. **GitOps** : Versionner tous les manifestes
6. **Chiffrer** : Les backups contiennent des secrets
7. **DRP** : Avoir un plan Ã©crit et Ã  jour
8. **RTO/RPO** : DÃ©finir vos objectifs
9. **Rotation** : Garder plusieurs gÃ©nÃ©rations de backups
10. **Documenter** : ProcÃ©dures, tests, rÃ©sultats

## Prochaines Ã‰tapes

Vous maÃ®trisez maintenant les backups du control plane ! Les prochains chapitres couvriront :

- **21.9** : StratÃ©gies de redondance avancÃ©es
- **21.10** : Tests de failover et chaos engineering

Avec des backups rÃ©guliers, testÃ©s et automatisÃ©s, votre cluster est maintenant protÃ©gÃ© contre les catastrophes majeures. Vous dormez sur vos deux oreilles ! ğŸš€

---

**FÃ©licitations !** Vous savez maintenant sauvegarder et restaurer votre cluster Kubernetes. C'est votre police d'assurance contre les catastrophes ! Ne nÃ©gligez jamais les backups !

â­ï¸ [StratÃ©gies de redondance](/21-multi-node-et-haute-disponibilite/09-strategies-de-redondance.md)
