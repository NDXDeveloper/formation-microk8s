üîù Retour au [Sommaire](/SOMMAIRE.md)

# 21.9 Strat√©gies de Redondance

## Introduction

Vous avez construit un cluster multi-node avec haute disponibilit√©, backups automatiques et stockage distribu√©. Mais la vraie r√©silience ne vient pas d'un seul m√©canisme - elle vient d'une **strat√©gie de redondance compl√®te** qui couvre tous les niveaux de votre infrastructure.

Dans ce chapitre, nous allons explorer :
- Les diff√©rents niveaux de redondance (infrastructure, r√©seau, donn√©es, applications)
- Comment concevoir une architecture v√©ritablement r√©siliente
- Les points de d√©faillance uniques (SPOF) et comment les √©liminer
- Les compromis entre co√ªt, complexit√© et r√©silience
- Comment tester et valider votre redondance

La redondance est l'art de **ne jamais avoir un seul point de d√©faillance**. C'est ce qui fait la diff√©rence entre un cluster qui "tient" et un cluster qui **tient vraiment** en production.

**Principe fondamental :** "N+1" ou "N+2" - Toujours avoir au moins une ressource de plus que le minimum n√©cessaire.

## Qu'est-ce que la Redondance ?

### D√©finition

La **redondance** consiste √† avoir plusieurs composants identiques ou √©quivalents, de sorte que si l'un tombe en panne, les autres peuvent prendre le relais sans interruption de service.

**Analogie de l'avion :**
Un avion de ligne a :
- 2 ou 4 moteurs (si un tombe, les autres compensent)
- 2 pilotes (si l'un est incapacit√©, l'autre prend le relais)
- Syst√®mes √©lectriques redondants
- Syst√®mes hydrauliques redondants
- Multiples pompes √† carburant

**Pourquoi ?** Parce que la vie des passagers en d√©pend.

Dans votre cluster, c'est pareil : la disponibilit√© de vos applications (et peut-√™tre votre business) en d√©pend.

### Types de Redondance

**1. Redondance Active-Active**
Tous les composants sont actifs en m√™me temps et partagent la charge.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Node 1   ‚îÇ      ‚îÇ Node 2   ‚îÇ      ‚îÇ Node 3   ‚îÇ
‚îÇ ACTIF    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ACTIF    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ACTIF    ‚îÇ
‚îÇ Pod A    ‚îÇ      ‚îÇ Pod B    ‚îÇ      ‚îÇ Pod C    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚ñ≤                 ‚ñ≤                 ‚ñ≤
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   Trafic r√©parti
```

**Avantages :**
- Utilisation optimale des ressources
- Performance maximale
- Pas de ressource "gaspill√©e"

**Inconv√©nients :**
- Si charge √©lev√©e, la perte d'un composant peut surcharger les autres

**2. Redondance Active-Passive**
Un composant est actif, les autres en standby (attente).

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Node 1   ‚îÇ      ‚îÇ Node 2   ‚îÇ
‚îÇ ACTIF    ‚îÇ      ‚îÇ PASSIF   ‚îÇ
‚îÇ Leader   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Standby  ‚îÇ
‚îÇ Tout le  ‚îÇ      ‚îÇ Pr√™t mais‚îÇ
‚îÇ trafic   ‚îÇ      ‚îÇ inactif  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Avantages :**
- Bascule simple
- Charge pr√©visible

**Inconv√©nients :**
- Ressources sous-utilis√©es (standby ne fait rien)
- Temps de bascule (quelques secondes)

**3. Redondance N+1**
Vous avez N composants n√©cessaires + 1 de secours.

Exemple : Si vous avez besoin de 3 n≈ìuds pour le quorum (N=3), avoir 4 n≈ìuds (N+1=4) vous prot√®ge.

**4. Redondance N+2**
N composants + 2 de secours (plus co√ªteux mais plus r√©silient).

### Points de D√©faillance Uniques (SPOF)

Un **SPOF** (Single Point of Failure) est un composant unique dont la d√©faillance entra√Æne l'arr√™t du syst√®me entier.

**Exemples de SPOF :**
- Un seul switch r√©seau
- Un seul serveur NFS
- Un seul n≈ìud Kubernetes (cluster single-node)
- Une seule alimentation √©lectrique
- Un seul uplink Internet

**Objectif :** Identifier et **√©liminer tous les SPOF**.

## Niveaux de Redondance

### Niveau 1 : Infrastructure Physique

#### Serveurs / N≈ìuds

**Configuration minimale HA (vue au chapitre 21.4) :**
```
3 n≈ìuds control plane + worker
- Tol√©rance : 1 panne
- Quorum : 2/3
```

**Configuration renforc√©e :**
```
3 n≈ìuds control plane + 2 workers purs
- Tol√©rance : 1 panne control plane + N workers
- Plus de capacit√© applicative
```

**Configuration maximale :**
```
5 n≈ìuds control plane + 5 workers purs
- Tol√©rance : 2 pannes simultan√©es control plane
- Quorum : 3/5
- Haute capacit√© applicative
```

**R√®gle :** Toujours nombre impair de n≈ìuds control plane (3, 5, 7).

#### R√©partition G√©ographique

**Probl√®me :** Si tous vos n≈ìuds sont dans la m√™me pi√®ce/rack, une panne (√©lectricit√©, climatisation, inondation) peut tout arr√™ter.

**Solution : Zones de disponibilit√©**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                DATACENTER / HOMELAB                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Zone A     ‚îÇ  ‚îÇ   Zone B     ‚îÇ  ‚îÇ  Zone C   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Rack 1      ‚îÇ  ‚îÇ  Rack 2      ‚îÇ  ‚îÇ  Rack 3   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Alim 1      ‚îÇ  ‚îÇ  Alim 2      ‚îÇ  ‚îÇ  Alim 3   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Switch 1    ‚îÇ  ‚îÇ  Switch 2    ‚îÇ  ‚îÇ  Switch 3 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Node 1      ‚îÇ  ‚îÇ  Node 2      ‚îÇ  ‚îÇ  Node 3   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Worker 1    ‚îÇ  ‚îÇ  Worker 2    ‚îÇ  ‚îÇ  Worker 3 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Principe :** R√©partir les n≈ìuds sur :
- Diff√©rents racks (panne d'un PDU)
- Diff√©rents switchs (panne r√©seau)
- Diff√©rentes alimentations
- Id√©alement, diff√©rentes pi√®ces ou datacenters

**Labelliser les zones :**
```bash
microk8s kubectl label node node1 topology.kubernetes.io/zone=zone-a
microk8s kubectl label node node2 topology.kubernetes.io/zone=zone-b
microk8s kubectl label node node3 topology.kubernetes.io/zone=zone-c
```

**Utiliser topology spread constraints :**
```yaml
spec:
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: topology.kubernetes.io/zone
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app: myapp
```

Garantit que les pods sont r√©partis √©quitablement entre les zones.

#### Alimentation √âlectrique

**SPOF : Une seule source d'alimentation**

**Solutions :**

**1. Onduleurs (UPS)**
- Prot√®ge contre les micro-coupures
- Donne le temps d'√©teindre proprement

**2. Alimentations redondantes**
```
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ  Serveur     ‚îÇ
                 ‚îÇ              ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ PSU 1  PSU 2 ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
        ‚îÇ                                ‚îÇ
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ Circuit A ‚îÇ                    ‚îÇ Circuit B ‚îÇ
  ‚îÇ Tableau 1 ‚îÇ                    ‚îÇ Tableau 2 ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Si un circuit tombe, le serveur continue via l'autre.

**3. G√©n√©rateur (pour homelab/PME)**
En cas de coupure prolong√©e, un g√©n√©rateur prend le relais.

#### Refroidissement

**Serveurs surchauffent ‚Üí Extinction automatique**

**Solutions :**
- Climatisation redondante (2 unit√©s)
- Surveillance de temp√©rature
- Alertes automatiques

### Niveau 2 : R√©seau

#### Connectivit√© R√©seau

**SPOF : Un seul switch**

**Solution : Topology r√©seau redondante**

```
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ  Internet  ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                       ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Router 1  ‚îÇ           ‚îÇ Router 2  ‚îÇ
        ‚îÇ (Actif)   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ (Backup)  ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ                       ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Switch 1  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Switch 2  ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ                       ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ           ‚îÇ           ‚îÇ         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê
‚îÇNode 1 ‚îÇ ‚îÇNode 2 ‚îÇ   ‚îÇNode 3 ‚îÇ   ‚îÇWorker1‚îÇ ‚îÇWorker2‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Caract√©ristiques :**
- Chaque n≈ìud connect√© √† 2 switchs (bonding)
- Redondance switch
- Redondance routeur

**Configuration bonding (exemple Ubuntu) :**
```yaml
# /etc/netplan/01-netcfg.yaml
network:
  version: 2
  ethernets:
    eth0:
      dhcp4: false
    eth1:
      dhcp4: false
  bonds:
    bond0:
      interfaces:
      - eth0
      - eth1
      addresses:
      - 192.168.1.10/24
      gateway4: 192.168.1.1
      parameters:
        mode: active-backup
        mii-monitor-interval: 100
```

Si une interface r√©seau ou un switch tombe, l'autre prend le relais automatiquement.

#### DNS

**SPOF : Un seul serveur DNS**

**Solution : DNS redondants**
```bash
# /etc/netplan/01-netcfg.yaml
nameservers:
  addresses:
  - 8.8.8.8      # Google DNS primaire
  - 8.8.4.4      # Google DNS secondaire
  - 1.1.1.1      # Cloudflare DNS tertiaire
```

**Ou DNS interne redondant :**
- 2 serveurs Pi-hole
- 2 serveurs Bind9
- Configuration automatique via DHCP

#### Uplink Internet

**SPOF : Un seul fournisseur Internet**

**Solution (entreprise) :** Dual WAN
- 2 FAI diff√©rents (Fibre + 4G/5G backup)
- Routeur avec failover automatique

**Solution (homelab) :**
- 1 FAI principal (fibre)
- 4G/5G en backup (Starlink, hotspot mobile)

### Niveau 3 : Stockage

#### Stockage Distribu√© (Longhorn)

**Redondance par r√©plication (vu au chapitre 21.7)**

**Configuration par d√©faut :** 3 replicas

```yaml
# StorageClass avec 3 replicas
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: longhorn-redundant
provisioner: driver.longhorn.io
parameters:
  numberOfReplicas: "3"
  staleReplicaTimeout: "2880"
```

**R√©partition des replicas :**
```
Volume "database-vol" (10 GB)
‚îú‚îÄ Replica 1 : Node 1 (Actif)
‚îú‚îÄ Replica 2 : Node 2 (Actif)
‚îî‚îÄ Replica 3 : Node 3 (Actif)

Si Node 2 tombe ‚Üí Replicas 1 et 3 continuent
```

**Configuration renforc√©e (donn√©es critiques) :**
```yaml
parameters:
  numberOfReplicas: "5"  # 5 copies !
```

N√©cessite 5 n≈ìuds minimum.

#### Backups des Volumes

**Redondance temporelle (versions)**

**Snapshots Longhorn :**
- Quotidiens : 7 jours
- Hebdomadaires : 4 semaines
- Mensuels : 12 mois

**Backup externe :**
- S3 (AWS, Backblaze B2, Wasabi)
- NFS sur un serveur d√©di√©
- Stockage offline (disque externe)

**R√®gle 3-2-1 (rappel) :**
- 3 copies
- 2 supports diff√©rents
- 1 hors-site

### Niveau 4 : Applications

#### Replicas

**Principe de base :** Toujours au moins 2 r√©plicas pour les applications critiques.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 3  # ‚Üê Minimum 2, recommand√© 3+
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
```

**R√®gles selon criticit√© :**

| Type d'application | Replicas min | Recommand√© |
|--------------------|--------------|------------|
| Non-critique (dev) | 1 | 1 |
| Standard | 2 | 3 |
| Importante | 3 | 5 |
| Critique | 3 | 7+ |

#### Pod Anti-Affinity

**Garantir que les replicas sont sur des n≈ìuds diff√©rents :**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: database
spec:
  replicas: 3
  selector:
    matchLabels:
      app: database
  template:
    metadata:
      labels:
        app: database
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - database
            topologyKey: kubernetes.io/hostname
      containers:
      - name: postgres
        image: postgres:15
```

**R√©sultat :**
- Replica 1 ‚Üí Node 1
- Replica 2 ‚Üí Node 2
- Replica 3 ‚Üí Node 3

Si Node 1 tombe, Replicas 2 et 3 continuent. ‚úÖ

#### Pod Disruption Budgets (PDB)

**Garantir un nombre minimum de pods disponibles pendant les maintenances :**

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: web-app-pdb
spec:
  minAvailable: 2  # Au moins 2 pods doivent rester actifs
  selector:
    matchLabels:
      app: web
```

**Ou :**
```yaml
spec:
  maxUnavailable: 1  # Max 1 pod peut √™tre down √† la fois
```

**Utilit√© :**
Quand vous drainez un n≈ìud (`kubectl drain`), Kubernetes respecte le PDB et n'√©vacue qu'un pod √† la fois, garantissant que l'application reste accessible.

#### Health Checks

**Liveness et Readiness probes :**

```yaml
spec:
  containers:
  - name: app
    image: myapp:v1
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
      initialDelaySeconds: 30
      periodSeconds: 10
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5
```

**Liveness :** Si √©chec, Kubernetes red√©marre le pod.
**Readiness :** Si √©chec, Kubernetes retire le pod du Service (pas de trafic).

**Redondance via auto-healing :**
Si un pod devient unhealthy, Kubernetes le remplace automatiquement.

#### StatefulSets pour Applications Stateful

**Pour bases de donn√©es, applications avec √©tat :**

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 3
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:15
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: longhorn
      resources:
        requests:
          storage: 10Gi
```

**Avantages :**
- Noms de pods stables (postgres-0, postgres-1, postgres-2)
- Volumes persistants d√©di√©s par pod
- Ordre de d√©marrage/arr√™t pr√©visible

### Niveau 5 : Bases de Donn√©es

#### R√©plication Master-Slave

**Configuration PostgreSQL avec r√©plication :**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Master    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   Slave 1   ‚îÇ        ‚îÇ   Slave 2   ‚îÇ
‚îÇ  (Writes)   ‚îÇ   sync ‚îÇ  (Reads)    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  (Reads)    ‚îÇ
‚îÇ             ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ             ‚îÇ  async ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                       ‚îÇ                       ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   Failover automatique
```

**En cas de panne du Master :**
- Slave 1 est promu Master
- Slave 2 se reconnecte au nouveau Master
- Downtime : 5-30 secondes

**Outils pour PostgreSQL :**
- **Patroni** (HA PostgreSQL)
- **Stolon** (HA PostgreSQL)
- Op√©rateurs Kubernetes : postgres-operator, zalando operator

#### Clustering avec Consensus

**Pour MySQL, MariaDB :**
- Galera Cluster (Active-Active)
- InnoDB Cluster

**Pour bases NoSQL :**
- MongoDB Replica Set
- Cassandra (naturellement distribu√©)
- Redis Sentinel

**Principe :** Toutes les instances sont actives, les donn√©es r√©pliqu√©es automatiquement.

### Niveau 6 : Services Critiques

#### DNS Interne (CoreDNS)

**Par d√©faut, CoreDNS tourne en 2 replicas :**

```bash
microk8s kubectl get deployment -n kube-system coredns
```

```
NAME      READY   UP-TO-DATE   AVAILABLE
coredns   2/2     2            2
```

**Si critique, augmenter :**
```bash
microk8s kubectl scale deployment coredns --replicas=3 -n kube-system
```

#### Ingress Controller

**NGINX Ingress Controller en HA :**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-ingress-controller
  namespace: ingress
spec:
  replicas: 3  # Au moins 3 replicas
  selector:
    matchLabels:
      app: nginx-ingress
  template:
    metadata:
      labels:
        app: nginx-ingress
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - nginx-ingress
            topologyKey: kubernetes.io/hostname
      containers:
      - name: nginx-ingress
        image: registry.k8s.io/ingress-nginx/controller:latest
```

**Exposer avec LoadBalancer (MetalLB) :**
Le trafic est automatiquement distribu√© entre les 3 replicas.

#### Monitoring (Prometheus/Grafana)

**Prometheus HA :**
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: prometheus
spec:
  replicas: 2  # 2 instances Prometheus
```

**Thanos pour f√©d√©ration :**
Agr√®ge les donn√©es de plusieurs Prometheus instances.

**Grafana HA :**
```yaml
spec:
  replicas: 2
```

Avec base de donn√©es externe (PostgreSQL) pour partager les dashboards.

## Strat√©gies par Niveau de Criticit√©

### Applications Non-Critiques (Dev/Test)

**Configuration minimale :**
- 1 replica
- Pas de PDB
- Pas d'anti-affinity
- Backups hebdomadaires

**Co√ªt :** Minimal
**R√©silience :** Faible (acceptable pour dev)

### Applications Standard (Production non-critique)

**Configuration recommand√©e :**
- 2-3 replicas
- PDB avec minAvailable: 1
- Anti-affinity optionnelle
- Backups quotidiens
- Health checks (liveness + readiness)

**Co√ªt :** Mod√©r√©
**R√©silience :** Bonne

### Applications Critiques (Production essentielle)

**Configuration compl√®te :**
- 3-5 replicas minimum
- PDB avec minAvailable: 2
- Anti-affinity obligatoire
- Topology spread constraints (zones)
- Backups multi-versions (quotidien + temps r√©el)
- Health checks avanc√©s
- Monitoring et alerting 24/7
- Tests de failover r√©guliers

**Co√ªt :** √âlev√©
**R√©silience :** Tr√®s √©lev√©e

### Applications Mission-Critiques (Z√©ro Downtime)

**Configuration maximale :**
- 7+ replicas
- PDB avec minAvailable: 5
- Multi-zones g√©ographiques
- Multi-clusters (si possible)
- Backups en continu + r√©tention longue
- Monitoring multi-niveaux
- √âquipe d'astreinte 24/7
- Proc√©dures de failover test√©es mensuellement

**Co√ªt :** Tr√®s √©lev√©
**R√©silience :** Maximale

## Matrice de Redondance

| Composant | Single-Node | HA (3 nodes) | Production | Mission-Critique |
|-----------|-------------|--------------|------------|------------------|
| **N≈ìuds Control Plane** | 1 | 3 | 3-5 | 5-7 |
| **Workers** | 0 (node=worker) | 0-2 | 3-5 | 5-10 |
| **Stockage Replicas** | 1 | 3 | 3 | 5 |
| **App Replicas** | 1 | 2-3 | 3-5 | 7+ |
| **Ingress Replicas** | 1 | 2 | 3 | 3-5 |
| **DNS Replicas** | 1 | 2 | 3 | 3 |
| **Backups** | Aucun | Quotidien | Multi-versions | Temps r√©el |
| **Zones** | 1 | 1 | 1-2 | 2-3 |
| **Switch R√©seau** | 1 | 1 | 2 | 2+ |
| **Alim √âlectrique** | 1 | 1 | UPS | UPS + G√©n√©rateur |

## Compromis : Co√ªt vs R√©silience

### Calcul du Co√ªt

**Exemple cluster 3 n≈ìuds :**
```
Mat√©riel :
- 3 mini-PCs @ 300‚Ç¨ = 900‚Ç¨
- 1 switch 24 ports = 150‚Ç¨
- Total initial : 1050‚Ç¨

√âlectricit√© :
- 3 machines √ó 50W √ó 24h √ó 365j √ó 0.20‚Ç¨/kWh = 262‚Ç¨/an

Total 1√®re ann√©e : 1312‚Ç¨
Total ann√©e suivante : 262‚Ç¨/an
```

**Passer √† 5 n≈ìuds :**
```
Mat√©riel suppl√©mentaire :
- 2 mini-PCs @ 300‚Ç¨ = 600‚Ç¨

√âlectricit√© suppl√©mentaire :
- 2 √ó 50W √ó 24h √ó 365j √ó 0.20‚Ç¨/kWh = 175‚Ç¨/an

Co√ªt additionnel 1√®re ann√©e : 775‚Ç¨
Co√ªt additionnel ann√©es suivantes : 175‚Ç¨/an
```

**Question :** Votre business justifie-t-il 775‚Ç¨ suppl√©mentaires pour passer de 1 panne tol√©r√©e √† 2 ?

### ROI de la Redondance

**Calcul du risque sans redondance :**
```
Probabilit√© de panne n≈ìud : 5% par an
Co√ªt d'une panne (downtime) : 10 000‚Ç¨

Risque = 5% √ó 10 000‚Ç¨ = 500‚Ç¨/an

Si redondance co√ªte 175‚Ç¨/an et √©vite le risque :
ROI = (500 - 175) / 175 = 186% ‚úÖ
```

**La redondance est rentable si le co√ªt d'une panne > co√ªt de la redondance.**

### Optimisation des Co√ªts

**1. Commencer petit, scaler progressivement**
- D√©marrer avec 3 n≈ìuds
- Ajouter des workers au besoin
- Augmenter replicas au fur et √† mesure

**2. R√©utiliser du mat√©riel existant**
- Vieux laptops comme n≈ìuds
- Mini-PCs √©conomiques (Raspberry Pi, Intel NUC d'occasion)

**3. Redondance s√©lective**
- Redondance compl√®te pour production
- Redondance minimale pour dev/test

**4. Cloud hybride**
- Cluster on-premise pour le quotidien
- Backup dans le cloud (S3) pour le DR

## Tests de Redondance

### Chaos Engineering

**Principe :** Casser volontairement des choses pour v√©rifier que le syst√®me tient.

#### Test 1 : Arr√™t d'un N≈ìud Worker

```bash
# Sur worker1
sudo shutdown -h now
```

**V√©rifications :**
- Les pods sont-ils redistribu√©s ?
- Combien de temps pour la redistribution ?
- Les applications restent-elles accessibles ?

**Attendu :**
- Redistribution en 1-2 minutes
- Aucune interruption de service (si replicas ‚â• 2)

#### Test 2 : Arr√™t du N≈ìud Leader (Control Plane)

```bash
# Identifier le leader
microk8s kubectl get lease -n kube-system

# Arr√™ter le leader
# Sur le n≈ìud leader
sudo shutdown -h now
```

**V√©rifications :**
- Nouvelle √©lection de leader ?
- Cluster reste-t-il fonctionnel ?
- Temps de basculement ?

**Attendu :**
- Nouvelle √©lection en 5-10 secondes
- Cluster continue de fonctionner
- Commandes kubectl fonctionnent (via les autres n≈ìuds)

#### Test 3 : Saturation R√©seau

```bash
# Simuler une charge r√©seau importante
# Sur un n≈ìud
apt install iperf3
iperf3 -s

# Sur un autre n≈ìud
iperf3 -c <ip-du-premier-noeud> -t 300 -P 10
```

**V√©rifications :**
- Les pods continuent de communiquer ?
- Latence augment√©e mais service maintenu ?

#### Test 4 : Remplissage du Disque

```bash
# Cr√©er un gros fichier pour saturer le disque
dd if=/dev/zero of=/tmp/bigfile bs=1M count=10000
```

**V√©rifications :**
- Kubernetes marque-t-il le n≈ìud comme "DiskPressure" ?
- Les nouveaux pods √©vitent-ils ce n≈ìud ?
- Alertes d√©clench√©es ?

**Nettoyer :**
```bash
rm /tmp/bigfile
```

#### Test 5 : Corruption de Pod

```bash
# Tuer un processus dans un pod
POD_NAME=$(microk8s kubectl get pod -l app=web -o jsonpath="{.items[0].metadata.name}")
microk8s kubectl exec $POD_NAME -- killall -9 nginx
```

**V√©rifications :**
- Kubernetes red√©marre-t-il le pod ?
- Temps de red√©marrage ?
- Service interrompu pour les autres replicas ?

**Attendu :**
- Pod red√©marr√© en 10-30 secondes
- Autres replicas continuent de servir le trafic

### Tests R√©guliers

**Fr√©quence recommand√©e :**
- **Tests basiques (arr√™t 1 n≈ìud)** : Mensuel
- **Tests avanc√©s (chaos engineering)** : Trimestriel
- **Tests de restauration compl√®te** : Semestriel

**Documenter chaque test :**
```markdown
# Test de Redondance - 2025-01-15

## Test Effectu√©
Arr√™t du n≈ìud worker2 pendant 10 minutes

## R√©sultats
- ‚úÖ Pods redistribu√©s en 1m30s
- ‚úÖ Aucune interruption de service
- ‚úÖ Alertes Prometheus d√©clench√©es
- ‚ö†Ô∏è Un pod en CrashLoopBackOff (bug ind√©pendant)

## Actions
- Investiguer le CrashLoopBackOff
- RAS sur la redondance

## Temps de R√©tablissement
- Red√©marrage de worker2 : 2 minutes
- Rejoindre le cluster : 1 minute
- Pods retournent sur worker2 : 5 minutes
- Total : 8 minutes

## Conclusion
‚úÖ Redondance fonctionnelle
```

## Surveillance de la Redondance

### M√©triques Cl√©s

**1. Nombre de n≈ìuds Ready**
```promql
count(kube_node_status_condition{condition="Ready", status="true"})
```

**Alerte si < 3** (cluster HA minimal)

**2. Nombre de replicas disponibles par Deployment**
```promql
kube_deployment_status_replicas_available < kube_deployment_spec_replicas
```

**Alerte si disponible < d√©sir√©**

**3. Pods √©vacu√©s (evicted)**
```promql
kube_pod_status_phase{phase="Failed"} > 0
```

**4. Utilisation disque par n≈ìud**
```promql
(node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes > 0.85
```

**Alerte si > 85%**

**5. Sant√© Longhorn**
```promql
longhorn_volume_robustness != 1
```

**Alerte si volume degraded**

### Dashboards Recommand√©s

**Grafana - Dashboard "Cluster Health"**
- Statut de chaque n≈ìud
- Nombre de pods par n≈ìud
- Utilisation CPU/RAM/Disk par n≈ìud
- R√©partition des pods entre zones
- √âtat des volumes Longhorn

**Grafana - Dashboard "Application Resilience"**
- Nombre de replicas par Deployment
- Pod restarts (derni√®res 24h)
- Pod evictions
- Temps de r√©ponse applicatif
- Taux d'erreur

## Bonnes Pratiques

### 1. Documentation de l'Architecture

**Maintenir un sch√©ma √† jour :**
```markdown
# Architecture Cluster K8s

## Infrastructure
- 3 n≈ìuds control+worker (node1-3)
- 2 workers purs (worker1-2)
- 2 switches (active-backup bonding)
- 1 UPS (autonomie 30 min)

## Redondance
- Control plane : 3 n≈ìuds (tol√®re 1 panne)
- Stockage : 3 replicas Longhorn
- Applications critiques : 3-5 replicas
- Backups : Quotidien (7j) + Hebdo (4 semaines)

## SPOF Identifi√©s
- ‚ùå Switch 1 (en cours : ajout Switch 2)
- ‚úÖ Aucun autre SPOF connu

## Derni√®re MAJ
2025-01-15 par Jean
```

### 2. Principe du "Cattle, Not Pets"

**Pets (animaux de compagnie) :**
- Serveurs nomm√©s avec soin (prod-01, db-master)
- Configur√©s manuellement
- Irrempla√ßables

**Cattle (b√©tail) :**
- Serveurs num√©rot√©s (node1, node2, worker3)
- Configur√©s automatiquement (scripts, Ansible)
- Rempla√ßables √† tout moment

**Objectif :** Tout doit pouvoir √™tre reconstruit automatiquement.

### 3. Immutabilit√©

**Ne pas modifier les n≈ìuds en place.**

**Mauvais :**
```bash
# Se connecter au n≈ìud et modifier manuellement
ssh node1
sudo apt install custom-package
sudo nano /etc/config.conf
```

**Bon :**
```bash
# Modifier le script d'installation
# Reconstruire le n≈ìud depuis z√©ro
# Ou utiliser Ansible/Terraform
```

**Avantage :** Si le n≈ìud doit √™tre reconstruit, vous savez exactement comment.

### 4. Versioning et GitOps

**Tout dans Git :**
- Manifestes YAML
- Scripts de configuration
- Documentation
- Proc√©dures

**Workflow :**
```
Modification ‚Üí Git commit ‚Üí Git push ‚Üí ArgoCD deploy
```

**Avantages :**
- Historique complet
- Rollback facile
- Collaboration
- Backup automatique

### 5. Tester la Redondance Avant d'en Avoir Besoin

**Ne d√©couvrez pas que votre redondance ne fonctionne pas lors d'une vraie panne.**

**Tests r√©guliers = assurance qualit√© de votre redondance.**

### 6. Automatisation du Failover

**√âviter les actions manuelles lors d'une panne.**

**Kubernetes fait d√©j√† beaucoup automatiquement :**
- Red√©marrage de pods crash√©s
- Redistribution sur panne n≈ìud
- √âlection de nouveau leader

**Compl√©ter avec :**
- Alertes automatiques (PagerDuty, Slack)
- Runbooks automatis√©s
- Scripts de failover test√©s

### 7. Mesurer et Am√©liorer

**KPIs de r√©silience :**
- **MTBF** (Mean Time Between Failures) : Temps moyen entre deux pannes
- **MTTR** (Mean Time To Recovery) : Temps moyen de r√©cup√©ration
- **Uptime** : % de disponibilit√©

**Objectif :**
- Augmenter MTBF (pannes moins fr√©quentes)
- R√©duire MTTR (r√©cup√©ration plus rapide)
- Maximiser Uptime (> 99.9%)

**Calcul de l'uptime :**
```
Uptime = (Temps total - Temps d'indisponibilit√©) / Temps total √ó 100

Exemple sur 1 mois (30 jours) :
- Downtime total : 1 heure
- Uptime = (30√ó24 - 1) / (30√ó24) √ó 100 = 99.86%
```

**SLA standards :**
- 99% = 7h20min downtime/mois (acceptable pour dev)
- 99.9% = 43min downtime/mois (production standard)
- 99.99% = 4min downtime/mois (production critique)
- 99.999% = 26 secondes/mois (mission-critique)

## Points Cl√©s √† Retenir

1. **Redondance = Ne jamais avoir un seul point de d√©faillance**
2. **N+1** : Toujours une ressource de plus que le minimum
3. **Niveaux de redondance** : Infrastructure, r√©seau, stockage, applications
4. **Active-Active** > Active-Passive (utilisation optimale)
5. **Replicas ‚â• 2** pour toutes les applications critiques
6. **Anti-affinity** pour r√©partir les pods sur diff√©rents n≈ìuds
7. **PDB** pour garantir un minimum de pods pendant les maintenances
8. **Tests r√©guliers** : Chaos engineering mensuel/trimestriel
9. **Documenter** : Architecture, SPOF, proc√©dures
10. **Mesurer** : MTBF, MTTR, Uptime

## Prochaines √âtapes

Vous ma√Ætrisez maintenant les strat√©gies de redondance compl√®tes ! Le prochain chapitre couvrira :

- **21.10** : Tests de failover et validation compl√®te de la r√©silience

Avec une strat√©gie de redondance bien pens√©e et test√©e, votre cluster peut d√©sormais affronter les pannes les plus courantes sans interruption de service ! üöÄ

---

**F√©licitations !** Vous savez maintenant concevoir et impl√©menter une architecture Kubernetes v√©ritablement r√©siliente avec redondance √† tous les niveaux. C'est la marque des architectures de production s√©rieuses !

‚è≠Ô∏è [Tests de failover](/21-multi-node-et-haute-disponibilite/10-tests-de-failover.md)
