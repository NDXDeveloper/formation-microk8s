ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 21.5 Ajout de Worker Nodes SupplÃ©mentaires

## Introduction

Votre cluster HA est maintenant opÃ©rationnel avec 3 nÅ“uds control plane. Mais que faire quand vos applications grandissent et que vous avez besoin de **plus de puissance de calcul** ? C'est lÃ  qu'interviennent les **worker nodes supplÃ©mentaires**.

Dans ce chapitre, nous allons apprendre Ã  :
- Ajouter des workers purs (sans control plane)
- Comprendre quand et pourquoi les ajouter
- GÃ©rer la capacitÃ© et le placement des pods
- Optimiser les ressources du cluster
- Scaler horizontalement votre infrastructure

L'ajout de workers est l'un des grands avantages de Kubernetes : vous pouvez augmenter la capacitÃ© de votre cluster **sans toucher au control plane**, qui reste stable et sÃ©curisÃ©.

## NÅ“uds Mixtes vs Workers Purs : Rappel

### NÅ“uds Mixtes (Control Plane + Worker)

**Ce que vous avez actuellement (3 nÅ“uds HA) :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node 1     â”‚  â”‚   Node 2     â”‚  â”‚   Node 3     â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ Control      â”‚  â”‚ Control      â”‚  â”‚ Control      â”‚
â”‚ Plane        â”‚  â”‚ Plane        â”‚  â”‚ Plane        â”‚
â”‚ + Worker     â”‚  â”‚ + Worker     â”‚  â”‚ + Worker     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avantages :**
- Simple Ã  gÃ©rer
- Utilisation optimale des ressources (pas de gaspillage)
- Parfait pour petits clusters (3-7 nÅ“uds)

**InconvÃ©nients :**
- Les pods applicatifs partagent les ressources avec le control plane
- Si forte charge applicative, le control plane peut Ãªtre impactÃ©
- Moins d'isolation

### Workers Purs (Worker Only)

**Avec workers supplÃ©mentaires :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node 1     â”‚  â”‚   Node 2     â”‚  â”‚   Node 3     â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ Control      â”‚  â”‚ Control      â”‚  â”‚ Control      â”‚
â”‚ Plane        â”‚  â”‚ Plane        â”‚  â”‚ Plane        â”‚
â”‚ + Worker     â”‚  â”‚ + Worker     â”‚  â”‚ + Worker     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                 â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                   â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Worker 1   â”‚  â”‚  Worker 2    â”‚  â”‚  Worker 3   â”‚
   â”‚             â”‚  â”‚              â”‚  â”‚             â”‚
   â”‚  Worker     â”‚  â”‚  Worker      â”‚  â”‚  Worker     â”‚
   â”‚  Only       â”‚  â”‚  Only        â”‚  â”‚  Only       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avantages :**
- Isolation : control plane dÃ©diÃ©, pas impactÃ© par la charge applicative
- ScalabilitÃ© : ajout facile de capacitÃ© sans complexifier le control plane
- Moins de ressources consommÃ©es par worker (pas de Dqlite, API server, etc.)
- SÃ©curitÃ© : control plane sÃ©parÃ© physiquement

**InconvÃ©nients :**
- Plus de machines nÃ©cessaires
- LÃ©gÃ¨rement plus complexe Ã  gÃ©rer

## Pourquoi Ajouter des Workers SupplÃ©mentaires ?

### 1. Augmentation de la CapacitÃ©

**ScÃ©nario typique :**
Vous avez un cluster 3 nÅ“uds avec :
- 4 CPU et 8 GB RAM par nÅ“ud
- Total : 12 CPU, 24 GB RAM

Vos applications grandissent et vous atteignez **80% d'utilisation** :
```bash
microk8s kubectl top nodes
```
```
NAME    CPU    CPU%   MEMORY   MEMORY%
node1   3200m  80%    6.4Gi    80%
node2   3100m  77%    6.2Gi    77%
node3   3300m  82%    6.6Gi    82%
```

**Solution :** Ajouter 2 workers avec 4 CPU et 8 GB chacun.
- Nouveau total : 20 CPU, 40 GB RAM
- Utilisation redescend Ã  ~50%

### 2. Isolation des Workloads

**Cas d'usage :**
- SÃ©parer les workloads critiques (bases de donnÃ©es) des workloads moins critiques (batch jobs)
- DÃ©dier certains workers Ã  certaines applications
- Isolation par tenant (si multi-tenant)

**Exemple :**
```
Control Plane (3 nÅ“uds) : Infrastructure systÃ¨me
Worker 1-2              : Applications web
Worker 3-4              : Bases de donnÃ©es (SSD rapides)
Worker 5-6              : Jobs de traitement (beaucoup de CPU)
```

### 3. Zones de DisponibilitÃ©

**Dans un datacenter ou cloud :**
RÃ©partir les workers sur plusieurs zones physiques :
```
Zone A : node1 (control) + worker1
Zone B : node2 (control) + worker2
Zone C : node3 (control) + worker3
```

Si une zone tombe (panne Ã©lectrique, rÃ©seau), les autres continuent.

### 4. Scaling Horizontal vs Vertical

**Vertical Scaling (Scale Up) :**
- Remplacer un serveur 4 CPU / 8 GB par un 8 CPU / 16 GB
- âŒ NÃ©cessite downtime
- âŒ Limite physique (max 128 CPU sur une machine)
- âŒ Plus cher (serveurs puissants = prix exponentiels)

**Horizontal Scaling (Scale Out) :**
- Ajouter un worker supplÃ©mentaire 4 CPU / 8 GB
- âœ… Pas de downtime
- âœ… Quasi illimitÃ© (ajoutez autant de workers que nÃ©cessaire)
- âœ… Moins cher (serveurs standards)

**Kubernetes favorise le scaling horizontal !**

### 5. Machines HÃ©tÃ©rogÃ¨nes

Vous pouvez avoir des workers avec des specs diffÃ©rentes :
```
node1-3   : 4 CPU, 8 GB RAM  (control plane + worker)
worker1-2 : 4 CPU, 8 GB RAM  (workers standards)
worker3-4 : 8 CPU, 16 GB RAM (workers puissants pour DB)
worker5   : 2 CPU, 4 GB RAM  (worker lÃ©ger pour monitoring)
```

Kubernetes s'adapte et schedule les pods en fonction des ressources disponibles.

## PrÃ©requis pour un Worker SupplÃ©mentaire

### 1. Ressources MatÃ©rielles

**Minimum par worker :**
```
CPU     : 2 cÅ“urs
RAM     : 4 GB
Stockage: 20 GB
RÃ©seau  : 1 Gbps
```

**RecommandÃ© par worker :**
```
CPU     : 4 cÅ“urs
RAM     : 8 GB
Stockage: 40 GB (SSD)
RÃ©seau  : 1 Gbps
```

**Note :** Un worker pur consomme **moins** de ressources qu'un nÅ“ud mixte, car il n'exÃ©cute pas le control plane.

### 2. Configuration RÃ©seau

**ConnectivitÃ© avec les nÅ“uds existants :**
```bash
# Depuis le nouveau worker, pinger les nÅ“uds existants
ping -c 3 192.168.1.10  # node1
ping -c 3 192.168.1.11  # node2
ping -c 3 192.168.1.12  # node3

# VÃ©rifier la latence (< 10ms recommandÃ©)
ping -c 10 192.168.1.10 | grep avg
```

**Adresse IP statique :**
```
node1   : 192.168.1.10  (control plane)
node2   : 192.168.1.11  (control plane)
node3   : 192.168.1.12  (control plane)
worker1 : 192.168.1.20  â† Nouvelle IP statique
worker2 : 192.168.1.21  â† Nouvelle IP statique
```

**Firewall :**
```bash
# Sur worker1, autoriser le trafic depuis les nÅ“uds du cluster
sudo ufw allow from 192.168.1.0/24

# Sur les nÅ“uds existants, autoriser worker1
sudo ufw allow from 192.168.1.20
sudo ufw allow from 192.168.1.21
```

### 3. Hostname Unique

```bash
# Sur worker1
sudo hostnamectl set-hostname worker1

# VÃ©rifier
hostname
```

**Ajouter dans /etc/hosts (optionnel mais recommandÃ©) :**
```bash
sudo nano /etc/hosts
```
```
192.168.1.10    node1
192.168.1.11    node2
192.168.1.12    node3
192.168.1.20    worker1
192.168.1.21    worker2
```

### 4. MÃªme Version de MicroK8s

**Sur le worker, installer la mÃªme version que le cluster :**
```bash
# VÃ©rifier la version sur le cluster existant
# (depuis node1, node2 ou node3)
microk8s version

# Sur worker1, installer la mÃªme version
sudo snap install microk8s --classic --channel=1.28/stable

# Ajouter l'utilisateur au groupe
sudo usermod -a -G microk8s $USER
sudo chown -f -R $USER ~/.kube
newgrp microk8s

# VÃ©rifier
microk8s version
```

## Ajouter un Worker : Processus DÃ©taillÃ©

### Ã‰tape 1 : PrÃ©parer le Worker

**Sur la nouvelle machine (worker1) :**

```bash
# 1. Mettre Ã  jour le systÃ¨me
sudo apt update && sudo apt upgrade -y

# 2. Configurer l'IP statique (si DHCP)
# Exemple avec netplan (Ubuntu)
sudo nano /etc/netplan/01-netcfg.yaml
```

```yaml
network:
  version: 2
  ethernets:
    eth0:
      addresses:
        - 192.168.1.20/24
      gateway4: 192.168.1.1
      nameservers:
        addresses: [8.8.8.8, 8.8.4.4]
```

```bash
sudo netplan apply

# 3. Configurer le hostname
sudo hostnamectl set-hostname worker1

# 4. Installer MicroK8s
sudo snap install microk8s --classic --channel=1.28/stable

# 5. Configuration utilisateur
sudo usermod -a -G microk8s $USER
sudo chown -f -R $USER ~/.kube
newgrp microk8s

# 6. Attendre que MicroK8s soit prÃªt
microk8s status --wait-ready
```

**Ã€ ce stade :** worker1 a MicroK8s installÃ©, mais tourne en standalone (pas encore connectÃ© au cluster).

### Ã‰tape 2 : GÃ©nÃ©rer le Token Worker

**Sur un nÅ“ud existant du cluster (node1, node2 ou node3) :**

```bash
microk8s add-node --worker
```

**Sortie attendue :**
```
From the node you wish to join to this cluster, run the following:
microk8s join 192.168.1.10:25000/abcd1234efgh5678ijkl9012mnop3456qrst7890 --worker

Use the '--worker' flag to join a node as a worker not running the control plane.
```

**Explication :**
- `--worker` : indique que c'est un worker pur (pas de control plane)
- Le token gÃ©nÃ©rÃ© est diffÃ©rent d'un token normal
- Le token est valide 24 heures

**Copier la commande complÃ¨te.**

### Ã‰tape 3 : Joindre le Cluster comme Worker

**Sur worker1 :**

```bash
microk8s join 192.168.1.10:25000/abcd1234efgh5678ijkl9012mnop3456qrst7890 --worker
```

**Ce qui se passe :**
```
Contacting cluster at 192.168.1.10...
Waiting for this node to finish joining the cluster. .. .. ..
Successfully joined the cluster as a worker node.
```

**En arriÃ¨re-plan, MicroK8s :**
1. Authentifie le worker avec le token
2. TÃ©lÃ©charge la configuration du cluster
3. DÃ©marre le kubelet (agent du worker)
4. N'installe PAS Dqlite ni l'API Server (c'est un worker pur)
5. Enregistre le nÅ“ud dans l'API Server du cluster

**Temps d'attente :** 30 secondes Ã  2 minutes.

### Ã‰tape 4 : VÃ©rifier que le Worker est AjoutÃ©

**Sur n'importe quel nÅ“ud du cluster :**

```bash
microk8s kubectl get nodes
```

**Sortie attendue :**
```
NAME      STATUS   ROLES    AGE     VERSION
node1     Ready    <none>   5d      v1.28.3
node2     Ready    <none>   5d      v1.28.3
node3     Ready    <none>   5d      v1.28.3
worker1   Ready    <none>   2m      v1.28.3
```

**VÃ©rifier les dÃ©tails du worker :**
```bash
microk8s kubectl get node worker1 -o wide
```

```
NAME      STATUS   ROLES    AGE   VERSION   INTERNAL-IP     OS-IMAGE
worker1   Ready    <none>   2m    v1.28.3   192.168.1.20    Ubuntu 22.04
```

**VÃ©rifier que worker1 n'est PAS dans Dqlite :**
```bash
microk8s status
```

```
microk8s is running
high-availability: yes
  datastore master nodes: 192.168.1.10:19001 192.168.1.11:19001 192.168.1.12:19001
  datastore standby nodes: none
```

worker1 n'apparaÃ®t **pas** dans la liste des "datastore master nodes". C'est normal et attendu ! âœ…

### Ã‰tape 5 : Labelliser le Worker (Optionnel mais RecommandÃ©)

**Ajouter des labels pour identifier le worker :**

```bash
# Label de rÃ´le
microk8s kubectl label node worker1 node-role.kubernetes.io/worker=true

# Label de type
microk8s kubectl label node worker1 node-type=worker

# Label de zone (si applicable)
microk8s kubectl label node worker1 topology.kubernetes.io/zone=zone-a

# VÃ©rifier
microk8s kubectl get nodes --show-labels
```

Ces labels seront utiles pour :
- Node selectors
- Affinity rules
- Visualisation dans les dashboards

## Ajouter Plusieurs Workers

### Ajouter Worker 2

**RÃ©pÃ©ter le processus :**

1. **Sur un nÅ“ud existant, gÃ©nÃ©rer un nouveau token :**
```bash
microk8s add-node --worker
```

2. **Sur worker2 (aprÃ¨s installation MicroK8s) :**
```bash
microk8s join 192.168.1.10:25000/<nouveau_token> --worker
```

3. **VÃ©rifier :**
```bash
microk8s kubectl get nodes
```

```
NAME      STATUS   ROLES    AGE
node1     Ready    <none>   5d
node2     Ready    <none>   5d
node3     Ready    <none>   5d
worker1   Ready    <none>   10m
worker2   Ready    <none>   1m
```

### Ajouter Worker 3, 4, 5...

**MÃªme processus pour chaque worker :**
- GÃ©nÃ©rer un token unique Ã  chaque fois
- Ne pas rÃ©utiliser un ancien token
- VÃ©rifier que chaque worker passe en "Ready"

**Combien de workers peut-on ajouter ?**
- MicroK8s supporte jusqu'Ã  **20-30 workers** confortablement
- Au-delÃ , envisager d'autres solutions (kubeadm, cloud managÃ©)

## Distribution des Pods sur les Workers

### Comportement par DÃ©faut

Une fois les workers ajoutÃ©s, Kubernetes **distribue automatiquement** les nouveaux pods :

```bash
# CrÃ©er un deployment avec 10 rÃ©plicas
microk8s kubectl create deployment nginx-test --image=nginx --replicas=10

# Voir oÃ¹ les pods sont schedulÃ©s
microk8s kubectl get pods -o wide
```

**RÃ©sultat typique (cluster avec 3 control+worker + 2 workers purs) :**
```
NAME                 NODE      STATUS
nginx-test-xxx-1     node1     Running
nginx-test-xxx-2     node2     Running
nginx-test-xxx-3     node3     Running
nginx-test-xxx-4     worker1   Running
nginx-test-xxx-5     worker1   Running
nginx-test-xxx-6     worker2   Running
nginx-test-xxx-7     worker2   Running
nginx-test-xxx-8     node1     Running
nginx-test-xxx-9     worker1   Running
nginx-test-xxx-10    node3     Running
```

Kubernetes rÃ©partit intelligemment les pods sur **tous** les nÅ“uds disponibles.

### Le Scheduler Kubernetes

**Comment Kubernetes dÃ©cide oÃ¹ placer un pod ?**

Le **Scheduler** Ã©value plusieurs critÃ¨res :
1. **Ressources disponibles** (CPU, RAM)
2. **Affinity / Anti-affinity** (prÃ©fÃ©rences de placement)
3. **Taints / Tolerations** (restrictions)
4. **PrioritÃ©s** des pods
5. **Topology spread** (rÃ©partition gÃ©ographique)

**Algorithme simplifiÃ© :**
```
Pour chaque pod Ã  scheduler:
  1. Filtrer les nÅ“uds (supprimer ceux qui ne peuvent pas hÃ©berger le pod)
  2. Scorer les nÅ“uds restants (donner une note Ã  chaque nÅ“ud)
  3. Choisir le nÅ“ud avec le meilleur score
  4. Attribuer le pod Ã  ce nÅ“ud
```

### Forcer le Placement sur un Worker

**Option 1 : Node Selector (Simple)**

```yaml
# deployment-on-worker.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-on-worker
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      nodeSelector:
        node-type: worker    # â† Forcer sur les workers uniquement
      containers:
      - name: nginx
        image: nginx
```

```bash
microk8s kubectl apply -f deployment-on-worker.yaml

# VÃ©rifier que les pods sont bien sur worker1 et worker2
microk8s kubectl get pods -o wide
```

**Option 2 : Node Affinity (Plus Flexible)**

```yaml
# deployment-prefer-worker.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-prefer-worker
spec:
  replicas: 5
  selector:
    matchLabels:
      app: myapp2
  template:
    metadata:
      labels:
        app: myapp2
    spec:
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: node-type
                operator: In
                values:
                - worker
      containers:
      - name: nginx
        image: nginx
```

**DiffÃ©rence :**
- `nodeSelector` : **Obligatoire** (hard requirement)
- `nodeAffinity preferred` : **PrÃ©fÃ©rÃ©** mais pas obligatoire (soft requirement)

### Exclure les Control Plane (Taint)

Si vous voulez que les workers purs hÃ©bergent **uniquement** les pods applicatifs (pas les pods systÃ¨me), vous pouvez "tainter" les nÅ“uds control plane :

```bash
# EmpÃªcher les pods applicatifs sur les nÅ“uds control plane
microk8s kubectl taint nodes node1 node-role.kubernetes.io/control-plane=:NoSchedule
microk8s kubectl taint nodes node2 node-role.kubernetes.io/control-plane=:NoSchedule
microk8s kubectl taint nodes node3 node-role.kubernetes.io/control-plane=:NoSchedule
```

**RÃ©sultat :**
- Les nouveaux pods seront schedulÃ©s **uniquement** sur worker1, worker2, etc.
- Les pods systÃ¨me (avec tolerations) peuvent toujours tourner sur les control plane
- Les pods existants sur control plane ne sont **pas** Ã©vacuÃ©s

**Retirer le taint (si besoin) :**
```bash
microk8s kubectl taint nodes node1 node-role.kubernetes.io/control-plane-
```

## Gestion de la CapacitÃ© du Cluster

### Surveiller l'Utilisation des Ressources

**Voir l'utilisation par nÅ“ud :**
```bash
microk8s kubectl top nodes
```

```
NAME      CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
node1     1200m        30%    3.2Gi           40%
node2     1100m        27%    3.0Gi           37%
node3     1300m        32%    3.4Gi           42%
worker1   800m         20%    2.1Gi           26%
worker2   700m         17%    1.9Gi           23%
```

**Analyse :**
- Les control plane (node1-3) sont plus chargÃ©s (control plane + apps)
- Les workers purs (worker1-2) sont moins chargÃ©s
- **Distribution saine** : chaque nÅ“ud utilise 20-40% des ressources

### CapacitÃ© Totale du Cluster

**Calculer la capacitÃ© :**
```bash
# CapacitÃ© CPU totale (en millicores)
microk8s kubectl get nodes -o json | jq '.items[] | .status.capacity.cpu' | awk '{sum+=$1} END {print sum " cores"}'

# CapacitÃ© RAM totale
microk8s kubectl get nodes -o json | jq '.items[] | .status.capacity.memory'
```

**Exemple de sortie :**
```
Cluster 3 control+worker + 2 workers:
- CPU: 5 nÅ“uds Ã— 4 cores = 20 cores
- RAM: 5 nÅ“uds Ã— 8 GB = 40 GB
```

### Requests vs Limits

**Concepts importants :**

**Requests (Demandes) :**
- Ressources **garanties** pour le pod
- Le Scheduler vÃ©rifie que le nÅ“ud a les requests disponibles avant de placer le pod
- Exemple : `requests: cpu: 500m, memory: 512Mi`

**Limits (Limites) :**
- Ressources **maximales** que le pod peut utiliser
- Si dÃ©passÃ©, le pod peut Ãªtre tuÃ© (OOMKilled pour la RAM)
- Exemple : `limits: cpu: 1000m, memory: 1Gi`

**Exemple de deployment avec requests/limits :**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-resources
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: nginx
        resources:
          requests:
            cpu: "250m"       # 0.25 CPU garanti
            memory: "256Mi"   # 256 MB garantis
          limits:
            cpu: "500m"       # Max 0.5 CPU
            memory: "512Mi"   # Max 512 MB
```

**Bonnes pratiques :**
- Toujours dÃ©finir des **requests** (permet au Scheduler de bien placer les pods)
- DÃ©finir des **limits** pour Ã©viter qu'un pod consomme tout
- Ratio limits/requests typique : 2x (exemple: request 250m, limit 500m)

### Seuil d'Alerte et Scaling

**RÃ¨gles de thumb :**
- **< 60% d'utilisation** : Cluster confortable
- **60-75%** : OK, mais surveiller
- **75-85%** : Zone d'alerte, prÃ©voir d'ajouter des workers
- **> 85%** : Critique, ajouter des workers rapidement

**Quand ajouter un worker ?**
```bash
# Si la moyenne d'utilisation dÃ©passe 75% pendant plusieurs heures
microk8s kubectl top nodes
```

Si vous voyez :
```
NAME      CPU%   MEMORY%
node1     78%    82%
node2     80%    79%
node3     76%    81%
worker1   75%    77%
worker2   77%    78%
```

**â†’ Il est temps d'ajouter worker3 !**

## StratÃ©gies de Placement AvancÃ©es

### 1. Topology Spread Constraints

**RÃ©partir Ã©quitablement les pods sur les workers :**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-spread
spec:
  replicas: 6
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: myapp
      containers:
      - name: nginx
        image: nginx
```

**RÃ©sultat :**
- 6 rÃ©plicas rÃ©parties sur 5 nÅ“uds (3 control+worker + 2 workers)
- Chaque nÅ“ud hÃ©berge 1 ou 2 pods (Ã©cart max = 1)

### 2. Pod Anti-Affinity

**Ã‰viter de placer 2 rÃ©plicas du mÃªme pod sur le mÃªme nÅ“ud :**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-antiaffinity
spec:
  replicas: 5
  selector:
    matchLabels:
      app: critical-app
  template:
    metadata:
      labels:
        app: critical-app
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - critical-app
            topologyKey: kubernetes.io/hostname
      containers:
      - name: app
        image: myapp:v1
```

**RÃ©sultat :**
- Chaque rÃ©plica est sur un nÅ“ud diffÃ©rent
- Garantit la rÃ©silience (si un nÅ“ud tombe, pas tous les pods)

### 3. DÃ©dier des Workers Ã  Certaines Apps

**ScÃ©nario :** Vous avez des workers avec GPU pour du machine learning.

```bash
# Labelliser les workers avec GPU
microk8s kubectl label node worker3 gpu=nvidia-rtx-3090
microk8s kubectl label node worker4 gpu=nvidia-rtx-3090
```

**Dans votre deployment ML :**
```yaml
spec:
  template:
    spec:
      nodeSelector:
        gpu: nvidia-rtx-3090
```

Les pods ML seront schedulÃ©s **uniquement** sur worker3 et worker4.

## Retirer un Worker du Cluster

### MÃ©thode Propre (Graceful)

**1. Drainer le worker (Ã©vacuer les pods) :**
```bash
microk8s kubectl drain worker1 --ignore-daemonsets --delete-emptydir-data
```

**Ce qui se passe :**
- worker1 est marquÃ© comme "non-schedulable"
- Tous les pods sur worker1 sont gracefully terminÃ©s
- Ils sont recrÃ©Ã©s sur d'autres nÅ“uds
- Les DaemonSets restent (d'oÃ¹ `--ignore-daemonsets`)

**2. Retirer le worker du cluster :**
```bash
# Depuis n'importe quel nÅ“ud du cluster
microk8s remove-node worker1
```

**3. Sur worker1, faire leave (optionnel) :**
```bash
# Sur worker1
microk8s leave
```

**4. VÃ©rifier :**
```bash
microk8s kubectl get nodes
```

worker1 n'apparaÃ®t plus dans la liste.

### MÃ©thode ForcÃ©e (NÅ“ud Mort)

Si le worker est mort (panne matÃ©rielle, inaccessible) :

```bash
# Forcer la suppression
microk8s remove-node worker1 --force
```

Les pods qui Ã©taient sur worker1 sont automatiquement redÃ©marrÃ©s ailleurs aprÃ¨s ~5 minutes (grace period).

## Monitoring des Workers

### Commandes Essentielles

**Ã‰tat de tous les nÅ“uds :**
```bash
watch microk8s kubectl get nodes -o wide
```

**Utilisation CPU/RAM par nÅ“ud :**
```bash
watch microk8s kubectl top nodes
```

**Pods par nÅ“ud :**
```bash
microk8s kubectl get pods --all-namespaces -o wide --sort-by=.spec.nodeName
```

**Compter les pods par nÅ“ud :**
```bash
for node in $(microk8s kubectl get nodes -o name); do
  echo "$node: $(microk8s kubectl get pods --all-namespaces --field-selector spec.nodeName=$(basename $node) --no-headers | wc -l) pods"
done
```

### Dashboard Kubernetes

**Activer le dashboard (si pas dÃ©jÃ  fait) :**
```bash
microk8s enable dashboard
```

**AccÃ©der :**
```bash
# Port-forward
microk8s kubectl port-forward -n kube-system service/kubernetes-dashboard 10443:443

# Obtenir le token
microk8s kubectl describe secret -n kube-system microk8s-dashboard-token
```

Ouvrez https://localhost:10443 dans votre navigateur.

**Visualisation :**
- Vue d'ensemble des nÅ“uds
- Utilisation des ressources en temps rÃ©el
- Pods par nÅ“ud

### Prometheus + Grafana (RecommandÃ©)

**Activer Prometheus :**
```bash
microk8s enable prometheus
```

**Dashboards utiles :**
- "Kubernetes / Compute Resources / Cluster"
- "Kubernetes / Compute Resources / Node (Pods)"
- "Node Exporter / Nodes"

**Voir la distribution des pods par nÅ“ud :**
Dans Grafana, requÃªte PromQL :
```promql
count(kube_pod_info) by (node)
```

## Bonnes Pratiques pour les Workers

### 1. Standardiser les Workers

**Recommandation :** Utilisez des workers avec les **mÃªmes specs** autant que possible.

**Avantages :**
- PrÃ©dictibilitÃ© (chaque worker peut hÃ©berger la mÃªme charge)
- Simplification de la gestion
- Facilite les calculs de capacitÃ©

**Exceptions acceptables :**
- Workers GPU pour ML
- Workers avec stockage SSD rapide pour DB

### 2. Documenter les Workers

**Maintenir un inventaire :**
```markdown
# Inventaire Cluster

## Control Plane
- node1: 192.168.1.10 - 4 CPU, 8 GB RAM - Control+Worker
- node2: 192.168.1.11 - 4 CPU, 8 GB RAM - Control+Worker
- node3: 192.168.1.12 - 4 CPU, 8 GB RAM - Control+Worker

## Workers Purs
- worker1: 192.168.1.20 - 4 CPU, 8 GB RAM - Worker - Apps gÃ©nÃ©rales
- worker2: 192.168.1.21 - 4 CPU, 8 GB RAM - Worker - Apps gÃ©nÃ©rales
- worker3: 192.168.1.22 - 8 CPU, 16 GB RAM - Worker - Bases de donnÃ©es
- worker4: 192.168.1.23 - 8 CPU, 16 GB RAM - Worker - Bases de donnÃ©es

## CapacitÃ© Totale
- CPU: 36 cores (12 control + 24 workers)
- RAM: 72 GB (24 control + 48 workers)
```

### 3. Labelliser et Organiser

**SystÃ¨me de labels cohÃ©rent :**
```bash
# RÃ´le
microk8s kubectl label node worker1 node-role.kubernetes.io/worker=true

# Type de workload
microk8s kubectl label node worker1 workload-type=general
microk8s kubectl label node worker3 workload-type=database

# Environnement (si multi-env sur mÃªme cluster)
microk8s kubectl label node worker1 env=production
microk8s kubectl label node worker5 env=staging

# Zone physique
microk8s kubectl label node worker1 zone=datacenter-a
```

### 4. Requests et Limits Partout

**Ne jamais dÃ©ployer sans requests :**
```yaml
# âŒ MAUVAIS
containers:
- name: app
  image: myapp

# âœ… BON
containers:
- name: app
  image: myapp
  resources:
    requests:
      cpu: "250m"
      memory: "256Mi"
    limits:
      cpu: "500m"
      memory: "512Mi"
```

Sans requests, le Scheduler ne peut pas bien rÃ©partir la charge.

### 5. PrÃ©voir de la Marge

**RÃ¨gle du 70% :**
Ne planifiez pas d'utiliser plus de **70% des ressources** en conditions normales.

**Pourquoi ?**
- Pics de charge inattendus
- RedÃ©ploiements (besoin de place pour les nouveaux pods)
- Maintenance (drain d'un worker)

**Exemple :**
Si vous avez besoin de 16 cores pour vos apps :
- 16 / 0.7 = ~23 cores nÃ©cessaires
- Avec des workers de 4 cores : 23 / 4 = 6 workers

### 6. Automatiser l'Ajout (AvancÃ©)

Pour les environnements cloud, vous pouvez scripter l'ajout de workers :

```bash
#!/bin/bash
# add-worker.sh

# 1. CrÃ©er la VM (Terraform, cloud CLI, etc.)
# 2. Installer MicroK8s
# 3. GÃ©nÃ©rer token et joindre
TOKEN=$(microk8s add-node --worker | grep "microk8s join" | awk '{print $3" "$4}')
ssh worker-new "sudo snap install microk8s --classic && microk8s $TOKEN"
```

## ScÃ©narios d'Usage Pratiques

### ScÃ©nario 1 : Startup en Croissance

**Phase 1 (DÃ©marrage) :**
```
3 nÅ“uds control+worker (12 CPU, 24 GB)
```

**Phase 2 (Croissance) :**
```
3 control+worker + 2 workers purs (20 CPU, 40 GB)
CoÃ»t: +2 serveurs
```

**Phase 3 (Scale Up) :**
```
3 control+worker + 5 workers purs (32 CPU, 64 GB)
CoÃ»t: +3 serveurs
```

**Phase 4 (Mature) :**
```
3 control+worker + 10 workers purs (52 CPU, 104 GB)
CoÃ»t: +5 serveurs
```

### ScÃ©nario 2 : Homelab Multi-Usage

**Configuration :**
```
3 nÅ“uds control+worker : Infrastructure systÃ¨me
worker1-2             : Services web (Nextcloud, Wiki, etc.)
worker3               : Media server (Plex, Jellyfin)
worker4               : Bases de donnÃ©es
```

Isolation par type d'application = meilleure gestion.

### ScÃ©nario 3 : Environnements SÃ©parÃ©s

**Sur le mÃªme cluster physique :**
```
worker1-2 : namespace "production" (taints)
worker3-4 : namespace "staging" (taints)
worker5   : namespace "development"
```

Avec des taints et tolerations, vous isolez les environnements.

## Limites et ConsidÃ©rations

### Limites de MicroK8s

**ScalabilitÃ© recommandÃ©e :**
- **Optimal** : 3-10 nÅ“uds (control + workers)
- **Maximum raisonnable** : 20-30 nÅ“uds total
- **Au-delÃ ** : Envisager Kubernetes "standard" (kubeadm) ou managÃ© (EKS, GKE, AKS)

**Pourquoi ?**
- Dqlite optimisÃ© pour petits clusters
- Au-delÃ  de 30 nÅ“uds, etcd est prÃ©fÃ©rable

### CoÃ»ts et ROI

**Calcul du coÃ»t :**
```
1 worker = 1 serveur = â‚¬X/mois (si cloud) ou coÃ»t matÃ©riel + Ã©lectricitÃ©

Exemple cloud (DigitalOcean) :
- 4 CPU, 8 GB = ~$48/mois
- 10 workers = $480/mois

Exemple on-premise :
- Mini PC 4 CPU, 8 GB = â‚¬300 + â‚¬5/mois Ã©lectricitÃ©
- 10 workers = â‚¬3000 initial + â‚¬50/mois
- Amortissement sur 3 ans : ~â‚¬133/mois
```

**Optimiser le ROI :**
- N'ajoutez des workers que quand nÃ©cessaire
- Utilisez bien les resources (requests/limits)
- Surveillez l'utilisation rÃ©elle

## Points ClÃ©s Ã  Retenir

1. **Workers purs** = nÅ“uds sans control plane, dÃ©diÃ©s aux workloads
2. **Scaling horizontal** : Ajoutez des workers plutÃ´t que d'upgrader les machines
3. **Token worker** : `microk8s add-node --worker` sur un nÅ“ud existant
4. **Join worker** : `microk8s join <token> --worker` sur le nouveau nÅ“ud
5. **Isolation** : Workers purs isolent le control plane des charges applicatives
6. **Labels** : Organisez vos workers avec des labels cohÃ©rents
7. **Requests/Limits** : Toujours dÃ©finir pour une bonne rÃ©partition
8. **Monitoring** : `kubectl top nodes` et Prometheus/Grafana
9. **CapacitÃ©** : Gardez 30% de marge pour les pics et maintenances
10. **Limites** : MicroK8s optimal jusqu'Ã  ~20-30 nÅ“uds

## Prochaines Ã‰tapes

Maintenant que vous savez gÃ©rer les workers, les prochains chapitres couvriront :

- **21.6** : Load balancing entre nÅ“uds avec MetalLB
- **21.7** : Stockage distribuÃ© pour partager les donnÃ©es entre workers
- **21.8** : Backup et restauration d'un cluster multi-node
- **21.9** : StratÃ©gies de redondance avancÃ©es
- **21.10** : Tests de failover et chaos engineering

Vous maÃ®trisez maintenant l'art du scaling horizontal avec MicroK8s ! Vous pouvez faire grandir votre cluster au rythme de vos besoins, sans limite (ou presque) ! ğŸš€

---

**FÃ©licitations !** Vous savez maintenant comment ajouter des workers supplÃ©mentaires pour scaler votre cluster Kubernetes horizontalement. C'est une compÃ©tence essentielle pour gÃ©rer la croissance et optimiser les ressources !

â­ï¸ [Load balancing entre nodes](/21-multi-node-et-haute-disponibilite/06-load-balancing-entre-nodes.md)
