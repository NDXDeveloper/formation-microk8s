üîù Retour au [Sommaire](/SOMMAIRE.md)

# 21.4 Configuration d'un Cluster HA (3+ N≈ìuds)

## Introduction

Vous savez maintenant comment ajouter des n≈ìuds √† un cluster MicroK8s. Dans ce chapitre, nous allons passer √† l'√©tape sup√©rieure : configurer un **cluster en haute disponibilit√© (HA) complet** avec 3 n≈ìuds ou plus.

Un cluster HA est con√ßu pour **ne jamais s'arr√™ter**, m√™me si un ou plusieurs serveurs tombent en panne. C'est la configuration que vous utiliseriez pour :
- Des applications critiques en production
- Un environnement de test r√©aliste
- Apprendre les concepts avanc√©s de Kubernetes
- H√©berger des services personnels avec redondance

Nous allons voir comment construire ce cluster de A √† Z, le configurer correctement, et v√©rifier qu'il est vraiment r√©silient.

## Qu'est-ce qu'un Cluster HA ?

### Rappel des Concepts

Un cluster **Haute Disponibilit√© (High Availability)** est un cluster qui :
1. **Continue de fonctionner** m√™me si un ou plusieurs n≈ìuds tombent
2. **Redistribue automatiquement** les workloads en cas de panne
3. **Maintient le quorum** du control plane avec Dqlite
4. **Offre z√©ro ou tr√®s peu de downtime** lors des incidents

**Analogie avec un avion :**
Un avion de ligne a plusieurs moteurs. Si un moteur tombe en panne, les autres compensent et l'avion peut continuer son vol et atterrir en s√©curit√©. Un cluster HA fonctionne de la m√™me mani√®re.

### Les Composants en HA

Dans un cluster MicroK8s HA, plusieurs composants sont redondants :

**1. Control Plane (Dqlite)**
- R√©pliqu√© sur 3 n≈ìuds minimum
- Tol√©rance √† la panne d'un n≈ìud
- √âlection automatique d'un nouveau Leader

**2. API Server**
- Actif sur chaque n≈ìud control plane
- Load balancing automatique entre les instances
- N'importe quel API Server peut traiter vos requ√™tes

**3. Scheduler et Controllers**
- Actifs sur tous les n≈ìuds control plane
- √âlection de leader automatique
- Basculement en quelques secondes

**4. Workloads (Pods)**
- R√©partis sur tous les n≈ìuds workers
- Red√©marrage automatique sur un autre n≈ìud si panne
- Load balancing entre r√©plicas

## Pourquoi 3 N≈ìuds Minimum ?

### Le Concept de Quorum

Pour comprendre pourquoi 3 n≈ìuds est le minimum, il faut comprendre le **quorum**.

**Quorum = Majorit√© simple**

Avec Dqlite (et l'algorithme Raft), pour qu'une d√©cision soit prise, il faut l'accord de la **majorit√©** des n≈ìuds.

**Calcul du quorum :**
```
Quorum = (Nombre de n≈ìuds / 2) + 1
```

**Exemples :**
- 1 n≈ìud : quorum = 1 (pas de HA)
- 2 n≈ìuds : quorum = 2 (si 1 tombe, pas de quorum ‚ùå)
- **3 n≈ìuds : quorum = 2** (si 1 tombe, quorum maintenu ‚úÖ)
- 4 n≈ìuds : quorum = 3 (si 1 tombe, quorum maintenu, mais pas mieux que 3)
- **5 n≈ìuds : quorum = 3** (si 2 tombent, quorum maintenu ‚úÖ)
- 7 n≈ìuds : quorum = 4 (si 3 tombent, quorum maintenu ‚úÖ)

### Tableau de Tol√©rance aux Pannes

| N≈ìuds | Quorum | Pannes tol√©r√©es | HA ? | Co√ªt | Recommandation |
|-------|--------|-----------------|------|------|----------------|
| 1 | 1 | 0 | ‚ùå | Faible | Dev/Test uniquement |
| 2 | 2 | 0 | ‚ùå | Moyen | **√Ä √âVITER** (pire que 1) |
| **3** | 2 | **1** | ‚úÖ | Moyen | **Configuration HA minimale** |
| 4 | 3 | 1 | ‚úÖ | √âlev√© | ‚ùå Pas rentable (identique √† 3) |
| **5** | 3 | **2** | ‚úÖ | √âlev√© | **HA renforc√©e** |
| 6 | 4 | 2 | ‚úÖ | Tr√®s √©lev√© | ‚ùå Pas rentable (identique √† 5) |
| **7** | 4 | **3** | ‚úÖ | Tr√®s √©lev√© | **HA maximale** |

**R√®gle d'or :** Utilisez toujours un **nombre impair** de n≈ìuds (3, 5, 7).

### Pourquoi Jamais 2 N≈ìuds ?

Avec 2 n≈ìuds :
- Quorum = 2
- Si 1 n≈ìud tombe ‚Üí quorum perdu (1/2 < 50%)
- Cluster en lecture seule (impossible de cr√©er/modifier des ressources)

**C'est pire qu'avoir 1 seul n≈ìud !** Vous consommez le double de ressources sans gain de r√©silience.

## Architecture Recommand√©e pour un Cluster HA

### Configuration 3 N≈ìuds (Recommand√©e pour Lab/PME)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CLUSTER MICROK8S HA - 3 N≈íUDS                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ   ‚îÇ   Node 1     ‚îÇ      ‚îÇ   Node 2     ‚îÇ      ‚îÇ   Node 3     ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ 192.168.1.10 ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ 192.168.1.11 ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ 192.168.1.12 ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ              ‚îÇ      ‚îÇ              ‚îÇ      ‚îÇ              ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ Control      ‚îÇ      ‚îÇ Control      ‚îÇ      ‚îÇ Control      ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ Plane        ‚îÇ      ‚îÇ Plane        ‚îÇ      ‚îÇ Plane        ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ + Worker     ‚îÇ      ‚îÇ + Worker     ‚îÇ      ‚îÇ + Worker     ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ              ‚îÇ      ‚îÇ              ‚îÇ      ‚îÇ              ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ Dqlite       ‚îÇ      ‚îÇ Dqlite       ‚îÇ      ‚îÇ Dqlite       ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ (Leader)     ‚îÇ      ‚îÇ (Follower)   ‚îÇ      ‚îÇ (Follower)   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ              ‚îÇ      ‚îÇ              ‚îÇ      ‚îÇ              ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ 4 CPU        ‚îÇ      ‚îÇ 4 CPU        ‚îÇ      ‚îÇ 4 CPU        ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ 8 GB RAM     ‚îÇ      ‚îÇ 8 GB RAM     ‚îÇ      ‚îÇ 8 GB RAM     ‚îÇ  ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ          ‚îÇ                      ‚îÇ                      ‚îÇ        ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                      R√©seau Gigabit (1 Gbps)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Tol√©rance aux pannes : 1 n≈ìud peut tomber
Quorum : 2/3 n≈ìuds n√©cessaires
```

**Caract√©ristiques :**
- Chaque n≈ìud fait **control plane ET worker**
- Simplicit√© de gestion
- Ressources partag√©es entre control plane et applications
- **Id√©al pour :** Labs personnels, PME, environnements de test

### Configuration 5 N≈ìuds (Production Renforc√©e)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CLUSTER MICROK8S HA - 5 N≈íUDS                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                ‚îÇ
‚îÇ         CONTROL PLANE (3 n≈ìuds)                                ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ   ‚îÇ  Node 1  ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ  Node 2  ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ  Node 3  ‚îÇ                 ‚îÇ
‚îÇ   ‚îÇ Control  ‚îÇ    ‚îÇ Control  ‚îÇ    ‚îÇ Control  ‚îÇ                 ‚îÇ
‚îÇ   ‚îÇ + Worker ‚îÇ    ‚îÇ + Worker ‚îÇ    ‚îÇ + Worker ‚îÇ                 ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ         WORKERS PURS (2 n≈ìuds)                                 ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ   ‚îÇ Worker 1 ‚îÇ                    ‚îÇ Worker 2 ‚îÇ                 ‚îÇ
‚îÇ   ‚îÇ Worker   ‚îÇ                    ‚îÇ Worker   ‚îÇ                 ‚îÇ
‚îÇ   ‚îÇ Only     ‚îÇ                    ‚îÇ Only     ‚îÇ                 ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Tol√©rance aux pannes : 2 n≈ìuds peuvent tomber
Quorum : 3/5 n≈ìuds n√©cessaires
```

**Caract√©ristiques :**
- 3 n≈ìuds control plane + worker
- 2 workers purs suppl√©mentaires
- Meilleure tol√©rance aux pannes (2 n≈ìuds)
- **Id√©al pour :** Production, applications critiques

## Pr√©requis pour un Cluster HA

### 1. Infrastructure Mat√©rielle

**Configuration minimale par n≈ìud (3 n≈ìuds HA) :**
```
CPU     : 2 c≈ìurs (4 recommand√©s)
RAM     : 4 GB (8 GB recommand√©s)
Stockage: 40 GB (SSD fortement recommand√©)
R√©seau  : 1 Gbps
```

**Total pour cluster 3 n≈ìuds :**
```
CPU     : 6-12 c≈ìurs
RAM     : 12-24 GB
Stockage: 120 GB
```

**V√©rifier les ressources sur chaque n≈ìud :**
```bash
# CPU
nproc

# RAM (disponible)
free -h

# Espace disque
df -h /

# Interface r√©seau (vitesse)
ethtool eth0 | grep Speed
```

### 2. Configuration R√©seau

**Adresses IP statiques pour chaque n≈ìud :**
```
Node 1: 192.168.1.10
Node 2: 192.168.1.11
Node 3: 192.168.1.12
```

**R√©solution DNS (optionnel mais recommand√©) :**

Ajouter dans `/etc/hosts` sur **chaque** n≈ìud :
```bash
sudo nano /etc/hosts
```

```
192.168.1.10    node1    node1.cluster.local
192.168.1.11    node2    node2.cluster.local
192.168.1.12    node3    node3.cluster.local
```

**V√©rifier la connectivit√© :**
```bash
# Depuis chaque n≈ìud, pinger les autres
ping -c 3 node1
ping -c 3 node2
ping -c 3 node3

# V√©rifier la latence (doit √™tre < 10ms id√©alement)
ping -c 10 node2 | grep avg
```

### 3. Ports et Firewall

**Ouvrir les ports n√©cessaires entre tous les n≈ìuds :**

**Sur chaque n≈ìud, autoriser les autres n≈ìuds :**
```bash
# Sur Node 1
sudo ufw allow from 192.168.1.11
sudo ufw allow from 192.168.1.12

# Sur Node 2
sudo ufw allow from 192.168.1.10
sudo ufw allow from 192.168.1.12

# Sur Node 3
sudo ufw allow from 192.168.1.10
sudo ufw allow from 192.168.1.11
```

**Ou plus pr√©cis√©ment (ports sp√©cifiques) :**
```bash
# Ports essentiels pour cluster HA
sudo ufw allow from 192.168.1.0/24 to any port 16443    # API Server
sudo ufw allow from 192.168.1.0/24 to any port 25000    # Cluster agent
sudo ufw allow from 192.168.1.0/24 to any port 12379    # Dqlite
sudo ufw allow from 192.168.1.0/24 to any port 10250    # Kubelet
```

### 4. Synchronisation du Temps

**Critique pour Dqlite !** Tous les n≈ìuds doivent avoir la m√™me heure.

**Installer et configurer NTP :**
```bash
# Sur chaque n≈ìud
sudo apt update
sudo apt install -y chrony

# V√©rifier la synchronisation
timedatectl status

# Doit afficher "System clock synchronized: yes"
```

**V√©rifier l'√©cart entre n≈ìuds :**
```bash
# Sur Node 1
date

# Sur Node 2
date

# Sur Node 3
date
```

L'√©cart doit √™tre de **moins de 1 seconde**.

### 5. Hostnames Uniques

**Sur chaque n≈ìud, d√©finir un hostname unique :**
```bash
# Sur Node 1
sudo hostnamectl set-hostname node1

# Sur Node 2
sudo hostnamectl set-hostname node2

# Sur Node 3
sudo hostnamectl set-hostname node3

# V√©rifier
hostname
```

## Construction d'un Cluster HA 3 N≈ìuds - √âtape par √âtape

### Phase 1 : Installation de MicroK8s sur Tous les N≈ìuds

**Sur Node 1, Node 2 ET Node 3 (m√™me version !) :**

```bash
# Mise √† jour du syst√®me
sudo apt update && sudo apt upgrade -y

# Installation de MicroK8s (utiliser le m√™me channel)
sudo snap install microk8s --classic --channel=1.28/stable

# Ajouter l'utilisateur au groupe
sudo usermod -a -G microk8s $USER
sudo chown -f -R $USER ~/.kube

# Recharger les groupes
newgrp microk8s

# Attendre que MicroK8s soit pr√™t
microk8s status --wait-ready
```

**V√©rifier la version sur chaque n≈ìud :**
```bash
microk8s version
# Doit afficher la m√™me version partout
```

**√Ä ce stade :**
- Node 1 : cluster standalone (1 n≈ìud)
- Node 2 : cluster standalone (1 n≈ìud)
- Node 3 : cluster standalone (1 n≈ìud)

Ils ne se connaissent pas encore.

### Phase 2 : Ajouter Node 2 au Cluster

**Sur Node 1 :**
```bash
microk8s add-node
```

**Copier la commande affich√©e, exemple :**
```
microk8s join 192.168.1.10:25000/abc123def456ghi789jkl012mno345pqr678
```

**Sur Node 2 :**
```bash
microk8s join 192.168.1.10:25000/abc123def456ghi789jkl012mno345pqr678
```

**Attendre la confirmation :**
```
Contacting cluster at 192.168.1.10...
Waiting for this node to finish joining the cluster. .. .. ..
Successfully joined the cluster.
```

**V√©rifier depuis n'importe quel n≈ìud :**
```bash
microk8s kubectl get nodes
```

```
NAME    STATUS   ROLES    AGE     VERSION
node1   Ready    <none>   10m     v1.28.3
node2   Ready    <none>   1m      v1.28.3
```

**V√©rifier Dqlite :**
```bash
microk8s status
```

```
microk8s is running
high-availability: yes
  datastore master nodes: 192.168.1.10:19001 192.168.1.11:19001
```

**Important :** √Ä ce stade, vous avez 2 n≈ìuds, mais **pas encore de HA** (quorum = 2, donc besoin des 2 n≈ìuds).

### Phase 3 : Ajouter Node 3 au Cluster (HA Activ√©e)

**Sur Node 1 ou Node 2 :**
```bash
microk8s add-node
```

**Copier le nouveau token (diff√©rent du pr√©c√©dent !), exemple :**
```
microk8s join 192.168.1.10:25000/xyz789uvw456rst123abc098def765mno432
```

**Sur Node 3 :**
```bash
microk8s join 192.168.1.10:25000/xyz789uvw456rst123abc098def765mno432
```

**Attendre la confirmation :**
```
Successfully joined the cluster.
```

**V√©rifier les 3 n≈ìuds :**
```bash
microk8s kubectl get nodes
```

```
NAME    STATUS   ROLES    AGE     VERSION
node1   Ready    <none>   15m     v1.28.3
node2   Ready    <none>   6m      v1.28.3
node3   Ready    <none>   30s     v1.28.3
```

**V√©rifier la HA compl√®te :**
```bash
microk8s status
```

```
microk8s is running
high-availability: yes
  datastore master nodes: 192.168.1.10:19001 192.168.1.11:19001 192.168.1.12:19001
  datastore standby nodes: none
```

**üéâ Vous avez maintenant un cluster HA fonctionnel !**

Quorum = 2/3 ‚Üí Vous pouvez perdre 1 n≈ìud sans perdre le cluster.

### Phase 4 : Activer les Addons Essentiels

**Sur n'importe quel n≈ìud :**

```bash
# DNS (essentiel)
microk8s enable dns

# Stockage persistant
microk8s enable hostpath-storage

# Dashboard (optionnel, pour monitoring visuel)
microk8s enable dashboard

# Metrics Server (pour kubectl top)
microk8s enable metrics-server
```

**V√©rifier que les addons sont activ√©s partout :**
```bash
microk8s status
```

Les addons activ√©s sur un n≈ìud sont **automatiquement disponibles** sur tous les n≈ìuds du cluster.

## V√©rifications Post-Configuration

### 1. √âtat des N≈ìuds

**Tous les n≈ìuds doivent √™tre Ready :**
```bash
microk8s kubectl get nodes -o wide
```

```
NAME    STATUS   ROLES    AGE   VERSION   INTERNAL-IP     OS-IMAGE
node1   Ready    <none>   20m   v1.28.3   192.168.1.10    Ubuntu 22.04
node2   Ready    <none>   11m   v1.28.3   192.168.1.11    Ubuntu 22.04
node3   Ready    <none>   5m    v1.28.3   192.168.1.12    Ubuntu 22.04
```

**Points √† v√©rifier :**
- STATUS = Ready sur tous les n≈ìuds
- VERSION identique
- INTERNAL-IP correcte

### 2. Pods Syst√®me R√©partis

**Les pods syst√®me doivent √™tre distribu√©s :**
```bash
microk8s kubectl get pods -n kube-system -o wide
```

Vous devriez voir des pods sur diff√©rents n≈ìuds :
```
NAME                    READY   STATUS    NODE
calico-node-abc         1/1     Running   node1
calico-node-def         1/1     Running   node2
calico-node-ghi         1/1     Running   node3
coredns-xyz             1/1     Running   node2
hostpath-provisioner    1/1     Running   node1
```

C'est normal et souhaitable : la charge syst√®me est r√©partie.

### 3. √âtat de Dqlite

**V√©rifier le status HA :**
```bash
microk8s status
```

```
high-availability: yes
  datastore master nodes: 192.168.1.10:19001 192.168.1.11:19001 192.168.1.12:19001
  datastore standby nodes: none
```

**Explication :**
- **master nodes** : Les 3 n≈ìuds participent au quorum Dqlite
- **standby nodes** : Aucun (tous sont actifs dans le quorum)

### 4. Sant√© G√©n√©rale

**Inspecter le cluster :**
```bash
microk8s inspect
```

Cette commande g√©n√®re un rapport complet. Cherchez les sections :
- "Inspection Status" : doit √™tre OK
- "Node Status" : tous Ready
- "Dqlite Status" : HA actif

Si tout est vert, le cluster est en bonne sant√© ! ‚úÖ

### 5. Communication Inter-N≈ìuds

**D√©ployer un test multi-r√©plicas :**
```bash
# Cr√©er un deployment avec 3 r√©plicas
microk8s kubectl create deployment nginx-test --image=nginx --replicas=3

# Attendre que les pods soient pr√™ts
microk8s kubectl rollout status deployment nginx-test

# Voir sur quels n≈ìuds les pods tournent
microk8s kubectl get pods -o wide
```

Les 3 pods devraient √™tre r√©partis sur les 3 n≈ìuds (ou au moins 2).

**Tester la communication :**
```bash
# Obtenir les IPs des pods
microk8s kubectl get pods -o wide

# Exec dans un pod et pinger un autre
microk8s kubectl exec -it nginx-test-xxx -- ping -c 3 <IP_du_pod_sur_autre_noeud>
```

Si le ping fonctionne, la communication inter-n≈ìuds est OK !

**Nettoyer :**
```bash
microk8s kubectl delete deployment nginx-test
```

## Configuration Optimale du Cluster HA

### 1. Labels de N≈ìuds

**Organiser les n≈ìuds avec des labels :**

```bash
# Ajouter des labels pour identifier les r√¥les
microk8s kubectl label node node1 node-role.kubernetes.io/control-plane=true
microk8s kubectl label node node2 node-role.kubernetes.io/control-plane=true
microk8s kubectl label node node3 node-role.kubernetes.io/control-plane=true

# Ajouter des labels pour la topologie (datacenter, rack, zone, etc.)
microk8s kubectl label node node1 topology.kubernetes.io/zone=zone-a
microk8s kubectl label node node2 topology.kubernetes.io/zone=zone-b
microk8s kubectl label node node3 topology.kubernetes.io/zone=zone-c

# V√©rifier
microk8s kubectl get nodes --show-labels
```

Ces labels sont utiles pour :
- Pod affinity/anti-affinity
- Node selectors
- Visualisation dans les dashboards

### 2. Taints (Optionnel)

Si vous voulez r√©server certains n≈ìuds au control plane uniquement :

```bash
# Emp√™cher les pods applicatifs de tourner sur node1
microk8s kubectl taint nodes node1 node-role.kubernetes.io/control-plane=true:NoSchedule
```

**Note :** Dans un cluster 3 n≈ìuds, ce n'est g√©n√©ralement **pas recommand√©**, car vous perdez de la capacit√© de calcul.

### 3. Resource Quotas par Namespace

**Prot√©ger les ressources critiques :**

```yaml
# resource-quota-default.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: default-quota
  namespace: default
spec:
  hard:
    requests.cpu: "8"
    requests.memory: 16Gi
    limits.cpu: "12"
    limits.memory: 24Gi
```

```bash
microk8s kubectl apply -f resource-quota-default.yaml
```

### 4. Pod Disruption Budgets

**Prot√©ger vos applications critiques :**

```yaml
# pdb-example.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: nginx-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: nginx
```

Cela garantit qu'au moins 2 pods nginx sont toujours disponibles, m√™me pendant les maintenances.

## Tester la R√©silience du Cluster

### Test 1 : Arr√™t d'un N≈ìud Worker

**Simuler une panne de Node 3 :**

```bash
# Sur Node 3
sudo shutdown -h now
```

**Sur Node 1 ou Node 2, observer :**
```bash
# Attendre ~30 secondes
microk8s kubectl get nodes
```

```
NAME    STATUS     ROLES    AGE
node1   Ready      <none>   1h
node2   Ready      <none>   50m
node3   NotReady   <none>   44m    ‚Üê PANNE
```

**V√©rifier que le cluster fonctionne toujours :**
```bash
# Cr√©er un deployment
microk8s kubectl create deployment test-resilience --image=nginx --replicas=5

# Les pods se cr√©ent sur node1 et node2 uniquement
microk8s kubectl get pods -o wide
```

**V√©rifier Dqlite (quorum maintenu) :**
```bash
microk8s status
```

```
high-availability: yes
  datastore master nodes: 192.168.1.10:19001 192.168.1.11:19001
```

Quorum = 2/2 actifs (sur 3 total) ‚Üí Cluster fonctionnel ‚úÖ

**Rallumer Node 3 :**
```bash
# Sur Node 3, red√©marrer la machine
# Apr√®s red√©marrage, MicroK8s red√©marre automatiquement

# V√©rifier
microk8s kubectl get nodes
```

Node 3 repasse en **Ready** apr√®s ~1-2 minutes. Les pods se redistribuent progressivement.

### Test 2 : Panne du Leader Dqlite

**Identifier le Leader :**
```bash
# Sur n'importe quel n≈ìud
microk8s kubectl get lease -n kube-system
```

Cherchez le lease avec le nom contenant "apiserver" pour identifier le Leader actuel.

**Arr√™ter le n≈ìud Leader (ex: Node 1) :**
```bash
# Sur Node 1
sudo shutdown -h now
```

**Sur Node 2 ou Node 3, observer l'√©lection :**
```bash
# Attendre ~5-10 secondes
microk8s kubectl get nodes
```

Le cluster reste fonctionnel ! Dqlite a automatiquement √©lu un nouveau Leader parmi Node 2 et Node 3.

**Tester la cr√©ation de ressources :**
```bash
microk8s kubectl run test-after-failover --image=nginx
microk8s kubectl get pods
```

√áa fonctionne ! Le nouveau Leader prend le relais. ‚úÖ

### Test 3 : Perte de Quorum (2 N≈ìuds Down)

**‚ö†Ô∏è Test destructif - √† faire en environnement de test uniquement !**

**Arr√™ter Node 1 ET Node 2 :**
```bash
# Sur Node 1
sudo shutdown -h now

# Sur Node 2
sudo shutdown -h now
```

**Sur Node 3, v√©rifier le status :**
```bash
microk8s status
```

```
microk8s is running
high-availability: no (quorum lost)
```

**Tenter de cr√©er un pod :**
```bash
microk8s kubectl run test-no-quorum --image=nginx
```

```
Error: cluster is in read-only mode (no quorum)
```

Le cluster est en **mode lecture seule**. Les pods existants continuent de tourner, mais vous ne pouvez plus faire de modifications.

**Solution :** Rallumer au moins 1 des 2 n≈ìuds down pour retrouver le quorum.

**Rallumer Node 1 ou Node 2 :**

Apr√®s red√©marrage, le quorum est restaur√© (2/3 actifs). Le cluster redevient fonctionnel.

## Strat√©gies de Maintenance

### Maintenance Planifi√©e d'un N≈ìud

Quand vous devez faire une maintenance sur un n≈ìud (mise √† jour OS, remplacement mat√©riel, etc.), suivez ce processus :

**1. Drainer le n≈ìud (√©vacuer les pods) :**
```bash
# Marquer le n≈ìud comme non-schedulable et √©vacuer les pods
microk8s kubectl drain node2 --ignore-daemonsets --delete-emptydir-data
```

**2. Faire la maintenance :**
```bash
# Sur Node 2
sudo apt update && sudo apt upgrade -y
sudo reboot
```

**3. R√©int√©grer le n≈ìud :**
```bash
# Une fois Node 2 de retour
microk8s kubectl uncordon node2
```

Les nouveaux pods peuvent √† nouveau √™tre schedul√©s sur node2.

### Mise √† Jour de MicroK8s en HA

**Mettre √† jour un n≈ìud √† la fois :**

```bash
# Sur Node 1
microk8s kubectl drain node1 --ignore-daemonsets
sudo snap refresh microk8s --channel=1.29/stable
microk8s kubectl uncordon node1

# Attendre que node1 soit Ready, puis r√©p√©ter pour Node 2
microk8s kubectl drain node2 --ignore-daemonsets
# ... sur node2 ...
sudo snap refresh microk8s --channel=1.29/stable
microk8s kubectl uncordon node2

# Enfin, Node 3
microk8s kubectl drain node3 --ignore-daemonsets
# ... sur node3 ...
sudo snap refresh microk8s --channel=1.29/stable
microk8s kubectl uncordon node3
```

**Zero downtime** si vos applications ont au moins 2 r√©plicas !

## Monitoring du Cluster HA

### 1. Commandes Essentielles

**Surveillance des n≈ìuds :**
```bash
# √âtat des n≈ìuds
watch microk8s kubectl get nodes

# Utilisation des ressources (CPU/RAM)
watch microk8s kubectl top nodes
```

**Surveillance de Dqlite :**
```bash
# Status g√©n√©ral
watch microk8s status

# Logs Dqlite (si probl√®me)
sudo journalctl -u snap.microk8s.daemon-k8s-dqlite -f
```

**√âv√©nements du cluster :**
```bash
# Voir les √©v√©nements r√©cents
microk8s kubectl get events --all-namespaces --sort-by='.lastTimestamp'
```

### 2. Prometheus et Grafana (Recommand√©)

**Activer le monitoring avanc√© :**
```bash
microk8s enable prometheus
```

Cela installe :
- Prometheus (collecte des m√©triques)
- Grafana (visualisation)
- Alertmanager (alertes)

**Acc√©der √† Grafana :**
```bash
# Obtenir le mot de passe admin
microk8s kubectl get secret -n observability grafana -o jsonpath="{.data.admin-password}" | base64 --decode

# Port-forward pour acc√©der
microk8s kubectl port-forward -n observability service/grafana 3000:3000
```

Ouvrez http://localhost:3000 dans votre navigateur.

**Dashboards recommand√©s :**
- Kubernetes / Cluster
- Kubernetes / Nodes
- Dqlite Performance

### 3. Alertes Critiques √† Configurer

**Alertes essentielles pour un cluster HA :**
- N≈ìud down (NotReady > 5 minutes)
- Perte de quorum Dqlite
- CPU > 80% sur un n≈ìud pendant > 10 minutes
- RAM > 90% sur un n≈ìud
- Espace disque < 10% sur un n≈ìud
- Pod crashlooping

## Bonnes Pratiques pour un Cluster HA

### 1. R√©partition Physique

**S√©parez physiquement vos n≈ìuds si possible :**
- Diff√©rents racks (√©vite la panne d'un PDU)
- Diff√©rents switchs r√©seau (√©vite un SPOF r√©seau)
- Diff√©rentes alimentations √©lectriques

**Dans un homelab :**
- Au minimum, diff√©rents serveurs physiques
- Si VMs, sur diff√©rents hyperviseurs

### 2. Backups R√©guliers

**M√™me avec la HA, faites des backups !**

```bash
# Backup de la config du cluster (√† faire r√©guli√®rement)
microk8s kubectl get all --all-namespaces -o yaml > backup-cluster-$(date +%Y%m%d).yaml

# Backup des secrets
microk8s kubectl get secrets --all-namespaces -o yaml > backup-secrets-$(date +%Y%m%d).yaml
```

**Automatiser avec cron :**
```bash
# Ajouter dans crontab
0 2 * * * /path/to/backup-script.sh
```

### 3. Documentation du Cluster

**Maintenir un document avec :**
- Inventaire des n≈ìuds (IP, hostname, specs)
- Addons activ√©s
- Applications d√©ploy√©es
- Proc√©dures de maintenance
- Contacts en cas d'urgence

**Exemple :**
```markdown
# Cluster K8s Production

## N≈ìuds
- node1: 192.168.1.10 - 4 CPU, 8 GB RAM - Control Plane + Worker
- node2: 192.168.1.11 - 4 CPU, 8 GB RAM - Control Plane + Worker
- node3: 192.168.1.12 - 4 CPU, 8 GB RAM - Control Plane + Worker

## Addons
- dns, storage, prometheus, ingress, cert-manager

## Applications Critiques
- App Production (namespace: prod)
- Base de donn√©es PostgreSQL (namespace: database)

## Proc√©dures
- Restart d'un n≈ìud: drain ‚Üí maintenance ‚Üí uncordon
- Contact support: ops@example.com
```

### 4. Tests de R√©silience R√©guliers

**Testez r√©guli√®rement votre HA :**

```bash
# 1x par mois : test de panne d'un n≈ìud
# 1x par trimestre : test de mise √† jour
# 1x par an : test de restauration de backup complet
```

**Chaos Engineering (avanc√©) :**
Utilisez des outils comme **Chaos Mesh** pour simuler des pannes al√©atoires et v√©rifier la r√©silience.

### 5. Monitoring Proactif

**Configurez des alertes AVANT les probl√®mes :**
- Disk > 75% ‚Üí warning
- Disk > 90% ‚Üí critical
- CPU moyen > 70% pendant 1h ‚Üí investigation
- Latence r√©seau > 20ms ‚Üí v√©rifier l'infra

## √âvolution du Cluster : 3 ‚Üí 5 ‚Üí 7 N≈ìuds

### Passer de 3 √† 5 N≈ìuds

**Ajouter 2 workers purs :**

```bash
# Sur un n≈ìud existant, g√©n√©rer token worker
microk8s add-node --worker

# Sur worker4
microk8s join <token> --worker

# R√©p√©ter pour worker5
microk8s add-node --worker
# Sur worker5
microk8s join <token> --worker

# V√©rifier
microk8s kubectl get nodes
```

```
NAME      STATUS   ROLES
node1     Ready    <none>
node2     Ready    <none>
node3     Ready    <none>
worker4   Ready    <none>
worker5   Ready    <none>
```

**Avantage :** Plus de capacit√© de calcul, mais toujours 3 n≈ìuds control plane (tol√©rance 1 panne).

### Passer de 3 √† 5 N≈ìuds Control Plane

**Ajouter 2 n≈ìuds mixtes (control plane + worker) :**

```bash
# Sur un n≈ìud existant
microk8s add-node

# Sur node4
microk8s join <token>

# R√©p√©ter pour node5
```

**Avantage :** Tol√©rance √† 2 pannes simultan√©es (quorum = 3/5).

```bash
microk8s status
```

```
high-availability: yes
  datastore master nodes:
    192.168.1.10:19001
    192.168.1.11:19001
    192.168.1.12:19001
    192.168.1.13:19001
    192.168.1.14:19001
```

## D√©pannage d'un Cluster HA

### Probl√®me : N≈ìud Reste NotReady

**Diagnostic :**
```bash
# Voir les d√©tails du n≈ìud
microk8s kubectl describe node node2

# Logs kubelet
sudo journalctl -u snap.microk8s.daemon-kubelet -n 100
```

**Causes courantes :**
- Probl√®me r√©seau (CNI)
- Espace disque plein
- Probl√®me Dqlite

**Solution :**
```bash
# Red√©marrer MicroK8s sur le n≈ìud probl√©matique
microk8s stop
microk8s start
```

### Probl√®me : Split-Brain (Tr√®s Rare)

**Sympt√¥me :** Deux parties du cluster pensent √™tre le Leader.

**Diagnostic :**
```bash
# V√©rifier les Leaders sur chaque n≈ìud
microk8s kubectl get lease -n kube-system
```

**Solution :**
Red√©marrer le cluster enti√®rement (tous les n≈ìuds) pour forcer une nouvelle √©lection.

### Probl√®me : Performances D√©grad√©es

**Causes possibles :**
- Latence r√©seau √©lev√©e (> 50ms)
- Disques lents (HDD au lieu de SSD)
- Charge CPU/RAM trop √©lev√©e

**Diagnostic :**
```bash
# V√©rifier latence
ping -c 100 node2 | grep avg

# V√©rifier I/O disque
sudo iotop

# V√©rifier charge
microk8s kubectl top nodes
```

## Points Cl√©s √† Retenir

1. **3 n≈ìuds minimum** pour la vraie HA (quorum = 2/3)
2. **Nombre impair** de n≈ìuds toujours (3, 5, 7)
3. **Ne jamais avoir 2 n≈ìuds** (pire que 1)
4. **Tol√©rance aux pannes** : (n-1)/2 n≈ìuds
5. **Dqlite g√®re automatiquement** la r√©plication et l'√©lection
6. **Tester r√©guli√®rement** la r√©silience (pannes simul√©es)
7. **Maintenance** : drainer avant, uncordon apr√®s
8. **Monitoring** : Prometheus + Grafana recommand√©
9. **Backups** : m√™me avec HA, toujours sauvegarder
10. **Documentation** : maintenir un inventaire √† jour

## Prochaines √âtapes

Votre cluster HA est maintenant op√©rationnel ! Les prochains chapitres couvriront :

- **21.5** : Ajouter des workers suppl√©mentaires pour scaler
- **21.6** : Load balancing entre n≈ìuds avec MetalLB
- **21.7** : Stockage distribu√© pour la HA des donn√©es
- **21.8** : Backup du control plane et strat√©gies DR
- **21.9** : Strat√©gies de redondance avanc√©es
- **21.10** : Tests de failover complets

F√©licitations ! Vous avez construit un cluster Kubernetes en haute disponibilit√©. Vous √™tes maintenant capable de g√©rer une infrastructure r√©siliente et pr√™te pour la production ! üöÄ

---

**Bravo !** Vous ma√Ætrisez maintenant la configuration d'un cluster MicroK8s HA complet. C'est une comp√©tence avanc√©e et tr√®s recherch√©e dans le monde DevOps et Cloud Native !

‚è≠Ô∏è [Ajout de worker nodes suppl√©mentaires](/21-multi-node-et-haute-disponibilite/05-ajout-de-worker-nodes-supplementaires.md)
